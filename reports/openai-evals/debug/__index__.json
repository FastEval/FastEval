{
    "belarusian-lexicon.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "belarusian-lexicon.dev.v0",
            "base_eval": "belarusian-lexicon",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "belarusian_lexicon/samples.jsonl"
                    },
                    "key": "belarusian-lexicon.dev.v0",
                    "group": "belarusian-lexicon"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180905BZVSOJOO",
            "created_at": "2023-07-21 18:09:05.776021"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "bitwise.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "bitwise.dev.v0",
            "base_eval": "bitwise",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "bitwise/samples.jsonl"
                    },
                    "key": "bitwise.dev.v0",
                    "group": "bitwise"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180905B2ST64MO",
            "created_at": "2023-07-21 18:09:05.779088"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "algebra-word-problems.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "algebra-word-problems.s1.simple-v0",
            "base_eval": "algebra-word-problems",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "algebra_word_problems/samples.jsonl"
                    },
                    "key": "algebra-word-problems.s1.simple-v0",
                    "group": "algebra-word-problems"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180905BSDIUCRB",
            "created_at": "2023-07-21 18:09:05.773211"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "aime_evaluation.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "aime_evaluation.dev.v0",
            "base_eval": "aime_evaluation",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "aime_evaluation/samples.jsonl"
                    },
                    "key": "aime_evaluation.dev.v0",
                    "group": "aime_evaluation"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809053JXONNYT",
            "created_at": "2023-07-21 18:09:05.774382"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "born-first.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "born-first.dev.v0",
            "base_eval": "born-first",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "born_first/born_first.jsonl"
                    },
                    "key": "born-first.dev.v0",
                    "group": "born-first"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180905P64NYNXZ",
            "created_at": "2023-07-21 18:09:05.861701"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "chess-piece-count.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "chess-piece-count.s1.simple-v0",
            "base_eval": "chess-piece-count",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "chess_piece_count/fuzzy_match.jsonl"
                    },
                    "key": "chess-piece-count.s1.simple-v0",
                    "group": "chess-piece-count"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180905WLZTO3RI",
            "created_at": "2023-07-21 18:09:05.886615"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "bulgarian-lexicon.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "bulgarian-lexicon.dev.v0",
            "base_eval": "bulgarian-lexicon",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "bulgarian-lexicon/samples.jsonl"
                    },
                    "key": "bulgarian-lexicon.dev.v0",
                    "group": "bulgarian-lexicon"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180905AH5THOBW",
            "created_at": "2023-07-21 18:09:05.885320"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "chess.match.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "chess.match.dev.v0",
            "base_eval": "chess",
            "split": "match",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "chess/match.jsonl"
                    },
                    "key": "chess.match.dev.v0",
                    "group": "chess"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180906XM2BGSAS",
            "created_at": "2023-07-21 18:09:06.236209"
        },
        "final_report": {
            "accuracy": 0.26785714285714285,
            "f1_score": 0.0
        }
    },
    "brazilian-lexicon.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "brazilian-lexicon.dev.v0",
            "base_eval": "brazilian-lexicon",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "brazilian-lexicon/samples.jsonl"
                    },
                    "key": "brazilian-lexicon.dev.v0",
                    "group": "brazilian-lexicon"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180905YOGUOOYJ",
            "created_at": "2023-07-21 18:09:05.863304"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "compare-countries-area.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "compare-countries-area.dev.v0",
            "base_eval": "compare-countries-area",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "compare-countries-area/samples.jsonl"
                    },
                    "key": "compare-countries-area.dev.v0",
                    "group": "compare-countries-area"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180906S7GUGLB4",
            "created_at": "2023-07-21 18:09:06.281007"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "convert-hex-hsl-lightness.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "convert-hex-hsl-lightness.dev.v0",
            "base_eval": "convert-hex-hsl-lightness",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "convert-hex-hsl-lightness/samples.jsonl"
                    },
                    "key": "convert-hex-hsl-lightness.dev.v0",
                    "group": "convert-hex-hsl-lightness"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180906Z4CPYEGA",
            "created_at": "2023-07-21 18:09:06.316769"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "emoji-riddle.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "emoji-riddle.s1.simple-v0",
            "base_eval": "emoji-riddle",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "emoji_riddle/fuzzy_match.jsonl"
                    },
                    "key": "emoji-riddle.s1.simple-v0",
                    "group": "emoji-riddle"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180906SBW6DLX3",
            "created_at": "2023-07-21 18:09:06.435066"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "dice-rotation-sequence.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "dice-rotation-sequence.dev.v0",
            "base_eval": "dice-rotation-sequence",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "dice-rotation-sequence/samples.jsonl"
                    },
                    "key": "dice-rotation-sequence.dev.v0",
                    "group": "dice-rotation-sequence"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "23072118090627QITNBK",
            "created_at": "2023-07-21 18:09:06.427240"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "dutch-lexicon.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "dutch-lexicon.dev.v0",
            "base_eval": "dutch-lexicon",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "dutch-lexicon/samples.jsonl"
                    },
                    "key": "dutch-lexicon.dev.v0",
                    "group": "dutch-lexicon"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809065NY7TC6Q",
            "created_at": "2023-07-21 18:09:06.433279"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "emotional-intelligence.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "emotional-intelligence.dev.v0",
            "base_eval": "emotional-intelligence",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "emotional-intelligence/samples.jsonl"
                    },
                    "key": "emotional-intelligence.dev.v0",
                    "group": "emotional-intelligence"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180906PBEER4RN",
            "created_at": "2023-07-21 18:09:06.479510"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "fcc_amateur_extra.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "fcc_amateur_extra.dev.v0",
            "base_eval": "fcc_amateur_extra",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "fcc_amateur_extra/samples.jsonl"
                    },
                    "key": "fcc_amateur_extra.dev.v0",
                    "group": "fcc_amateur_extra"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180906COMMGWQW",
            "created_at": "2023-07-21 18:09:06.562433"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "forth-stack-sim.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "forth-stack-sim.dev.v0",
            "base_eval": "forth-stack-sim",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "forth_stack_sim/samples.jsonl"
                    },
                    "key": "forth-stack-sim.dev.v0",
                    "group": "forth-stack-sim"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180906NFKBILJE",
            "created_at": "2023-07-21 18:09:06.568031"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "forth-stack-sim-basic.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "forth-stack-sim-basic.dev.v0",
            "base_eval": "forth-stack-sim-basic",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "forth_stack_sim/basic_samples.jsonl"
                    },
                    "key": "forth-stack-sim-basic.dev.v0",
                    "group": "forth-stack-sim"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180906OCB2WJAI",
            "created_at": "2023-07-21 18:09:06.680216"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "forth-stack-sim-detailed.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "forth-stack-sim-detailed.dev.v0",
            "base_eval": "forth-stack-sim-detailed",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "forth_stack_sim/detailed_samples.jsonl"
                    },
                    "key": "forth-stack-sim-detailed.dev.v0",
                    "group": "forth-stack-sim"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180907XQTXXTAX",
            "created_at": "2023-07-21 18:09:07.034770"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "heart-disease.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "heart-disease.v0",
            "base_eval": "heart-disease",
            "split": "v0",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "heart-disease/samples.jsonl"
                    },
                    "key": "heart-disease.v0",
                    "group": "heart-disease"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180907B4Q2Q4BO",
            "created_at": "2023-07-21 18:09:07.093871"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "infiniteloop-match.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "infiniteloop-match.s1.simple-v0",
            "base_eval": "infiniteloop-match",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "infiniteloop-match/infiniteloop-match.jsonl"
                    },
                    "key": "infiniteloop-match.s1.simple-v0",
                    "group": "infiniteloop-match"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180907K7C5SZO7",
            "created_at": "2023-07-21 18:09:07.255346"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "invoices.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "invoices.dev.v0",
            "base_eval": "invoices",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "invoices/match.jsonl"
                    },
                    "key": "invoices.dev.v0",
                    "group": "invoices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809077VPBGPUD",
            "created_at": "2023-07-21 18:09:07.604636"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "hebrew-rhyme.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "hebrew-rhyme.v0",
            "base_eval": "hebrew-rhyme",
            "split": "v0",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "hebrew_rhyme/samples.jsonl"
                    },
                    "key": "hebrew-rhyme.v0",
                    "group": "hebrew-rhyme"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180907LBDN3TPI",
            "created_at": "2023-07-21 18:09:07.253305"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "japanese_driving_license.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "japanese_driving_license.s1.simple-v0",
            "base_eval": "japanese_driving_license",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "japanese_driving_license/samples.jsonl"
                    },
                    "key": "japanese_driving_license.s1.simple-v0",
                    "group": "japanese_driving_license"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180907EA3YHBOM",
            "created_at": "2023-07-21 18:09:07.812596"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "job_listing_title_for_a_caregiver_in_japan.test.v1.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "job_listing_title_for_a_caregiver_in_japan.test.v1",
            "base_eval": "job_listing_title_for_a_caregiver_in_japan",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "job_listing_title_for_a_caregiver_in_japan/samples.jsonl"
                    },
                    "key": "job_listing_title_for_a_caregiver_in_japan.test.v1",
                    "group": "job_listing_title_for_a_caregiver_in_japan"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809077REYPTJR",
            "created_at": "2023-07-21 18:09:07.908173"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "number-reading.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "number-reading.dev.v0",
            "base_eval": "number-reading",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "number_reading/number_reading.jsonl"
                    },
                    "key": "number-reading.dev.v0",
                    "group": "number-reading"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180908QQDVY7GU",
            "created_at": "2023-07-21 18:09:08.136835"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "moral_exceptQA.test.v1.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "moral_exceptQA.test.v1",
            "base_eval": "moral_exceptQA",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "moral_exceptQA/samples.jsonl"
                    },
                    "key": "moral_exceptQA.test.v1",
                    "group": "moral_exceptQA"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809086L7LSIAN",
            "created_at": "2023-07-21 18:09:08.034504"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "last-word-nth.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "last-word-nth.s1.simple-v0",
            "base_eval": "last-word-nth",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "last_word_nth/samples.jsonl"
                    },
                    "key": "last-word-nth.s1.simple-v0",
                    "group": "last-word-nth"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180907ACNDGW2B",
            "created_at": "2023-07-21 18:09:07.947064"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "rucola.test.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "rucola.test.v0",
            "base_eval": "rucola",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "rucola/samples.jsonl",
                        "few_shot_jsonl": "rucola/few_shot.jsonl",
                        "num_few_shot": 4
                    },
                    "key": "rucola.test.v0",
                    "group": "rucola"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180908G57TXB7T",
            "created_at": "2023-07-21 18:09:08.691461"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "ph-calculation.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ph-calculation.dev.v0",
            "base_eval": "ph-calculation",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "ph_calculation/samples.jsonl"
                    },
                    "key": "ph-calculation.dev.v0",
                    "group": "ph_calculation"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180908YSXDHA27",
            "created_at": "2023-07-21 18:09:08.689202"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "russian-rhyme.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "russian-rhyme.v0",
            "base_eval": "russian-rhyme",
            "split": "v0",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "russian-rhyme/samples.jsonl"
                    },
                    "key": "russian-rhyme.v0",
                    "group": "russian-rhyme"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180908UPRZACES",
            "created_at": "2023-07-21 18:09:08.971710"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "russe.test.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "russe.test.v0",
            "base_eval": "russe",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "russe/samples.jsonl",
                        "few_shot_jsonl": "russe/few_shot.jsonl",
                        "num_few_shot": 2
                    },
                    "key": "russe.test.v0",
                    "group": "russe"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809084V6AAJMQ",
            "created_at": "2023-07-21 18:09:08.912394"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "sort-numbers.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "sort-numbers.s1.simple-v0",
            "base_eval": "sort-numbers",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "sort_numeric/samples.jsonl"
                    },
                    "key": "sort-numbers.s1.simple-v0",
                    "group": "sort-numeric"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180909IHLUAXRJ",
            "created_at": "2023-07-21 18:09:09.846640"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "sarcasm.test.v1.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "sarcasm.test.v1",
            "base_eval": "sarcasm",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "sarcasm/samples.jsonl",
                        "few_shot_jsonl": "sarcasm/few_shot.jsonl",
                        "num_few_shot": 5
                    },
                    "key": "sarcasm.test.v1",
                    "group": "sarcasm"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180908NENXI7WF",
            "created_at": "2023-07-21 18:09:08.970020"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "simple-knowledge-mongolian.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "simple-knowledge-mongolian.dev.v0",
            "base_eval": "simple-knowledge-mongolian",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "simple-knowledge-mongolian/samples.v0.jsonl"
                    },
                    "key": "simple-knowledge-mongolian.dev.v0",
                    "group": "simple-knowledge-mongolian"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180909PJA3FFZE",
            "created_at": "2023-07-21 18:09:09.845150"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "stock-options-bear-call-spread.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "stock-options-bear-call-spread.dev.v0",
            "base_eval": "stock-options-bear-call-spread",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "stock_options/stock_options_bear_call_spread.jsonl"
                    },
                    "key": "stock-options-bear-call-spread.dev.v0",
                    "group": "stock-options"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180909DFN5ENJK",
            "created_at": "2023-07-21 18:09:09.953776"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "stock-option-terms-bear-call-spread.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "stock-option-terms-bear-call-spread.dev.v0",
            "base_eval": "stock-option-terms-bear-call-spread",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "stock_options/stock_option_terms_bear_call_spread.jsonl"
                    },
                    "key": "stock-option-terms-bear-call-spread.dev.v0",
                    "group": "stock-options"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180909IBTGJCMY",
            "created_at": "2023-07-21 18:09:09.958357"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "formal-logic.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "formal-logic.dev.v0",
            "base_eval": "formal-logic",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "formal_logic/formal_logic_expressions.jsonl"
                    },
                    "key": "formal-logic.dev.v0",
                    "group": "formal_logic"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180906VXORQNOU",
            "created_at": "2023-07-21 18:09:06.566307"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "stock-option-terms-bull-call-spread.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "stock-option-terms-bull-call-spread.dev.v0",
            "base_eval": "stock-option-terms-bull-call-spread",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "stock_options/stock_option_terms_bull_call_spread.jsonl"
                    },
                    "key": "stock-option-terms-bull-call-spread.dev.v0",
                    "group": "stock-options"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180910NNC4RJCO",
            "created_at": "2023-07-21 18:09:10.045362"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "stock-option-terms-iron-condor-spread.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "stock-option-terms-iron-condor-spread.dev.v0",
            "base_eval": "stock-option-terms-iron-condor-spread",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "stock_options/stock_option_terms_iron_condor_spread.jsonl"
                    },
                    "key": "stock-option-terms-iron-condor-spread.dev.v0",
                    "group": "stock-options"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809107ABDIFZ3",
            "created_at": "2023-07-21 18:09:10.164299"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "stock-option-terms-inverse-iron-condor-spread.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "stock-option-terms-inverse-iron-condor-spread.dev.v0",
            "base_eval": "stock-option-terms-inverse-iron-condor-spread",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "stock_options/stock_option_terms_inverse_iron_condor_spread.jsonl"
                    },
                    "key": "stock-option-terms-inverse-iron-condor-spread.dev.v0",
                    "group": "stock-options"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180910JEMVSEWE",
            "created_at": "2023-07-21 18:09:10.192519"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "stock-option-terms-iron-butterfly-spread.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "stock-option-terms-iron-butterfly-spread.dev.v0",
            "base_eval": "stock-option-terms-iron-butterfly-spread",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "stock_options/stock_option_terms_iron_butterfly_spread.jsonl"
                    },
                    "key": "stock-option-terms-iron-butterfly-spread.dev.v0",
                    "group": "stock-options"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180910JIY3XHRW",
            "created_at": "2023-07-21 18:09:10.146333"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "swedish-spelling.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "swedish-spelling.dev.v0",
            "base_eval": "swedish-spelling",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "swedish-spelling/samples.jsonl"
                    },
                    "key": "swedish-spelling.dev.v0",
                    "group": "swedish-spelling"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180910AY5P5PCM",
            "created_at": "2023-07-21 18:09:10.271963"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "tempo_to_measure_count.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "tempo_to_measure_count.dev.v0",
            "base_eval": "tempo_to_measure_count",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "tempo_to_measure_count/samples.jsonl"
                    },
                    "key": "tempo_to_measure_count.dev.v0",
                    "group": "tempo_to_measure_count"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180910RV3X4HZ5",
            "created_at": "2023-07-21 18:09:10.294424"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "computer-science-problems.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "computer-science-problems.s1.simple-v0",
            "base_eval": "computer-science-problems",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "test_comp_sci/questions.jsonl"
                    },
                    "key": "computer-science-problems.s1.simple-v0",
                    "group": "test-comp-sci"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809105XTW3SFW",
            "created_at": "2023-07-21 18:09:10.302895"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "three-pt-mapping.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "three-pt-mapping.dev.v0",
            "base_eval": "three-pt-mapping",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "three-pt-mapping/three_pt_mapping.jsonl"
                    },
                    "key": "three-pt-mapping.dev.v0",
                    "group": "three-pt-mapping"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180910LXQTQPEO",
            "created_at": "2023-07-21 18:09:10.336649"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "which-is-heavier.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "which-is-heavier.dev.v0",
            "base_eval": "which-is-heavier",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "which_is_heavier/which_is_heavier.jsonl"
                    },
                    "key": "which-is-heavier.dev.v0",
                    "group": "which-is-heavier"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180910TKZFG35K",
            "created_at": "2023-07-21 18:09:10.384618"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "2d_movement.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "2d_movement.dev.v0",
            "base_eval": "2d_movement",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "2d_movement/samples.jsonl"
                    },
                    "key": "2d_movement.dev.v0",
                    "group": "2d_movement"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180910IVW5YRSR",
            "created_at": "2023-07-21 18:09:10.479725"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "3d_globe_movement.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "3d_globe_movement.dev.v0",
            "base_eval": "3d_globe_movement",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "3d_globe_movement/samples.jsonl"
                    },
                    "key": "3d_globe_movement.dev.v0",
                    "group": "3d_globe_movement"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180910TZCAI7J6",
            "created_at": "2023-07-21 18:09:10.504967"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "Chinese_character_riddles.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "Chinese_character_riddles.dev.v0",
            "base_eval": "Chinese_character_riddles",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "Chinese_character_riddles/samples.jsonl"
                    },
                    "key": "Chinese_character_riddles.dev.v0",
                    "group": "Chinese_character_riddles"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809102HGU2E6C",
            "created_at": "2023-07-21 18:09:10.563549"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "3d_object_manipulation.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "3d_object_manipulation.dev.v0",
            "base_eval": "3d_object_manipulation",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "3d_object_manipulation/samples.jsonl"
                    },
                    "key": "3d_object_manipulation.dev.v0",
                    "group": "3d_object_manipulation"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180910WE35LWOV",
            "created_at": "2023-07-21 18:09:10.548078"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "abstract-causal-reasoning-text.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "abstract-causal-reasoning-text.dev.v0",
            "base_eval": "abstract-causal-reasoning-text",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "abstract-causal-reasoning/text_samples.jsonl"
                    },
                    "key": "abstract-causal-reasoning-text.dev.v0",
                    "group": "abstract-causal-reasoning"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809104KNPKQPP",
            "created_at": "2023-07-21 18:09:10.625895"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "GPT-model-text-detection.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "GPT-model-text-detection.dev.v0",
            "base_eval": "GPT-model-text-detection",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "GPT-model-text-detection/samples.jsonl"
                    },
                    "key": "GPT-model-text-detection.dev.v0",
                    "group": "GPT-model-text-detection"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180910IHIUJ4US",
            "created_at": "2023-07-21 18:09:10.602309"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "us-tort-law.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "us-tort-law.dev.v0",
            "base_eval": "us-tort-law",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "few_shot_jsonl": "us_tort_law/few_shot.jsonl",
                        "num_few_shot": 4,
                        "samples_jsonl": "us_tort_law/samples.jsonl"
                    },
                    "key": "us-tort-law.dev.v0",
                    "group": "us-tort-law"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180910DG3PX6MP",
            "created_at": "2023-07-21 18:09:10.346581"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "abstract-causal-reasoning-symbolic.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "abstract-causal-reasoning-symbolic.dev.v0",
            "base_eval": "abstract-causal-reasoning-symbolic",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "abstract-causal-reasoning/symbolic_samples.jsonl"
                    },
                    "key": "abstract-causal-reasoning-symbolic.dev.v0",
                    "group": "abstract-causal-reasoning"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "23072118091063RYQUGH",
            "created_at": "2023-07-21 18:09:10.726322"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "adultery_state_laws.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "adultery_state_laws.dev.v0",
            "base_eval": "adultery_state_laws",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "adultery-state-laws/samples.jsonl"
                    },
                    "key": "adultery_state_laws.dev.v0",
                    "group": "adultery_state_laws"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180910QFHBHN3T",
            "created_at": "2023-07-21 18:09:10.908206"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "afrikaans-lexicon.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "afrikaans-lexicon.dev.v0",
            "base_eval": "afrikaans-lexicon",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "afrikaans-lexicon/samples.jsonl"
                    },
                    "key": "afrikaans-lexicon.dev.v0",
                    "group": "afrikaans-lexicon"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180910MBZ76ZJC",
            "created_at": "2023-07-21 18:09:10.944957"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "ambiguous-sentences.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ambiguous-sentences.dev.v0",
            "base_eval": "ambiguous-sentences",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "ambiguous-sentences/samples.jsonl"
                    },
                    "key": "ambiguous-sentences.dev.v0",
                    "group": "ambiguous-sentences"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911AB6CCHES",
            "created_at": "2023-07-21 18:09:11.032526"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "alternate_numeral_systems.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "alternate_numeral_systems.dev.v0",
            "base_eval": "alternate_numeral_systems",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "alternate_numeral_systems/samples.jsonl"
                    },
                    "key": "alternate_numeral_systems.dev.v0",
                    "group": "alternate-numeral-systems"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "23072118091146BQJ7CZ",
            "created_at": "2023-07-21 18:09:11.024331"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "arithmetical_puzzles.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "arithmetical_puzzles.dev.v0",
            "base_eval": "arithmetical_puzzles",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "arithmetical_puzzles/arithmetical_puzzles.jsonl"
                    },
                    "key": "arithmetical_puzzles.dev.v0",
                    "group": "arithmetical_puzzles"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911JRMUBHU4",
            "created_at": "2023-07-21 18:09:11.090629"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "ascii-digit-recognition.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ascii-digit-recognition.dev.v0",
            "base_eval": "ascii-digit-recognition",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "ascii-digit-recognition/samples.jsonl"
                    },
                    "key": "ascii-digit-recognition.dev.v0",
                    "group": "ascii-digit-recognition"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911NRDH7HNP",
            "created_at": "2023-07-21 18:09:11.132623"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "ascii-wordart.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ascii-wordart.dev.v0",
            "base_eval": "ascii-wordart",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "ascii_wordart/ascii_wordart.jsonl"
                    },
                    "key": "ascii-wordart.dev.v0",
                    "group": "ascii-wordart"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911WAQ4ZBTY",
            "created_at": "2023-07-21 18:09:11.173065"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "asl-classifiers.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "asl-classifiers.dev.v0",
            "base_eval": "asl-classifiers",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "asl-classifiers/samples.jsonl"
                    },
                    "key": "asl-classifiers.dev.v0",
                    "group": "asl-classifiers"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911GQSD3QHT",
            "created_at": "2023-07-21 18:09:11.203978"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "astro_eval.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "astro_eval.dev.v0",
            "base_eval": "astro_eval",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "astro_eval/samples.jsonl"
                    },
                    "key": "astro_eval.dev.v0",
                    "group": "astro_eval"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911ZCUSUXJ6",
            "created_at": "2023-07-21 18:09:11.226081"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "automata-and-complexity.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "automata-and-complexity.dev.v0",
            "base_eval": "automata-and-complexity",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "automata-and-complexity/samples.jsonl"
                    },
                    "key": "automata-and-complexity.dev.v0",
                    "group": "automata-and-complexity"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911EZDUPIR6",
            "created_at": "2023-07-21 18:09:11.244071"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "backgammon-can-hit.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "backgammon-can-hit.dev.v0",
            "base_eval": "backgammon-can-hit",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "backgammon/backgammon-can-hit.jsonl"
                    },
                    "key": "backgammon-can-hit.dev.v0",
                    "group": "backgammon"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911VQXGHPEI",
            "created_at": "2023-07-21 18:09:11.273398"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "base64-decode-simple.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "base64-decode-simple.dev.v0",
            "base_eval": "base64-decode-simple",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "base64_decode/base64_decode.jsonl"
                    },
                    "key": "base64-decode-simple.dev.v0",
                    "group": "base64-decode"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911E7I7L5LT",
            "created_at": "2023-07-21 18:09:11.329176"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "beam.analysis.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "beam.analysis.dev.v0",
            "base_eval": "beam",
            "split": "analysis",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "beam_analysis/beam-analysis.jsonl"
                    },
                    "key": "beam.analysis.dev.v0",
                    "group": "beam-analysis"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911FH4PZQIU",
            "created_at": "2023-07-21 18:09:11.395109"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "belarusian-grammar.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "belarusian-grammar.dev.v0",
            "base_eval": "belarusian-grammar",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "belarusian_grammar/samples.jsonl"
                    },
                    "key": "belarusian-grammar.dev.v0",
                    "group": "belarusian-grammar"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911EIVVLL3H",
            "created_at": "2023-07-21 18:09:11.414909"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "belarusian-numerals.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "belarusian-numerals.dev.v0",
            "base_eval": "belarusian-numerals",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "belarusian_numerals/samples.jsonl"
                    },
                    "key": "belarusian-numerals.dev.v0",
                    "group": "belarusian-numerals"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911GILRDCLA",
            "created_at": "2023-07-21 18:09:11.457723"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "belarusian-orthography.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "belarusian-orthography.dev.v0",
            "base_eval": "belarusian-orthography",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "belarusian_orthography/samples.jsonl"
                    },
                    "key": "belarusian-orthography.dev.v0",
                    "group": "belarusian-orthography"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911ROQ37R7R",
            "created_at": "2023-07-21 18:09:11.485680"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "belarusian-proverbs.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "belarusian-proverbs.dev.v0",
            "base_eval": "belarusian-proverbs",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "belarusian_proverbs/samples.jsonl"
                    },
                    "key": "belarusian-proverbs.dev.v0",
                    "group": "belarusian-proverbs"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911CZZSJBVK",
            "created_at": "2023-07-21 18:09:11.506556"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "belarusian-rhyme.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "belarusian-rhyme.dev.v0",
            "base_eval": "belarusian-rhyme",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "belarusian_rhyme/samples.jsonl"
                    },
                    "key": "belarusian-rhyme.dev.v0",
                    "group": "belarusian-rhyme"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809115ALQL6LY",
            "created_at": "2023-07-21 18:09:11.528301"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "belarusian-russian-translation.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "belarusian-russian-translation.dev.v0",
            "base_eval": "belarusian-russian-translation",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "belarusian_russian_translation/samples.jsonl"
                    },
                    "key": "belarusian-russian-translation.dev.v0",
                    "group": "belarusian-russian-translation"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911PE4R2LR6",
            "created_at": "2023-07-21 18:09:11.540462"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "belarusian-syllable-count.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "belarusian-syllable-count.dev.v0",
            "base_eval": "belarusian-syllable-count",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "belarusian_syllable_count/samples.jsonl"
                    },
                    "key": "belarusian-syllable-count.dev.v0",
                    "group": "belarusian-syllable-count"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911YURAQ2OQ",
            "created_at": "2023-07-21 18:09:11.559301"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "belarusian-synonyms.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "belarusian-synonyms.dev.v0",
            "base_eval": "belarusian-synonyms",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "belarusian_synonyms/samples.jsonl"
                    },
                    "key": "belarusian-synonyms.dev.v0",
                    "group": "belarusian-synonyms"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911RHXWLYZJ",
            "created_at": "2023-07-21 18:09:11.579665"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "belarusian-word-analogy-inflection.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "belarusian-word-analogy-inflection.dev.v0",
            "base_eval": "belarusian-word-analogy-inflection",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "belarusian_word_analogy_inflection/samples.jsonl"
                    },
                    "key": "belarusian-word-analogy-inflection.dev.v0",
                    "group": "belarusian-word-analogy-inflection"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911DO2MHZEY",
            "created_at": "2023-07-21 18:09:11.605436"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "bias_detection.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "bias_detection.dev.v0",
            "base_eval": "bias_detection",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "bias_detection/samples.jsonl",
                        "ignore_case": true
                    },
                    "key": "bias_detection.dev.v0",
                    "group": "bias_detection"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809115GFFTP77",
            "created_at": "2023-07-21 18:09:11.625175"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "blackfoot-numerals-modern.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "blackfoot-numerals-modern.dev.v0",
            "base_eval": "blackfoot-numerals-modern",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "blackfoot-numerals-modern/samples.jsonl"
                    },
                    "key": "blackfoot-numerals-modern.dev.v0",
                    "group": "blackfoot-numerals-modern"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911B25SPFOG",
            "created_at": "2023-07-21 18:09:11.644430"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "body-movement.dev.zero_shot_v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "body-movement.dev.zero_shot_v0",
            "base_eval": "body-movement",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "body_movement/body_movement.jsonl"
                    },
                    "key": "body-movement.dev.zero_shot_v0",
                    "group": "body-movement"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "23072118091157PEWN3Z",
            "created_at": "2023-07-21 18:09:11.665111"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "canto_wu_pronunciation.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "canto_wu_pronunciation.dev.v0",
            "base_eval": "canto_wu_pronunciation",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "canto_wu_pronunciation/samples_zero.jsonl"
                    },
                    "key": "canto_wu_pronunciation.dev.v0",
                    "group": "canto_wu_pronunciation"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809115YME3FU2",
            "created_at": "2023-07-21 18:09:11.686536"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "canto_wu_pronunciation_fewshot.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "canto_wu_pronunciation_fewshot.dev.v0",
            "base_eval": "canto_wu_pronunciation_fewshot",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "canto_wu_pronunciation/samples_few.jsonl"
                    },
                    "key": "canto_wu_pronunciation_fewshot.dev.v0",
                    "group": "canto_wu_pronunciation_fewshot"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911M6H5DXZ6",
            "created_at": "2023-07-21 18:09:11.711951"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "chinese-lantern-riddles.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "chinese-lantern-riddles.dev.v0",
            "base_eval": "chinese-lantern-riddles",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "chinese-lantern-riddles/samples.jsonl"
                    },
                    "key": "chinese-lantern-riddles.dev.v0",
                    "group": "chinese-lantern-riddles"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911GOBYW7AS",
            "created_at": "2023-07-21 18:09:11.741918"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "chinese_chu_ci.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "chinese_chu_ci.dev.v0",
            "base_eval": "chinese_chu_ci",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "chinese_chu_ci/samples.jsonl"
                    },
                    "key": "chinese_chu_ci.dev.v0",
                    "group": "chinese_chu_ci"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911PA5TZYVZ",
            "created_at": "2023-07-21 18:09:11.836456"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "chinese-remainder-theorem.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "chinese-remainder-theorem.dev.v0",
            "base_eval": "chinese-remainder-theorem",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "chinese-remainder-theorem/samples.jsonl"
                    },
                    "key": "chinese-remainder-theorem.dev.v0",
                    "group": "chinese-remainder-theorem"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911OVDLLMG7",
            "created_at": "2023-07-21 18:09:11.766794"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "chinese_ancient_masterpieces_dynasty.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "chinese_ancient_masterpieces_dynasty.dev.v0",
            "base_eval": "chinese_ancient_masterpieces_dynasty",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "chinese_ancient_masterpieces_dynasty/samples.jsonl"
                    },
                    "key": "chinese_ancient_masterpieces_dynasty.dev.v0",
                    "group": "chinese_ancient_masterpieces_dynasty"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911UFOKAZPS",
            "created_at": "2023-07-21 18:09:11.797114"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "chinese_ancient_poetry.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "chinese_ancient_poetry.dev.v0",
            "base_eval": "chinese_ancient_poetry",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "chinese_ancient_poetry/samples.jsonl"
                    },
                    "key": "chinese_ancient_poetry.dev.v0",
                    "group": "chinese_ancient_poetry"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911TPTY2JMP",
            "created_at": "2023-07-21 18:09:11.816044"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "chinese_famous_novel.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "chinese_famous_novel.dev.v0",
            "base_eval": "chinese_famous_novel",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "chinese_famous_novel/samples.jsonl"
                    },
                    "key": "chinese_famous_novel.dev.v0",
                    "group": "chinese_famous_novel"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809113MXQYNUV",
            "created_at": "2023-07-21 18:09:11.856052"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "chinese_homonym.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "chinese_homonym.dev.v0",
            "base_eval": "chinese_homonym",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "chinese_homonym/samples.jsonl"
                    },
                    "key": "chinese_homonym.dev.v0",
                    "group": "chinese_homonym"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911BJCIXSC3",
            "created_at": "2023-07-21 18:09:11.884350"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "chinese_tang_poetries.dev.match-v1.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "chinese_tang_poetries.dev.match-v1",
            "base_eval": "chinese_tang_poetries",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "chinese_tang_poetries/sample.jsonl"
                    },
                    "key": "chinese_tang_poetries.dev.match-v1",
                    "group": "chinese_tang_poetries"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911XNMWF2K5",
            "created_at": "2023-07-21 18:09:11.904075"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "spider-sql.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug",
                "openai:gpt-3.5-turbo-16k-0613"
            ],
            "eval_name": "spider-sql.dev.v0",
            "base_eval": "spider-sql",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug",
                    "openai:gpt-3.5-turbo-16k-0613"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "sql/spider_sql.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "sql"
                    },
                    "key": "spider-sql.dev.v0",
                    "group": "sql"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180909FGJCF2CJ",
            "created_at": "2023-07-21 18:09:09.904637"
        },
        "final_report": {
            "counts/Incorrect": 2,
            "score": 0.0
        }
    },
    "code_combination.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "code_combination.dev.v0",
            "base_eval": "code_combination",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "code_combination/samples.jsonl"
                    },
                    "key": "code_combination.dev.v0",
                    "group": "code_combination"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180912N24Z52I3",
            "created_at": "2023-07-21 18:09:12.101279"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "code_progress.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "code_progress.dev.v0",
            "base_eval": "code_progress",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "code_progress/samples.jsonl"
                    },
                    "key": "code_progress.dev.v0",
                    "group": "code_progress"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180912LL5BOCW7",
            "created_at": "2023-07-21 18:09:12.134263"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "color_theory_complementary.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "color_theory_complementary.dev.v0",
            "base_eval": "color_theory_complementary",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "color_theory/complementary.jsonl"
                    },
                    "key": "color_theory_complementary.dev.v0",
                    "group": "color_theory_complementary"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180912FGAJBSDC",
            "created_at": "2023-07-21 18:09:12.161217"
        },
        "final_report": {
            "accuracy": 1.0,
            "f1_score": 0.0
        }
    },
    "comprehensive-graph-reasoning.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "comprehensive-graph-reasoning.dev.v0",
            "base_eval": "comprehensive-graph-reasoning",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "comprehensive-graph-reasoning/samples.jsonl"
                    },
                    "key": "comprehensive-graph-reasoning.dev.v0",
                    "group": "comprehensive-graph-reasoning"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180912YIFT3KJQ",
            "created_at": "2023-07-21 18:09:12.176759"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "confusing_korean.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "confusing_korean.dev.v0",
            "base_eval": "confusing_korean",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "confusing_korean/samples.jsonl"
                    },
                    "key": "confusing_korean.dev.v0",
                    "group": "confusing_korean"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180912F3XSNBSP",
            "created_at": "2023-07-21 18:09:12.198814"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "context-free-grammar.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "context-free-grammar.dev.v0",
            "base_eval": "context-free-grammar",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "context-free-grammar/samples.jsonl"
                    },
                    "key": "context-free-grammar.dev.v0",
                    "group": "context-free-grammar"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809122XZEG5AV",
            "created_at": "2023-07-21 18:09:12.214867"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "convert_chinese_lower_case_num_to_num.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "convert_chinese_lower_case_num_to_num.dev.v0",
            "base_eval": "convert_chinese_lower_case_num_to_num",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "convert-bwt-num-and-chinese-num/c_lower_to_n_samples_few_shot.jsonl"
                    },
                    "key": "convert_chinese_lower_case_num_to_num.dev.v0",
                    "group": "convert_bwt_num_and_chinese_num"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180912TLO2YCLC",
            "created_at": "2023-07-21 18:09:12.228602"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "convert_num_to_chinese_lower_case_num.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "convert_num_to_chinese_lower_case_num.dev.v0",
            "base_eval": "convert_num_to_chinese_lower_case_num",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "convert-bwt-num-and-chinese-num/n_to_c_lower_samples_few_shot.jsonl"
                    },
                    "key": "convert_num_to_chinese_lower_case_num.dev.v0",
                    "group": "convert_bwt_num_and_chinese_num"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180912TEM5FVCB",
            "created_at": "2023-07-21 18:09:12.251256"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "convert_chinese_upper_case_num_to_num.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "convert_chinese_upper_case_num_to_num.dev.v0",
            "base_eval": "convert_chinese_upper_case_num_to_num",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "convert-bwt-num-and-chinese-num/c_upper_to_n_samples_few_shot.jsonl"
                    },
                    "key": "convert_chinese_upper_case_num_to_num.dev.v0",
                    "group": "convert_bwt_num_and_chinese_num"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180912WY6TAZMX",
            "created_at": "2023-07-21 18:09:12.273398"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "convert_num_to_chinese_upper_case_num.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "convert_num_to_chinese_upper_case_num.dev.v0",
            "base_eval": "convert_num_to_chinese_upper_case_num",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "convert-bwt-num-and-chinese-num/n_to_c_upper_samples_few_shot.jsonl"
                    },
                    "key": "convert_num_to_chinese_upper_case_num.dev.v0",
                    "group": "convert_bwt_num_and_chinese_num"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180912CWI3463A",
            "created_at": "2023-07-21 18:09:12.301480"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "co-sql.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug",
                "openai:gpt-3.5-turbo-16k-0613"
            ],
            "eval_name": "co-sql.dev.v0",
            "base_eval": "co-sql",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug",
                    "openai:gpt-3.5-turbo-16k-0613"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "sql/co_sql.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "sql"
                    },
                    "key": "co-sql.dev.v0",
                    "group": "co-sql"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180911XADRARCF",
            "created_at": "2023-07-21 18:09:11.925649"
        },
        "final_report": {
            "counts/Incorrect": 2,
            "score": 0.0
        }
    },
    "coq-proof-step-match.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "coq-proof-step-match.dev.v0",
            "base_eval": "coq-proof-step-match",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "coq-proof-step/match.jsonl"
                    },
                    "key": "coq-proof-step-match.dev.v0",
                    "group": "coq-proof-step"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180918M4SNJWAR",
            "created_at": "2023-07-21 18:09:18.686755"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "corr2cause.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "corr2cause.dev.v0",
            "base_eval": "corr2cause",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "corr2cause/corr2cause.jsonl"
                    },
                    "key": "corr2cause.dev.v0",
                    "group": "corr2cause"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180918EGIMPMMN",
            "created_at": "2023-07-21 18:09:18.718375"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "count_intersections_polynomial.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "count_intersections_polynomial.dev.v0",
            "base_eval": "count_intersections_polynomial",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "count_intersections_polynomial/samples.jsonl"
                    },
                    "key": "count_intersections_polynomial.dev.v0",
                    "group": "count_intersections_polynomial"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180918QHXWLYL6",
            "created_at": "2023-07-21 18:09:18.765567"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "count_token_freq_dna.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "count_token_freq_dna.dev.v0",
            "base_eval": "count_token_freq_dna",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "count_token_freq_dna/samples.jsonl"
                    },
                    "key": "count_token_freq_dna.dev.v0",
                    "group": "count_token_freq_dna"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809183QROWDMA",
            "created_at": "2023-07-21 18:09:18.815741"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "arithmetic-expression.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug",
                "openai:gpt-3.5-turbo-16k-0613"
            ],
            "eval_name": "arithmetic-expression.dev.v0",
            "base_eval": "arithmetic-expression",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug",
                    "openai:gpt-3.5-turbo-16k-0613"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "arithmetic-expression/samples.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "arithmetic-expression"
                    },
                    "key": "arithmetic-expression.dev.v0",
                    "group": "arithmetic-expression"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809116WCBX7F6",
            "created_at": "2023-07-21 18:09:11.067587"
        },
        "final_report": {
            "counts/N": 15,
            "score": 0.0
        }
    },
    "csharp-linq.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "csharp-linq.dev.v0",
            "base_eval": "csharp-linq",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "csharp-linq/questions.jsonl"
                    },
                    "key": "csharp-linq.dev.v0",
                    "group": "csharp-linq"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809182FCDI343",
            "created_at": "2023-07-21 18:09:18.900322"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "cricket_situations.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "cricket_situations.dev.v0",
            "base_eval": "cricket_situations",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "cricket_situations/samples.jsonl"
                    },
                    "key": "cricket_situations.dev.v0",
                    "group": "cricket_situations"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180918TICNCMW5",
            "created_at": "2023-07-21 18:09:18.890351"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "css-selectors-verbal.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "css-selectors-verbal.dev.v0",
            "base_eval": "css-selectors-verbal",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "css-selectors/verbal.jsonl"
                    },
                    "key": "css-selectors-verbal.dev.v0",
                    "group": "css-selectors"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180918EG6XOSWG",
            "created_at": "2023-07-21 18:09:18.923380"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "css-selectors-explain.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "css-selectors-explain.dev.v0",
            "base_eval": "css-selectors-explain",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "css-selectors/explain.jsonl"
                    },
                    "key": "css-selectors-explain.dev.v0",
                    "group": "css-selectors"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180918G6C2TRTI",
            "created_at": "2023-07-21 18:09:18.946168"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "cybersecurity-filepaths.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "cybersecurity-filepaths.dev.v0",
            "base_eval": "cybersecurity-filepaths",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "cybersecurity/filepaths.jsonl"
                    },
                    "key": "cybersecurity-filepaths.dev.v0",
                    "group": "cybersecurity-filepaths"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180918K2Z7KRFD",
            "created_at": "2023-07-21 18:09:18.961962"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "dhammapada-reference.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "dhammapada-reference.dev.v0",
            "base_eval": "dhammapada-reference",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "dhammapada-reference/samples.jsonl"
                    },
                    "key": "dhammapada-reference.dev.v0",
                    "group": "dhammapada-reference"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180918UR7DZMUF",
            "created_at": "2023-07-21 18:09:18.977213"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "directions.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "directions.dev.v0",
            "base_eval": "directions",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "directions/samples.jsonl"
                    },
                    "key": "directions.dev.v0",
                    "group": "directions"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919AWIKBIGB",
            "created_at": "2023-07-21 18:09:19.022584"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "dna-melting-calculation.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "dna-melting-calculation.dev.v0",
            "base_eval": "dna-melting-calculation",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "dna_melting_calculation/samples.jsonl"
                    },
                    "key": "dna-melting-calculation.dev.v0",
                    "group": "dna-melting-calculation"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919D2TP4GJG",
            "created_at": "2023-07-21 18:09:19.044081"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "dutch-rhymes.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "dutch-rhymes.dev.v0",
            "base_eval": "dutch-rhymes",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "dutch-rhymes/samples.jsonl"
                    },
                    "key": "dutch-rhymes.dev.v0",
                    "group": "dutch-rhymes"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "23072118091956H55IVP",
            "created_at": "2023-07-21 18:09:19.066783"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "european-date-format-challenge.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "european-date-format-challenge.dev.v0",
            "base_eval": "european-date-format-challenge",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "european_date_format_challenge/samples.jsonl"
                    },
                    "key": "european-date-format-challenge.dev.v0",
                    "group": "european-date-format-challenge"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919F2THEMGR",
            "created_at": "2023-07-21 18:09:19.086688"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "finance_calc.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "finance_calc.dev.v0",
            "base_eval": "finance_calc",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "finance_calc/samples.jsonl"
                    },
                    "key": "finance_calc.dev.v0",
                    "group": "finance_calc"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919BPRJGXNG",
            "created_at": "2023-07-21 18:09:19.099178"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "financial-derivatives.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "financial-derivatives.dev.v0",
            "base_eval": "financial-derivatives",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "financial-derivatives/questions.jsonl"
                    },
                    "key": "financial-derivatives.dev.v0",
                    "group": "financial-derivatives"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919TLQT34LQ",
            "created_at": "2023-07-21 18:09:19.107912"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "find-thirukkural.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "find-thirukkural.dev.v0",
            "base_eval": "find-thirukkural",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "find-thirukkural/samples.jsonl"
                    },
                    "key": "find-thirukkural.dev.v0",
                    "group": "find-thirukkural"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919LBQYIVKW",
            "created_at": "2023-07-21 18:09:19.170755"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "find_country_from_svg.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "find_country_from_svg.dev.v0",
            "base_eval": "find_country_from_svg",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "find_country_from_svg/samples.jsonl"
                    },
                    "key": "find_country_from_svg.dev.v0",
                    "group": "find_country_from_svg"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "23072118091923N3G2M5",
            "created_at": "2023-07-21 18:09:19.176280"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "finger-tracking.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "finger-tracking.dev.v0",
            "base_eval": "finger-tracking",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "finger-tracking/samples.jsonl"
                    },
                    "key": "finger-tracking.dev.v0",
                    "group": "finger-tracking"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919T5AWMXWS",
            "created_at": "2023-07-21 18:09:19.202333"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "finnish-rhyme.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "finnish-rhyme.dev.v0",
            "base_eval": "finnish-rhyme",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "finnish-rhyme/samples.jsonl"
                    },
                    "key": "finnish-rhyme.dev.v0",
                    "group": "finnish-rhyme"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809194RHF6XYE",
            "created_at": "2023-07-21 18:09:19.233343"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "french-lexicon.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "french-lexicon.dev.v0",
            "base_eval": "french-lexicon",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "french-lexicon/samples.jsonl"
                    },
                    "key": "french-lexicon.dev.v0",
                    "group": "french-lexicon"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809195ZYZVDH7",
            "created_at": "2023-07-21 18:09:19.263594"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "french-part-of-speech.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "french-part-of-speech.dev.v0",
            "base_eval": "french-part-of-speech",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "french-part-of-speech/samples.jsonl"
                    },
                    "key": "french-part-of-speech.dev.v0",
                    "group": "french-part-of-speech"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919NRXHLM5I",
            "created_at": "2023-07-21 18:09:19.301150"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "french_homonym_and_homograph.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "french_homonym_and_homograph.dev.v0",
            "base_eval": "french_homonym_and_homograph",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "french_homonym_and_homograph/samples.jsonl"
                    },
                    "key": "french_homonym_and_homograph.dev.v0",
                    "group": "french_homonym_and_homograph"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919L3XL3BYI",
            "created_at": "2023-07-21 18:09:19.340070"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "game-theory.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "game-theory.dev.v0",
            "base_eval": "game-theory",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "game_theory/samples.jsonl",
                        "ignore_case": true
                    },
                    "key": "game-theory.dev.v0",
                    "group": "game-theory"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919KWRC3CDY",
            "created_at": "2023-07-21 18:09:19.360365"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "gears_rotation.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "gears_rotation.dev.v0",
            "base_eval": "gears_rotation",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "gears_rotation/samples.jsonl"
                    },
                    "key": "gears_rotation.dev.v0",
                    "group": "gears_rotation"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919X2OXPJUD",
            "created_at": "2023-07-21 18:09:19.392608"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "geometry_puzzle.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "geometry_puzzle.dev.v0",
            "base_eval": "geometry_puzzle",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "geometry_puzzle/samples.jsonl"
                    },
                    "key": "geometry_puzzle.dev.v0",
                    "group": "geometry_puzzle"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919B6YDFGI3",
            "created_at": "2023-07-21 18:09:19.408720"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "german-part-of-speech.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "german-part-of-speech.dev.v0",
            "base_eval": "german-part-of-speech",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "german-part-of-speech/samples.jsonl"
                    },
                    "key": "german-part-of-speech.dev.v0",
                    "group": "german-part-of-speech"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919VAPDXA2T",
            "created_at": "2023-07-21 18:09:19.434279"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "gol.dev.v1.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "gol.dev.v1",
            "base_eval": "gol",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "GOL/samples.jsonl"
                    },
                    "key": "gol.dev.v1",
                    "group": "gol"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919KKZU3AO3",
            "created_at": "2023-07-21 18:09:19.466420"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "gregorian-to-hebrew-date.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "gregorian-to-hebrew-date.dev.v0",
            "base_eval": "gregorian-to-hebrew-date",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "gregorian-to-hebrew-date/samples.jsonl"
                    },
                    "key": "gregorian-to-hebrew-date.dev.v0",
                    "group": "gregorian-to-hebrew-date"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919MTUFAL2A",
            "created_at": "2023-07-21 18:09:19.519317"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "greek-nt-manuscripts.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "greek-nt-manuscripts.v0",
            "base_eval": "greek-nt-manuscripts",
            "split": "v0",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "greek_nt_manuscripts/codes-sigla-centuries.jsonl"
                    },
                    "key": "greek-nt-manuscripts.v0",
                    "group": "greek-nt-manuscripts"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919OFVH4OJB",
            "created_at": "2023-07-21 18:09:19.500955"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "hebrew-bible.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "hebrew-bible.dev.v0",
            "base_eval": "hebrew-bible",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "hebrew_bible/samples.jsonl"
                    },
                    "key": "hebrew-bible.dev.v0",
                    "group": "hebrew-bible"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919VJUQV6IC",
            "created_at": "2023-07-21 18:09:19.547659"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "hebrew-homophones.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "hebrew-homophones.dev.v0",
            "base_eval": "hebrew-homophones",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "hebrew_homophones/samples.jsonl"
                    },
                    "key": "hebrew-homophones.dev.v0",
                    "group": "hebrew-homophones"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919WNUFKRU6",
            "created_at": "2023-07-21 18:09:19.587733"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "hebrew-same-noun-gender.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "hebrew-same-noun-gender.v0",
            "base_eval": "hebrew-same-noun-gender",
            "split": "v0",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "hebrew_same_noun_gender/samples.jsonl"
                    },
                    "key": "hebrew-same-noun-gender.v0",
                    "group": "hebrew-same-noun-gender"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919L3BBS2RU",
            "created_at": "2023-07-21 18:09:19.655319"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "hebrew-plurals.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "hebrew-plurals.dev.v0",
            "base_eval": "hebrew-plurals",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "hebrew_plurals/samples.jsonl"
                    },
                    "key": "hebrew-plurals.dev.v0",
                    "group": "hebrew_plurals"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919KLCTRMK6",
            "created_at": "2023-07-21 18:09:19.720475"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "guess-the-singer.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "guess-the-singer.dev.v0",
            "base_eval": "guess-the-singer",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "guess_the_singer/samples.jsonl"
                    },
                    "key": "guess-the-singer.dev.v0",
                    "group": "guess-the-singer"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809197QRLOPSL",
            "created_at": "2023-07-21 18:09:19.570141"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "hebrew_talmud_suka.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "hebrew_talmud_suka.dev.v0",
            "base_eval": "hebrew_talmud_suka",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "hebrew_talmud_suka/samples.jsonl"
                    },
                    "key": "hebrew_talmud_suka.dev.v0",
                    "group": "hebrew_talmud_suka"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919ROJUWJRH",
            "created_at": "2023-07-21 18:09:19.746158"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "historical-kana-orthography-reading.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "historical-kana-orthography-reading.dev.v0",
            "base_eval": "historical-kana-orthography-reading",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "historical-kana-orthography-reading/samples.jsonl"
                    },
                    "key": "historical-kana-orthography-reading.dev.v0",
                    "group": "historical-kana-orthography-reading"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919KC7UKFM3",
            "created_at": "2023-07-21 18:09:19.813556"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "human-safety.test.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "human-safety.test.v0",
            "base_eval": "human-safety",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "human-safety/human-safety.jsonl"
                    },
                    "key": "human-safety.test.v0",
                    "group": "human-safety"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809197NP3KU4U",
            "created_at": "2023-07-21 18:09:19.839116"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "interlingual-homograph.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "interlingual-homograph.dev.v0",
            "base_eval": "interlingual-homograph",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "interlingual-homograph/samples.jsonl"
                    },
                    "key": "interlingual-homograph.dev.v0",
                    "group": "interlingual-homograph"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919IN644ZGF",
            "created_at": "2023-07-21 18:09:19.866762"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "invert_word_wise.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "invert_word_wise.dev.v0",
            "base_eval": "invert_word_wise",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "invert_word_wise/invert.jsonl"
                    },
                    "key": "invert_word_wise.dev.v0",
                    "group": "invert_word_wise"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919OT3UXE6H",
            "created_at": "2023-07-21 18:09:19.878050"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "abstract2title.test.v1.json": {
        "spec": {
            "completion_fns": [
                "debug:debug",
                "openai:gpt-3.5-turbo-16k-0613"
            ],
            "eval_name": "abstract2title.test.v1",
            "base_eval": "abstract2title",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "debug:debug",
                    "openai:gpt-3.5-turbo-16k-0613"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "abstract2title/samples.jsonl",
                        "modelgraded_spec": "closedqa",
                        "modelgraded_spec_args": {
                            "criteria": "conciseness: Does the title properly describe the provided content?"
                        }
                    },
                    "key": "abstract2title.test.v1",
                    "group": "abstract2title"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180910TDLURSPI",
            "created_at": "2023-07-21 18:09:10.904395"
        },
        "final_report": {
            "counts/N": 10,
            "score": 0.0
        }
    },
    "irish-plural-nouns.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "irish-plural-nouns.dev.v0",
            "base_eval": "irish-plural-nouns",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "irish_plural_nouns/samples.jsonl"
                    },
                    "key": "irish-plural-nouns.dev.v0",
                    "group": "irish-plural-nouns"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180920AJURUNIQ",
            "created_at": "2023-07-21 18:09:20.484732"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "irish-lexicon.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "irish-lexicon.dev.v0",
            "base_eval": "irish-lexicon",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "irish-lexicon/samples.jsonl"
                    },
                    "key": "irish-lexicon.dev.v0",
                    "group": "irish-lexicon"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919KFGJOOR6",
            "created_at": "2023-07-21 18:09:19.943086"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "japanese-remote-island-to-prefecture.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "japanese-remote-island-to-prefecture.dev.v0",
            "base_eval": "japanese-remote-island-to-prefecture",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "islands/japanese_remote_island_to_prefecture.jsonl"
                    },
                    "key": "japanese-remote-island-to-prefecture.dev.v0",
                    "group": "islands"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180920FOTWNBWL",
            "created_at": "2023-07-21 18:09:20.536730"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "irony.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "irony.dev.v0",
            "base_eval": "irony",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "irony/samples.jsonl"
                    },
                    "key": "irony.dev.v0",
                    "group": "irony"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180920S457SI7M",
            "created_at": "2023-07-21 18:09:20.535033"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "italian-new-words.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "italian-new-words.dev.v0",
            "base_eval": "italian-new-words",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "italian-new-words/samples.jsonl"
                    },
                    "key": "italian-new-words.dev.v0",
                    "group": "italian-new-words"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809206I7HKU47",
            "created_at": "2023-07-21 18:09:20.570617"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "italian-rhyme.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "italian-rhyme.v0",
            "base_eval": "italian-rhyme",
            "split": "v0",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "italian_rhyme/samples.jsonl"
                    },
                    "key": "italian-rhyme.v0",
                    "group": "italian-rhyme"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180920IRWPMQV5",
            "created_at": "2023-07-21 18:09:20.594628"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "italian_big_math_expression.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "italian_big_math_expression.dev.v0",
            "base_eval": "italian_big_math_expression",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "italian_big_math_expression/samples.jsonl"
                    },
                    "key": "italian_big_math_expression.dev.v0",
                    "group": "italian_big_math_expression"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809205J54K7WP",
            "created_at": "2023-07-21 18:09:20.615585"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "japanese-decimal-units.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "japanese-decimal-units.dev.v0",
            "base_eval": "japanese-decimal-units",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "japanese-decimal-units/samples.jsonl"
                    },
                    "key": "japanese-decimal-units.dev.v0",
                    "group": "japanese-decimal-units"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180920USJ7SBHU",
            "created_at": "2023-07-21 18:09:20.625767"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "japanese-itpassport-exam01.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "japanese-itpassport-exam01.dev.v0",
            "base_eval": "japanese-itpassport-exam01",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "japanese-itpassport-exam01/japanese-itpassport-exam01.jsonl"
                    },
                    "key": "japanese-itpassport-exam01.dev.v0",
                    "group": "japanese-itpassport-exam01"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180920VBEJMMHA",
            "created_at": "2023-07-21 18:09:20.648880"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "japanese_approval.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "japanese_approval.dev.v0",
            "base_eval": "japanese_approval",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "japanese_approval/samples.jsonl"
                    },
                    "key": "japanese_approval.dev.v0",
                    "group": "japanese_approval"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180920LED3XC2O",
            "created_at": "2023-07-21 18:09:20.668756"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "japanese_mahjong_discard_tile.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "japanese_mahjong_discard_tile.dev.v0",
            "base_eval": "japanese_mahjong_discard_tile",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "japanese_mahjong_discard_tile/samples.jsonl"
                    },
                    "key": "japanese_mahjong_discard_tile.dev.v0",
                    "group": "japanese_mahjong_discard_tile"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180920AGUGIGVM",
            "created_at": "2023-07-21 18:09:20.708310"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "japanese_city_name_pronunciation.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "japanese_city_name_pronunciation.dev.v0",
            "base_eval": "japanese_city_name_pronunciation",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "japanese_city_name_pronunciation/samples.jsonl"
                    },
                    "key": "japanese_city_name_pronunciation.dev.v0",
                    "group": "japanese_city_name_pronuciation"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180920ZAKWFALO",
            "created_at": "2023-07-21 18:09:20.690710"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "japanese-number-reading.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "japanese-number-reading.dev.v0",
            "base_eval": "japanese-number-reading",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "japanese_number_reading/japanese_number_reading.jsonl"
                    },
                    "key": "japanese-number-reading.dev.v0",
                    "group": "japanese_number_reading"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180920YADDVM4C",
            "created_at": "2023-07-21 18:09:20.759534"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "japanese_populer_video_game_title_and_the_publisher.val.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "japanese_populer_video_game_title_and_the_publisher.val.v0",
            "base_eval": "japanese_populer_video_game_title_and_the_publisher",
            "split": "val",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "japanese_populer_video_game_title_and_the_publisher/samples.jsonl"
                    },
                    "key": "japanese_populer_video_game_title_and_the_publisher.val.v0",
                    "group": "japanese_populer_video_game_title_and_the_publisher"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180920YBVYJGQ3",
            "created_at": "2023-07-21 18:09:20.760504"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "kanji-idioms.test.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "kanji-idioms.test.v0",
            "base_eval": "kanji-idioms",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "kanji-idioms/samples.jsonl"
                    },
                    "key": "kanji-idioms.test.v0",
                    "group": "kanji-idioms"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180920ODO7OVSV",
            "created_at": "2023-07-21 18:09:20.801519"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "json_patch_object.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "json_patch_object.dev.v0",
            "base_eval": "json_patch_object",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "json_patch_object/samples.jsonl"
                    },
                    "key": "json_patch_object.dev.v0",
                    "group": "json_patch_object"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180920YKOYCEBI",
            "created_at": "2023-07-21 18:09:20.796483"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "korean-consonant-vowel-combination.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "korean-consonant-vowel-combination.dev.v0",
            "base_eval": "korean-consonant-vowel-combination",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "korean-consonant-vowel-combination/samples.jsonl"
                    },
                    "key": "korean-consonant-vowel-combination.dev.v0",
                    "group": "korean-consonant-vowel-combination"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180920KT3EBHDA",
            "created_at": "2023-07-21 18:09:20.837334"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "korean-honorific.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "korean-honorific.dev.v0",
            "base_eval": "korean-honorific",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "korean-honorific/samples.jsonl"
                    },
                    "key": "korean-honorific.dev.v0",
                    "group": "korean-honorific"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809202G2IXPBK",
            "created_at": "2023-07-21 18:09:20.892970"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "korean-phonetics.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "korean-phonetics.dev.v0",
            "base_eval": "korean-phonetics",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "korean-phonetics/samples.jsonl"
                    },
                    "key": "korean-phonetics.dev.v0",
                    "group": "korean-phonetics"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809207EBRJUMZ",
            "created_at": "2023-07-21 18:09:20.921489"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "korean-postposition.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "korean-postposition.dev.v0",
            "base_eval": "korean-postposition",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "korean-postposition/samples.jsonl"
                    },
                    "key": "korean-postposition.dev.v0",
                    "group": "korean-postposition"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180920RAY42XLT",
            "created_at": "2023-07-21 18:09:20.934736"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "korean_dialects.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "korean_dialects.dev.v0",
            "base_eval": "korean_dialects",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "korean_dialects/samples.jsonl"
                    },
                    "key": "korean_dialects.dev.v0",
                    "group": "korean_dialects"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180920KL7YRUSD",
            "created_at": "2023-07-21 18:09:20.979722"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "korean_date_counting.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "korean_date_counting.dev.v0",
            "base_eval": "korean_date_counting",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "korean_date_counting/samples.jsonl"
                    },
                    "key": "korean_date_counting.dev.v0",
                    "group": "korean_date_counting"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180920BQ3QOUK3",
            "created_at": "2023-07-21 18:09:20.962641"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "korean_foreign_words.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "korean_foreign_words.dev.v0",
            "base_eval": "korean_foreign_words",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "korean_foreign_words/samples.jsonl"
                    },
                    "key": "korean_foreign_words.dev.v0",
                    "group": "korean_foreign_words"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921MFOW52XD",
            "created_at": "2023-07-21 18:09:21.005360"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "korean_romanization.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "korean_romanization.dev.v0",
            "base_eval": "korean_romanization",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "korean_romanization/samples.jsonl",
                        "ignore_case": true
                    },
                    "key": "korean_romanization.dev.v0",
                    "group": "korean_romanization"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921WGOVNUPC",
            "created_at": "2023-07-21 18:09:21.021113"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "latin-grammar.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "latin-grammar.dev.v0",
            "base_eval": "latin-grammar",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "latin_grammar/samples.jsonl"
                    },
                    "key": "latin-grammar.dev.v0",
                    "group": "latin_grammar"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921DC53VRT5",
            "created_at": "2023-07-21 18:09:21.104969"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "korean_yaminjeongeum.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "korean_yaminjeongeum.dev.v0",
            "base_eval": "korean_yaminjeongeum",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "korean_yaminjeongeum/samples.jsonl"
                    },
                    "key": "korean_yaminjeongeum.dev.v0",
                    "group": "korean_yaminjeongeum"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921JKTPTXWX",
            "created_at": "2023-07-21 18:09:21.047451"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "largest_country.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "largest_country.dev.v0",
            "base_eval": "largest_country",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "largest_country/samples.jsonl"
                    },
                    "key": "largest_country.dev.v0",
                    "group": "largest_country"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921BCE2A63V",
            "created_at": "2023-07-21 18:09:21.065880"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "list_comparison_missing_name.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "list_comparison_missing_name.dev.v0",
            "base_eval": "list_comparison_missing_name",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "list_comparison_missing_name/samples.jsonl"
                    },
                    "key": "list_comparison_missing_name.dev.v0",
                    "group": "list_comparison_missing_name"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921AYK4QOGW",
            "created_at": "2023-07-21 18:09:21.165616"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "logic-grid.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "logic-grid.dev.v0",
            "base_eval": "logic-grid",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "logic-grid/logic-grid.jsonl",
                        "max_tokens": 3072
                    },
                    "key": "logic-grid.dev.v0",
                    "group": "logic-grid-eval"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921F6YCBFEH",
            "created_at": "2023-07-21 18:09:21.201810"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "logic_and_probability.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "logic_and_probability.dev.v0",
            "base_eval": "logic_and_probability",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "logic_and_probability/logic_and_probability.jsonl"
                    },
                    "key": "logic_and_probability.dev.v0",
                    "group": "logic_and_probability"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921RUUBEE5G",
            "created_at": "2023-07-21 18:09:21.232063"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "logical-black-scholes.test.v1.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "logical-black-scholes.test.v1",
            "base_eval": "logical-black-scholes",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "logical-black-scholes/samples.jsonl"
                    },
                    "key": "logical-black-scholes.test.v1",
                    "group": "logical-black-scholes"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921MTXJ4FMW",
            "created_at": "2023-07-21 18:09:21.263539"
        },
        "final_report": {
            "accuracy": 0.04,
            "boostrap_std": 0.04166591665991655
        }
    },
    "logical_reasoning_letter_series_test.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "logical_reasoning_letter_series_test.dev.v0",
            "base_eval": "logical_reasoning_letter_series_test",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "logical_reasoning_letter_series_test/samples.jsonl"
                    },
                    "key": "logical_reasoning_letter_series_test.dev.v0",
                    "group": "logical_reasoning_letter_series_test"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921VHHJEQ34",
            "created_at": "2023-07-21 18:09:21.292384"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "logiqa-logical-reasoning-plus.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "logiqa-logical-reasoning-plus.dev.v0",
            "base_eval": "logiqa-logical-reasoning-plus",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "logiqa-logical-reasoning-plus/logiqa-logical-reasoning-plus.jsonl"
                    },
                    "key": "logiqa-logical-reasoning-plus.dev.v0",
                    "group": "logiqa-logical-reasoning-plus"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921QD35ANVG",
            "created_at": "2023-07-21 18:09:21.326621"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "logiqav2-logical-reasoning-plus.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "logiqav2-logical-reasoning-plus.dev.v0",
            "base_eval": "logiqav2-logical-reasoning-plus",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "logiqa-logical-reasoning-plus/logiqav2-logical-reasoning-plus.jsonl"
                    },
                    "key": "logiqav2-logical-reasoning-plus.dev.v0",
                    "group": "logiqa-logical-reasoning-plus"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921LAZ5RHNX",
            "created_at": "2023-07-21 18:09:21.393880"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "reclor-logical-reasoning-plus.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "reclor-logical-reasoning-plus.dev.v0",
            "base_eval": "reclor-logical-reasoning-plus",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "logiqa-logical-reasoning-plus/reclor-logical-reasoning-plus.jsonl"
                    },
                    "key": "reclor-logical-reasoning-plus.dev.v0",
                    "group": "logiqa-logical-reasoning-plus"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921IGCNWH4U",
            "created_at": "2023-07-21 18:09:21.468658"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "iso-to-lunar-calendar.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "iso-to-lunar-calendar.dev.v0",
            "base_eval": "iso-to-lunar-calendar",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "lunar_calendar/iso_to_lunar_calendar.jsonl"
                    },
                    "key": "iso-to-lunar-calendar.dev.v0",
                    "group": "lunar-calendar"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809212VZUFRVD",
            "created_at": "2023-07-21 18:09:21.533780"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "lunar-calendar-to-iso.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "lunar-calendar-to-iso.dev.v0",
            "base_eval": "lunar-calendar-to-iso",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "lunar_calendar/lunar_calendar_to_iso.jsonl"
                    },
                    "key": "lunar-calendar-to-iso.dev.v0",
                    "group": "lunar-calendar"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921BKYAR3N7",
            "created_at": "2023-07-21 18:09:21.554513"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "mandaliof-table.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "mandaliof-table.dev.v0",
            "base_eval": "mandaliof-table",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "mandaliof-table/samples.jsonl"
                    },
                    "key": "mandaliof-table.dev.v0",
                    "group": "mandaliof-table"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921ZZ7JLSXF",
            "created_at": "2023-07-21 18:09:21.577760"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "marxist_philosophy_exam_simple.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "marxist_philosophy_exam_simple.dev.v0",
            "base_eval": "marxist_philosophy_exam_simple",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "marxist_philosophy_exam/fuzzy_match.jsonl"
                    },
                    "key": "marxist_philosophy_exam_simple.dev.v0",
                    "group": "marxist_philosophy_exam"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921DUSLZUOG",
            "created_at": "2023-07-21 18:09:21.600761"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "mate-in-one.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "mate-in-one.dev.v0",
            "base_eval": "mate-in-one",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "mate-in-one/samples.jsonl"
                    },
                    "key": "mate-in-one.dev.v0",
                    "group": "mate-in-one"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921NE2R6WHM",
            "created_at": "2023-07-21 18:09:21.608230"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "math-derivatives.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "math-derivatives.dev.v0",
            "base_eval": "math-derivatives",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "math-derivatives/questions.jsonl"
                    },
                    "key": "math-derivatives.dev.v0",
                    "group": "math-derivatives"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921UAXXFCCR",
            "created_at": "2023-07-21 18:09:21.651935"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "math_equations.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "math_equations.dev.v0",
            "base_eval": "math_equations",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "math_equations/math_equations.jsonl"
                    },
                    "key": "math_equations.dev.v0",
                    "group": "math_equations"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921MW3GUL3U",
            "created_at": "2023-07-21 18:09:21.691201"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "math_for_5th-grader.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "math_for_5th-grader.dev.v0",
            "base_eval": "math_for_5th-grader",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "math_for_5th-grader/samples.jsonl"
                    },
                    "key": "math_for_5th-grader.dev.v0",
                    "group": "math_for_5th-grader"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921UGTTGBEQ",
            "created_at": "2023-07-21 18:09:21.737661"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "math_logic_operations.dev.v0-1.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "math_logic_operations.dev.v0-1",
            "base_eval": "math_logic_operations",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "math_logic_operations/samples.jsonl"
                    },
                    "key": "math_logic_operations.dev.v0-1",
                    "group": "math_logic_operations"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "23072118092176G7XSCK",
            "created_at": "2023-07-21 18:09:21.764630"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "math_polish.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "math_polish.dev.v0",
            "base_eval": "math_polish",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "math_polish/samples.jsonl"
                    },
                    "key": "math_polish.dev.v0",
                    "group": "math_polish"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921C5U5WHOT",
            "created_at": "2023-07-21 18:09:21.798694"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "matrix_mult_rows.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "matrix_mult_rows.dev.v0",
            "base_eval": "matrix_mult_rows",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "matrix_mult_rows/samples.jsonl"
                    },
                    "key": "matrix_mult_rows.dev.v0",
                    "group": "matrix-mult-rows"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "23072118092165GUUA3O",
            "created_at": "2023-07-21 18:09:21.818344"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "mazes-singlemove-3x3.test.v2.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "mazes-singlemove-3x3.test.v2",
            "base_eval": "mazes-singlemove-3x3",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "mazes/3x3-mazes-singlemove.jsonl"
                    },
                    "key": "mazes-singlemove-3x3.test.v2",
                    "group": "mazes"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921W2O5XG7J",
            "created_at": "2023-07-21 18:09:21.863349"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "mazes-singlemove-4x4.test.v2.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "mazes-singlemove-4x4.test.v2",
            "base_eval": "mazes-singlemove-4x4",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "mazes/4x4-mazes-singlemove.jsonl"
                    },
                    "key": "mazes-singlemove-4x4.test.v2",
                    "group": "mazes"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809213LZADP7Q",
            "created_at": "2023-07-21 18:09:21.920812"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "mazes-singlemove-10x10.test.v2.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "mazes-singlemove-10x10.test.v2",
            "base_eval": "mazes-singlemove-10x10",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "mazes/10x10-mazes-singlemove.jsonl"
                    },
                    "key": "mazes-singlemove-10x10.test.v2",
                    "group": "mazes"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921KE2F7T26",
            "created_at": "2023-07-21 18:09:21.985814"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "mazes-3x3.test.v2.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "mazes-3x3.test.v2",
            "base_eval": "mazes-3x3",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "mazes/3x3-mazes.jsonl"
                    },
                    "key": "mazes-3x3.test.v2",
                    "group": "mazes"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922P76IEE6T",
            "created_at": "2023-07-21 18:09:22.049222"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "mazes-4x4.test.v2.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "mazes-4x4.test.v2",
            "base_eval": "mazes-4x4",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "mazes/4x4-mazes.jsonl"
                    },
                    "key": "mazes-4x4.test.v2",
                    "group": "mazes"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922DQMBON7T",
            "created_at": "2023-07-21 18:09:22.110464"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "mazes-10x10.test.v2.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "mazes-10x10.test.v2",
            "base_eval": "mazes-10x10",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "mazes/10x10-mazes.jsonl"
                    },
                    "key": "mazes-10x10.test.v2",
                    "group": "mazes"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922JVWTTN5O",
            "created_at": "2023-07-21 18:09:22.171599"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "medication_dose.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "medication_dose.dev.v0",
            "base_eval": "medication_dose",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "medication_dose/samples.jsonl"
                    },
                    "key": "medication_dose.dev.v0",
                    "group": "medication_dose"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922IPKX4YYS",
            "created_at": "2023-07-21 18:09:22.219879"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "missing-operators.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "missing-operators.s1.simple-v0",
            "base_eval": "missing-operators",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "missing_operators/samples.jsonl"
                    },
                    "key": "missing-operators.s1.simple-v0",
                    "group": "missing-operators"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809226OGDKCUN",
            "created_at": "2023-07-21 18:09:22.240005"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "monthly_metric_comparison.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "monthly_metric_comparison.dev.v0",
            "base_eval": "monthly_metric_comparison",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "monthly_metric_comparison/samples.jsonl"
                    },
                    "key": "monthly_metric_comparison.dev.v0",
                    "group": "monthly_metric_comparison"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922SQ5TX7OK",
            "created_at": "2023-07-21 18:09:22.263356"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "multistep-word-problems.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "multistep-word-problems.dev.v0",
            "base_eval": "multistep-word-problems",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "multistep-word-problems/samples.jsonl"
                    },
                    "key": "multistep-word-problems.dev.v0",
                    "group": "multistep-word-problems"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922JB4BGAXK",
            "created_at": "2023-07-21 18:09:22.286830"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "music-theory-chord-names.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "music-theory-chord-names.dev.v0",
            "base_eval": "music-theory-chord-names",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "music_theory/music_theory_chord_names.jsonl"
                    },
                    "key": "music-theory-chord-names.dev.v0",
                    "group": "music-theory-chord-names"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922XJOL6RBY",
            "created_at": "2023-07-21 18:09:22.312448"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "music-theory-chord-notes.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "music-theory-chord-notes.dev.v0",
            "base_eval": "music-theory-chord-notes",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "music_theory/music_theory_chord_notes.jsonl"
                    },
                    "key": "music-theory-chord-notes.dev.v0",
                    "group": "music-theory-chord-notes"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922MHSRNUDB",
            "created_at": "2023-07-21 18:09:22.341460"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "music-theory-triads-identification.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "music-theory-triads-identification.dev.v0",
            "base_eval": "music-theory-triads-identification",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "music-theory/triads-samples.jsonl",
                        "few_shot_jsonl": "music-theory/triads-few-shot.jsonl",
                        "num_few_shot": 7
                    },
                    "key": "music-theory-triads-identification.dev.v0",
                    "group": "music-theory"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922EEXL3ZQR",
            "created_at": "2023-07-21 18:09:22.362187"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "music-theory-tetrads-identification.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "music-theory-tetrads-identification.dev.v0",
            "base_eval": "music-theory-tetrads-identification",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "music-theory/tetrads-samples.jsonl",
                        "few_shot_jsonl": "music-theory/tetrads-few-shot.jsonl",
                        "num_few_shot": 15
                    },
                    "key": "music-theory-tetrads-identification.dev.v0",
                    "group": "music-theory"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922CF34UXLL",
            "created_at": "2023-07-21 18:09:22.445631"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "music_theory_scale_modes.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "music_theory_scale_modes.dev.v0",
            "base_eval": "music_theory_scale_modes",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "music_theory_scale_modes/samples.jsonl"
                    },
                    "key": "music_theory_scale_modes.dev.v0",
                    "group": "music_theory_scale_modes"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922PCHBRWNE",
            "created_at": "2023-07-21 18:09:22.547283"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "nepali-numerals.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "nepali-numerals.dev.v0",
            "base_eval": "nepali-numerals",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "nepali_numerals/samples.jsonl"
                    },
                    "key": "nepali-numerals.dev.v0",
                    "group": "nepali-numerals"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922RUGV2PWS",
            "created_at": "2023-07-21 18:09:22.585998"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "nepali-song-singer.dev.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "nepali-song-singer.dev",
            "base_eval": "nepali-song-singer",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "nepali-song-singer/nepali-song-singer.jsonl"
                    },
                    "key": "nepali-song-singer.dev",
                    "group": "nepali-song-singer"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809226ISLR6R5",
            "created_at": "2023-07-21 18:09:22.608192"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "ner_finance.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ner_finance.dev.v0",
            "base_eval": "ner_finance",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "ner_finance/samples.jsonl"
                    },
                    "key": "ner_finance.dev.v0",
                    "group": "ner_finance"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922BAJJOU7D",
            "created_at": "2023-07-21 18:09:22.631306"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "newsology.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "newsology.dev.v0",
            "base_eval": "newsology",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "newsology/samples.jsonl"
                    },
                    "key": "newsology.dev.v0",
                    "group": "newsology"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922XVJLRK6B",
            "created_at": "2023-07-21 18:09:22.701876"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "next-val-series.dev.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "next-val-series.dev.simple-v0",
            "base_eval": "next-val-series",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "next-val-series/next-val-series.jsonl"
                    },
                    "key": "next-val-series.dev.simple-v0",
                    "group": "next-val-series"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809224AVLB5GW",
            "created_at": "2023-07-21 18:09:22.729840"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "nfl-point-combinations.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "nfl-point-combinations.dev.v0",
            "base_eval": "nfl-point-combinations",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "nfl-point-combinations/samples.jsonl"
                    },
                    "key": "nfl-point-combinations.dev.v0",
                    "group": "nfl-point-combinations"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922EB3NBNFO",
            "created_at": "2023-07-21 18:09:22.755935"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "norwegian-lexicon.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "norwegian-lexicon.dev.v0",
            "base_eval": "norwegian-lexicon",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "norwegian-lexicon/samples.jsonl"
                    },
                    "key": "norwegian-lexicon.dev.v0",
                    "group": "norwegian-lexicon"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922Q6B2TORL",
            "created_at": "2023-07-21 18:09:22.779173"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "norwegian-rhymes.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "norwegian-rhymes.dev.v0",
            "base_eval": "norwegian-rhymes",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "norwegian-rhymes/samples.jsonl"
                    },
                    "key": "norwegian-rhymes.dev.v0",
                    "group": "norwegian-rhymes"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922S4LBCIZH",
            "created_at": "2023-07-21 18:09:22.799555"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "numbers_game.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "numbers_game.dev.v0",
            "base_eval": "numbers_game",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "numbers_game/samples.jsonl"
                    },
                    "key": "numbers_game.dev.v0",
                    "group": "numbers_game"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922TQOB4C7T",
            "created_at": "2023-07-21 18:09:22.820159"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "numeral-type-comparisons.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "numeral-type-comparisons.dev.v0",
            "base_eval": "numeral-type-comparisons",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "numeral-type-comparisons/samples.jsonl"
                    },
                    "key": "numeral-type-comparisons.dev.v0",
                    "group": "numeral-type-comparisons"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922HIWLPUCM",
            "created_at": "2023-07-21 18:09:22.856043"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "nutrition.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "nutrition.dev.v0",
            "base_eval": "nutrition",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "nutrition/facts.jsonl"
                    },
                    "key": "nutrition.dev.v0",
                    "group": "nutrition"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922Q2RWYXL2",
            "created_at": "2023-07-21 18:09:22.879017"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "ordering_randomised_versionlist.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ordering_randomised_versionlist.dev.v0",
            "base_eval": "ordering_randomised_versionlist",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "ordering_randomised_versionlist/samples.jsonl"
                    },
                    "key": "ordering_randomised_versionlist.dev.v0",
                    "group": "ordering_randomised_versionlist"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922PK23YG6M",
            "created_at": "2023-07-21 18:09:22.902080"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "passing-balls.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "passing-balls.dev.v0",
            "base_eval": "passing-balls",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "passing-balls/passing-balls.jsonl"
                    },
                    "key": "passing-balls.dev.v0",
                    "group": "passing-balls"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922FD6ORUCI",
            "created_at": "2023-07-21 18:09:22.923770"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "pararule-plus-multi-step-deductive-reasoning.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "pararule-plus-multi-step-deductive-reasoning.dev.v0",
            "base_eval": "pararule-plus-multi-step-deductive-reasoning",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "pararule-plus-multi-step-deductive-reasoning/pararule-plus-multi-step-deductive-reasoning.jsonl"
                    },
                    "key": "pararule-plus-multi-step-deductive-reasoning.dev.v0",
                    "group": "pararule-plus-multi-step-deductive-reasoning"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922GLGQKKZT",
            "created_at": "2023-07-21 18:09:22.931275"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "path_enclosed_area.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "path_enclosed_area.dev.v0",
            "base_eval": "path_enclosed_area",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "path_enclosed_area/samples.jsonl"
                    },
                    "key": "path_enclosed_area.dev.v0",
                    "group": "path_enclosed_area"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922KAZWXYGN",
            "created_at": "2023-07-21 18:09:22.959876"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "persian-kinship-riddles.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "persian-kinship-riddles.dev.v0",
            "base_eval": "persian-kinship-riddles",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "persian-kinship-riddles/samples.jsonl"
                    },
                    "key": "persian-kinship-riddles.dev.v0",
                    "group": "persian-kinship-riddles"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180922FHN4KPBO",
            "created_at": "2023-07-21 18:09:22.982578"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "phonetics-identify-words-needing-missing-gpcs.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "phonetics-identify-words-needing-missing-gpcs.s1.simple-v0",
            "base_eval": "phonetics-identify-words-needing-missing-gpcs",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "phonetics-identify-words-needing-missing-gpcs/samples.jsonl"
                    },
                    "key": "phonetics-identify-words-needing-missing-gpcs.s1.simple-v0",
                    "group": "phonetics-identify-words-needing-missing-gpcs"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923LXIGX2JE",
            "created_at": "2023-07-21 18:09:23.012259"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "physics.interaction.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "physics.interaction.dev.v0",
            "base_eval": "physics",
            "split": "interaction",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "physics-interaction/samples.jsonl"
                    },
                    "key": "physics.interaction.dev.v0",
                    "group": "physics-interaction"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923I3CGOOHZ",
            "created_at": "2023-07-21 18:09:23.035440"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "pointer-value-retrieval-easy-few-examples.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "pointer-value-retrieval-easy-few-examples.dev.v0",
            "base_eval": "pointer-value-retrieval-easy-few-examples",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "pointer-value-retrieval/easy_few_examples.jsonl"
                    },
                    "key": "pointer-value-retrieval-easy-few-examples.dev.v0",
                    "group": "pointer-value-retrieval"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923FXEJMKY3",
            "created_at": "2023-07-21 18:09:23.172726"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "pointer-value-retrieval-easy-many-examples.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "pointer-value-retrieval-easy-many-examples.dev.v0",
            "base_eval": "pointer-value-retrieval-easy-many-examples",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "pointer-value-retrieval/easy_many_examples.jsonl"
                    },
                    "key": "pointer-value-retrieval-easy-many-examples.dev.v0",
                    "group": "pointer-value-retrieval"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923G3K47EHF",
            "created_at": "2023-07-21 18:09:23.197821"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "pointer-value-retrieval-medium-few-examples.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "pointer-value-retrieval-medium-few-examples.dev.v0",
            "base_eval": "pointer-value-retrieval-medium-few-examples",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "pointer-value-retrieval/medium_few_examples.jsonl"
                    },
                    "key": "pointer-value-retrieval-medium-few-examples.dev.v0",
                    "group": "pointer-value-retrieval"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923IAM5AADR",
            "created_at": "2023-07-21 18:09:23.222017"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "pointer-value-retrieval-medium-many-examples.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "pointer-value-retrieval-medium-many-examples.dev.v0",
            "base_eval": "pointer-value-retrieval-medium-many-examples",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "pointer-value-retrieval/medium_many_examples.jsonl"
                    },
                    "key": "pointer-value-retrieval-medium-many-examples.dev.v0",
                    "group": "pointer-value-retrieval"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923VNOSODBO",
            "created_at": "2023-07-21 18:09:23.245154"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "pointer-value-retrieval-hard-few-examples.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "pointer-value-retrieval-hard-few-examples.dev.v0",
            "base_eval": "pointer-value-retrieval-hard-few-examples",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "pointer-value-retrieval/hard_few_examples.jsonl"
                    },
                    "key": "pointer-value-retrieval-hard-few-examples.dev.v0",
                    "group": "pointer-value-retrieval"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923M4S7QJ5L",
            "created_at": "2023-07-21 18:09:23.268705"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "pointer-value-retrieval-hard-many-examples.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "pointer-value-retrieval-hard-many-examples.dev.v0",
            "base_eval": "pointer-value-retrieval-hard-many-examples",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "pointer-value-retrieval/hard_many_examples.jsonl"
                    },
                    "key": "pointer-value-retrieval-hard-many-examples.dev.v0",
                    "group": "pointer-value-retrieval"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923OVWDDIRK",
            "created_at": "2023-07-21 18:09:23.293650"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "points-on-line.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "points-on-line.dev.v0",
            "base_eval": "points-on-line",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "points_on_line/points_on_line.jsonl"
                    },
                    "key": "points-on-line.dev.v0",
                    "group": "points-on-line"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809235KECNZTW",
            "created_at": "2023-07-21 18:09:23.317070"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "poker_analysis.test.v1.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "poker_analysis.test.v1",
            "base_eval": "poker_analysis",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "poker_analysis/samples.jsonl"
                    },
                    "key": "poker_analysis.test.v1",
                    "group": "poker_analysis"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923Y2VN3M56",
            "created_at": "2023-07-21 18:09:23.339084"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "coq-editing.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug",
                "openai:gpt-3.5-turbo-16k-0613"
            ],
            "eval_name": "coq-editing.dev.v0",
            "base_eval": "coq-editing",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug",
                    "openai:gpt-3.5-turbo-16k-0613"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "coq-editing/samples.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "closedqa"
                    },
                    "key": "coq-editing.dev.v0",
                    "group": "coq-editing"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180912ETXHJC7C",
            "created_at": "2023-07-21 18:09:12.321015"
        },
        "final_report": {
            "counts/Y": 11,
            "counts/N": 4,
            "score": 0.7333333333333333
        }
    },
    "polish-lexicon.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "polish-lexicon.dev.v0",
            "base_eval": "polish-lexicon",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "polish-lexicon/samples.jsonl"
                    },
                    "key": "polish-lexicon.dev.v0",
                    "group": "polish-lexicon"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923IFLFJFA7",
            "created_at": "2023-07-21 18:09:23.383272"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "polish-proverbs.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "polish-proverbs.dev.v0",
            "base_eval": "polish-proverbs",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "polish-proverbs/samples.jsonl"
                    },
                    "key": "polish-proverbs.dev.v0",
                    "group": "polish-proverbs"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923CYZYPU7S",
            "created_at": "2023-07-21 18:09:23.399298"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "polish_rhymes_generation.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "polish_rhymes_generation.v0",
            "base_eval": "polish_rhymes_generation",
            "split": "v0",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "polish_rhymes_generation/samples.jsonl"
                    },
                    "key": "polish_rhymes_generation.v0",
                    "group": "polish_rhymes_generation"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923ISXUNQ24",
            "created_at": "2023-07-21 18:09:23.441492"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "portuguese-kinship-riddles.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "portuguese-kinship-riddles.dev.v0",
            "base_eval": "portuguese-kinship-riddles",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "portuguese-kinship-riddles/samples.jsonl"
                    },
                    "key": "portuguese-kinship-riddles.dev.v0",
                    "group": "portuguese-kinship-riddles"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923L3ZI5SD6",
            "created_at": "2023-07-21 18:09:23.479239"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "portuguese-syllable-count.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "portuguese-syllable-count.dev.v0",
            "base_eval": "portuguese-syllable-count",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "portuguese-syllable-count/samples.jsonl"
                    },
                    "key": "portuguese-syllable-count.dev.v0",
                    "group": "portuguese-syllable-count"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923OXWKNWIR",
            "created_at": "2023-07-21 18:09:23.509158"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "portuguese-sarcasm.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "portuguese-sarcasm.dev.v0",
            "base_eval": "portuguese-sarcasm",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "portuguese-sarcasm/samples.jsonl"
                    },
                    "key": "portuguese-sarcasm.dev.v0",
                    "group": "portuguese-sarcasm"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923AR4A6H6Y",
            "created_at": "2023-07-21 18:09:23.487475"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "premature-conclusions.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "premature-conclusions.dev.v0",
            "base_eval": "premature-conclusions",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "premature-conclusions/samples.jsonl"
                    },
                    "key": "premature-conclusions.dev.v0",
                    "group": "premature-conclusions"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923HHI46XFF",
            "created_at": "2023-07-21 18:09:23.533644"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "probabilities-word-problems.test.v1.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "probabilities-word-problems.test.v1",
            "base_eval": "probabilities-word-problems",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "probabilities-word-problems/samples.jsonl"
                    },
                    "key": "probabilities-word-problems.test.v1",
                    "group": "probabilities-word-problems"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923VO6IK2RT",
            "created_at": "2023-07-21 18:09:23.579397"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "probability-questions.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "probability-questions.dev.v0",
            "base_eval": "probability-questions",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "probability_questions/probability_questions.jsonl"
                    },
                    "key": "probability-questions.dev.v0",
                    "group": "probability_questions"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923XMIDJBAV",
            "created_at": "2023-07-21 18:09:23.587997"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "match_product-matching_fewshot.dev.v1.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "match_product-matching_fewshot.dev.v1",
            "base_eval": "match_product-matching_fewshot",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "product-matching/fewshot/samples.jsonl"
                    },
                    "key": "match_product-matching_fewshot.dev.v1",
                    "group": "product-matching"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923PHIRX7FJ",
            "created_at": "2023-07-21 18:09:23.632816"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "match_product-matching_rules.dev.v1.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "match_product-matching_rules.dev.v1",
            "base_eval": "match_product-matching_rules",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "product-matching/rules/samples.jsonl"
                    },
                    "key": "match_product-matching_rules.dev.v1",
                    "group": "product-matching"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923GR5GQITL",
            "created_at": "2023-07-21 18:09:23.682466"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "match_product-matching_zeroshot.dev.v1.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "match_product-matching_zeroshot.dev.v1",
            "base_eval": "match_product-matching_zeroshot",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "product-matching/zeroshot/samples.jsonl"
                    },
                    "key": "match_product-matching_zeroshot.dev.v1",
                    "group": "product-matching"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923BGLWAHGY",
            "created_at": "2023-07-21 18:09:23.716009"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "prompt-injection.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "prompt-injection.dev.v0",
            "base_eval": "prompt-injection",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "prompt-injection/samples.jsonl"
                    },
                    "key": "prompt-injection.dev.v0",
                    "group": "prompt-injection"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923ZZV7FYUV",
            "created_at": "2023-07-21 18:09:23.749540"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "proofreader.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "proofreader.dev.v0",
            "base_eval": "proofreader",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "proofreader/samples.jsonl"
                    },
                    "key": "proofreader.dev.v0",
                    "group": "proofreader"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923TCGDTEXD",
            "created_at": "2023-07-21 18:09:23.772057"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "pure_korean.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "pure_korean.dev.v0",
            "base_eval": "pure_korean",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "pure_korean/samples.jsonl"
                    },
                    "key": "pure_korean.dev.v0",
                    "group": "pure_korean"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923FTD27RDV",
            "created_at": "2023-07-21 18:09:23.822417"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "python_list_comprehension.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "python_list_comprehension.dev.v0",
            "base_eval": "python_list_comprehension",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "python_list_comprehension/samples.jsonl"
                    },
                    "key": "python_list_comprehension.dev.v0",
                    "group": "python_list_comprehension"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "23072118092346FDPQZY",
            "created_at": "2023-07-21 18:09:23.824197"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "rare-and-loanwords-dutch-lexicon.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "rare-and-loanwords-dutch-lexicon.dev.v0",
            "base_eval": "rare-and-loanwords-dutch-lexicon",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "rare-and-loanwords-dutch-lexicon/samples.jsonl"
                    },
                    "key": "rare-and-loanwords-dutch-lexicon.dev.v0",
                    "group": "rare-and-loanwords-dutch-lexicon"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809234TAGP7ZI",
            "created_at": "2023-07-21 18:09:23.874379"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "resource_id_extraction.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "resource_id_extraction.dev.v0",
            "base_eval": "resource_id_extraction",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "resource_id_extraction/samples.jsonl"
                    },
                    "key": "resource_id_extraction.dev.v0",
                    "group": "resource_id_extraction"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "23072118092634UWOONM",
            "created_at": "2023-07-21 18:09:26.118027"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "raven-matrices-symbolic-center-single.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-symbolic-center-single.dev.v0",
            "base_eval": "raven-matrices-symbolic-center-single",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/symbolic/center_single.jsonl"
                    },
                    "key": "raven-matrices-symbolic-center-single.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923Z57H3AP5",
            "created_at": "2023-07-21 18:09:23.881397"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-symbolic-distribute-four.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-symbolic-distribute-four.dev.v0",
            "base_eval": "raven-matrices-symbolic-distribute-four",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/symbolic/distribute_four.jsonl"
                    },
                    "key": "raven-matrices-symbolic-distribute-four.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180923B6TGHL5Y",
            "created_at": "2023-07-21 18:09:23.944535"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-symbolic-distribute-nine.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-symbolic-distribute-nine.dev.v0",
            "base_eval": "raven-matrices-symbolic-distribute-nine",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/symbolic/distribute_nine.jsonl"
                    },
                    "key": "raven-matrices-symbolic-distribute-nine.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180924BN3ARYGH",
            "created_at": "2023-07-21 18:09:24.006226"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-symbolic-in-center-single-out-center-single.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-symbolic-in-center-single-out-center-single.dev.v0",
            "base_eval": "raven-matrices-symbolic-in-center-single-out-center-single",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/symbolic/in_center_single_out_center_single.jsonl"
                    },
                    "key": "raven-matrices-symbolic-in-center-single-out-center-single.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180924OQ544MP4",
            "created_at": "2023-07-21 18:09:24.078505"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-symbolic-in-distribute-four-out-center-single.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-symbolic-in-distribute-four-out-center-single.dev.v0",
            "base_eval": "raven-matrices-symbolic-in-distribute-four-out-center-single",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/symbolic/in_distribute_four_out_center_single.jsonl"
                    },
                    "key": "raven-matrices-symbolic-in-distribute-four-out-center-single.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809242B5ECWWS",
            "created_at": "2023-07-21 18:09:24.143975"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-symbolic-left-center-single-right-center-single.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-symbolic-left-center-single-right-center-single.dev.v0",
            "base_eval": "raven-matrices-symbolic-left-center-single-right-center-single",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/symbolic/left_center_single_right_center_single.jsonl"
                    },
                    "key": "raven-matrices-symbolic-left-center-single-right-center-single.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180924YVCHVIM6",
            "created_at": "2023-07-21 18:09:24.222883"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-symbolic-up-center-single-down-center-single.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-symbolic-up-center-single-down-center-single.dev.v0",
            "base_eval": "raven-matrices-symbolic-up-center-single-down-center-single",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/symbolic/up_center_single_down_center_single.jsonl"
                    },
                    "key": "raven-matrices-symbolic-up-center-single-down-center-single.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180924DVGUTDPF",
            "created_at": "2023-07-21 18:09:24.301460"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-symbolic-open-center-single.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-symbolic-open-center-single.dev.v0",
            "base_eval": "raven-matrices-symbolic-open-center-single",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/symbolic-open/center_single.jsonl"
                    },
                    "key": "raven-matrices-symbolic-open-center-single.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809247B2X6CL6",
            "created_at": "2023-07-21 18:09:24.368307"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-symbolic-open-distribute-four.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-symbolic-open-distribute-four.dev.v0",
            "base_eval": "raven-matrices-symbolic-open-distribute-four",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/symbolic-open/distribute_four.jsonl"
                    },
                    "key": "raven-matrices-symbolic-open-distribute-four.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180924U5XT5DHM",
            "created_at": "2023-07-21 18:09:24.458184"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-symbolic-open-distribute-nine.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-symbolic-open-distribute-nine.dev.v0",
            "base_eval": "raven-matrices-symbolic-open-distribute-nine",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/symbolic-open/distribute_nine.jsonl"
                    },
                    "key": "raven-matrices-symbolic-open-distribute-nine.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180924YGHPTKT4",
            "created_at": "2023-07-21 18:09:24.522565"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-symbolic-open-in-center-single-out-center-single.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-symbolic-open-in-center-single-out-center-single.dev.v0",
            "base_eval": "raven-matrices-symbolic-open-in-center-single-out-center-single",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/symbolic-open/in_center_single_out_center_single.jsonl"
                    },
                    "key": "raven-matrices-symbolic-open-in-center-single-out-center-single.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180924UWBSIB63",
            "created_at": "2023-07-21 18:09:24.576873"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-symbolic-open-in-distribute-four-out-center-single.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-symbolic-open-in-distribute-four-out-center-single.dev.v0",
            "base_eval": "raven-matrices-symbolic-open-in-distribute-four-out-center-single",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/symbolic-open/in_distribute_four_out_center_single.jsonl"
                    },
                    "key": "raven-matrices-symbolic-open-in-distribute-four-out-center-single.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180924OHNHASTN",
            "created_at": "2023-07-21 18:09:24.597035"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-symbolic-open-up-center-single-down-center-single.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-symbolic-open-up-center-single-down-center-single.dev.v0",
            "base_eval": "raven-matrices-symbolic-open-up-center-single-down-center-single",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/symbolic-open/up_center_single_down_center_single.jsonl"
                    },
                    "key": "raven-matrices-symbolic-open-up-center-single-down-center-single.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180924VUHJYTX6",
            "created_at": "2023-07-21 18:09:24.767011"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-symbolic-open-left-center-single-right-center-single.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-symbolic-open-left-center-single-right-center-single.dev.v0",
            "base_eval": "raven-matrices-symbolic-open-left-center-single-right-center-single",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/symbolic-open/left_center_single_right_center_single.jsonl"
                    },
                    "key": "raven-matrices-symbolic-open-left-center-single-right-center-single.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180924EYHQWWFQ",
            "created_at": "2023-07-21 18:09:24.700902"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-text-center-single.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-text-center-single.dev.v0",
            "base_eval": "raven-matrices-text-center-single",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/text/center_single.jsonl"
                    },
                    "key": "raven-matrices-text-center-single.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180924CNYFERMC",
            "created_at": "2023-07-21 18:09:24.870870"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-text-distribute-four.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-text-distribute-four.dev.v0",
            "base_eval": "raven-matrices-text-distribute-four",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/text/distribute_four.jsonl"
                    },
                    "key": "raven-matrices-text-distribute-four.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180924FJSD4CHB",
            "created_at": "2023-07-21 18:09:24.872588"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-text-distribute-nine.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-text-distribute-nine.dev.v0",
            "base_eval": "raven-matrices-text-distribute-nine",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/text/distribute_nine.jsonl"
                    },
                    "key": "raven-matrices-text-distribute-nine.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180925NUAIJMAE",
            "created_at": "2023-07-21 18:09:25.188351"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-text-in-center-single-out-center-single.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-text-in-center-single-out-center-single.dev.v0",
            "base_eval": "raven-matrices-text-in-center-single-out-center-single",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/text/in_center_single_out_center_single.jsonl"
                    },
                    "key": "raven-matrices-text-in-center-single-out-center-single.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180925UPGZHRL7",
            "created_at": "2023-07-21 18:09:25.267785"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-text-in-distribute-four-out-center-single.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-text-in-distribute-four-out-center-single.dev.v0",
            "base_eval": "raven-matrices-text-in-distribute-four-out-center-single",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/text/in_distribute_four_out_center_single.jsonl"
                    },
                    "key": "raven-matrices-text-in-distribute-four-out-center-single.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809252CUKA7LO",
            "created_at": "2023-07-21 18:09:25.359962"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-text-left-center-single-right-center-single.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-text-left-center-single-right-center-single.dev.v0",
            "base_eval": "raven-matrices-text-left-center-single-right-center-single",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/text/left_center_single_right_center_single.jsonl"
                    },
                    "key": "raven-matrices-text-left-center-single-right-center-single.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180925E27WWHST",
            "created_at": "2023-07-21 18:09:25.439126"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-text-up-center-single-down-center-single.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-text-up-center-single-down-center-single.dev.v0",
            "base_eval": "raven-matrices-text-up-center-single-down-center-single",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/text/up_center_single_down_center_single.jsonl"
                    },
                    "key": "raven-matrices-text-up-center-single-down-center-single.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809252V2LNHMS",
            "created_at": "2023-07-21 18:09:25.537638"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-text-open-center-single.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-text-open-center-single.dev.v0",
            "base_eval": "raven-matrices-text-open-center-single",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/text-open/center_single.jsonl"
                    },
                    "key": "raven-matrices-text-open-center-single.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180925R2WMIYTV",
            "created_at": "2023-07-21 18:09:25.576255"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-text-open-distribute-four.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-text-open-distribute-four.dev.v0",
            "base_eval": "raven-matrices-text-open-distribute-four",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/text-open/distribute_four.jsonl"
                    },
                    "key": "raven-matrices-text-open-distribute-four.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180925OJWNLTOZ",
            "created_at": "2023-07-21 18:09:25.693684"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-text-open-distribute-nine.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-text-open-distribute-nine.dev.v0",
            "base_eval": "raven-matrices-text-open-distribute-nine",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/text-open/distribute_nine.jsonl"
                    },
                    "key": "raven-matrices-text-open-distribute-nine.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180925JQG3OUKI",
            "created_at": "2023-07-21 18:09:25.695800"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-text-open-in-center-single-out-center-single.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-text-open-in-center-single-out-center-single.dev.v0",
            "base_eval": "raven-matrices-text-open-in-center-single-out-center-single",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/text-open/in_center_single_out_center_single.jsonl"
                    },
                    "key": "raven-matrices-text-open-in-center-single-out-center-single.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809257UYWJQVZ",
            "created_at": "2023-07-21 18:09:25.820258"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-text-open-in-distribute-four-out-center-single.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-text-open-in-distribute-four-out-center-single.dev.v0",
            "base_eval": "raven-matrices-text-open-in-distribute-four-out-center-single",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/text-open/in_distribute_four_out_center_single.jsonl"
                    },
                    "key": "raven-matrices-text-open-in-distribute-four-out-center-single.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180925DO4RPGAL",
            "created_at": "2023-07-21 18:09:25.884313"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-text-open-left-center-single-right-center-single.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-text-open-left-center-single-right-center-single.dev.v0",
            "base_eval": "raven-matrices-text-open-left-center-single-right-center-single",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/text-open/left_center_single_right_center_single.jsonl"
                    },
                    "key": "raven-matrices-text-open-left-center-single-right-center-single.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180925B7W4QGPH",
            "created_at": "2023-07-21 18:09:25.975985"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "raven-matrices-text-open-up-center-single-down-center-single.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "raven-matrices-text-open-up-center-single-down-center-single.dev.v0",
            "base_eval": "raven-matrices-text-open-up-center-single-down-center-single",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "raven-matrices/text-open/up_center_single_down_center_single.jsonl"
                    },
                    "key": "raven-matrices-text-open-up-center-single-down-center-single.dev.v0",
                    "group": "raven-matrices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180925X7H7PSKI",
            "created_at": "2023-07-21 18:09:25.978666"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "resistor-ohm-calculator.dev.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "resistor-ohm-calculator.dev.simple-v0",
            "base_eval": "resistor-ohm-calculator",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "resistor_ohm_calculator/samples.jsonl"
                    },
                    "key": "resistor-ohm-calculator.dev.simple-v0",
                    "group": "resistor-ohm-calculator"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180926BW2FNK72",
            "created_at": "2023-07-21 18:09:26.086715"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "reverse-polish-notation.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "reverse-polish-notation.dev.v0",
            "base_eval": "reverse-polish-notation",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "reverse-polish-notation/questions.jsonl"
                    },
                    "key": "reverse-polish-notation.dev.v0",
                    "group": "reverse-polish-notation"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180926KZHUSG6U",
            "created_at": "2023-07-21 18:09:26.152470"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "reverse-shell.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "reverse-shell.dev.v0",
            "base_eval": "reverse-shell",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "reverse-shell/samples.jsonl"
                    },
                    "key": "reverse-shell.dev.v0",
                    "group": "reverse-shell"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180926HRZ3NRCX",
            "created_at": "2023-07-21 18:09:26.176796"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "reverse-sort-words-eng-simple.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "reverse-sort-words-eng-simple.dev.v0",
            "base_eval": "reverse-sort-words-eng-simple",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "reverse-sort-words-eng/samples.jsonl"
                    },
                    "key": "reverse-sort-words-eng-simple.dev.v0",
                    "group": "reverse-sort-words-eng"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180926WGRHWAXN",
            "created_at": "2023-07-21 18:09:26.208464"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "rhetorical-devices.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "rhetorical-devices.dev.v0",
            "base_eval": "rhetorical-devices",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "rhetorical_devices/samples.jsonl"
                    },
                    "key": "rhetorical-devices.dev.v0",
                    "group": "rhetorical-devices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809265RL2NF6M",
            "created_at": "2023-07-21 18:09:26.231203"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "romanian-logic.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "romanian-logic.dev.v0",
            "base_eval": "romanian-logic",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "romanian-logic/romanian-logic.jsonl"
                    },
                    "key": "romanian-logic.dev.v0",
                    "group": "romanian-logic"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809266YXUSIQT",
            "created_at": "2023-07-21 18:09:26.259119"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "romanian_homonyms.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "romanian_homonyms.dev.v0",
            "base_eval": "romanian_homonyms",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "romanian_homonyms/samples.jsonl"
                    },
                    "key": "romanian_homonyms.dev.v0",
                    "group": "romanian_homonyms"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180926ISBHIADC",
            "created_at": "2023-07-21 18:09:26.277805"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "rubiks-colors.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "rubiks-colors.dev.v0",
            "base_eval": "rubiks-colors",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "rubiks-colors/samples.jsonl"
                    },
                    "key": "rubiks-colors.dev.v0",
                    "group": "rubiks-colors"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180926QOVUXPT2",
            "created_at": "2023-07-21 18:09:26.348318"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "russian-lexicon.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "russian-lexicon.dev.v0",
            "base_eval": "russian-lexicon",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "russian-lexicon/samples.jsonl"
                    },
                    "key": "russian-lexicon.dev.v0",
                    "group": "russian-lexicon"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180926CIYT7HU5",
            "created_at": "2023-07-21 18:09:26.376788"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "russian-verse.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "russian-verse.dev.v0",
            "base_eval": "russian-verse",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "russian-verse/samples.jsonl"
                    },
                    "key": "russian-verse.dev.v0",
                    "group": "russian-verse"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180926KIJFAHHJ",
            "created_at": "2023-07-21 18:09:26.393506"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "russian_sarcasm.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "russian_sarcasm.dev.v0",
            "base_eval": "russian_sarcasm",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "russian_sarcasm/samples.jsonl"
                    },
                    "key": "russian_sarcasm.dev.v0",
                    "group": "russian_sarcasm"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180926FB7Z37NC",
            "created_at": "2023-07-21 18:09:26.399609"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "seating_arrangements.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "seating_arrangements.dev.v0",
            "base_eval": "seating_arrangements",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "seating_arrangements/samples.jsonl"
                    },
                    "key": "seating_arrangements.dev.v0",
                    "group": "seating_arrangements"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180926ZW53CHM5",
            "created_at": "2023-07-21 18:09:26.421883"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "iqbal-poetry-translation.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug",
                "openai:gpt-3.5-turbo-16k-0613"
            ],
            "eval_name": "iqbal-poetry-translation.dev.v0",
            "base_eval": "iqbal-poetry-translation",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug",
                    "openai:gpt-3.5-turbo-16k-0613"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "iqbal-poetry-translation/samples.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "translation",
                        "modelgraded_spec_args": {
                            "language": "Urdu"
                        }
                    },
                    "key": "iqbal-poetry-translation.dev.v0",
                    "group": "iqbal-poetry-translation"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180919LK57UZNM",
            "created_at": "2023-07-21 18:09:19.903939"
        },
        "final_report": {
            "counts/N": 6,
            "counts/Y": 4,
            "score": 0.4
        }
    },
    "shape-in-shape.dev.v1.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "shape-in-shape.dev.v1",
            "base_eval": "shape-in-shape",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "shape_in_shape/shape_in_shape.jsonl"
                    },
                    "key": "shape-in-shape.dev.v1",
                    "group": "shape-in-shape"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180927LGTFTAHL",
            "created_at": "2023-07-21 18:09:27.158109"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "shared-borders.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "shared-borders.dev.v0",
            "base_eval": "shared-borders",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "shared_border/samples.jsonl"
                    },
                    "key": "shared-borders.dev.v0",
                    "group": "shared-borders"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180927EB4BXA4W",
            "created_at": "2023-07-21 18:09:27.192575"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "shopping_discount_comparison.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "shopping_discount_comparison.dev.v0",
            "base_eval": "shopping_discount_comparison",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "shopping_discount_comparison/samples.jsonl"
                    },
                    "key": "shopping_discount_comparison.dev.v0",
                    "group": "shopping_discount_comparison"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180927DCMDXGG4",
            "created_at": "2023-07-21 18:09:27.229635"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "simple-block-puzzles.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "simple-block-puzzles.dev.v0",
            "base_eval": "simple-block-puzzles",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "simple-block-puzzles/block-puzzles.v1.jsonl"
                    },
                    "key": "simple-block-puzzles.dev.v0",
                    "group": "simple-block-puzzles"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809276B7KVHEN",
            "created_at": "2023-07-21 18:09:27.257137"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "simple-charting.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "simple-charting.dev.v0",
            "base_eval": "simple-charting",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "simple-charting/samples.jsonl"
                    },
                    "key": "simple-charting.dev.v0",
                    "group": "simple-charting"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180927CHPEFSX7",
            "created_at": "2023-07-21 18:09:27.300074"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "simple-visual-understanding.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "simple-visual-understanding.dev.v0",
            "base_eval": "simple-visual-understanding",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "simple-visual-understanding/simple-visual-understanding.jsonl"
                    },
                    "key": "simple-visual-understanding.dev.v0",
                    "group": "simple-visual-understanding"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180927QAEFSNR4",
            "created_at": "2023-07-21 18:09:27.324651"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "simple_math.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "simple_math.dev.v0",
            "base_eval": "simple_math",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "simple_math/simple_math.jsonl"
                    },
                    "key": "simple_math.dev.v0",
                    "group": "simple_math"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180927YPKYTTDS",
            "created_at": "2023-07-21 18:09:27.344520"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "simple_physics_engine.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "simple_physics_engine.dev.v0",
            "base_eval": "simple_physics_engine",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "simple_physics_engine/samples.jsonl"
                    },
                    "key": "simple_physics_engine.dev.v0",
                    "group": "simple_physics_engine"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180927FTENWAH3",
            "created_at": "2023-07-21 18:09:27.368754"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "sindarin-fluency.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "sindarin-fluency.dev.v0",
            "base_eval": "sindarin-fluency",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "sindarin_fluency/sindarin_nouns.jsonl"
                    },
                    "key": "sindarin-fluency.dev.v0",
                    "group": "sindarin-fluency"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180927E6QNN6VE",
            "created_at": "2023-07-21 18:09:27.391004"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "singapore_data_protection_decisions.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "singapore_data_protection_decisions.dev.v0",
            "base_eval": "singapore_data_protection_decisions",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "singapore_data_protection_decisions/samples.jsonl"
                    },
                    "key": "singapore_data_protection_decisions.dev.v0",
                    "group": "singapore_data_protection_decisions"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180927RSQTKUZP",
            "created_at": "2023-07-21 18:09:27.420219"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "ru_rhyming_phrases.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug",
                "openai:gpt-3.5-turbo-16k-0613"
            ],
            "eval_name": "ru_rhyming_phrases.dev.v0",
            "base_eval": "ru_rhyming_phrases",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug",
                    "openai:gpt-3.5-turbo-16k-0613"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "ru_rhyming_phrases/samples.jsonl",
                        "modelgraded_spec": "closedqa",
                        "modelgraded_spec_args": {
                            "criteria": "correctness: Is the answer correct?"
                        }
                    },
                    "key": "ru_rhyming_phrases.dev.v0",
                    "group": "ru_rhymes"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180926OCGFN4WT",
            "created_at": "2023-07-21 18:09:26.308930"
        },
        "final_report": {
            "counts/Y": 1,
            "score": 1.0
        }
    },
    "solve-for-variable.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "solve-for-variable.dev.v0",
            "base_eval": "solve-for-variable",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "solve-for-variable/samples.jsonl"
                    },
                    "key": "solve-for-variable.dev.v0",
                    "group": "solve-for-variable"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180928VGZM6BOU",
            "created_at": "2023-07-21 18:09:28.864668"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "south-african-bands.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "south-african-bands.dev.v0",
            "base_eval": "south-african-bands",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "south-african-bands/south-african-bands.jsonl"
                    },
                    "key": "south-african-bands.dev.v0",
                    "group": "south-african-bands"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180928E66ZBW7O",
            "created_at": "2023-07-21 18:09:28.890813"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "spanish-lexicon.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "spanish-lexicon.dev.v0",
            "base_eval": "spanish-lexicon",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "spanish-lexicon/samples.jsonl"
                    },
                    "key": "spanish-lexicon.dev.v0",
                    "group": "spanish-lexicon"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180928WIOORUAP",
            "created_at": "2023-07-21 18:09:28.919877"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "spanish_feminine_noun_masculine_article.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "spanish_feminine_noun_masculine_article.dev.v0",
            "base_eval": "spanish_feminine_noun_masculine_article",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "spanish_feminine_noun_masculine_article/samples.jsonl"
                    },
                    "key": "spanish_feminine_noun_masculine_article.dev.v0",
                    "group": "spanish_feminine_noun_masculine_article"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180929H4NHF45M",
            "created_at": "2023-07-21 18:09:29.489325"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "squares-gpt.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "squares-gpt.dev.v0",
            "base_eval": "squares-gpt",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "squares-gpt/square-samples.jsonl"
                    },
                    "key": "squares-gpt.dev.v0",
                    "group": "squares-gpt"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180929M6OWFUEE",
            "created_at": "2023-07-21 18:09:29.518225"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "svg_alphabet.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "svg_alphabet.dev.v0",
            "base_eval": "svg_alphabet",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "svg_alphabet/samples.jsonl"
                    },
                    "key": "svg_alphabet.dev.v0",
                    "group": "svg_alphabet"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180929JMPJYFYM",
            "created_at": "2023-07-21 18:09:29.570444"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "svg_to_text.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "svg_to_text.dev.v0",
            "base_eval": "svg_to_text",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "svg_to_text/samples.jsonl"
                    },
                    "key": "svg_to_text.dev.v0",
                    "group": "svg_to_text"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180929RS4MYO7C",
            "created_at": "2023-07-21 18:09:29.602351"
        },
        "final_report": {
            "accuracy": 0.2,
            "boostrap_std": 0.13549774905879433
        }
    },
    "swedish_sat.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "swedish_sat.dev.v0",
            "base_eval": "swedish_sat",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "swedish_sat/samples.jsonl"
                    },
                    "key": "swedish_sat.dev.v0",
                    "group": "swedish_sat"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180929J6BJPHEF",
            "created_at": "2023-07-21 18:09:29.648384"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "syntax-check.dev.v1.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "syntax-check.dev.v1",
            "base_eval": "syntax-check",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "syntax-check/samples.jsonl"
                    },
                    "key": "syntax-check.dev.v1",
                    "group": "syntax-check"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180929PSZ5N3DX",
            "created_at": "2023-07-21 18:09:29.689367"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "test_english_pronunciations.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "test_english_pronunciations.dev.v0",
            "base_eval": "test_english_pronunciations",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "test_english_pronunciations/samples.jsonl"
                    },
                    "key": "test_english_pronunciations.dev.v0",
                    "group": "test_english_pronunciations"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180929ZPKNDQ4M",
            "created_at": "2023-07-21 18:09:29.719863"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "test_japanese_english_numerals.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "test_japanese_english_numerals.dev.v0",
            "base_eval": "test_japanese_english_numerals",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "test_japanese_english_numerals/samples.jsonl"
                    },
                    "key": "test_japanese_english_numerals.dev.v0",
                    "group": "test_japanese_english_numerals"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180929QCOWHH6E",
            "created_at": "2023-07-21 18:09:29.768506"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "test_japanese_radical.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "test_japanese_radical.dev.v0",
            "base_eval": "test_japanese_radical",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "test_japanese_radical/samples.jsonl"
                    },
                    "key": "test_japanese_radical.dev.v0",
                    "group": "test_japanese_radical"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180929PZVLOUQH",
            "created_at": "2023-07-21 18:09:29.796655"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "test-japanese-units.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "test-japanese-units.dev.v0",
            "base_eval": "test-japanese-units",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "test_japanese_units/samples.jsonl"
                    },
                    "key": "test-japanese-units.dev.v0",
                    "group": "test_japanese_units"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180929TQDNE4UG",
            "created_at": "2023-07-21 18:09:29.808854"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "tetris.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "tetris.dev.v0",
            "base_eval": "tetris",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "tetris/tetris.jsonl"
                    },
                    "key": "tetris.dev.v0",
                    "group": "tetris"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180929DYFGI5YE",
            "created_at": "2023-07-21 18:09:29.844114"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "thirty_six_stratagems.test.v1.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "thirty_six_stratagems.test.v1",
            "base_eval": "thirty_six_stratagems",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "thirty_six_stratagems/samples.jsonl"
                    },
                    "key": "thirty_six_stratagems.test.v1",
                    "group": "thirty_six_stratagems"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180929VTW2SROD",
            "created_at": "2023-07-21 18:09:29.866798"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "track_objects.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "track_objects.dev.v0",
            "base_eval": "track_objects",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "track_objects/samples.jsonl"
                    },
                    "key": "track_objects.dev.v0",
                    "group": "track_objects"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180929CMZOLMNM",
            "created_at": "2023-07-21 18:09:29.934060"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "test-time-zone-conversion.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "test-time-zone-conversion.dev.v0",
            "base_eval": "test-time-zone-conversion",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "test_time_zone_conversion/samples.v0.jsonl"
                    },
                    "key": "test-time-zone-conversion.dev.v0",
                    "group": "time-zone-conversion"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809292KXA7XO3",
            "created_at": "2023-07-21 18:09:29.889267"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "tokyo-station-number.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "tokyo-station-number.dev.v0",
            "base_eval": "tokyo-station-number",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "tokyo-station-number/samples.jsonl"
                    },
                    "key": "tokyo-station-number.dev.v0",
                    "group": "tokyo-station-number"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809295TWUXMUG",
            "created_at": "2023-07-21 18:09:29.910166"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "tricky-word-problems.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "tricky-word-problems.dev.v0",
            "base_eval": "tricky-word-problems",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "tricky-word-problems/samples.jsonl"
                    },
                    "key": "tricky-word-problems.dev.v0",
                    "group": "tricky-word-problems"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180929QWY6VIEJ",
            "created_at": "2023-07-21 18:09:29.960119"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "turkish_characters.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "turkish_characters.dev.v0",
            "base_eval": "turkish_characters",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "turkish_characters/samples.jsonl"
                    },
                    "key": "turkish_characters.dev.v0",
                    "group": "turkish_characters"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180929QRBZUEAL",
            "created_at": "2023-07-21 18:09:29.989425"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "ukraine-gec-fluency-style.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ukraine-gec-fluency-style.dev.v0",
            "base_eval": "ukraine-gec-fluency-style",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "ukraine_gec/ukraine_gec_fluency_style.jsonl"
                    },
                    "key": "ukraine-gec-fluency-style.dev.v0",
                    "group": "ukraine-gec"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930V6ZZY6MB",
            "created_at": "2023-07-21 18:09:30.016099"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "ukraine-gec-fluency-calque.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ukraine-gec-fluency-calque.dev.v0",
            "base_eval": "ukraine-gec-fluency-calque",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "ukraine_gec/ukraine_gec_fluency_calque.jsonl"
                    },
                    "key": "ukraine-gec-fluency-calque.dev.v0",
                    "group": "ukraine-gec"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930JSIQRE2X",
            "created_at": "2023-07-21 18:09:30.082064"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "ukraine-gec-fluency-poorflow.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ukraine-gec-fluency-poorflow.dev.v0",
            "base_eval": "ukraine-gec-fluency-poorflow",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "ukraine_gec/ukraine_gec_fluency_poorflow.jsonl"
                    },
                    "key": "ukraine-gec-fluency-poorflow.dev.v0",
                    "group": "ukraine-gec"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930JEE2TBMW",
            "created_at": "2023-07-21 18:09:30.124995"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "ukraine-gec-fluency-repetition.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ukraine-gec-fluency-repetition.dev.v0",
            "base_eval": "ukraine-gec-fluency-repetition",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "ukraine_gec/ukraine_gec_fluency_repetition.jsonl"
                    },
                    "key": "ukraine-gec-fluency-repetition.dev.v0",
                    "group": "ukraine-gec"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930KMMHLK52",
            "created_at": "2023-07-21 18:09:30.175584"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "ukraine-gec-fluency-other.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ukraine-gec-fluency-other.dev.v0",
            "base_eval": "ukraine-gec-fluency-other",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "ukraine_gec/ukraine_gec_fluency_other.jsonl"
                    },
                    "key": "ukraine-gec-fluency-other.dev.v0",
                    "group": "ukraine-gec"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930W2ASCZLK",
            "created_at": "2023-07-21 18:09:30.202830"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "ukraine-gec-grammar-aspect.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ukraine-gec-grammar-aspect.dev.v0",
            "base_eval": "ukraine-gec-grammar-aspect",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "ukraine_gec/ukraine_gec_grammar_aspect.jsonl"
                    },
                    "key": "ukraine-gec-grammar-aspect.dev.v0",
                    "group": "ukraine-gec"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930ORUDX255",
            "created_at": "2023-07-21 18:09:30.231308"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "ukraine-gec-grammar-case.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ukraine-gec-grammar-case.dev.v0",
            "base_eval": "ukraine-gec-grammar-case",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "ukraine_gec/ukraine_gec_grammar_case.jsonl"
                    },
                    "key": "ukraine-gec-grammar-case.dev.v0",
                    "group": "ukraine-gec"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809305N4XABBP",
            "created_at": "2023-07-21 18:09:30.253606"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "ukraine-gec-grammar-comparison.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ukraine-gec-grammar-comparison.dev.v0",
            "base_eval": "ukraine-gec-grammar-comparison",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "ukraine_gec/ukraine_gec_grammar_comparison.jsonl"
                    },
                    "key": "ukraine-gec-grammar-comparison.dev.v0",
                    "group": "ukraine-gec"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930HUPKZNXV",
            "created_at": "2023-07-21 18:09:30.298941"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "ukraine-gec-grammar-conjunction.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ukraine-gec-grammar-conjunction.dev.v0",
            "base_eval": "ukraine-gec-grammar-conjunction",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "ukraine_gec/ukraine_gec_grammar_conjunction.jsonl"
                    },
                    "key": "ukraine-gec-grammar-conjunction.dev.v0",
                    "group": "ukraine-gec"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930GSSAEZCB",
            "created_at": "2023-07-21 18:09:30.319998"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "singlestore-vectorsearch.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug",
                "openai:gpt-3.5-turbo-16k-0613"
            ],
            "eval_name": "singlestore-vectorsearch.dev.v0",
            "base_eval": "singlestore-vectorsearch",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug",
                    "openai:gpt-3.5-turbo-16k-0613"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "singlestore-vectorsearch/samples.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "singlestore"
                    },
                    "key": "singlestore-vectorsearch.dev.v0",
                    "group": "singlestore-vectorsearch"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180927WXZBQQRX",
            "created_at": "2023-07-21 18:09:27.442949"
        },
        "final_report": {
            "counts/Incorrect": 1,
            "counts/__invalid__": 1,
            "score": 0.0
        }
    },
    "linear-regression.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug",
                "openai:gpt-3.5-turbo-16k-0613"
            ],
            "eval_name": "linear-regression.dev.v0",
            "base_eval": "linear-regression",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug",
                    "openai:gpt-3.5-turbo-16k-0613"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "linear-regression/samples.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "regression-equation"
                    },
                    "key": "linear-regression.dev.v0",
                    "group": "linear-regression"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180921VR36FZTK",
            "created_at": "2023-07-21 18:09:21.133632"
        },
        "final_report": {
            "counts/N": 66,
            "counts/Y": 1,
            "score": 0.014925373134328358
        }
    },
    "ukraine-gec-grammar-gender.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ukraine-gec-grammar-gender.dev.v0",
            "base_eval": "ukraine-gec-grammar-gender",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "ukraine_gec/ukraine_gec_grammar_gender.jsonl"
                    },
                    "key": "ukraine-gec-grammar-gender.dev.v0",
                    "group": "ukraine-gec"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930AFIWFEEX",
            "created_at": "2023-07-21 18:09:30.356134"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "ukraine-gec-grammar-number.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ukraine-gec-grammar-number.dev.v0",
            "base_eval": "ukraine-gec-grammar-number",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "ukraine_gec/ukraine_gec_grammar_number.jsonl"
                    },
                    "key": "ukraine-gec-grammar-number.dev.v0",
                    "group": "ukraine-gec"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930CWY6YNDL",
            "created_at": "2023-07-21 18:09:30.366829"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "ukraine-gec-grammar-partvoice.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ukraine-gec-grammar-partvoice.dev.v0",
            "base_eval": "ukraine-gec-grammar-partvoice",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "ukraine_gec/ukraine_gec_grammar_partvoice.jsonl"
                    },
                    "key": "ukraine-gec-grammar-partvoice.dev.v0",
                    "group": "ukraine-gec"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930MRAAMYK2",
            "created_at": "2023-07-21 18:09:30.389307"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "ukraine-gec-grammar-tense.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ukraine-gec-grammar-tense.dev.v0",
            "base_eval": "ukraine-gec-grammar-tense",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "ukraine_gec/ukraine_gec_grammar_tense.jsonl"
                    },
                    "key": "ukraine-gec-grammar-tense.dev.v0",
                    "group": "ukraine-gec"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930SPCVNMKK",
            "created_at": "2023-07-21 18:09:30.466950"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "ukraine-gec-grammar-ungrammaticalstructure.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ukraine-gec-grammar-ungrammaticalstructure.dev.v0",
            "base_eval": "ukraine-gec-grammar-ungrammaticalstructure",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "ukraine_gec/ukraine_gec_grammar_ungrammaticalstructure.jsonl"
                    },
                    "key": "ukraine-gec-grammar-ungrammaticalstructure.dev.v0",
                    "group": "ukraine-gec"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930T2C5ZPO5",
            "created_at": "2023-07-21 18:09:30.475497"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "ukraine-gec-grammar-prep.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ukraine-gec-grammar-prep.dev.v0",
            "base_eval": "ukraine-gec-grammar-prep",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "ukraine_gec/ukraine_gec_grammar_prep.jsonl"
                    },
                    "key": "ukraine-gec-grammar-prep.dev.v0",
                    "group": "ukraine-gec"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930Z2N2QKW7",
            "created_at": "2023-07-21 18:09:30.428246"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "ukraine-gec-grammar-verbaform.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ukraine-gec-grammar-verbaform.dev.v0",
            "base_eval": "ukraine-gec-grammar-verbaform",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "ukraine_gec/ukraine_gec_grammar_verbaform.jsonl"
                    },
                    "key": "ukraine-gec-grammar-verbaform.dev.v0",
                    "group": "ukraine-gec"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930K7IM3WWT",
            "created_at": "2023-07-21 18:09:30.547425"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "ukraine-gec-grammar-verbvoice.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ukraine-gec-grammar-verbvoice.dev.v0",
            "base_eval": "ukraine-gec-grammar-verbvoice",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "ukraine_gec/ukraine_gec_grammar_verbvoice.jsonl"
                    },
                    "key": "ukraine-gec-grammar-verbvoice.dev.v0",
                    "group": "ukraine-gec"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "23072118093045QCHGN7",
            "created_at": "2023-07-21 18:09:30.550713"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "ukraine-gec-grammar-other.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "ukraine-gec-grammar-other.dev.v0",
            "base_eval": "ukraine-gec-grammar-other",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "ukraine_gec/ukraine_gec_grammar_other.jsonl"
                    },
                    "key": "ukraine-gec-grammar-other.dev.v0",
                    "group": "ukraine-gec"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930BQCBGRUQ",
            "created_at": "2023-07-21 18:09:30.581758"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": NaN
        }
    },
    "unique_combinations.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "unique_combinations.dev.v0",
            "base_eval": "unique_combinations",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "unique_combinations/samples.jsonl"
                    },
                    "key": "unique_combinations.dev.v0",
                    "group": "unique_combinations"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930DFFGUJNZ",
            "created_at": "2023-07-21 18:09:30.601267"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "urdu-lexicon.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "urdu-lexicon.dev.v0",
            "base_eval": "urdu-lexicon",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "urdu-lexicon/samples.jsonl"
                    },
                    "key": "urdu-lexicon.dev.v0",
                    "group": "urdu-lexicon"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930U5AAA6PC",
            "created_at": "2023-07-21 18:09:30.623841"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "urdu-transliteration.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "urdu-transliteration.dev.v0",
            "base_eval": "urdu-transliteration",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "urdu-transliteration/samples.jsonl"
                    },
                    "key": "urdu-transliteration.dev.v0",
                    "group": "urdu-transliteration"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930MWJKHXBQ",
            "created_at": "2023-07-21 18:09:30.680670"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "utah_real_estate.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "utah_real_estate.dev.v0",
            "base_eval": "utah_real_estate",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "utah_real_estate/samples.jsonl"
                    },
                    "key": "utah_real_estate.dev.v0",
                    "group": "utah_real_estate"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930A2LX6NO6",
            "created_at": "2023-07-21 18:09:30.691262"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "viewport_to_grid_size.dev.v3.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "viewport_to_grid_size.dev.v3",
            "base_eval": "viewport_to_grid_size",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "viewport_to_grid_size/samples.jsonl"
                    },
                    "key": "viewport_to_grid_size.dev.v3",
                    "group": "viewport_to_grid_size"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930GK772SQO",
            "created_at": "2023-07-21 18:09:30.705787"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "vigenere.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "vigenere.s1.simple-v0",
            "base_eval": "vigenere",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "vigenere/samples.jsonl"
                    },
                    "key": "vigenere.s1.simple-v0",
                    "group": "vigenere"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930ACBLZBLE",
            "created_at": "2023-07-21 18:09:30.739008"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "vintage_phone_keyboard_decode.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "vintage_phone_keyboard_decode.dev.v0",
            "base_eval": "vintage_phone_keyboard_decode",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "vintage_phone_keyboard_decode/samples.jsonl"
                    },
                    "key": "vintage_phone_keyboard_decode.dev.v0",
                    "group": "vintage_phone_keyboard_decode"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930R6HTQMNJ",
            "created_at": "2023-07-21 18:09:30.800738"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "wkt_understanding.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "wkt_understanding.dev.v0",
            "base_eval": "wkt_understanding",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "wkt_understanding/samples.jsonl"
                    },
                    "key": "wkt_understanding.dev.v0",
                    "group": "wkt_understanding"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930LYRMB3A4",
            "created_at": "2023-07-21 18:09:30.822453"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "word-association-related-words-2.test.v1.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "word-association-related-words-2.test.v1",
            "base_eval": "word-association-related-words-2",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "word_association/related_words_2.jsonl"
                    },
                    "key": "word-association-related-words-2.test.v1",
                    "group": "word-association"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2307211809304DFOQAJO",
            "created_at": "2023-07-21 18:09:30.844537"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "word-association-related-words-3.test.v1.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "word-association-related-words-3.test.v1",
            "base_eval": "word-association-related-words-3",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "word_association/related_words_3.jsonl"
                    },
                    "key": "word-association-related-words-3.test.v1",
                    "group": "word-association"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930IKGR64DD",
            "created_at": "2023-07-21 18:09:30.870220"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "word-association-related-words-5.test.v1.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "word-association-related-words-5.test.v1",
            "base_eval": "word-association-related-words-5",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "word_association/related_words_5.jsonl"
                    },
                    "key": "word-association-related-words-5.test.v1",
                    "group": "word-association"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930AO3WQRMV",
            "created_at": "2023-07-21 18:09:30.913929"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "word_vector_over_reliance.dev.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "word_vector_over_reliance.dev.simple-v0",
            "base_eval": "word_vector_over_reliance",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "word_vector_over_reliance/word_vector_over_reliance_samples.jsonl"
                    },
                    "key": "word_vector_over_reliance.dev.simple-v0",
                    "group": "word_vector_over_reliance"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930D2E7SV7W",
            "created_at": "2023-07-21 18:09:30.935031"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "word-association-related-words-4.test.v1.json": {
        "spec": {
            "completion_fns": [
                "debug:debug"
            ],
            "eval_name": "word-association-related-words-4.test.v1",
            "base_eval": "word-association-related-words-4",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "debug:debug"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "word_association/related_words_4.jsonl"
                    },
                    "key": "word-association-related-words-4.test.v1",
                    "group": "word-association"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180930ID7W2EVD",
            "created_at": "2023-07-21 18:09:30.895689"
        },
        "final_report": {
            "accuracy": 0.0,
            "boostrap_std": 0.0
        }
    },
    "seo-keywords.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "debug:debug",
                "openai:gpt-3.5-turbo-16k-0613"
            ],
            "eval_name": "seo-keywords.dev.v0",
            "base_eval": "seo-keywords",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "debug:debug",
                    "openai:gpt-3.5-turbo-16k-0613"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "seo_keywords/samples.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "seo_keywords"
                    },
                    "key": "seo-keywords.dev.v0",
                    "group": "seo_keywords"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./evaluate.py -b openai-evals -m dummy:dummy",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230721180926D6SCZZ3T",
            "created_at": "2023-07-21 18:09:26.456242"
        },
        "final_report": {
            "counts/0": 10,
            "score": 0.0
        }
    }
}