{
    "Pandas": [
        "[Begin of Missing Code]\nresult = df.reindex(List)\n[End of Missing Code]",
        "[Missing Code]\ndf_new = df.reindex(List)\nresult = sum(df_new['Type'] != df['Type'])\n[End of Missing Code]",
        "[Missing Code]\n```python\nfor col in df.columns:\n    s = df[col].value_counts()\n    df[col] = df[col].apply(lambda x: x if s[x] >= 2 else 'other')\nresult = df\n```",
        "[Missing Code]\n```python\nfor col in df.columns:\n    counts = df[col].value_counts()\n    mask = df[col].map(counts) < 3\n    df.loc[mask, col] = 'other'\nresult = df\n```",
        "[Missing Code]\n```python\nfor col in df.columns:\n    mask = df[col].map(df[col].value_counts()) < 2\n    df.loc[mask, col] = 'other'\nresult = df\n```",
        "[Missing Code]\n```python\nfor col in df.columns:\n    if col == 'Qu1':\n        s = df[col].value_counts()\n        df[col] = df[col].apply(lambda x: x if s[x] >= 3 else 'other')\n    else:\n        s = df[col].value_counts()\n        df[col] = df[col].apply(lambda x: x if s[x] >= 2 else 'other')\nresult = df\n```",
        "[Missing Code]\n```python\nfor col in ['Qu1', 'Qu2', 'Qu3']:\n    if col == 'Qu1':\n        s = df[col].value_counts()\n        df[col] = df[col].apply(lambda x: x if (s[x] >= 3 or x == 'apple') else 'other')\n    else:\n        s = df[col].value_counts()\n        df[col] = df[col].apply(lambda x: x if s[x] >= 2 else 'other')\nresult = df\n```",
        "[Begin of Missing Code]\nresult = pd.concat([df[df['keep_if_dup'] == 'Yes'], df[df['keep_if_dup'] == 'No'].drop_duplicates(subset='url', keep='first')])\n[End of Missing Code]",
        "[Begin of Missing Code]\ndf_yes = df[df['drop_if_dup'] == 'Yes'].drop_duplicates(subset='url', keep='first')\ndf_no = df[df['drop_if_dup'] == 'No']\nresult = pd.concat([df_yes, df_no]).sort_index()\n[End of Missing Code]",
        "[Begin of Missing Code]\ndf1 = df[df['keep_if_dup'] == 'Yes']\ndf2 = df[df['keep_if_dup'] == 'No'].drop_duplicates(subset='url', keep='last')\nresult = pd.concat([df1, df2]).sort_index()\n[End of Missing Code]",
        "[Missing Code]\n```python\ndef nested_dict(df):\n    if len(df.columns) == 1:\n        if df.values.size == 1: return df.values[0][0]\n        return df.values.squeeze()\n    grouped = df.groupby(df.columns[0])\n    d = {k: nested_dict(g.iloc[:,1:]) for k,g in grouped}\n    return d\n\nresult = nested_dict(df)\n```",
        "[Missing Code]\ndf['datetime'] = df['datetime'].dt.tz_localize(None)\n[End of Missing Code]",
        "[Missing Code]\n```python\ndf['datetime'] = df['datetime'].dt.tz_localize(None)\nresult = df\n```",
        "[Missing Code]\ndf['datetime'] = df['datetime'].dt.tz_localize(None)\ndf['datetime'] = df['datetime'].dt.strftime('%d-%b-%Y %H:%M:%S')\ndf = df.sort_values(by='datetime')\n[End of Missing Code]",
        "[Missing Code]\ndf['datetime'] = df['datetime'].dt.tz_localize(None)\ndf = df.sort_values(by='datetime')\n[End of Missing Code]",
        "[Begin of Missing Code]\ndef parse_message(message):\n    message = message.strip('[]')\n    pairs = message.split(',')\n    result = {}\n    for pair in pairs:\n        key, value = pair.split(':')\n        result[key.strip()] = value.strip() if value.strip() else 'none'\n    return result\n\ndf['message'] = df['message'].apply(parse_message)\nresult = pd.concat([df.drop(['message'], axis=1), df['message'].apply(pd.Series)], axis=1)\n[End of Missing Code]",
        "[Missing Code]\ndf.loc[df['product'].isin(products), 'score'] *= 10",
        "[Missing Code]\ndf.loc[~df['product'].isin(products), 'score'] *= 10",
        "```python\nimport pandas as pd\n\n\ndf = pd.DataFrame({'product': [1179160, 1066490, 1148126, 1069104, 1069105, 1160330, 1069098, 1077784, 1193369, 1179741],\n                   'score': [0.424654, 0.424509, 0.422207, 0.420455, 0.414603, 0.168784, 0.168749, 0.168738, 0.168703, 0.168684]})\nproducts = [[1069104, 1069105], [1066489, 1066491]]\n# [Begin of Missing Code]\nfor product_range in products:\n    df.loc[df['product'].between(product_range[0], product_range[1]), 'score'] *= 10\n# [End of Missing Code]\nresult = df\nprint(result)\n```",
        "[Missing Code]\n```python\nmask = df['product'].isin(products)\ndf.loc[mask, 'score'] = (df.loc[mask, 'score'] - df.loc[mask, 'score'].min()) / (df.loc[mask, 'score'].max() - df.loc[mask, 'score'].min())\n```",
        "[Begin of Missing Code]\ndf['category'] = df.apply(lambda x: df.columns[x.idxmax()], axis=1)\n[End of Missing Code]",
        "[Missing Code]\ndf['category'] = df.eq(0).dot(df.columns)",
        "[Missing Code]\ndf['category'] = df.apply(lambda row: [col for col in df.columns if row[col]==1], axis=1)",
        "[Missing Code]\ndf['Date'] = df['Date'].dt.strftime('%b-%Y')",
        "[Missing Code]\ndf['Date'] = df['Date'].dt.strftime('%d-%b-%Y')\n[End of Missing Code]",
        "[Begin of Missing Code]\nstart_date = '2019-01-17'\nend_date = '2019-02-20'\n\nmask = (df['Date'] > start_date) & (df['Date'] <= end_date)\ndf = df.loc[mask]\n\ndf['Date'] = df['Date'].dt.strftime('%d-%b-%Y %A')\n[End of Missing Code]",
        "[Missing Code]\ndf['#1'] = df['#1'].shift(1)\ndf['#1'].iloc[0] = df['#1'].iloc[-1]",
        "[Missing Code]\ndf['#1'] = df['#1'].shift(-1)\ndf['#1'].fillna(df['#1'].iloc[0], inplace=True)",
        "[Begin of Missing Code]\ndf['#1'] = df['#1'].shift(1)\ndf['#1'].iloc[0] = df['#1'].iloc[-1]\ndf['#2'] = df['#2'].shift(-1)\ndf['#2'].iloc[-1] = df['#2'].iloc[0]\n[End of Missing Code]",
        "[Missing Code]\n```python\nfrom sklearn.metrics import r2_score\nimport numpy as np\n\nmin_r2 = np.inf\nmin_df = None\nfor i in range(len(df)):\n    df['#1'] = df['#1'].shift(-1)\n    df.iloc[0, 0] = df.iloc[-1, 0]\n    r2 = r2_score(df['#1'], df['#2'])\n    if r2 < min_r2:\n        min_r2 = r2\n        min_df = df.copy()\ndf = min_df\n```",
        "[Missing Code]\ndf.columns = [col + 'X' for col in df.columns]",
        "[Missing Code]\ndf.columns = 'X' + df.columns\n[End of Missing Code]",
        "[Missing Code]\ndf.columns = ['X' + col if not col.endswith('X') else col for col in df.columns]\n[End of Missing Code]",
        "[Missing Code]\nagg_dict = {col: 'mean' for col in df.columns if 'val' in col}\nagg_dict['group_color'] = 'first'\nresult = df.groupby('group').agg(agg_dict)\n[End of Missing Code]",
        "[Missing Code]\nagg_dict = {col: 'sum' for col in df.columns if 'val' in col}\nagg_dict['group_color'] = 'first'\nresult = df.groupby('group').agg(agg_dict)\n[End of Missing Code]",
        "[Begin of Missing Code]\nagg_dict = {col: 'mean' if col.endswith('2') else 'sum' for col in df.columns if col not in ['group', 'group_color']}\nagg_dict['group_color'] = 'first'\nresult = df.groupby('group').agg(agg_dict)\n[End of Missing Code]",
        "[Missing Code]\nresult = df.loc[row_list, column_list].mean()",
        "[Missing Code]\nresult = df.loc[row_list, column_list].sum()\n[End of Missing Code]",
        "[Missing Code]\nresult = df.loc[row_list, column_list].sum()\nresult = result.drop(result.idxmax())\n[End of Missing Code]",
        "[Missing Code]\n```python\nresult = df.apply(lambda x: x.value_counts()).stack().sort_index(level=1)\n```",
        "[Missing Code]\n```python\nresult = df.isnull().sum()\n```",
        "[Missing Code]\n```python\nresult = \"\"\nfor col in df:\n    result += \"---- \" + col + \" ---\\n\"\n    result += str(df[col].value_counts()) + \"\\n\"\n```",
        "[Begin of Missing Code]\ndf.columns = df.iloc[0]\ndf = df.reindex(df.index.drop(0)).reset_index(drop=True)\nresult = df\n[End of Missing Code]",
        "[Begin of Missing Code]\ndf.columns = df.iloc[0].fillna('') + df.iloc[1].fillna('')\ndf = df.iloc[2:]\nresult = df.reset_index(drop=True)\n[End of Missing Code]",
        "```python\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame([[3,1,2],[np.nan,1,2],[np.nan,np.nan,2]],columns=['0','1','2'])\n# [Begin of Missing Code]\nresult = df.apply(lambda x: pd.Series(x.dropna().values.tolist() + x[x.isnull()].values.tolist()), axis=1)\n# [End of Missing Code]\nprint(result)",
        "```python\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame([[3,1,2],[1,2,np.nan],[2,np.nan,np.nan]],columns=['0','1','2'])\n# [Begin of Missing Code]\nresult = df.apply(lambda x: pd.Series(np.concatenate([x[x.isnull()].values, x[x.notnull()].values])), axis=1)\n# [End of Missing Code]\nprint(result)\n```",
        "```python\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame([[3,1,2],[np.nan,1,2],[np.nan,np.nan,2]],columns=['0','1','2'])\n# [Begin of Missing Code]\nresult = df.apply(lambda s: pd.Series(s.dropna().values, index=s.index[:len(s.dropna())]), axis=0)\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\ndf_above_thresh = df[df['value'] >= thresh]\ndf_below_thresh = df[df['value'] < thresh]\ndf_below_thresh = df_below_thresh.sum()\ndf_below_thresh.name = 'X'\nresult = df_above_thresh.append(df_below_thresh)\n```",
        "[Missing Code]\n```python\ndf_below_thresh = df[df['value'] < thresh]\ndf_above_thresh = df[df['value'] >= thresh]\navg_above_thresh = df_above_thresh['value'].mean()\nresult = df_below_thresh.append(pd.DataFrame({'value': avg_above_thresh}, index=['X']))\n```",
        "[Missing Code]\n```python\ndf_in_section = df[(df['value'] >= section_left) & (df['value'] <= section_right)]\ndf_out_section = df[(df['value'] < section_left) | (df['value'] > section_right)]\naverage_out_section = df_out_section['value'].mean()\ndf_out_section = pd.DataFrame({'value': [average_out_section]}, index=['X'])\nresult = pd.concat([df_in_section, df_out_section])\n```",
        "[Missing Code]\n```python\nresult = df.copy()\nfor col in df.columns:\n    result['inv_'+col] = 1/df[col]\n```",
        "[Missing Code]\n```python\nimport numpy as np\n\nfor col in df.columns:\n    df['exp_'+col] = np.exp(df[col])\nresult = df\n```",
        "[Missing Code]\n```python\nresult = df.copy()\nfor col in df.columns:\n    result['inv_'+col] = 1/df[col].replace(0, float('inf'))\n```",
        "```python\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n# [Begin of Missing Code]\nfor col in df.columns:\n    df['sigmoid_'+col] = 1 / (1 + np.exp(-df[col]))\nresult = df\n# [End of Missing Code]\nprint(result)\n```",
        "[Begin of Missing Code]\nresult = df.where(df.values == df.expanding().max().values).idxmax()\nresult = result.where(result <= df.idxmin())\n# [End of Missing Code]",
        "[Begin of Missing Code]\nresult = df.where(df.ge(df.min()).cumsum().gt(0)).idxmax()\n[End of Missing Code]",
        "[Missing Code]\n```python\ndf.set_index('dt', inplace=True)\ndf = df.groupby('user').resample('D').first()\ndf['user'].fillna(method='ffill', inplace=True)\ndf['val'].fillna(0, inplace=True)\ndf.reset_index(inplace=True)\nresult = df\n```",
        "[Missing Code]\n```python\ndf.set_index('dt', inplace=True)\ndf = df.groupby('user').resample('D').first().reset_index()\ndf['val'].fillna(0, inplace=True)\nresult = df\n```",
        "[Missing Code]\n```python\ndf.set_index('dt', inplace=True)\ndf = df.groupby('user').resample('D').asfreq()\ndf['val'].fillna(233, inplace=True)\ndf.reset_index(inplace=True)\nresult = df\n```",
        "[Missing Code]\n```python\ndf = df.set_index('dt').groupby('user').resample('D').first().reset_index()\ndf['val'] = df.groupby('user')['val'].transform(lambda x: x.ffill().fillna(x.max()))\nresult = df\n```",
        "[Missing Code]\n```python\ndf = df.sort_values(['user', 'dt'])\ndf['val'] = df.groupby('user')['val'].transform('max')\n\nr = pd.date_range(start=df.dt.min(), end=df.dt.max())\ndf = df.set_index('dt').reindex(r).fillna(method='ffill').rename_axis('dt').reset_index()\n\ndf['dt'] = df['dt'].dt.strftime('%d-%b-%Y')\nresult = df\n```",
        "[Missing Code]\ndf['name'] = df['name'].astype('category')\ndf['name'] = df['name'].cat.codes\nresult = df\n[End of Missing Code]",
        "[Missing Code]\ndf['a'] = df.groupby('name').cumcount() + 1\nresult = df\n[End of Missing Code]",
        "[Missing Code]\n```python\ndf['name'] = df['name'].astype('category')\ndf['name'] = df['name'].cat.codes\nresult = df\n```",
        "[Missing Code]\ndf['ID'] = (df['name'] + df['a'].astype(str)).astype('category').cat.codes\nresult = df.drop(['name', 'a'], axis=1)\n[End of Missing Code]",
        "[Missing Code]\ndf = df.melt(id_vars=['user', 'someBool'], var_name='date', value_name='value')\n[End of Missing Code]",
        "[Missing Code]\ndf = df.melt(id_vars='user', var_name='others', value_name='value')\n[End of Missing Code]",
        "[Missing Code]\ndf = df.melt(id_vars=['user', 'someBool'], var_name='date', value_name='value')\ndf = df.dropna(subset=['value'])\ndf = df.sort_values(by=['user'])\n[End of Missing Code]",
        "[Missing Code]\nresult = df.loc[df['c'] > 0.5, columns]",
        "[Missing Code]\nresult = df.loc[df['c'] > 0.45, columns].values\n[End of Missing Code]",
        "[Missing Code]\nresult = df.loc[df['c'] > 0.5, columns].values\n[End of Missing Code]",
        "[Solution Code]\n```python\nimport pandas as pd\ndef f(df, columns=['b', 'e']):\n    # [Begin of Missing Code]\n    result = df[df['c'] > 0.5][columns]\n    result['sum'] = result[columns].sum(axis=1)\n    # [End of Missing Code]\n    return result\n```",
        "[Missing Code]\nresult = df.loc[df['c'] > 0.5, columns]",
        "[Begin of Missing Code]\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.sort_values('date')\ndf['diff'] = df['date'].diff().dt.days\nresult = df[df['diff'].isna() | (df['diff'] > X)]\n[End of Missing Code]",
        "[Begin of Missing Code]\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.sort_values('date')\ndf['diff'] = df['date'].diff().dt.days\nresult = df[df['diff'] > X*7].drop('diff', axis=1)\n[End of Missing Code]",
        "[Begin of Missing Code]\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.sort_values('date')\ndf['diff'] = df['date'].diff().dt.days\ndf['diff'] = df['diff'].fillna(0)\ndf['diff'] = df['diff'].apply(lambda x: x/7)\nresult = df[df['diff'] >= X]\n[End of Missing Code]",
        "[Missing Code]\n```python\nresult = df.groupby(df.index // 3).mean()\n```",
        "[Missing Code]\n```python\ndf['group'] = df.index // 3\nresult = df.groupby('group')['col1'].mean().reset_index(drop=True)\n```",
        "[Missing Code]\n```python\ndf['group'] = df.index // 4\nresult = df.groupby('group').sum()\n```",
        "[Missing Code]\n```python\ndf = df.iloc[::-1]\nresult = df.rolling(3).mean().iloc[::-1]\nresult = result.dropna()\n```",
        "[Missing Code]\n```python\nresult = pd.DataFrame()\nresult['col1'] = [df['col1'][i:i+3].sum() if i%5<3 else df['col1'][i:i+2].mean() for i in range(0, len(df), 3 if i%5<3 else 2)]\n```",
        "[Missing Code]\n```python\ndf = df[::-1].reset_index(drop=True)\ngrouped = df.groupby(df.index // 3)\nresult = grouped['col1'].agg(['sum', 'mean']).stack().reset_index(drop=True)\nresult = result[::-1].reset_index(drop=True)\n```",
        "[Missing Code]\n```python\ndf['A'] = df['A'].replace(0, pd.np.nan)\ndf['A'] = df['A'].fillna(method='ffill')\n```",
        "[Missing Code]\n```python\ndf['A'] = df['A'].replace(0, pd.np.nan)\ndf['A'] = df['A'].fillna(method='bfill')\n```",
        "[Missing Code]\n```python\ndf['A'] = df['A'].replace(0, pd.np.nan)\ndf['A'] = df['A'].fillna(method='ffill').where(df['A'].fillna(method='ffill') >= df['A'].fillna(method='bfill'), df['A'].fillna(method='bfill'))\n```",
        "[Missing Code]\ndf['number'] = df['duration'].str.extract('(\\d+)').astype(int)\ndf['time'] = df['duration'].str.extract('([a-zA-Z]+)')\ndf['time_days'] = df['time'].replace({'year': 365, 'month': 30, 'week': 7, 'day': 1})",
        "[Missing Code]\ndf['number'] = df['duration'].str.extract('(\\d+)', expand=False)\ndf['time'] = df['duration'].str.extract('([a-zA-Z]+)', expand=False)\ndf['time_day'] = df['time'].map({'year': 365, 'month': 30, 'week': 7, 'day': 1})\n[End of Missing Code]",
        "[Solution Code]\n```python\nimport pandas as pd\n\nexample_df = pd.DataFrame({'duration': ['7 year', '2day', '4 week', '8 month']},\n                  index=list(range(1,5)))\ndef f(df=example_df):\n    # [Begin of Missing Code]\n    df['number'] = df['duration'].str.extract('(\\d+)').astype(int)\n    df['time'] = df['duration'].str.extract('([a-zA-Z]+)')\n    df['time_days'] = df['time'].map({'year': 365, 'day': 1, 'week': 7, 'month': 30})\n    # [End of Missing Code]\n    return df\n```\n[Instruction]\nFix the [Missing Code] part to complete the [Solution Code]. You must use the [Begin of Missing Code] and [End of Missing Code] and only put the fixed code inside these tags. Do not output anything else.",
        "[Missing Code]\ndf['number'] = df['duration'].str.extract('(\\d+)').astype(int)\ndf['time'] = df['duration'].str.extract('([a-zA-Z]+)')\ndf['time_day'] = df['time'].map({'year': 365, 'month': 30, 'week': 7, 'day': 1})\ndf['time_day'] = df['time_day'] * df['number']\n[End of Missing Code]",
        "[Missing Code]\n```python\nresult = (df1[columns_check_list] != df2[columns_check_list]).any(axis=1).tolist()\n```",
        "[Begin of Missing Code]\nresult = (df1[columns_check_list] == df2[columns_check_list]).all(axis=1).tolist()\n[End of Missing Code]",
        "```python\nimport pandas as pd\n\n\nindex = pd.MultiIndex.from_tuples([('abc', '3/1/1994'), ('abc', '9/1/1994'), ('abc', '3/1/1995')],\n                                 names=('id', 'date'))\ndf = pd.DataFrame({'x': [100, 90, 80], 'y':[7, 8, 9]}, index=index)\n# [Begin of Missing Code]\ndf.reset_index(level=1, inplace=True)\ndf['date'] = pd.to_datetime(df['date'])\ndf.set_index('date', append=True, inplace=True)\n# [End of Missing Code]\nresult = df\nprint(result)\n```",
        "```python\nimport pandas as pd\n\n\nindex = pd.MultiIndex.from_tuples([('abc', '3/1/1994'), ('abc', '9/1/1994'), ('abc', '3/1/1995')],\n                                 names=('name', 'datetime'))\ndf = pd.DataFrame({'fee': [100, 90, 80], 'credits':[7, 8, 9]}, index=index)\n# [Begin of Missing Code]\ndf.reset_index(inplace=True)\ndf['datetime'] = pd.to_datetime(df['datetime'])\ndf.set_index(['name', 'datetime'], inplace=True)\n# [End of Missing Code]\nresult = df\nprint(result)\n```",
        "[Solution Code]\n```python\nimport pandas as pd\ndef f(df):\n    # [Begin of Missing Code]\n    df = df.reset_index()\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.values\n    # [End of Missing Code]\n    return df\n```",
        "[Missing Code]\n```python\ndf.index = pd.MultiIndex.from_tuples([(i[1], pd.to_datetime(i[0])) for i in df.index.values])\ndf = df.swaplevel(0, 1)\n```",
        "[Begin of Missing Code]\ndf = df.melt(id_vars=['Country', 'Variable'], var_name='year')\ndf = df.pivot_table(index=['Country', 'year'], columns='Variable', values='value').reset_index()\ndf.columns.name = None\n# [End of Missing Code]",
        "[Begin of Missing Code]\ndf = df.melt(id_vars=['Country', 'Variable'], var_name='year')\ndf['year'] = df['year'].astype(int)\ndf = df.sort_values(['Country', 'Variable', 'year'], ascending=[True, True, False])\ndf = df.pivot_table(index=['Country', 'year'], columns='Variable', values='value').reset_index()\ndf.columns.name = None\n[End of Missing Code]",
        "[Missing Code]\nvalue_cols = [col for col in df.columns if 'Value' in col]\ndf = df[df[value_cols].abs().max(axis=1) < 1]",
        "[Begin of Missing Code]\nvalue_cols = [col for col in df.columns if 'Value' in col]\ndf = df[df[value_cols].abs().max(axis=1) > 1]\n[End of Missing Code]",
        "[Begin of Missing Code]\nvalue_cols = [col for col in df.columns if 'Value' in col]\ndf = df[df[value_cols].abs().max(axis=1) > 1]\ndf.columns = [col.replace('Value_', '') for col in df.columns]\n[End of Missing Code]",
        "[Missing Code]\n```python\ndf = df.replace('&AMP;', '&', regex=True)\n```",
        "[Missing Code]\n```python\ndf = df.replace('&LT;', '<', regex=True)\n```",
        "[Missing Code]\n```python\nfor col in df.columns:\n    df[col] = df[col].replace('&AMP;', '&', regex=True)\nresult = df\n```",
        "[Missing Code]\n```python\ndf = df.replace({'&AMP;': '&', '&LT;': '<', '&GT;': '>'}, regex=True)\n```",
        "[Missing Code]\n```python\ndf = df.replace({'&AMP;': '&'}, regex=True)\ndf['A'] = df['A'].replace({'1 & 1': '1 & 1 = 1', '1 & 0': '1 & 0 = 0'}, regex=True)\ndf['C'] = df['C'].replace({'0 & 0': '0 & 0 = 0'}, regex=True)\n```",
        "[Missing Code]\n```python\ndef split_name(name):\n    parts = name.split()\n    if len(parts) == 2:\n        return pd.Series((parts[0], parts[1]))\n    else:\n        return pd.Series((name, None))\n\ndf[['first_name', 'last_name']] = df['name'].apply(split_name)\n```",
        "[Missing Code]\n```python\ndef split_name(name):\n    parts = name.split()\n    if len(parts) == 2:\n        return pd.Series([parts[0], parts[1]])\n    else:\n        return pd.Series([name, None])\n\ndf[['1_name', '2_name']] = df['name'].apply(split_name)\n```",
        "```python\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({'name':['Jack Fine','Kim Q. Danger','Jane 114 514 Smith', 'Zhongli']})\n# [Begin of Missing Code]\ndf['name_split'] = df['name'].str.split(' ')\ndf['first_name'] = df['name_split'].apply(lambda x: x[0])\ndf['middle_name'] = df['name_split'].apply(lambda x: ' '.join(x[1:-1]) if len(x) > 2 else np.nan)\ndf['last_name'] = df['name_split'].apply(lambda x: x[-1] if len(x) > 1 else np.nan)\ndf.drop(columns=['name', 'name_split'], inplace=True)\n# [End of Missing Code]\nresult = df\nprint(result)\n```",
        "[Begin of Missing Code]\ndf1.set_index('Timestamp', inplace=True)\ndf2.set_index('Timestamp', inplace=True)\nresult = df2.join(df1, how='left')\n[End of Missing Code]",
        "```python\n# [Begin of Missing Code]\ndf1.set_index('Timestamp', inplace=True)\ndf2.set_index('Timestamp', inplace=True)\nresult = df1.join(df2, how='left')\n# [End of Missing Code]```",
        "[Missing Code]\ndf['state'] = df.apply(lambda row: row['col1'] if row['col2'] <= 50 and row['col3'] <= 50 else max(row['col1'], row['col2'], row['col3']), axis=1)",
        "[Begin of Missing Code]\ndf['state'] = df.apply(lambda row: row['col1'] if row['col2']>50 and row['col3']>50 else row['col1']+row['col2']+row['col3'], axis=1)\n[End of Missing Code]",
        "[Missing Code]\n```python\nerrors = []\nfor index, row in df.iterrows():\n    if not isinstance(row['Field1'], int):\n        errors.append(row['Field1'])\nresult = errors\n```",
        "[Missing Code]\n```python\nresult = [x for x in df['Field1'] if isinstance(x, int)]\n```",
        "[Missing Code]\n```python\nresult = []\nfor index, row in df.iterrows():\n    if not isinstance(row['Field1'], int):\n        result.append(row['Field1'])\n```",
        "[Missing Code]\ndf.set_index('cat', inplace=True)\ndf = df.div(df.sum(axis=1), axis=0)\ndf.reset_index(inplace=True)",
        "[Missing Code]\ndf.iloc[:, 1:] = df.iloc[:, 1:].div(df.iloc[:, 1:].sum(), axis='columns')\n[End of Missing Code]",
        "[Begin of Missing Code]\nresult = df.loc[test]\n[End of Missing Code]",
        "[Begin of Missing Code]\nresult = df.loc[test]\n[End of Missing Code]",
        "[Missing Code]\nresult = df.drop(test)\n[End of Missing Code]",
        "[Missing Code]\n```python\nresult = df.loc[test].drop_duplicates()\n```",
        "[Missing Code]\n```python\nfrom scipy.spatial import distance_matrix\n\ndef nearest_neighbour(df):\n    dist_matrix = distance_matrix(df[['x', 'y']].values, df[['x', 'y']].values)\n    np.fill_diagonal(dist_matrix, np.inf)\n    nearest_neighbour = np.argmin(dist_matrix, axis=1)\n    euclidean_distance = np.min(dist_matrix, axis=1)\n    df['nearest_neighbour'] = df.iloc[nearest_neighbour]['car'].values\n    df['euclidean_distance'] = euclidean_distance\n    return df\n\ndf = df.groupby('time').apply(nearest_neighbour)\n```",
        "[Missing Code]\n```python\nfrom scipy.spatial.distance import pdist, squareform\nfrom itertools import combinations\n\ndef get_farthest_neighbour(group):\n    if len(group) == 1:\n        return pd.DataFrame({'car': group['car'], 'farthest_neighbour': [None], 'euclidean_distance': [None]})\n    else:\n        dist_matrix = pdist(group[['x', 'y']])\n        dist_matrix = squareform(dist_matrix)\n        np.fill_diagonal(dist_matrix, -1)\n        farthest_neighbour = np.argmax(dist_matrix, axis=1)\n        euclidean_distance = np.max(dist_matrix, axis=1)\n        return pd.DataFrame({'car': group['car'], 'farthest_neighbour': group['car'].iloc[farthest_neighbour], 'euclidean_distance': euclidean_distance})\n\ndf = df.groupby('time').apply(get_farthest_neighbour).reset_index()\n```",
        "```python\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.DataFrame({'keywords_0':[\"a\", np.nan, \"c\"], \n                'keywords_1':[\"d\", \"e\", np.nan],\n                'keywords_2':[np.nan, np.nan, \"b\"],\n                'keywords_3':[\"f\", np.nan, \"g\"]})\n# [Begin of Missing Code]\ndf['keywords_all'] = df.apply(lambda row: ','.join(row.dropna().astype(str)), axis=1)\n# [End of Missing Code]\nresult = df\nprint(result)\n```",
        "```python\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.DataFrame({'keywords_0':[\"a\", np.nan, \"c\"], \n                'keywords_1':[\"d\", \"e\", np.nan],\n                'keywords_2':[np.nan, np.nan, \"b\"],\n                'keywords_3':[\"f\", np.nan, \"g\"]})\n# [Begin of Missing Code]\ndf['keywords_all'] = df.apply(lambda row: '-'.join(row.dropna().astype(str)), axis=1)\n# [End of Missing Code]\nresult = df\nprint(result)\n```",
        "```python\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.DataFrame({'users': ['Hu Tao', 'Zhongli', 'Xingqiu'],\n                   'keywords_0': [\"a\", np.nan, \"c\"],\n                   'keywords_1': [\"d\", \"e\", np.nan],\n                   'keywords_2': [np.nan, np.nan, \"b\"],\n                   'keywords_3': [\"f\", np.nan, \"g\"]})\n# [Begin of Missing Code]\ndf['keywords_all'] = df[['keywords_0', 'keywords_1', 'keywords_2', 'keywords_3']].apply(lambda x: '-'.join(x.dropna().astype(str)), axis=1)\n# [End of Missing Code]\nresult = df\nprint(result)\n```",
        "```python\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.DataFrame({'users': ['Hu Tao', 'Zhongli', 'Xingqiu'],\n                   'keywords_0': [\"a\", np.nan, \"c\"],\n                   'keywords_1': [\"d\", \"e\", np.nan],\n                   'keywords_2': [np.nan, np.nan, \"b\"],\n                   'keywords_3': [\"f\", np.nan, \"g\"]})\n# [Begin of Missing Code]\ncols = ['keywords_0', 'keywords_1', 'keywords_2', 'keywords_3']\ndf['keywords_all'] = df[cols].apply(lambda row: '-'.join(row.dropna().values[::-1]), axis=1)\n# [End of Missing Code]\nresult = df\nprint(result)\n```",
        "[Missing Code]\n```python\nsample = df.sample(frac=0.2, random_state=0)\ndf.loc[sample.index, 'Quantity'] = 0\n```",
        "[Missing Code]\n```python\nsample = df.sample(frac=0.2, random_state=0)\ndf.loc[sample.index, 'ProductId'] = 0\n```",
        "[Begin of Missing Code]\nfor user in df['UserId'].unique():\n    user_rows = df[df['UserId'] == user]\n    sample_rows = user_rows.sample(frac=0.2, random_state=0)\n    df.loc[sample_rows.index, 'Quantity'] = 0\n[End of Missing Code]",
        "```python\nimport pandas as pd\n\n\ndf=pd.DataFrame(data=[[1,2],[3,4],[1,2],[1,4],[1,2]],columns=['col1','col2'])\n# [Begin of Missing Code]\nduplicate_bool = df.duplicated(subset=['col1','col2'], keep='first')\nduplicate = df.loc[duplicate_bool == True]\nfirst_duplicate_index = df.drop_duplicates(subset=['col1','col2'], keep='first').reset_index()\nfirst_duplicate_index = first_duplicate_index.rename(columns={'index':'index_original'})\nresult = pd.merge(duplicate, first_duplicate_index, on=['col1','col2'], how='left')\n# [End of Missing Code]\nprint(result)\n```",
        "```python\nimport pandas as pd\n\ndf=pd.DataFrame(data=[[1,2],[3,4],[1,2],[1,4],[1,2]],columns=['col1','col2'])\n# [Begin of Missing Code]\nduplicate_bool = df.duplicated(subset=['col1','col2'], keep='last')\nduplicate = df.loc[duplicate_bool == True]\nduplicate['index_original'] = duplicate.apply(lambda row: df[(df['col1'] == row['col1']) & (df['col2'] == row['col2'])].index[-1], axis=1)\nresult = duplicate\n# [End of Missing Code]\nprint(result)\n```",
        "```python\nimport pandas as pd\n\nexample_df=pd.DataFrame(data=[[1,2],[3,4],[1,2],[1,4],[1,2]],columns=['col1','col2'])\ndef f(df=example_df):\n    # [Begin of Missing Code]\n    duplicate_bool = df.duplicated(subset=['col1','col2'], keep='first')\n    duplicate = df.loc[duplicate_bool == True]\n    duplicate['index_original'] = duplicate.groupby(['col1','col2']).cumcount()\n    result = duplicate\n    # [End of Missing Code]\n    return result\n```",
        "```python\nimport pandas as pd\n\ndf=pd.DataFrame(data=[[1,1,2,5],[1,3,4,1],[4,1,2,5],[5,1,4,9],[1,1,2,5]],columns=['val', 'col1','col2','3col'])\n# [Begin of Missing Code]\ndf['index_original'] = df.duplicated(subset=['col1','col2', '3col'], keep='first').groupby(df[['col1','col2', '3col']].apply(tuple)).cumcount()\nresult = df[df['index_original'] != 0]\n# [End of Missing Code]\nprint(result)\n```",
        "```python\nimport pandas as pd\n\n\ndf=pd.DataFrame(data=[[1,1,2,5],[1,3,4,1],[4,1,2,5],[5,1,4,9],[1,1,2,5]],columns=['val', 'col1','col2','3col'])\n# [Begin of Missing Code]\ndf['index_original'] = df.duplicated(subset=['col1','col2'], keep=False).groupby(df[['col1','col2']].apply(tuple,1)).cumsum()\ndf['index_original'] = df['index_original'].map(df[df.duplicated(subset=['col1','col2'], keep=False)].groupby(['col1','col2']).apply(lambda x: x.index[-1]))\nresult = df[df.duplicated(subset=['col1','col2'], keep='first')]\n# [End of Missing Code]\nprint(result)\n```",
        "```python\nimport pandas as pd\n\n\ndf = pd.DataFrame({'Sp': ['MM1', 'MM1', 'MM1', 'MM2', 'MM2', 'MM2', 'MM4', 'MM4', 'MM4'],\n                   'Mt': ['S1', 'S1', 'S3', 'S3', 'S4', 'S4', 'S2', 'S2', 'S2'],\n                   'Value': ['a', 'n', 'cb', 'mk', 'bg', 'dgd', 'rd', 'cb', 'uyi'],\n                   'count': [3, 2, 5, 8, 10, 1, 2, 2, 7]})\n# [Begin of Missing Code]\nidx = df.groupby(['Sp','Mt'])['count'].transform(max) == df['count']\nresult = df[idx]\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\nresult = df.loc[df.groupby(['Sp','Mt'])['count'].idxmax()]\n```",
        "```python\nimport pandas as pd\n\n\ndf = pd.DataFrame({'Sp': ['MM1', 'MM1', 'MM1', 'MM2', 'MM2', 'MM2', 'MM4', 'MM4', 'MM4'],\n                   'Mt': ['S1', 'S1', 'S3', 'S3', 'S4', 'S4', 'S2', 'S2', 'S2'],\n                   'Value': ['a', 'n', 'cb', 'mk', 'bg', 'dgd', 'rd', 'cb', 'uyi'],\n                   'count': [3, 2, 5, 8, 10, 1, 2, 2, 7]})\n# [Begin of Missing Code]\nidx = df.groupby(['Sp','Mt'])['count'].transform(min) == df['count']\nresult = df[idx]\n# [End of Missing Code]\nprint(result)\n```",
        "[Begin of Missing Code]\nresult = df[df.groupby(['Sp','Value'])['count'].transform(max) == df['count']]\n[End of Missing Code]",
        "[Begin of Missing Code]\nresult = df[df['Category'].isin(filter_list)]\n[End of Missing Code]",
        "[Missing Code]\nresult = df[~df['Category'].isin(filter_list)]",
        "[Missing Code]\n```python\nresult = pd.melt(df, value_vars=df.columns.tolist())\n```",
        "[Begin of Missing Code]\ndf.columns = df.columns.map('_'.join)\ndf = df.reset_index().melt(id_vars='index', var_name=['variable_0', 'variable_1', 'variable_2'])\nresult = df.sort_values(['variable_0', 'variable_1', 'variable_2']).drop('index', axis=1).reset_index(drop=True)\n[End of Missing Code]",
        "[Begin of Missing Code]\ndf['cumsum'] = df.groupby('id')['val'].cumsum()\n[End of Missing Code]",
        "```python\nimport pandas as pd\n\ndf = pd.DataFrame.from_dict({'id': ['A', 'B', 'A', 'C', 'D', 'B', 'C'],\n                             'val': [1,2,-3,1,5,6,-2],\n                             'stuff':['12','23232','13','1234','3235','3236','732323']})\n# [Begin of Missing Code]\ndf['cumsum'] = df.groupby('id')['val'].cumsum()\n# [End of Missing Code]\nprint(df)\nresult = df\n```",
        "[Begin of Missing Code]\ndf['cumsum'] = df.groupby('id')['val'].cumsum()\n[End of Missing Code]",
        "[Begin of Missing Code]\ndf['cummax'] = df.groupby('id')['val'].cummax()\n[End of Missing Code]",
        "```python\nimport pandas as pd\n\ndf = pd.DataFrame.from_dict({'id': ['A', 'B', 'A', 'C', 'D', 'B', 'C'],\n                             'val': [1,2,-3,1,5,6,-2],\n                             'stuff':['12','23232','13','1234','3235','3236','732323']})\n# [Begin of Missing Code]\ndf['cumsum'] = df.groupby('id')['val'].cumsum()\ndf['cumsum'] = df['cumsum'].clip(lower=0)\n# [End of Missing Code]\nprint(df)\nresult = df\n```",
        "[Missing Code]\n```python\nresult = df.groupby('l')['v'].apply(lambda x: x.sum(skipna=False))\n```",
        "[Missing Code]\n```python\nresult = df.groupby('r')['v'].apply(lambda x: np.sum(x) if not x.isnull().any() else np.nan)\n```",
        "```python\nimport pandas as pd\nimport numpy as np\n\n\nd = {'l':  ['left', 'right', 'left', 'right', 'left', 'right'],\n     'r': ['right', 'left', 'right', 'left', 'right', 'left'],\n     'v': [-1, 1, -1, 1, -1, np.nan]}\ndf = pd.DataFrame(d)\n# [Begin of Missing Code]\nresult = df.groupby('l')['v'].apply(lambda x: np.sum(x) if not x.isnull().any() else np.nan).reset_index()\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\nresult = []\nfor col1 in df.columns:\n    for col2 in df.columns:\n        if col1 != col2:\n            if df[col1].nunique() == df[col2].nunique():\n                if df[col1].nunique() == len(df):\n                    result.append(f'{col1} {col2} one-to-one')\n                else:\n                    result.append(f'{col1} {col2} many-to-many')\n            elif df[col1].nunique() > df[col2].nunique():\n                result.append(f'{col1} {col2} one-to-many')\n            else:\n                result.append(f'{col1} {col2} many-to-one')\n```\n[End of Missing Code]",
        "[Missing Code]\n```python\ndef relationship_type(df, col1, col2):\n    if df[col1].is_unique and df[col2].is_unique:\n        return 'one-2-one'\n    elif df[col1].is_unique and not df[col2].is_unique:\n        return 'one-2-many'\n    elif not df[col1].is_unique and df[col2].is_unique:\n        return 'many-2-one'\n    else:\n        return 'many-2-many'\n\nresult = []\nfor col1 in df.columns:\n    for col2 in df.columns:\n        if col1 != col2:\n            result.append(f'{col1} {col2} {relationship_type(df, col1, col2)}')\n```",
        "[Missing Code]\n```python\ndef relationship_type(df, col1, col2):\n    if df[col1].is_unique and df[col2].is_unique:\n        return 'one-to-one'\n    elif df[col1].is_unique and not df[col2].is_unique:\n        return 'one-to-many'\n    elif not df[col1].is_unique and df[col2].is_unique:\n        return 'many-to-one'\n    else:\n        return 'many-to-many'\n\nresult = pd.DataFrame(index=df.columns, columns=df.columns)\n\nfor col1 in df.columns:\n    for col2 in df.columns:\n        if col1 != col2:\n            result.loc[col1, col2] = relationship_type(df, col1, col2)\n```\n",
        "[Missing Code]\n```python\ndef relationship_type(df, col1, col2):\n    if df[col1].is_unique and df[col2].is_unique:\n        return 'one-2-one'\n    elif df[col1].is_unique and not df[col2].is_unique:\n        return 'one-2-many'\n    elif not df[col1].is_unique and df[col2].is_unique:\n        return 'many-2-one'\n    else:\n        return 'many-2-many'\n\nresult = pd.DataFrame(index=df.columns, columns=df.columns)\n\nfor col1 in df.columns:\n    for col2 in df.columns:\n        if col1 != col2:\n            result.loc[col1, col2] = relationship_type(df, col1, col2)\n```\n[End of Missing Code]",
        "[Missing Code]\n```python\n# sort by bank column in descending order so that NaN values will be at the end\ndf = df.sort_values(by='bank', ascending=False)\n\n# drop duplicates based on firstname, lastname, email and keep the first one which will be the one with bank account\nresult = df.drop_duplicates(subset=['firstname', 'lastname', 'email'], keep='first')\n```",
        "```python\nimport pandas as pd\n\n\ns = pd.Series(['2,144.78', '2,036.62', '1,916.60', '1,809.40', '1,711.97', '6,667.22', '5,373.59', '4,071.00', '3,050.20', '-0.06', '-1.88', '', '-0.13', '', '-0.14', '0.07', '0', '0'],\n              index=['2016-10-31', '2016-07-31', '2016-04-30', '2016-01-31', '2015-10-31', '2016-01-31', '2015-01-31', '2014-01-31', '2013-01-31', '2016-09-30', '2016-06-30', '2016-03-31', '2015-12-31', '2015-09-30', '2015-12-31', '2014-12-31', '2013-12-31', '2012-12-31'])\n# [Begin of Missing Code]\nresult = pd.to_numeric(s.str.replace(',',''), errors='coerce')\n# [End of Missing Code]\nprint(result)\n```",
        "[Begin of Missing Code]\ndf['Family'] = ['Has Family' if x > 0 or y > 0 else 'No Family' for x, y in zip(df['SibSp'], df['Parch'])]\nresult = df.groupby('Family')['Survived'].mean()\n[End of Missing Code]",
        "[Begin of Missing Code]\ndf['Group'] = ['Has Family' if x > 0 or y > 0 else 'No Family' for x, y in zip(df['Survived'], df['Parch'])]\nresult = df.groupby('Group')['SibSp'].mean()\n[End of Missing Code]",
        "[Missing Code]\ndf['Family'] = pd.np.select(\n    [\n        (df['SibSp'] == 1) & (df['Parch'] == 1), \n        (df['SibSp'] == 0) & (df['Parch'] == 0), \n        (df['SibSp'] == 0) & (df['Parch'] == 1), \n        (df['SibSp'] == 1) & (df['Parch'] == 0)\n    ], \n    [\n        'Has Family', \n        'No Family', \n        'New Family', \n        'Old Family'\n    ], \n    default='Unknown'\n)\n\nresult = df.groupby('Family')['Survived'].mean()",
        "[Begin of Missing Code]\ndf = df.sort_values(['cokey', 'A'])\ndf.set_index(['cokey'], inplace=True)\nresult = df\n[End of Missing Code]",
        "```python\nimport pandas as pd\n\n\ndf = pd.DataFrame({'cokey':[11168155,11168155,11168155,11168156,11168156],\n                   'A':[18,0,56,96,0],\n                   'B':[56,18,96,152,96]})\n# [Begin of Missing Code]\ndf = df.sort_values(['cokey', 'A'], ascending=[True, False])\nresult = df.set_index(['cokey', df.groupby('cokey').cumcount()])\n# [End of Missing Code]\nprint(result)```",
        "[Missing Code]\ndf.columns = pd.MultiIndex.from_tuples(df.columns, names=['Caps', 'Lower'])\n[End of Missing Code]",
        "[Missing Code]\ndf.columns = pd.MultiIndex.from_tuples(df.columns, names=['Caps', 'Middle', 'Lower'])",
        "[Missing Code]\ndf.columns = pd.MultiIndex.from_tuples(df.columns, names=['Caps', 'Middle', 'Lower'])",
        "[Missing Code]\nresult = pd.DataFrame({'birdType': someTuple[0], 'birdCount': someTuple[1]})\n[End of Missing Code]",
        "[Missing Code]\n```python\nresult = df.groupby('a').b.agg(['mean', 'std'])\n```",
        "[Begin of Missing Code]\nresult = df.groupby('b').agg({'a':['mean','std']})\n[End of Missing Code]",
        "[Missing Code]\n```python\nimport numpy as np\n\ndef softmax(x):\n    e_x = np.exp(x - np.max(x))\n    return e_x / e_x.sum()\n\ndef min_max(x):\n    return (x - np.min(x)) / (np.max(x) - np.min(x))\n\ndf['softmax'] = df.groupby('a')['b'].transform(softmax)\ndf['min-max'] = df.groupby('a')['b'].transform(min_max)\n```",
        "```python\nimport pandas as pd\n\n\ndf = pd.DataFrame([[1,1,0,1],[0,0,0,0],[1,0,0,1],[0,1,0,0],[1,1,0,1]],columns=['A','B','C','D'])\n# [Begin of Missing Code]\nresult = df.loc[:, (df != 0).any(axis=0)]\nresult = result.loc[(result != 0).any(axis=1)]\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\nresult = df.loc[:, (df != 0).any(axis=0)]\nresult = result.loc[(result != 0).any(axis=1)]\n```",
        "```python\nimport pandas as pd\n\n\ndf = pd.DataFrame([[1,2,3,1],[0,0,0,0],[1,0,0,1],[0,1,2,0],[1,1,0,1]],columns=['A','B','C','D'])\n# [Begin of Missing Code]\nresult = df.loc[:, (df.max() < 3)]\nresult = result.loc[(result.max(axis=1) < 3)]\n# [End of Missing Code]\nprint(result)",
        "```python\nimport pandas as pd\n\n\ndf = pd.DataFrame([[1,2,3,1],[0,0,0,0],[1,0,0,1],[0,1,2,0],[1,1,0,1]],columns=['A','B','C','D'])\n# [Begin of Missing Code]\nresult = df.mask(df == 2, 0)\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\nresult = s.sort_values().sort_index(kind='mergesort')",
        "[Begin of Missing Code]\ndf = s.sort_values().reset_index()\ndf.columns = ['index', 1]\ndf = df.sort_values(by=[1, 'index'])\n[End of Missing Code]",
        "[Missing Code]\n```python\nresult = df[pd.to_numeric(df['A'], errors='coerce').notnull()]\n```",
        "[Missing Code]\n```python\nresult = df[df['A'].apply(lambda x: isinstance(x, str))]\n```",
        "```python\nimport pandas as pd\n\n\ndf = pd.DataFrame({'Sp': ['MM1', 'MM1', 'MM1', 'MM2', 'MM2', 'MM2', 'MM4', 'MM4', 'MM4'],\n                   'Mt': ['S1', 'S1', 'S3', 'S3', 'S4', 'S4', 'S2', 'S2', 'S2'],\n                   'Value': ['a', 'n', 'cb', 'mk', 'bg', 'dgd', 'rd', 'cb', 'uyi'],\n                   'count': [3, 2, 5, 8, 10, 1, 2, 2, 7]})\n# [Begin of Missing Code]\nidx = df.groupby(['Sp','Mt'])['count'].transform(max) == df['count']\nresult = df[idx]\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\nresult = df.loc[df.groupby(['Sp','Mt'])['count'].idxmax()]\n```",
        "```python\nimport pandas as pd\n\n\ndf = pd.DataFrame({'Sp': ['MM1', 'MM1', 'MM1', 'MM2', 'MM2', 'MM2', 'MM4', 'MM4', 'MM4'],\n                   'Mt': ['S1', 'S1', 'S3', 'S3', 'S4', 'S4', 'S2', 'S2', 'S2'],\n                   'Value': ['a', 'n', 'cb', 'mk', 'bg', 'dgd', 'rd', 'cb', 'uyi'],\n                   'count': [3, 2, 5, 8, 10, 1, 2, 2, 7]})\n# [Begin of Missing Code]\nresult = df[df.groupby(['Sp','Mt'])['count'].transform(min) == df['count']]\n# [End of Missing Code]\nprint(result)\n```",
        "[Begin of Missing Code]\nresult = df.loc[df.groupby(['Sp','Value'])['count'].idxmax()]\n[End of Missing Code]",
        "```python\nimport pandas as pd\nimport numpy as np\n\ndict = {'abc':'1/2/2003', 'def':'1/5/2017', 'ghi':'4/10/2013'}\ndf = pd.DataFrame({'Member':['xyz', 'uvw', 'abc', 'def', 'ghi'], 'Group':['A', 'B', 'A', 'B', 'B'], 'Date':[np.nan, np.nan, np.nan, np.nan, np.nan]})\n# [Begin of Missing Code]\ndf['Date'] = df['Member'].map(dict).fillna(df['Date'])\n# [End of Missing Code]\nresult = df\nprint(result)\n```",
        "[Begin of Missing Code]\ndf['Date'] = df['Member'].map(dict)\ndf['Date'].fillna('17/8/1926', inplace=True)\n[End of Missing Code]",
        "```python\nimport pandas as pd\nimport numpy as np\n\nexample_dict = {'abc':'1/2/2003', 'def':'1/5/2017', 'ghi':'4/10/2013'}\nexample_df = pd.DataFrame({'Member':['xyz', 'uvw', 'abc', 'def', 'ghi'], 'Group':['A', 'B', 'A', 'B', 'B'], 'Date':[np.nan, np.nan, np.nan, np.nan, np.nan]})\ndef f(dict=example_dict, df=example_df):\n    # [Begin of Missing Code]\n    df['Date'] = df['Member'].map(dict).fillna(df['Date'])\n    result = df\n    # [End of Missing Code]\n    return result\n```",
        "[Begin of Missing Code]\ndf['Date'] = df['Member'].map(dict)\ndf['Date'] = df['Date'].fillna('17/8/1926')\ndf['Date'] = pd.to_datetime(df['Date']).dt.strftime('%d-%b-%Y')\n[End of Missing Code]",
        "[Missing Code]\ndf['Date'] = pd.to_datetime(df['Date'], format= '%d/%m/%y')\ndf['Count_d'] = df.Date.map(df.groupby('Date').size())\ndf['Count_m'] = df.Date.dt.to_period('M').map(df.groupby(df.Date.dt.to_period('M')).size())\ndf['Count_y'] = df.Date.dt.to_period('Y').map(df.groupby(df.Date.dt.to_period('Y')).size())",
        "[Begin of Missing Code]\ndf['Date'] = pd.to_datetime(df['Date'], format= '%d/%m/%y')\ndf['Count_d'] = df.groupby('Date')['Date'].transform('count')\ndf['Count_m'] = df.groupby(df['Date'].dt.to_period('M'))['Date'].transform('count')\ndf['Count_y'] = df.groupby(df['Date'].dt.to_period('Y'))['Date'].transform('count')\ndf['Count_Val'] = df.groupby(['Date', 'Val'])['Val'].transform('count')\n[End of Missing Code]",
        "[Missing Code]\ndf['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%y')\ndf['Count_d'] = df.groupby('Date')['Date'].transform('count')\ndf['Count_m'] = df.groupby(df['Date'].dt.to_period('M'))['Date'].transform('count')\ndf['Count_y'] = df.groupby(df['Date'].dt.year)['Date'].transform('count')\ndf['Count_w'] = df.groupby(df['Date'].dt.week)['Date'].transform('count')\ndf['Count_Val'] = df.groupby(['Date', 'Val'])['Val'].transform('count')\n[End of Missing Code]",
        "[Missing Code]\ndf['B_zero'] = (df['B'] == 0)\ndf['C_zero'] = (df['C'] == 0)\ndf['B_non_zero'] = (df['B'] != 0)\ndf['C_non_zero'] = (df['C'] != 0)\n\nresult1 = df.groupby('Date')[['B_zero', 'C_zero']].sum().astype(int)\nresult2 = df.groupby('Date')[['B_non_zero', 'C_non_zero']].sum().astype(int)\n\nresult1.columns = ['B', 'C']\nresult2.columns = ['B', 'C']\n[End of Missing Code]",
        "[Missing Code]\n```python\ndf['B_even'] = df['B'] % 2 == 0\ndf['C_even'] = df['C'] % 2 == 0\ndf['B_odd'] = df['B'] % 2 == 1\ndf['C_odd'] = df['C'] % 2 == 1\n\nresult1 = df.groupby('Date')[['B_even', 'C_even']].sum().astype(int)\nresult1.columns = ['B', 'C']\n\nresult2 = df.groupby('Date')[['B_odd', 'C_odd']].sum().astype(int)\nresult2.columns = ['B', 'C']\n```\n[End of Missing Code]",
        "[Missing Code]\n```python\nresult = pd.pivot_table(df, values=['D','E'], index=['B'], \n                        aggfunc={'D': np.sum, 'E': np.mean})\n```",
        "[Missing Code]\n```python\nresult = pd.pivot_table(df, values=['D','E'], index=['B'], \n                        aggfunc={'D': np.sum, 'E': np.mean})\n```",
        "[Missing Code]\n```python\nresult = pd.pivot_table(df, values=['D','E'], index=['B'], aggfunc={'D': np.sum, 'E': np.mean})\n```",
        "[Missing Code]\n```python\nresult = df.groupby('B').agg({'D': np.max, 'E': np.min})\n```",
        "```python\nimport pandas as pd\n\n\ndf = pd.DataFrame([[\"A\", \"Z,Y\"], [\"B\", \"X\"], [\"C\", \"W,U,V\"]], index=[1,2,3], columns=['var1', 'var2'])\n# [Begin of Missing Code]\ndf = df.reset_index().rename(columns={'index':'id'})\ndf['var2'] = df['var2'].str.split(',')\nresult = df.explode('var2')\n# [End of Missing Code]\nprint(result)",
        "```python\nimport pandas as pd\nimport dask.dataframe as dd\n\ndf = pd.DataFrame([[\"A\", \"Z,Y\"], [\"B\", \"X\"], [\"C\", \"W,U,V\"]], index=[1,2,3], columns=['var1', 'var2'])\n# [Begin of Missing Code]\nddf = dd.from_pandas(df, npartitions=2)\nddf['var2'] = ddf['var2'].str.split(',')\nresult = ddf.explode('var2').compute()\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\ndf['var2'] = df['var2'].str.split('-')\nresult = df.explode('var2').reset_index(drop=True)\n```",
        "[Missing Code]\ndef count_special_char(string):\n    special_char = 0\n    for i in range(len(string)):\n        if(string[i].isalpha()):\n            continue\n        else:\n            special_char = special_char + 1\n    return special_char\n\ndf[\"new\"] = df[\"str\"].apply(count_special_char)",
        "[Missing Code]\n```python\ndef count_alpha_chars(string):\n    alpha_chars = 0\n    for i in range(len(string)):\n        if(string[i].isalpha()):\n            alpha_chars = alpha_chars + 1\n    return alpha_chars\n\ndf[\"new\"] = df['str'].apply(count_alpha_chars)\n```",
        "[Missing Code]\ndf[['fips', 'row']] = df['row'].str.split(' ', 1, expand=True)",
        "[Missing Code]\ndf[['fips', 'row']] = df['row'].str.split(' ', expand=True)",
        "[Missing Code]\ndf[['fips','medi','row']] = df['row'].str.split(' ', 2, expand=True)\ndf['fips'] = df['fips'].str.zfill(5)\ndf['medi'] = df['medi'].str.zfill(5)\ndf['row'] = df['row'].str.zfill(5)",
        "[Begin of Missing Code]\ndf.set_index('Name', inplace=True)\ndf = df.mask(df == 0).expanding(1).mean().fillna(0)\ndf.reset_index(inplace=True)\n[End of Missing Code]",
        "[Begin of Missing Code]\ndf.set_index('Name', inplace=True)\ndf = df.iloc[:, ::-1]\ndf = df.mask(df == 0).expanding(axis=1).mean().round(2)\ndf = df.iloc[:, ::-1]\ndf.reset_index(inplace=True)\n[End of Missing Code]",
        "[Missing Code]\n```python\ndf = df.set_index('Name')\ndf = df.mask(df == 0)\nresult = df.expanding(1).mean().round(3)\n```",
        "[Begin of Missing Code]\ndf.set_index('Name', inplace=True)\ndf = df.iloc[:, ::-1]\ndf = df.mask(df == 0)\ndf = df.expanding(axis=1).mean()\ndf = df.iloc[:, ::-1]\n# [End of Missing Code]",
        "[Missing Code]\ndf['Label'] = (df['Close'].diff() > 0).astype(int)\ndf['Label'].iloc[0] = 1\n[End of Missing Code]",
        "[Missing Code]\ndf['label'] = df['Close'].diff().apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))\ndf['label'].iloc[0] = 1\n[End of Missing Code]",
        "[Missing Code]\ndf['DateTime'] = df['DateTime'].dt.strftime('%d-%b-%Y')\ndf['label'] = df['Close'].diff().apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))\ndf['label'].iloc[0] = 1\n[End of Missing Code]",
        "[Begin of Missing Code]\ndf['arrival_time'] = pd.to_datetime(df['arrival_time'], errors='coerce')\ndf['departure_time'] = pd.to_datetime(df['departure_time'], errors='coerce')\ndf['Duration'] = df['arrival_time'].shift(-1) - df['departure_time']\n[End of Missing Code]",
        "[Begin of Missing Code]\ndf['arrival_time'] = pd.to_datetime(df['arrival_time'], errors='coerce')\ndf['departure_time'] = pd.to_datetime(df['departure_time'], errors='coerce')\ndf['Duration'] = (df['arrival_time'].shift(-1) - df['departure_time']).dt.total_seconds()\n[End of Missing Code]",
        "[Begin of Missing Code]\ndf['arrival_time'] = pd.to_datetime(df['arrival_time'], errors='coerce')\ndf['departure_time'] = pd.to_datetime(df['departure_time'], errors='coerce')\ndf['Duration'] = (df['arrival_time'].shift(-1) - df['departure_time']).dt.total_seconds()\ndf['arrival_time'] = df['arrival_time'].dt.strftime('%d-%b-%Y %H:%M:%S')\ndf['departure_time'] = df['departure_time'].dt.strftime('%d-%b-%Y %H:%M:%S')\ndf['arrival_time'] = df['arrival_time'].replace('NaT', 'NaN')\ndf['departure_time'] = df['departure_time'].replace('NaT', 'NaN')\n[End of Missing Code]",
        "[Missing Code]\n```python\ndf['count'] = df['key2'] == 'one'\nresult = df.groupby('key1')['count'].sum().reset_index()\n```",
        "```python\nimport pandas as pd\n\n\ndf = pd.DataFrame({'key1': ['a', 'a', 'b', 'b', 'a', 'c'],\n                   'key2': ['one', 'two', 'one', 'two', 'one', 'two']})\n# [Begin of Missing Code]\nresult = df[df['key2'] == 'two'].groupby(['key1']).size().reset_index(name='count')\n# [End of Missing Code]\nprint(result)",
        "[Missing Code]\n```python\ndf['endswith_e'] = df['key2'].apply(lambda x: x.endswith('e'))\nresult = df.groupby('key1')['endswith_e'].sum().reset_index()\nresult.columns = ['key1', 'count']\n```",
        "[Begin of Missing Code]\ndf.index = pd.to_datetime(df.index)\nmax_result = df.index.max()\nmin_result = df.index.min()\n[End of Missing Code]",
        "[Missing Code]\n```python\ndf.index = pd.to_datetime(df.index)\nmode_result = df.index.mode()[0]\nmedian_result = df.index.median()\n```",
        "[Missing Code]\n```python\nresult = df[(df['closing_price'] >= 99) & (df['closing_price'] <= 101)]\n```",
        "[Missing Code]\n```python\nresult = df[~((df['closing_price'] >= 99) & (df['closing_price'] <= 101))]\n```",
        "[Begin of Missing Code]\nresult = df.loc[df.groupby(\"item\")[\"diff\"].idxmin()]\n[End of Missing Code]",
        "[Missing Code]\ndf['SOURCE_NAME'] = df['SOURCE_NAME'].apply(lambda x: \"_\".join(x.split(\"_\")[:-1]) if \"_\" in x else x)\n[End of Missing Code]",
        "[Missing Code]\ndf['SOURCE_NAME'] = df['SOURCE_NAME'].apply(lambda x: x.split('_')[-1] if '_' in x else x)\n[End of Missing Code]",
        "[Missing Code]\ndf['SOURCE_NAME'] = df['SOURCE_NAME'].str.rsplit('_', 1).str[0]\nresult = df\n[End of Missing Code]",
        "[Missing Code]\n```python\nnan_indexes = df[df['Column_x'].isna()].index\nhalf = len(nan_indexes) // 2\ndf.loc[nan_indexes[:half], 'Column_x'] = 0\ndf.loc[nan_indexes[half:], 'Column_x'] = 1\n```",
        "[Missing Code]\n```python\nnan_indexes = df[df['Column_x'].isna()].index\nnan_count = len(nan_indexes)\n\nfirst_third = int(nan_count * 0.3)\nsecond_third = int(nan_count * 0.6)\n\ndf.loc[nan_indexes[:first_third], 'Column_x'] = 0\ndf.loc[nan_indexes[first_third:second_third], 'Column_x'] = 0.5\ndf.loc[nan_indexes[second_third:], 'Column_x'] = 1\n```",
        "[Missing Code]\n```python\nnan_count = df['Column_x'].isna().sum()\nhalf_count = nan_count // 2\n\ndf.loc[df['Column_x'].isna(), 'Column_x'] = [0]*half_count + [1]*(nan_count-half_count)\n```",
        "[Missing Code]\n```python\nresult = pd.DataFrame({col: list(zip(a[col], b[col])) for col in a.columns})\n```",
        "[Missing Code]\n```python\ndataframes = [a, b, c]\nresult = pd.concat([df.stack() for df in dataframes], axis=1).apply(tuple, axis=1).unstack()\n```",
        "[Missing Code]\n```python\n# Align the dataframes\na_aligned, b_aligned = a.align(b, fill_value=np.nan)\n\n# Combine the dataframes into tuples\nresult = a_aligned.combine(b_aligned, lambda s1, s2: list(zip(s1, s2)))\n```",
        "[Begin of Missing Code]\ndf['bins'] = pd.cut(df.views, bins)\nresult = df.groupby(['username', 'bins']).size().unstack().fillna(0)\n[End of Missing Code]",
        "[Begin of Missing Code]\ndf['bins'] = pd.cut(df.views, bins)\nresult = df.groupby(['username', 'bins']).size().unstack(fill_value=0)\n[End of Missing Code]",
        "[Begin of Missing Code]\nresult = df.groupby(['username', pd.cut(df.views, bins)]).size().unstack().fillna(0)\n[End of Missing Code]",
        "```python\nimport pandas as pd\n\n\ndf = pd.DataFrame({'text': ['abc', 'def', 'ghi', 'jkl']})\n# [Begin of Missing Code]\nresult = pd.DataFrame({'text': [', '.join(df['text'].values)]})\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\nresult = pd.DataFrame({'text': ['-'.join(df['text'].tolist())]}, index=[0])\n```",
        "[Missing Code]\n```python\nresult = pd.DataFrame({'text': [', '.join(df['text'][::-1])]})\n```",
        "[Missing Code]\n```python\nresult = pd.Series(df['text'].str.cat(sep=', '))\n```",
        "[Missing Code]\n```python\nresult = pd.Series({'text': '-'.join(df['text'][::-1])})\n```",
        "[Begin of Missing Code]\ndf2 = df2.merge(df1[['id', 'city', 'district']], on='id', how='left')\nresult = pd.concat([df1, df2], axis=0, ignore_index=True)\n[End of Missing Code]",
        "[Begin of Missing Code]\ndf1['date'] = pd.to_datetime(df1['date']).dt.strftime('%d-%b-%Y')\ndf2['date'] = pd.to_datetime(df2['date']).dt.strftime('%d-%b-%Y')\n\ndf = pd.concat([df1, df2], axis=0, ignore_index=True)\n\ndf = df.merge(df1[['id', 'city', 'district']], on='id', how='left')\n\ndf = df.sort_values(['id', 'date'], ascending=[True, False]).reset_index(drop=True)\nresult = df\n[End of Missing Code]",
        "[Begin of Missing Code]\ndf2 = df2.merge(df1[['id', 'city', 'district']], on='id', how='left')\nresult = pd.concat([df1, df2], axis=0).sort_values(['id', 'date'])\n[End of Missing Code]",
        "[Missing Code]\n```python\nresult = C.set_index('A').combine_first(D.set_index('A')).reset_index()\nresult['B'] = result['B'].astype(int)\n```",
        "[Missing Code]\n```python\nmerged = pd.merge(C, D, on='A', how='left')\nmerged['B'] = merged['B_x'].where(merged['B_x'].notnull(), merged['B_y'])\nresult = merged[['A', 'B']]\n```",
        "[Missing Code]\n```python\nresult = pd.concat([C.set_index('A'), D.set_index('A')], axis=0).reset_index().drop_duplicates(subset='A', keep='last')\nresult['dulplicated'] = result.duplicated(subset='A', keep=False)\nresult = result.sort_index()\n```",
        "[Missing Code]\n```python\ndf = df.sort_values(['user', 'time'])\nresult = df.groupby('user')[['time', 'amount']].apply(lambda x: list(map(list, x.values)))\n```",
        "[Missing Code]\ndf = df.sort_values(['user', 'time'])\ndf['amount-time-tuple'] = list(zip(df.time, df.amount))\nresult = df.groupby('user')['amount-time-tuple'].apply(list)\n[End of Missing Code]",
        "```python\nimport pandas as pd\n\n\ndf = pd.DataFrame({'user':[1,1,2,2,3], 'time':[20,10,11,18, 15], 'amount':[10.99, 4.99, 2.99, 1.99, 10.99]})\n### Output your answer into variable 'result'\n# [Begin of Missing Code]\ndf = df.sort_values(['user', 'time'], ascending=[True, False])\ndf['amount-time-tuple'] = list(zip(df.amount, df.time))\nresult = df.groupby('user')['amount-time-tuple'].apply(list)\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\ndf = pd.DataFrame(series.tolist(), index=series.index)",
        "```python\nimport pandas as pd\nimport numpy as np\n\n\nseries = pd.Series([np.array([1,2,3,4]), np.array([5,6,7,8]), np.array([9,10,11,12])], index=['file1', 'file2', 'file3'])\n# [Begin of Missing Code]\ndf = pd.DataFrame(series.tolist(), index=series.index).reset_index()\ndf.columns = ['name'] + list(df.columns[1:])\n# [End of Missing Code]\nresult = df\nprint(result)\n```",
        "[Missing Code]\nresult = [col for col in df.columns if s in col]",
        "[Begin of Missing Code]\nresult = [col for col in df.columns if s in col]\n[End of Missing Code]",
        "[Missing Code]\n```python\nspike_cols = [col for col in df.columns if s in col]\nfor i, col in enumerate(spike_cols, 1):\n    df.rename(columns={col: f'spike{i}'}, inplace=True)\nresult = df\n```",
        "```python\nimport pandas as pd\n\n\ndf = pd.DataFrame({'codes':[[71020], [77085], [36415], [99213, 99287], [99233, 99233, 99233]]})\n# [Begin of Missing Code]\nresult = pd.DataFrame(df['codes'].to_list(), columns=['code_0', 'code_1', 'code_2'])\n# [End of Missing Code]\nprint(result)\n```",
        "```python\nimport pandas as pd\n\n\ndf = pd.DataFrame({'codes':[[71020], [77085], [36415], [99213, 99287], [99233, 99233, 99233]]})\n# [Begin of Missing Code]\nresult = pd.DataFrame(df['codes'].to_list(), columns=['code_1', 'code_2', 'code_3'])\n# [End of Missing Code]\nprint(result)\n```",
        "```python\nimport pandas as pd\n\n\ndf = pd.DataFrame({'codes':[[71020], [77085], [36415], [99213, 99287], [99234, 99233, 99233]]})\n# [Begin of Missing Code]\ndf['codes'] = df['codes'].apply(lambda x: sorted(x))\nresult = pd.DataFrame(df['codes'].to_list(), columns=['code_1', 'code_2', 'code_3'])\n# [End of Missing Code]\nprint(result)\n```",
        "[Solution Code]\n```python\nimport pandas as pd\nfrom ast import literal_eval\n\ndf = pd.DataFrame(dict(col1=[[1, 2, 3]] * 2))\n# [Begin of Missing Code]\ndf['col1'] = df['col1'].apply(literal_eval)\nresult = [item for sublist in df['col1'].tolist() for item in sublist]\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\nresult = ','.join([str(i) for sublist in df['col1'] for i in reversed(sublist)])\n```",
        "[Begin of Missing Code]\nresult = ','.join(map(str, [elem for sublist in df['col1'] for elem in sublist]))\n[End of Missing Code]",
        "[Begin of Missing Code]\ndf.set_index('Time', inplace=True)\ndf = df.resample('2T').mean()\ndf.reset_index(inplace=True)\n[End of Missing Code]",
        "[Begin of Missing Code]\ndf.set_index('Time', inplace=True)\ndf = df.resample('3T').sum()\ndf.reset_index(inplace=True)\n[End of Missing Code]",
        "[Begin of Missing Code]\ndf['TIME'] = pd.to_datetime(df['TIME'])\ndf['RANK'] = df.groupby('ID')['TIME'].rank(method='min')\n[End of Missing Code]",
        "[Begin of Missing Code]\ndf['TIME'] = pd.to_datetime(df['TIME'])\ndf['RANK'] = df.groupby('ID')['TIME'].rank(ascending=False)\n[End of Missing Code]",
        "[Begin of Missing Code]\ndf['TIME'] = pd.to_datetime(df['TIME'])\ndf['RANK'] = df.groupby('ID')['TIME'].rank(ascending=False)\ndf['TIME'] = df['TIME'].dt.strftime('%d-%b-%Y %a %H:%M:%S')\n[End of Missing Code]",
        "[Missing Code]\n```python\nresult = df[df.index.get_level_values('a').map(filt)]\n```",
        "[Missing Code]\nresult = df[filt[df.index.get_level_values('a')]]",
        "[Missing Code]\n```python\nresult = df.columns[df.loc[0] != df.loc[8]]\n```",
        "[Missing Code]\n```python\nresult = df.loc[0].eq(df.loc[8])\nresult = result[result].index\n```",
        "[Missing Code]\n```python\nresult = df.columns[df.loc[0] != df.loc[8]].tolist()\n```",
        "[Missing Code]\n```python\nrow0 = df.iloc[0]\nrow8 = df.iloc[8]\nresult = [(x, y) for x, y in zip(row0, row8) if x != y or (pd.isnull(x) and not pd.isnull(y)) or (not pd.isnull(x) and pd.isnull(y))]\n```",
        "```python\nimport pandas as pd\n\n\ndates = ['2016-1-{}'.format(i)for i in range(1,21)]\nvalues = [i for i in range(20)]\ndata = {'Date': dates, 'Value': values}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\n# [Begin of Missing Code]\nts = pd.Series(df['Value'].values, index=df['Date'])\n# [End of Missing Code]\nresult = ts\nprint(result)\n```",
        "```python\nimport pandas as pd\n\ndf = pd.DataFrame([[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15]],columns=['A','B','C','D','E'])\n# [Begin of Missing Code]\ndf.columns = [f\"{col}_{i+1}\" for i in range(df.shape[0]) for col in df.columns]\ndf = df.T.reset_index(drop=True).T\n# [End of Missing Code]\nresult = df\nprint(result)\n```",
        "```python\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame([[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15]],columns=['A','B','C','D','E'])\n# [Begin of Missing Code]\ndf = df.T\ndf.columns = [f'{col}_{i}' for i in range(len(df.columns)) for col in df.index]\ndf = df.T\ndf = df.iloc[0:1, :]\n# [End of Missing Code]\nresult = df\nprint(result)\n```",
        "[Solution Code]\n```python\nimport pandas as pd\n\n\ndf = pd.DataFrame([(.21, .3212), (.01, .61237), (.66123, .03), (.21, .18),(pd.NA, .18)],\n                  columns=['dogs', 'cats'])\n# [Begin of Missing Code]\ndf = df.round(2)\n# [End of Missing Code]\nresult = df\nprint(result)\n```",
        "```python\nimport pandas as pd\n\n\ndf = pd.DataFrame([(.21, .3212), (.01, .61237), (.66123, pd.NA), (.21, .18),(pd.NA, .188)],\n                  columns=['dogs', 'cats'])\n# [Begin of Missing Code]\ndf = df.round(2)\n# [End of Missing Code]\nresult = df\nprint(result)\n```",
        "[Missing Code]\ndf['Sum'] = df[list_of_my_columns].sum(axis=1)\n[End of Missing Code]",
        "[Missing Code]\ndf['Avg'] = df[list_of_my_columns].mean(axis=1)",
        "[Missing Code]\n```python\ndf['Avg'] = df[list_of_my_columns].mean(axis=1)\ndf['Min'] = df[list_of_my_columns].min(axis=1)\ndf['Max'] = df[list_of_my_columns].max(axis=1)\ndf['Median'] = df[list_of_my_columns].median(axis=1)\n```",
        "[Begin of Missing Code]\nresult = df.sort_index(level='time')\n[End of Missing Code]",
        "[Missing Code]\nresult = df.sort_values('VIM', kind='mergesort')\n[End of Missing Code]",
        "[Begin of Missing Code]\nresult = df[~df.index.strftime('%Y-%m-%d').isin(['2020-02-17', '2020-02-18'])]\n[End of Missing Code]",
        "[Begin of Missing Code]\n# Remove the dates\ndates_to_remove = ['2020-02-17', '2020-02-18']\ndf = df[~df.index.strftime('%Y-%m-%d').isin(dates_to_remove)]\n\n# Add day of week\ndf['Day of Week'] = df.index.strftime('%d-%b-%Y %A')\nresult = df\n[End of Missing Code]",
        "[Missing Code]\n```python\ncorr = corr.where(np.triu(np.ones(corr.shape)).astype(np.bool))\ncorr = corr.stack().reset_index()\ncorr.columns = ['Col1', 'Col2', 'Pearson Correlation Coefficient']\nresult = corr[corr['Pearson Correlation Coefficient'] > 0.3]\n```",
        "[Missing Code]\nresult = corr[corr > 0.3].stack().dropna()",
        "[Missing Code]\ndf.columns = ['A' if x!=max(df.columns.get_loc(x)) else 'Test' for x in df.columns]\nresult = df\n[End of Missing Code]",
        "[Missing Code]\ndf.columns = ['Test' if x==df.columns[0] else x for x in df.columns]\nresult = df\n[End of Missing Code]",
        "[Missing Code]\n```python\ndf['frequent'] = df.mode(axis=1)[0]\ndf['freq_count'] = df.apply(lambda row: list(row).count(row['frequent']), axis=1)\n```",
        "[Missing Code]\ndf['frequent'] = df.mode(axis=1)[0]\ndf['freq_count'] = df.apply(lambda row: list(row).count(row['frequent']), axis=1)",
        "[Missing Code]\ndf['frequent'] = df.apply(lambda x: x.mode().tolist(), axis=1)\ndf['freq_count'] = df['frequent'].apply(lambda x: len(x))",
        "```python\nimport pandas as pd\n\n\ndf = pd.DataFrame({\"foo\":[8,5,3,4,7,9,5,7], \n                   \"id1\":[1,1,1,1,1,1,1,1], \n                   \"bar\":['NULL','NULL','NULL',1,3,4,2,3], \n                   \"id2\":[1,1,1,2,2,3,3,1]})\n# [Begin of Missing Code]\ndf['bar'] = pd.to_numeric(df['bar'], errors='coerce')\nresult = df.groupby([\"id1\",\"id2\"])[\"foo\",\"bar\"].mean()\n# [End of Missing Code]\nprint(result)```",
        "```python\nimport pandas as pd\n\n\ndf = pd.DataFrame({\"foo\":[8,5,3,4,7,9,5,7], \n                   \"id1\":[1,1,1,1,1,1,1,1], \n                   \"bar\":['NULL','NULL','NULL',1,3,4,2,3], \n                   \"id2\":[1,1,1,2,2,3,3,1]})\n# [Begin of Missing Code]\ndf['bar'] = df['bar'].replace('NULL', 0)\ndf['bar'] = df['bar'].astype(float)\nresult = df.groupby([\"id1\",\"id2\"])[\"foo\",\"bar\"].mean()\n# [End of Missing Code]\nprint(result)```",
        "[Begin of Missing Code]\nresult = pd.merge(df_a, df_b[['EntityNum', 'a_col']], on='EntityNum')\n[End of Missing Code]",
        "[Missing Code]\nresult = pd.merge(df_a, df_b[['EntityNum', 'b_col']], on='EntityNum')\n[End of Missing Code]"
    ],
    "Numpy": [
        "[Missing Code]\n```python\nresult = a.shape\n```",
        "[Missing Code]\nx = x[~np.isnan(x)]",
        "[Missing Code]\nx[np.isnan(x)] = np.inf",
        "[Missing Code]\n```python\nresult = [[elem for elem in row if not np.isnan(elem)] for row in x]\n```",
        "[Missing Code]\nb = np.zeros((a.size, a.max()+1))\nb[np.arange(a.size),a] = 1",
        "[Missing Code]\nb = np.zeros((a.size, a.max()+1))\nb[np.arange(a.size),a] = 1",
        "```python\nimport numpy as np\na = np.array([-1, 0, 3])\n# [Begin of Missing Code]\nb = np.zeros((a.size, a.max()-a.min()+1))\nb[np.arange(a.size), a-a.min()] = 1\n# [End of Missing Code]\nprint(b)\n```",
        "[Missing Code]\n```python\nunique_a = np.unique(a)\nb = (unique_a[:, None] == a).astype(int)\n```",
        "[Missing Code]\nb = np.zeros((a.size, a.max()+1), dtype=int)\nb[np.arange(a.size), a.ravel()] = 1\nb = b.reshape(*a.shape, -1)",
        "[Missing Code]\n```python\nresult = np.percentile(a, p)\n```",
        "[Missing Code]\nB = A.reshape(-1, ncol)",
        "[Missing Code]\nB = A.reshape(nrow, -1)",
        "[Missing Code]\nnrow = len(A) // ncol\nB = A[:nrow*ncol].reshape(nrow, ncol)\n[End of Missing Code]",
        "[Missing Code]\n```python\nnrow = len(A) // ncol\nA = A[-nrow*ncol:]\nB = A.reshape(nrow, ncol)[::-1]\n```",
        "[Missing Code]\n```python\nresult = np.empty_like(a)\nif shift > 0:\n    result[:shift] = np.nan\n    result[shift:] = a[:-shift]\nelif shift < 0:\n    result[shift:] = np.nan\n    result[:shift] = a[-shift:]\nelse:\n    result = a\n```",
        "[Missing Code]\n```python\ndef shift_array(arr, num, fill_value=np.nan):\n    result = np.empty_like(arr)\n    if num > 0:\n        result[:num] = fill_value\n        result[num:] = arr[:-num]\n    elif num < 0:\n        result[num:] = fill_value\n        result[:num] = arr[-num:]\n    else:\n        result = arr\n    return result\n\nresult = shift_array(a, shift)\n```",
        "[Missing Code]\n```python\nresult = np.empty_like(a)\nfor i, s in enumerate(shift):\n    if s > 0:\n        result[i, s:] = a[i, :-s]\n        result[i, :s] = np.nan\n    elif s < 0:\n        result[i, :s] = a[i, -s:]\n        result[i, s:] = np.nan\n    else:\n        result[i] = a[i]\n```",
        "[Missing Code]\n```python\nnp.random.seed(0)\nr_old = np.random.randint(3, size=(100, 2000)) - 1\nnp.random.seed(0)\nr_new = np.random.randint(3, size=(100, 2000)) - 1\n```",
        "[Missing Code]\nresult = np.unravel_index(np.argmax(a, axis=None), a.shape)",
        "[Missing Code]\nresult = np.unravel_index(np.argmin(a, axis=None), a.shape)",
        "[Missing Code]\nresult = np.unravel_index(np.argmax(a, axis=None), a.shape, order='F')",
        "[Missing Code]\nresult = np.unravel_index(np.argmax(a, axis=None), a.shape)",
        "[Missing Code]\n```python\nresult = np.unravel_index(np.argmax(a, axis=None), a.shape)\n```",
        "[Missing Code]\n```python\nflat_indices = np.argpartition(a.flatten(), -2)[-2]\nresult = np.unravel_index(flat_indices, a.shape)\n```",
        "[Missing Code]\nmask = np.all(np.isnan(a), axis=0)\na = a[:, ~mask]",
        "[Missing Code]\na = a[~np.isnan(a).any(axis=1)]\n[End of Missing Code]",
        "```python\nimport numpy as np\na = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] \n# [Begin of Missing Code]\nresult = np.array(a)\n# [End of Missing Code]\nprint(result)\n```",
        "[Begin of Missing Code]\na = a[:, permutation]\n[End of Missing Code]",
        "[Begin of Missing Code]\nresult = a[permutation]\n[End of Missing Code]",
        "[Missing Code]\n```python\nresult = np.unravel_index(a.argmin(), a.shape)\n```",
        "[Missing Code]\nresult = np.unravel_index(a.argmax(), a.shape)\n[End of Missing Code]",
        "[Missing Code]\n```python\nresult = np.argwhere(a == np.min(a)).tolist()\n```",
        "[Missing Code]\n```python\nresult = np.sin(np.radians(degree))\n```",
        "[Missing Code]\n```python\nradians = np.deg2rad(degree)\nresult = np.cos(radians)\n```",
        "[Missing Code]\n```python\nif np.sin(np.deg2rad(number)) > np.sin(number):\n    result = 1\nelse:\n    result = 0\n```",
        "[Missing Code]\n```python\nresult = np.degrees(np.arcsin(value))\n```",
        "[Missing Code]\n```python\nresult = np.pad(A, (0, length - len(A)), 'constant')\n```",
        "[Missing Code]\n```python\nresult = np.pad(A, (0, length - len(A)), 'constant')\n```",
        "[Begin of Missing Code]\na = np.power(a, power)\n[End of Missing Code]",
        "[Missing Code]\n```python\nresult = np.power(a, power)\n```",
        "[Missing Code]\n```python\nfrom fractions import Fraction\nresult = Fraction(numerator, denominator)\nresult = (result.numerator, result.denominator)\n```",
        "[Missing Code]\n```python\nfrom fractions import Fraction\nresult = Fraction(numerator, denominator)\nresult = (result.numerator, result.denominator)\n```",
        "[Missing Code]\n```python\nfrom math import gcd\nif denominator == 0:\n    result = (np.nan, np.nan)\nelse:\n    g = gcd(numerator, denominator)\n    result = (numerator//g, denominator//g)\n```",
        "[Missing Code]\n```python\nresult = (a + b + c) / 3\n```",
        "[Missing Code]\n```python\nresult = np.maximum(np.maximum(a, b), c)\n```",
        "```python\nimport numpy as np\na = np.array([[ 0,  1,  2,  3,  4],\n   [ 5,  6,  7,  8,  9],\n   [10, 11, 12, 13, 14],\n   [15, 16, 17, 18, 19],\n   [20, 21, 22, 23, 24]])\n# [Begin of Missing Code]\nresult = np.fliplr(a).diagonal()\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\nresult = np.fliplr(a).diagonal()\n```",
        "[Begin of Missing Code]\nresult = np.array([a[i, i] for i in range(a.shape[0])], [a[i, a.shape[0]-i-1] for i in range(a.shape[0])])\n[End of Missing Code]",
        "[Missing Code]\n```python\nresult = []\nfor i in range(a.shape[1]):\n    result.append(a.diagonal(i))\nfor i in range(1, a.shape[0]):\n    result.append(a.diagonal(-i))\nresult = np.array(result)\n```",
        "[Missing Code]\n```python\nresult = X.flatten().tolist()\n```",
        "[Missing Code]\n```python\nresult = []\nfor i in range(X.shape[0]):\n    for j in range(X.shape[1]):\n        result.append(X[i, j])\n```",
        "[Missing Code]\n```python\nresult = []\nfor i in range(X.shape[0]):\n    for j in range(X.shape[1]):\n        result.append(X[i][j])\n```",
        "[Missing Code]\n```python\nresult = X.flatten(order='F').tolist()\n```",
        "[Solution Code]\n```python\nimport numpy as np\nmystr = \"100110\"\n# [Begin of Missing Code]\nresult = np.array(list(map(int, list(mystr))))\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\na[:, col] *= multiply_number\nresult = np.cumsum(a[:, col])\n```",
        "[Missing Code]\n```python\na[row] = a[row] * multiply_number\nresult = np.cumsum(a[row])\n```",
        "[Missing Code]\n```python\na[row] = a[row] / divide_number\nresult = np.prod(a[row])\n```",
        "[Missing Code]\n```python\nu, indices = np.unique(a, axis=0, return_index=True)\nresult = a[sorted(indices)]\n```",
        "[Missing Code]\nresult = a.shape[1]\n[End of Missing Code]",
        "[Missing Code]\n```python\nt_stat, p_value = scipy.stats.ttest_ind(a, b, equal_var=False)\n```",
        "[Missing Code]\n```python\n# Remove nans from the data\na = a[~np.isnan(a)]\nb = b[~np.isnan(b)]\n\n# Perform the t-test\nt_stat, p_value = scipy.stats.ttest_ind(a, b, equal_var=False)\n```",
        "[Missing Code]\n```python\n# calculate the standard deviation\nastd = np.sqrt(avar)\nbstd = np.sqrt(bvar)\n\n# calculate the standard error\nse = np.sqrt(astd**2/anobs + bstd**2/bnobs)\n\n# calculate the t statistic\nt_stat = (amean - bmean) / se\n\n# calculate the degrees of freedom\ndf = anobs + bnobs - 2\n\n# calculate the p-value\np_value = 2 * (1 - scipy.stats.t.cdf(np.abs(t_stat), df))\n```",
        "[Missing Code]\noutput = [x for x in A.tolist() if x not in B.tolist()]\n[End of Missing Code]",
        "```python\nimport numpy as np\nA=np.asarray([[1,1,1], [1,1,2], [1,1,3], [1,1,4]])\nB=np.asarray([[0,0,0], [1,0,2], [1,0,3], [1,0,4], [1,1,0], [1,1,1], [1,1,4]])\n# [Begin of Missing Code]\nA1 = np.array([tuple(i) for i in A])\nB1 = np.array([tuple(i) for i in B])\nA1_rows = set(map(tuple, A1))\nB1_rows = set(map(tuple, B1))\nsym_diff = np.array(list(A1_rows.symmetric_difference(B1_rows)))\noutput = np.array([x for x in sym_diff if tuple(x) in A1] + [x for x in sym_diff if tuple(x) in B1])\n# [End of Missing Code]\nprint(output)\n```",
        "[Missing Code]\nindices = np.ogrid[[slice(i) for i in a.shape]]\nindices[0] = np.argsort(a, axis=0)\nc = b[tuple(indices)]\n[End of Missing Code]",
        "[Missing Code]\nsort_indices = np.argsort(a, axis=0)\nixgrid = np.ogrid[[slice(x) for x in a.shape]]\nixgrid[0] = sort_indices\nc = b[ixgrid]\n[End of Missing Code]",
        "[Missing Code]\nindices = np.argsort(a, axis=0)[::-1]\nc = np.take_along_axis(b, indices, axis=0)\n[End of Missing Code]",
        "[Missing Code]\nindices = np.argsort(a.sum(axis=(1,2)))\nresult = b[indices]\n[End of Missing Code]",
        "[Missing Code]\na = np.delete(a, 2, 1)\n[End of Missing Code]",
        "[Missing Code]\na = np.delete(a, 2, 0)",
        "[Missing Code]\na = np.delete(a, [0, 2], axis=1)\n[End of Missing Code]",
        "[Missing Code]\n```python\ndel_col = del_col[del_col < a.shape[1]]\nresult = np.delete(a, del_col, axis=1)\n```",
        "[Missing Code]\na = np.insert(a, pos, element)",
        "[Missing Code]\na = np.insert(a, pos, element, axis=0)",
        "[Missing Code]\na = np.insert(a, pos, element)",
        "[Missing Code]\nfor i in range(len(pos)):\n    a = np.insert(a, pos[i], element[i], axis=0)",
        "```python\nimport numpy as np\npairs = [(2, 3), (3, 4), (4, 5)]\narray_of_arrays = np.array([np.arange(a*b).reshape(a,b) for (a, b) in pairs])\n# [Begin of Missing Code]\nimport copy\nresult = copy.deepcopy(array_of_arrays.tolist())\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\nresult = np.all(a == a[0,:])\n```",
        "[Missing Code]\n```python\nresult = np.all(a == a[:,0][:,None])\n```",
        "[Missing Code]\n```python\nresult = np.all(a[1:] == a[:-1])\n```",
        "[Missing Code]\n```python\nfrom scipy import integrate\n\nX, Y = np.meshgrid(x, y)\nZ = (np.cos(X))**4 + (np.sin(Y))**2\n\nresult = integrate.simps(integrate.simps(Z, x), y)\n```",
        "[Missing Code]\nresult = (np.cos(x)**4 + np.sin(y)**2)\n[End of Missing Code]",
        "[Missing Code]\n```python\ndef ecdf(data):\n    \"\"\" Compute ECDF \"\"\"\n    x = np.sort(data)\n    n = x.size\n    y = np.arange(1, n+1) / n\n    return(x,y)\n\nx, y = ecdf(grades)\nresult = dict(zip(x, y))\n```",
        "[Missing Code]\n```python\ndef ecdf(data):\n    \"\"\" Compute ECDF \"\"\"\n    x = np.sort(data)\n    n = x.size\n    y = np.arange(1, n+1) / n\n    return(x,y)\n\nx, y = ecdf(grades)\nresult = np.interp(eval, x, y)\n```",
        "[Missing Code]\n```python\ndef ecdf(x):\n    x = np.sort(x)\n    n = x.size\n    y = np.arange(1, n+1) / n\n    return(x,y)\n\nx, y = ecdf(grades)\nlow = x[np.argmax(y < threshold)]\nhigh = x[np.argmax(y >= threshold)]\nif high < low:\n    high = np.max(x)\n```\n[End of Missing Code]",
        "[Missing Code]\n```python\nnums = np.random.choice([0, 1], size=size, p=[1-one_ratio, one_ratio])\n```",
        "```python\nimport torch\nimport numpy as np\na = torch.ones(5)\n# [Begin of Missing Code]\na_np = a.numpy()\n# [End of Missing Code]\nprint(a_np)\n```",
        "```python\nimport torch\nimport numpy as np\na = np.ones(5)\n# [Begin of Missing Code]\na_pt = torch.from_numpy(a)\n# [End of Missing Code]\nprint(a_pt)\n```",
        "```python\nimport tensorflow as tf\nimport numpy as np\na = tf.ones([2,3,4])\n# [Begin of Missing Code]\na_np = a.numpy()\n# [End of Missing Code]\nprint(a_np)\n```",
        "```python\nimport tensorflow as tf\nimport numpy as np\na = np.ones([2,3,4])\n# [Begin of Missing Code]\na_tf = tf.convert_to_tensor(a)\n# [End of Missing Code]\nprint(a_tf)\n```",
        "[Missing Code]\n```python\nresult = np.argsort(a)[::-1]\n```",
        "[Missing Code]\n```python\nresult = np.argsort(a)\n```",
        "[Missing Code]\n```python\nresult = np.argsort(a)[-N:][::-1]\n```",
        "[Missing Code]\n```python\nfrom scipy.linalg import fractional_matrix_power\nresult = fractional_matrix_power(A, n)\n```",
        "```python\nimport numpy as np\na = np.array([[1,5,9,13],\n              [2,6,10,14],\n              [3,7,11,15],\n              [4,8,12,16]])\n# [Begin of Missing Code]\nresult = []\nfor i in range(0, a.shape[0], 2):\n    for j in range(0, a.shape[1], 2):\n        result.append(a[i:i+2, j:j+2])\nresult = np.array(result)\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\nresult = []\nfor i in range(a.shape[0]-1):\n    for j in range(a.shape[1]-1):\n        result.append(a[i:i+2, j:j+2])\n```",
        "[Missing Code]\n```python\nresult = []\nfor i in range(0, a.shape[0], 2):\n    for j in range(0, a.shape[1], 2):\n        result.append(a[i:i+2, j:j+2])\nresult = np.array(result)\n```",
        "[Missing Code]\n```python\nresult = []\nfor i in range(0, a.shape[0], patch_size):\n    for j in range(0, a.shape[1], patch_size):\n        if i + patch_size <= a.shape[0] and j + patch_size <= a.shape[1]:\n            result.append(a[i:i+patch_size, j:j+patch_size])\nresult = np.array(result)\n```",
        "[Missing Code]\n```python\nresult = a.reshape(h, w)\n```",
        "[Missing Code]\n```python\nresult = []\nfor i in range(0, a.shape[0], patch_size):\n    for j in range(0, a.shape[1], patch_size):\n        result.append(a[i:i+patch_size, j:j+patch_size])\nresult = [x for x in result if x.shape == (patch_size, patch_size)]\n```",
        "[Missing Code]\nresult = a[:, low:high]",
        "[Missing Code]\nresult = a[low:high]\n[End of Missing Code]",
        "[Begin of Missing Code]\nresult = a[:, low:min(high, a.shape[1])]\n[End of Missing Code]",
        "[Missing Code]\n```python\na = np.array(eval(string))\n```",
        "[Missing Code]\n```python\nbase = 10\nlog_min = np.log(min)/np.log(base)\nlog_max = np.log(max)/np.log(base)\nresult = np.power(base, np.random.uniform(log_min, log_max, n))\n```",
        "[Missing Code]\n```python\nbase = 10\nlog_min = np.log10(min)\nlog_max = np.log10(max)\nresult = np.power(base, np.random.uniform(log_min, log_max, n))\n```",
        "[Missing Code]\n```python\nlog_min = np.log(min)\nlog_max = np.log(max)\nresult = np.exp(np.random.uniform(log_min, log_max, n))\n```",
        "[Begin of Missing Code]\nB = pd.Series(index=A.index)\nB[0] = a * A[0]\nfor t in range(1, len(A)):\n    B[t] = a * A[t] + b * B[t-1]\n[End of Missing Code]",
        "[Missing Code]\n```python\nB = pd.Series(index=A.index)\nB[0] = a * A[0]\nB[1] = a * A[1] + b * B[0]\nfor t in range(2, len(A)):\n    B[t] = a * A[t] + b * B[t-1] + c * B[t-2]\n```",
        "[Missing Code]\n```python\nresult = np.empty((0,))\n```",
        "[Missing Code]\n```python\nresult = np.empty(shape=(3,0))\n```",
        "[Missing Code]\nresult = np.ravel_multi_index(index, dims)\n[End of Missing Code]",
        "[Missing Code]\n```python\nresult = np.ravel_multi_index(index, dims)\n```",
        "[Missing Code]\n```python\nvalues = np.zeros((2,3), dtype='int32')\ndf = pd.DataFrame(data=values, index=index, columns=columns)\ndf['b'] = df['b'].astype('float32')\ndf['c'] = df['c'].astype('float32')\n```",
        "[Missing Code]\nresult = np.bincount(accmap, weights=a)\n[End of Missing Code]",
        "[Missing Code]\n```python\nresult = np.bincount(index, weights=a).astype(int)\n```",
        "```python\nimport numpy as np\na = np.arange(1,11)\naccmap = np.array([0,1,0,0,0,-1,-1,2,2,1])\n# [Begin of Missing Code]\naccmap[accmap<0] += len(a)\nunique, inverse = np.unique(accmap, return_inverse=True)\nresult = np.bincount(inverse, weights=a)\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\nresult = np.minimum.reduceat(a, np.r_[np.unique(index, return_index=True)[1], len(a)])\n```",
        "[Missing Code]\n```python\nx = np.array(x)\ny = np.array(y)\nz = np.vectorize(elementwise_function)(x, y)\n```",
        "[Begin of Missing Code]\nresult = np.random.choice(len(lista_elegir), samples, p=probabilit)\nresult = [lista_elegir[i] for i in result]\n[End of Missing Code]",
        "[Missing Code]\n```python\ndef pad_slice(a, low_index, high_index):\n    pad_width = max(-low_index, high_index - a.shape[0] + 1, 0)\n    a_padded = np.pad(a, pad_width, mode='constant')\n    slice_ = a_padded[low_index + pad_width:high_index + pad_width, low_index + pad_width:high_index + pad_width]\n    return slice_\n\nresult = pad_slice(a, low_index, high_index)\n```\n[End of Missing Code]",
        "```python\nimport numpy as np\nx = np.array([-2, -1.4, -1.1, 0, 1.2, 2.2, 3.1, 4.4, 8.3, 9.9, 10, 14, 16.2])\n# [Begin of Missing Code]\nresult = x[x >= 0]\n# [End of Missing Code]\nprint(result)",
        "```python\nimport numpy as np\nx = np.array([-2+1j, -1.4, -1.1, 0, 1.2, 2.2+2j, 3.1, 4.4, 8.3, 9.9, 10+0j, 14, 16.2])\n# [Begin of Missing Code]\nresult = x[np.iscomplex(x)]\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\ndata = data[:len(data)//bin_size*bin_size]\nbin_data = data.reshape(-1, bin_size)\nbin_data_mean = bin_data.mean(axis=1)\n```",
        "[Missing Code]\n```python\ndata = data[:len(data)//bin_size*bin_size]\nbin_data = np.split(data, len(data)//bin_size)\nbin_data_max = [np.max(bin) for bin in bin_data]\n```",
        "```python\nimport numpy as np\ndata = np.array([[4, 2, 5, 6, 7],\n[ 5, 4, 3, 5, 7]])\nbin_size = 3\n# [Begin of Missing Code]\nbin_data = np.array([data[i:i+bin_size] for i in range(0, len(data), bin_size)])\nbin_data_mean = np.mean(bin_data, axis=2)\n# [End of Missing Code]\nprint(bin_data_mean)\n```",
        "[Missing Code]\n```python\ndata = data[::-1] # reverse the array\nbin_data = np.array_split(data, len(data)//bin_size) # split the array into bins\nbin_data_mean = [np.mean(bin) for bin in bin_data if len(bin) == bin_size] # calculate the mean of each bin\n```",
        "[Missing Code]\n```python\nbin_data = np.array([row[-bin_size::-bin_size][::-1] for row in data])\nbin_data_mean = np.mean(bin_data, axis=2)\n```",
        "[Missing Code]\n```python\nn_rows, n_cols = data.shape\nn_bins = n_cols // bin_size\nbin_data = data[:, -n_bins*bin_size:].reshape(n_rows, n_bins, bin_size)\nbin_data_mean = bin_data.mean(axis=2)\n```\n[End of Missing Code]",
        "[Missing Code]\n```python\ndef smoothclamp(x, x_min=0, x_max=1):\n    x = np.clip((x - x_min) / (x_max - x_min), 0, 1)\n    return (3 - 2 * x) * x * x * (x_max - x_min) + x_min\n```",
        "[Missing Code]\n```python\ndef smoothclamp(x, x_min=0, x_max=1, N=1):\n    x = np.clip((x - x_min) / (x_max - x_min), 0, 1)\n    return x_min + (x_max - x_min) * (x**N * (N+1 - N*x))\n```",
        "[Missing Code]\n```python\nfrom scipy.linalg import circulant\n\n# Create a circulant matrix with b\nc = circulant(b)\n\n# Perform dot product of a and each row of c\nresult = np.dot(c, a)\n```",
        "```python\n# [Begin of Missing Code]\nresult = df.values.reshape((4, 15, 5))\n# [End of Missing Code]```",
        "[Begin of Missing Code]\nresult = df.values.reshape((15, 4, 5))\n[End of Missing Code]",
        "[Missing Code]\n```python\nresult = ((a[:, None] & (1 << np.arange(m))) > 0).astype(int)\nresult = result[:, ::-1]\n```",
        "[Missing Code]\n```python\nresult = np.zeros((len(a), m), dtype=np.uint8)\nfor i in range(len(a)):\n    result[i] = np.array(list(np.binary_repr(np.abs(a[i]), m)), dtype=np.uint8)\n```",
        "[Missing Code]\n```python\nbinary_a = ((a[:, None] & (1 << np.arange(m))) > 0).astype(int)\nresult = np.bitwise_xor.reduce(binary_a)\n```",
        "[Missing Code]\n```python\nmean = np.mean(a)\nstd_dev = np.std(a)\nresult = (mean - 3*std_dev, mean + 3*std_dev)\n```",
        "[Missing Code]\n```python\nmu = np.mean(a)\nsigma = np.std(a)\nresult = (mu - 2*sigma, mu + 2*sigma)\n```",
        "[Missing Code]\n```python\nmu = np.mean(a)\nsigma = np.std(a)\nresult = (mu - 3*sigma, mu + 3*sigma)\n```",
        "[Missing Code]\n```python\nmu, sigma = a.mean(), a.std()\nresult = (a < mu - 2 * sigma) | (a > mu + 2 * sigma)\n```",
        "[Missing Code]\n```python\nimport numpy.ma as ma\nmasked_data = ma.masked_where(DataArray < 0, DataArray)\nprob = ma.median(masked_data)\n```",
        "[Missing Code]\na[zero_rows, :] = 0\na[:, zero_cols] = 0",
        "[Missing Code]\na[zero_rows, :] = 0\na[:, zero_cols] = 0",
        "[Missing Code]\n```python\na[1,:] = 0\na[:,0] = 0\n```",
        "```python\nimport numpy as np\na = np.array([[0, 1], [2, 1], [4, 8]])\n# [Begin of Missing Code]\nmask = (a == np.max(a, axis=1)[:, None])\n# [End of Missing Code]\nprint(mask)\n```",
        "[Missing Code]\n```python\nmask = a == np.min(a, axis=1)[:, None]\n```",
        "[Missing Code]\n```python\nresult = np.corrcoef(post, distance)[0, 1]\n```",
        "```python\nimport numpy as np\nX = np.random.randint(2, 10, (5, 6))\n# [Begin of Missing Code]\nresult = np.einsum('ij,ik->jik', X, X)\n# [End of Missing Code]\nprint(result)\n```",
        "```python\n# [Begin of Missing Code]\nX = np.array([np.linalg.cholesky(Y[i]) for i in range(Y.shape[0])]).T\n# [End of Missing Code]\n```",
        "[Missing Code]\nis_contained = number in a\n[End of Missing Code]",
        "[Begin of Missing Code]\nC = np.setdiff1d(A, B)\n[End of Missing Code]",
        "[Missing Code]\n```python\nC = A[np.isin(A, B)]\n```",
        "```python\nimport numpy as np\nA = np.array([1,1,2,3,3,3,4,5,6,7,8,8])\nB = np.array([1,4,8])\n# [Begin of Missing Code]\nC = A[np.logical_or(np.logical_and(A > B[0], A < B[1]), np.logical_and(A > B[1], A < B[2]))]\n# [End of Missing Code]\nprint(C)\n```",
        "[Missing Code]\n```python\nresult = len(a) - rankdata(a).astype(int) + 1\n```",
        "```python\nimport numpy as np\nfrom scipy.stats import rankdata\na = [1,2,3,4,3,2,3,4]\n# [Begin of Missing Code]\nresult = len(a) - rankdata(a, method='ordinal') + 1\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\n    result = len(a) - rankdata(a).astype(int) + 1\n```",
        "[Missing Code]\ndists = np.dstack((x_dists, y_dists))",
        "```python\nimport numpy as np\nx_dists = np.array([[ 0, -1, -2],\n                 [ 1,  0, -1],\n                 [ 2,  1,  0]])\n\ny_dists = np.array([[ 0, -1, -2],\n                 [ 1,  0, -1],\n                 [ 2,  1,  0]])\n# [Begin of Missing Code]\ndists = np.dstack((x_dists, y_dists))\n# [End of Missing Code]\nprint(dists)\n```",
        "[Missing Code]\nresult = a[:, second][:, :, third]\n[End of Missing Code]",
        "[Missing Code]\n```python\narr = np.zeros((20,10,10,2))\n```",
        "[Missing Code]\n```python\nl1 = np.abs(X).sum(axis=1)\nresult = X / l1[:, None]\n```",
        "[Begin of Missing Code]\nnorm = np.linalg.norm(X, ord=2, axis=1, keepdims=True)\nresult = X/norm\n[End of Missing Code]",
        "[Begin of Missing Code]\nnorms = np.abs(X).max(axis=1)\nresult = X / norms[:, None]\n[End of Missing Code]",
        "[Missing Code]\nconditions = [df['a'].astype(str).str.contains(target)]\ndf['result'] = np.select(conditions, choices, default=np.nan)",
        "[Missing Code]\n```python\nfrom scipy.spatial import distance_matrix\nresult = distance_matrix(a, a)\n```",
        "[Missing Code]\n```python\nfrom scipy.spatial import distance\nresult = distance.cdist(a, a, 'euclidean')\n```",
        "[Missing Code]\n```python\nfrom scipy.spatial.distance import pdist, squareform\nresult = squareform(pdist(a, 'euclidean'))\n```",
        "[Begin of Missing Code]\nNA = NA.astype(float)\nAVG = np.mean(NA, axis=0)\n[End of Missing Code]",
        "[Begin of Missing Code]\nNA = np.asarray(A, dtype=np.float)\nAVG = np.mean(NA, axis=0)\n[End of Missing Code]",
        "[Missing Code]\n```python\nNA = np.array([np.inf if i=='np.inf' else float(i) for i in A])\nAVG = np.mean(NA[~np.isinf(NA)], axis=0)\n```",
        "[Missing Code]\n```python\nmask = np.concatenate(([True], a[1:] != a[:-1], [True]))\nresult = a[mask]\nresult = result[result != 0]\n```",
        "[Missing Code]\n```python\nmask = np.concatenate(([False], a[1:] != a[:-1]))\nresult = a[mask]\nresult = result[result != 0]\n```",
        "[Begin of Missing Code]\ndf = pd.DataFrame({'lat': lat.flatten(), 'lon': lon.flatten(), 'val': val.flatten()})\n[End of Missing Code]",
        "[Missing Code]\n```python\n    lat = lat.flatten()\n    lon = lon.flatten()\n    val = val.flatten()\n    df = pd.DataFrame({'lat': lat, 'lon': lon, 'val': val})\n```",
        "[Missing Code]\n```python\ndf = pd.DataFrame({'lat': lat.flatten(), 'lon': lon.flatten(), 'val': val.flatten()})\ndf['maximum'] = df[['lat', 'lon', 'val']].max(axis=1)\n```",
        "[Missing Code]\n```python\nresult = []\nfor i in range(a.shape[0]):\n    for j in range(a.shape[1]):\n        r = np.arange(max(0,i-size[0]//2),min(a.shape[0],i+size[0]//2+1))\n        c = np.arange(max(0,j-size[1]//2),min(a.shape[1],j+size[1]//2+1))\n        result.append(a[np.ix_(r,c)])\n```",
        "```python\nimport numpy as np\na = np.array([[1,2,3,4],\n       [2,3,4,5],\n       [3,4,5,6],\n       [4,5,6,7]])\nsize = (3, 3)\n# [Begin of Missing Code]\nresult = []\nfor i in range(a.shape[0]):\n    for j in range(a.shape[1]):\n        result.append(a[max(0, i - size[0] // 2):min(a.shape[0], i + size[0] // 2 + 1),\n                        max(0, j - size[1] // 2):min(a.shape[1], j + size[1] // 2 + 1)])\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\nreal_parts = np.mean(a.real)\nimag_parts = np.mean(a.imag)\nresult = complex(real_parts, imag_parts)\n```",
        "[Missing Code]\n```python\nreal_parts = np.real(a)\nimag_parts = np.imag(a)\nreal_mean = np.mean(real_parts[np.isfinite(real_parts)])\nimag_mean = np.mean(imag_parts[np.isfinite(imag_parts)])\nresult = real_mean + imag_mean*1j\n```",
        "[Missing Code]\n```python\nslicer = [slice(None)] * Z.ndim\nslicer[-1] = slice(-1, None)\nresult = Z[tuple(slicer)]\n```",
        "[Missing Code]\n```python\nslices = [slice(None)] * a.ndim\nslices[0] = slice(-1, None)\nresult = a[tuple(slices)]\n```",
        "```python\n# [Begin of Missing Code]\nresult = any((c == x).all() for x in CNTS)\n# [End of Missing Code]\nprint(result)",
        "[Begin of Missing Code]\nresult = any((np.array_equal(c, cnt) for cnt in CNTS))\n[End of Missing Code]",
        "[Missing Code]\n```python\nf = intp.interp2d(x_new, y_new, a, kind='linear')\nresult = f(x_new, y_new)\n```",
        "[Missing Code]\ndf = pd.DataFrame(data)\ndf[name] = df.groupby('D')['Q'].cumsum()",
        "[Missing Code]\n```python\ni = np.diag(i)\n```",
        "[Missing Code]\n```python\na *= np.eye(a.shape[0])\n```",
        "[Missing Code]\n```python\nstart_u = pd.to_datetime(start).value//10**9\nend_u = pd.to_datetime(end).value//10**9\nresult = pd.to_datetime(np.linspace(start_u, end_u, n), unit='s')\n```",
        "[Missing Code]\n```python\nresult = np.where((x == a) & (y == b))\nif len(result[0]) > 0:\n    result = result[0][0]\nelse:\n    result = -1\n```",
        "[Missing Code]\n```python\nresult = np.where((x == a) & (y == b))[0]\n```",
        "[Missing Code]\n```python\nx = np.array(x)\ny = np.array(y)\np = np.polyfit(x, y, 2)\nresult = p.tolist()\n```",
        "[Missing Code]\n```python\nX = np.vander(x, degree + 1)\nresult = np.linalg.lstsq(X, y, rcond=None)[0]\n```",
        "```python\nimport numpy as np\nimport pandas as pd\na = np.arange(4)\ndf = pd.DataFrame(np.repeat([1, 2, 3, 4], 4).reshape(4, -1))\n# [Begin of Missing Code]\ndf = df.apply(lambda x: x-a[x.name], axis=1)\n# [End of Missing Code]\nprint(df)\n```",
        "[Missing Code]\n```python\nresult = np.einsum('...k,kl->...l', A, B)\n```",
        "[Missing Code]\n```python\nscaler = MinMaxScaler()\na = a.reshape(-1, 1)\nresult = scaler.fit_transform(a)\nresult = result.reshape(2, 2)\n```",
        "[Missing Code]\n```python\nscaler = MinMaxScaler()\nresult = scaler.fit_transform(arr.T).T\n```",
        "[Missing Code]\n```python\nresult = []\nfor matrix in a:\n    scaler = MinMaxScaler()\n    scaler.fit(matrix)\n    result.append(scaler.transform(matrix))\nresult = np.array(result)\n```",
        "[Solution Code]\n```python\nimport numpy as np\narr = (np.random.rand(100, 50)-0.5) * 50\n# [Begin of Missing Code]\nmask1 = arr < -10\nmask2 = arr >= 15\narr[mask1] = 0\narr[mask2] = 30\narr[~mask1 & ~mask2] += 5\n# [End of Missing Code]\nprint(arr)\n```",
        "[Missing Code]\n```python\nfor i in range(arr.shape[0]):\n    mask = arr[i] < n1[i]\n    mask2 = arr[i] >= n2[i]\n    arr[i][mask] = 0\n    arr[i][mask2] = 30\n    arr[i][~mask & ~mask2] += 5\n```",
        "[Missing Code]\n```python\ntolerance = 1e-10\nresult = np.nonzero(np.abs(s1 - s2) > tolerance)[0].shape[0]\n```\n[End of Missing Code]",
        "[Missing Code]\n```python\n# Use np.isclose to compare s1 and s2 with a tolerance\nmask = np.isclose(s1, s2, equal_nan=True)\n# Count the number of False in mask, which are the truly different elements in s1 and s2\nresult = np.count_nonzero(~mask)\n```",
        "[Missing Code]\nresult = all((np.array_equal(a[0], x) for x in a))\n[End of Missing Code]",
        "[Missing Code]\nresult = all(np.isnan(x).any() for x in a)",
        "[Missing Code]\n```python\npad_shape = ((0, shape[0] - a.shape[0]), (0, shape[1] - a.shape[1]))\nresult = np.pad(a, pad_width=pad_shape, mode='constant', constant_values=0)\n```",
        "[Missing Code]\n```python\npad_shape = ((0, shape[0] - a.shape[0]), (0, shape[1] - a.shape[1]))\nresult = np.pad(a, pad_width=pad_shape, mode='constant', constant_values=0)\n```",
        "[Missing Code]\n```python\npad_width = ((0, shape[0] - a.shape[0]), (0, shape[1] - a.shape[1]))\nresult = np.pad(a, pad_width, mode='constant', constant_values=element)\n```",
        "[Missing Code]\n```python\npad_shape = ((0, shape[0] - arr.shape[0]), (0, shape[1] - arr.shape[1]))\nresult = np.pad(arr, pad_shape, 'constant')\n```",
        "[Missing Code]\n```python\npad_rows = shape[0] - a.shape[0]\npad_cols = shape[1] - a.shape[1]\n\npad_top = pad_rows // 2\npad_bottom = pad_rows - pad_top\n\npad_left = pad_cols // 2\npad_right = pad_cols - pad_left\n\nresult = np.pad(a, ((pad_top, pad_bottom), (pad_left, pad_right)), 'constant', constant_values=0)\n```",
        "[Missing Code]\na = a.reshape(a.shape[0]//3,3)\n[End of Missing Code]",
        "[Begin of Missing Code]\nresult = np.choose(b, a.transpose(2,0,1))\n[End of Missing Code]",
        "```python\n# [Begin of Missing Code]\nresult = np.take_along_axis(a, np.expand_dims(b, axis=-1), axis=-1).squeeze()\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\nN, M = b.shape\nI, J = np.ogrid[:N,:M]\nresult = a[I, J, b]\n```",
        "[Missing Code]\n```python\nN, M, T = a.shape\nindices = np.ogrid[:N, :M]\nresult = a[indices[0], indices[1], b].sum()\n```",
        "[Begin of Missing Code]\nN, M, T = a.shape\nindices = np.indices((N, M))\nresult = np.sum(a[indices[0], indices[1], b] * np.arange(T) != b)\n[End of Missing Code]",
        "[Begin of Missing Code]\ndf['b'] = np.where((df['a'] > 1) & (df['a'] <= 4), df['b'], np.nan)\nresult = df['b'].tolist()\n[End of Missing Code]",
        "[Missing Code]\n```python\nmask = np.any(im, axis=0)\nmask2 = np.any(im, axis=1)\nresult = im[np.ix_(mask2, mask)]\n```",
        "[Missing Code]\n```python\nrows = np.any(A, axis=1)\ncols = np.any(A, axis=0)\nrmin, rmax = np.where(rows)[0][[0, -1]]\ncmin, cmax = np.where(cols)[0][[0, -1]]\nresult = A[rmin:rmax+1, cmin:cmax+1]\n```",
        "[Missing Code]\n```python\nwhile np.any(im[0]):\n    im = im[1:]\n\nwhile np.any(im[:,0]):\n    im = np.delete(im,0,1)\n\nwhile np.any(im[-1]):\n    im = im[:-1]\n\nwhile np.any(im[:,-1]):\n    im = np.delete(im,-1,1)\n\nresult = im\n```",
        "[Missing Code]\n```python\nmask = im > 0\nrows = np.flatnonzero(np.any(mask, axis=1))\ncols = np.flatnonzero(np.any(mask, axis=0))\nresult = im[rows.min():rows.max()+1, cols.min():cols.max()+1]\n```"
    ],
    "Matplotlib": [
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = 10 * np.random.randn(10)\ny = x\n\n# plot x vs y, label them using \"x-y\" in the legend\n# SOLUTION START\nplt.plot(x, y, label='x-y')\nplt.legend()\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.random.rand(10)\ny = np.random.rand(10)\nplt.scatter(x, y)\n\n# how to turn on minor ticks on y axis only\n# SOLUTION START\nplt.gca().yaxis.set_minor_locator(plt.AutoMinorLocator())\nplt.grid(which='minor', axis='y', linestyle=':', linewidth=0.5)\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.random.rand(10)\ny = np.random.rand(10)\nplt.scatter(x, y)\n\n# how to turn on minor ticks\n# SOLUTION START\nplt.minorticks_on()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.random.rand(10)\ny = np.random.rand(10)\nplt.scatter(x, y)\n\n# how to turn on minor ticks on x axis only\n# SOLUTION START\nplt.gca().xaxis.set_minor_locator(plt.MultipleLocator(0.1))\nplt.minorticks_on()\nplt.tick_params(axis='y', which='both', left=False, right=False, labelleft=True)\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.arange(10)\n\n# draw a line (with random y) for each different line style\n# SOLUTION START\nline_styles = ['-', '--', '-.', ':']\n\nfor style in line_styles:\n    y = np.random.rand(10)\n    plt.plot(x, y, linestyle=style)\n\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.arange(10)\n\n# draw a line (with random y) for each different line style\n# SOLUTION START\nline_styles = ['-', '--', '-.', ':']\n\nfor style in line_styles:\n    y = np.random.rand(10)\n    plt.plot(x, y, linestyle=style)\n\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.arange(10)\ny = np.random.randn(10)\n\n# line plot x and y with a thin diamond marker\n# SOLUTION START\nplt.plot(x, y, 'd-', markersize=5)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.arange(10)\ny = np.random.randn(10)\n\n# line plot x and y with a thick diamond marker\n# SOLUTION START\nplt.plot(x, y, 'D-', markersize=10)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style(\"whitegrid\")\ntips = sns.load_dataset(\"tips\")\nax = sns.boxplot(x=\"day\", y=\"total_bill\", data=tips)\n\n# set the y axis limit to be 0 to 40\n# SOLUTION START\nax.set(ylim=(0, 40))\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = 10 * np.random.randn(10)\n\nplt.plot(x)\n\n# highlight in red the x range 2 to 4\n# SOLUTION START\nplt.axvspan(2, 4, color='red', alpha=0.5)\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# draw a full line from (0,0) to (1,2)\n# SOLUTION START\nplt.plot([0, 1], [0, 2])\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# draw a line segment from (0,0) to (1,2)\n# SOLUTION START\nplt.plot([0, 1], [0, 2])\nplt.show()\n# SOLUTION END\n```",
        "```python\n# SOLUTION START\nseaborn.relplot(x=\"Height (cm)\", y=\"Weight (kg)\", hue=\"Gender\", data=df)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.arange(10)\ny = 2 * np.random.rand(10)\n\n# draw a regular matplotlib style plot using seaborn\n# SOLUTION START\nsns.set_style(\"whitegrid\")\nplt.plot(x, y)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.sin(x)\n\n# draw a line plot of x vs y using seaborn and pandas\n# SOLUTION START\n# Create a pandas DataFrame\ndf = pd.DataFrame({'x': x, 'y': y})\n\n# Use seaborn to create a line plot\nsns.lineplot(data=df, x='x', y='y')\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.random.randn(10)\ny = np.random.randn(10)\n\n# in plt.plot(x, y), use a plus marker and give it a thickness of 7\n# SOLUTION START\nplt.plot(x, y, marker='+', linewidth=7)\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.linspace(0, 2 * np.pi, 10)\ny = np.cos(x)\n\nplt.plot(x, y, label=\"sin\")\n\n# show legend and set the font to size 20\n# SOLUTION START\nplt.legend(fontsize=20)\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.linspace(0, 2 * np.pi, 10)\ny = np.cos(x)\n\n# set legend title to xyz and set the title font to size 20\n# SOLUTION START\nplt.plot(x, y, label='cos(x)')\nplt.legend(title='xyz', title_fontsize='20')\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.random.randn(10)\ny = np.random.randn(10)\n\n(l,) = plt.plot(range(10), \"o-\", lw=5, markersize=30)\n\n# set the face color of the markers to have an alpha (transparency) of 0.2\n# SOLUTION START\nplt.setp(l, markerfacecolor=(1, 1, 1, 0.2))\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.random.randn(10)\ny = np.random.randn(10)\n\n(l,) = plt.plot(range(10), \"o-\", lw=5, markersize=30)\n\n# make the border of the markers solid black\n# SOLUTION START\nplt.setp(l, markeredgecolor='black', markeredgewidth=1)\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.random.randn(10)\ny = np.random.randn(10)\n\n(l,) = plt.plot(range(10), \"o-\", lw=5, markersize=30)\n\n# set both line and marker colors to be solid red\n# SOLUTION START\nl.set_color('red')\nl.set_markerfacecolor('red')\nl.set_markeredgecolor('red')\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.linspace(0, 2 * np.pi, 10)\ny = np.cos(x)\nplt.plot(x, y, label=\"sin\")\n\n# rotate the x axis labels clockwise by 45 degrees\n# SOLUTION START\nplt.xticks(rotation=45)\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.linspace(0, 2 * np.pi, 10)\ny = np.cos(x)\nplt.plot(x, y, label=\"sin\")\n\n# rotate the x axis labels counter clockwise by 45 degrees\n# SOLUTION START\nplt.xticks(rotation=45)\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.linspace(0, 2 * np.pi, 10)\ny = np.cos(x)\nplt.plot(x, y, label=\"sin\")\n\n# put a x axis ticklabels at 0, 2, 4...\n# SOLUTION START\nplt.xticks(np.arange(0, max(x), 2))\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.random.randn(10)\ny = np.random.randn(10)\nsns.distplot(x, label=\"a\", color=\"0.25\")\nsns.distplot(y, label=\"b\", color=\"0.25\")\n\n# add legends\n# SOLUTION START\nplt.legend()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nH = np.random.randn(10, 10)\n\n# color plot of the 2d array H\n# SOLUTION START\nplt.imshow(H, cmap='viridis')\nplt.colorbar()\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nH = np.random.randn(10, 10)\n\n# show the 2d array H in black and white\n# SOLUTION START\nplt.imshow(H, cmap='gray')\nplt.colorbar()\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.linspace(0, 2 * np.pi, 10)\ny = np.cos(x)\n\n# set xlabel as \"X\"\n# put the x label at the right end of the x axis\n# SOLUTION START\nplt.plot(x, y)\nplt.xlabel(\"X\", loc='right')\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = sns.load_dataset(\"planets\")\ng = sns.boxplot(x=\"method\", y=\"orbital_period\", data=df)\n\n# rotate the x axis labels by 90 degrees\n# SOLUTION START\nplt.xticks(rotation=90)\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ny = 2 * np.random.rand(10)\nx = np.arange(10)\nplt.plot(x, y)\nmyTitle = \"Some really really long long long title I really really need - and just can't - just can't - make it any - simply any - shorter - at all.\"\n\n# fit a very long title myTitle into multiple lines\n# SOLUTION START\nplt.title(\"\\n\".join([myTitle[i:i+30] for i in range(0, len(myTitle), 30)]))\n# SOLUTION END\nplt.show()\n```\nIn the solution, we are splitting the title into multiple lines by inserting a newline character (`\\n`) every 30 characters. This is done using a list comprehension that iterates over the title string in steps of 30 characters, and then joining the resulting list of strings with the newline character. The number 30 can be adjusted according to the desired line length.",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ny = 2 * np.random.rand(10)\nx = np.arange(10)\n\n# make the y axis go upside down\n# SOLUTION START\nplt.scatter(x, y)\nplt.gca().invert_yaxis()\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.random.randn(10)\ny = x\nplt.scatter(x, y)\n\n# put x ticks at 0 and 1.5 only\n# SOLUTION START\nplt.xticks([0, 1.5])\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.random.randn(10)\ny = x\nplt.scatter(x, y)\n\n# put y ticks at -1 and 1 only\n# SOLUTION START\nplt.yticks([-1, 1])\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.random.rand(10)\ny = np.random.rand(10)\nz = np.random.rand(10)\n\n# plot x, then y then z, but so that x covers y and y covers z\n# SOLUTION START\nplt.plot(z, color='blue', linewidth=5)\nplt.plot(y, color='green', linewidth=7)\nplt.plot(x, color='red', linewidth=9)\nplt.show()\n# SOLUTION END\n```\nIn this solution, we plot z first, then y, then x. The linewidth parameter is used to control the thickness of the lines. By making the line for x thicker than the line for y, and the line for y thicker than the line for z, we ensure that x covers y and y covers z.",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.random.randn(10)\ny = np.random.randn(10)\n\n# in a scatter plot of x, y, make the points have black borders and blue face\n# SOLUTION START\nplt.scatter(x, y, edgecolors='black', facecolors='blue')\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ny = 2 * np.random.rand(10)\nx = np.arange(10)\n\n# make all axes ticks integers\n# SOLUTION START\nplt.plot(x, y)\nplt.xticks(np.arange(min(x), max(x)+1, 1.0))\nplt.yticks(np.arange(min(y), max(y)+1, 1.0))\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndata = {\n    \"reports\": [4, 24, 31, 2, 3],\n    \"coverage\": [35050800, 54899767, 57890789, 62890798, 70897871],\n}\ndf = pd.DataFrame(data)\nsns.factorplot(y=\"coverage\", x=\"reports\", kind=\"bar\", data=df, label=\"Total\")\n\n# do not use scientific notation in the y axis ticks labels\n# SOLUTION START\nplt.ticklabel_format(style='plain', axis='y')\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ny = 2 * np.random.rand(10)\nx = np.arange(10)\nax = sns.lineplot(x=x, y=y)\n\n# How to plot a dashed line on seaborn lineplot?\n# SOLUTION START\nax.lines[0].set_linestyle(\"--\")\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.linspace(0, 2 * np.pi, 400)\ny1 = np.sin(x)\ny2 = np.cos(x)\n\n# plot x vs y1 and x vs y2 in two subplots, sharing the x axis\n# SOLUTION START\nfig, axs = plt.subplots(2, sharex=True)\nfig.suptitle('Sine and Cosine Plots')\naxs[0].plot(x, y1, 'tab:orange')\naxs[0].set_title('Sine')\naxs[1].plot(x, y2, 'tab:blue')\naxs[1].set_title('Cosine')\n\nfor ax in axs.flat:\n    ax.set(xlabel='x', ylabel='y')\n\n# Hide x labels and tick labels for top plots and y ticks for right plots.\nfor ax in axs.flat:\n    ax.label_outer()\n\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.linspace(0, 2 * np.pi, 400)\ny1 = np.sin(x)\ny2 = np.cos(x)\n\n# plot x vs y1 and x vs y2 in two subplots\n# remove the frames from the subplots\n# SOLUTION START\n\nfig, axs = plt.subplots(2)\nfig.suptitle('Sin and Cos Functions')\n\n# Plotting sin function\naxs[0].plot(x, y1, 'tab:orange')\naxs[0].set_title('sin(x)')\naxs[0].spines['top'].set_visible(False)\naxs[0].spines['right'].set_visible(False)\naxs[0].spines['bottom'].set_visible(False)\naxs[0].spines['left'].set_visible(False)\n\n# Plotting cos function\naxs[1].plot(x, y2, 'tab:blue')\naxs[1].set_title('cos(x)')\naxs[1].spines['top'].set_visible(False)\naxs[1].spines['right'].set_visible(False)\naxs[1].spines['bottom'].set_visible(False)\naxs[1].spines['left'].set_visible(False)\n\nplt.show()\n\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.arange(10)\ny = np.sin(x)\ndf = pd.DataFrame({\"x\": x, \"y\": y})\nsns.lineplot(x=\"x\", y=\"y\", data=df)\n\n# remove x axis label\n# SOLUTION START\nplt.xlabel('')\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.arange(10)\ny = np.sin(x)\ndf = pd.DataFrame({\"x\": x, \"y\": y})\nsns.lineplot(x=\"x\", y=\"y\", data=df)\n\n# remove x tick labels\n# SOLUTION START\nplt.xticks([], [])\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.arange(10)\ny = np.random.randn(10)\nplt.scatter(x, y)\n\n# show xticks and vertical grid at x positions 3 and 4\n# SOLUTION START\nplt.xticks([3, 4])\nplt.grid(axis='x')\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.arange(10)\ny = np.random.randn(10)\nplt.scatter(x, y)\n\n# show yticks and horizontal grid at y positions 3 and 4\n# SOLUTION START\nplt.yticks([3, 4])\nplt.grid(axis='y')\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.arange(10)\ny = np.random.randn(10)\nplt.scatter(x, y)\n\n# show yticks and horizontal grid at y positions 3 and 4\n# show xticks and vertical grid at x positions 1 and 2\n# SOLUTION START\nplt.yticks([3, 4])\nplt.xticks([1, 2])\nplt.grid(axis='y', which='both', linestyle='-', color='grey')\nplt.grid(axis='x', which='both', linestyle='-', color='grey')\n# SOLUTION END\nplt.show()\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = np.arange(10)\ny = np.random.randn(10)\nplt.scatter(x, y)\n\n# show grids\n# SOLUTION START\nplt.grid(True)\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = 10 * np.random.randn(10)\ny = x\nplt.plot(x, y, label=\"x-y\")\n\n# put legend in the lower right\n# SOLUTION START\nplt.legend(loc='lower right')\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(ncols=2, nrows=2, figsize=(8, 6))\naxes = axes.flatten()\n\nfor ax in axes:\n    ax.set_ylabel(r\"$\\ln\\left(\\frac{x_a-x_b}{x_a-x_c}\\right)$\")\n    ax.set_xlabel(r\"$\\ln\\left(\\frac{x_a-x_d}{x_a-x_e}\\right)$\")\n\n# Adjust the subplot padding\nplt.tight_layout()\n\nplt.show()\nplt.clf()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10, 20)\nz = np.arange(10)\n\nimport matplotlib.pyplot as plt\n\nplt.plot(x, y, label='Y')\nplt.plot(x, z, label='Z')\n\n# Give names to the lines in the above plot 'Y' and 'Z' and show them in a legend\n# SOLUTION START\nplt.legend()\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ncolumn_labels = list(\"ABCD\")\nrow_labels = list(\"WXYZ\")\ndata = np.random.rand(4, 4)\nfig, ax = plt.subplots()\nheatmap = ax.pcolor(data, cmap=plt.cm.Blues)\n\n# Move the x-axis of this heatmap to the top of the plot\n# SOLUTION START\nax.xaxis.tick_top()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x\n# Label the x-axis as \"X\"\n# Set the space between the x-axis label and the x-axis to be 20\n# SOLUTION START\nplt.plot(x, y)\nplt.xlabel(\"X\", labelpad=20)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# plot y over x\n# do not show xticks for the plot\n# SOLUTION START\nplt.plot(x, y)\nplt.xticks([]) # this line hides the xticks\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x\n# move the y axis ticks to the right\n# SOLUTION START\nplt.plot(x, y)\nplt.gca().yaxis.tick_right()\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x and label y axis \"Y\"\n# Show y axis ticks on the left and y axis label on the right\n# SOLUTION START\nplt.plot(x, y)\nplt.ylabel(\"Y\")\nplt.yticks(np.arange(min(y), max(y)+1, 1))\nplt.gca().yaxis.tick_left()\nplt.gca().yaxis.set_label_position(\"right\")\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\nimport numpy as np, pandas as pd\nimport seaborn as sns\n\ntips = sns.load_dataset(\"tips\")\n\n# Make a seaborn joint regression plot (kind='reg') of 'total_bill' and 'tip' in the tips dataframe\n# change the line and scatter plot color to green but keep the distribution plot in blue\n# SOLUTION START\njoint = sns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind='reg', color='g')\njoint.plot_joint(plt.scatter, c='g', s=30, linewidth=1, marker=\"+\")\njoint.ax_marg_x.hist(tips['total_bill'], color=\"b\", alpha=.6)\njoint.ax_marg_y.hist(tips['tip'], color=\"b\", alpha=.6, orientation=\"horizontal\")\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\nimport numpy as np, pandas as pd\nimport seaborn as sns\n\ntips = sns.load_dataset(\"tips\")\n\n# Make a seaborn joint regression plot (kind='reg') of 'total_bill' and 'tip' in the tips dataframe\n# change the line color in the regression to green but keep the histograms in blue\n# SOLUTION START\njoint = sns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind='reg', color='b')\njoint.plot_joint(plt.scatter, c='b', s=30, linewidth=1, marker=\"+\")\njoint.ax_joint.collections[0].set_color('g')\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\nimport numpy as np, pandas as pd\nimport seaborn as sns\n\ntips = sns.load_dataset(\"tips\")\n\n# Make a seaborn joint regression plot (kind='reg') of 'total_bill' and 'tip' in the tips dataframe\n# do not use scatterplot for the joint plot\n# SOLUTION START\nsns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind='reg')\nplt.show()\n# SOLUTION END\n```",
        "```python\n# SOLUTION START\ndf.set_index('celltype').plot(kind='bar', rot=0)\nplt.xlabel('celltype')\nplt.ylabel('value')\nplt.show()\n# SOLUTION END\n```",
        "```python\n# SOLUTION START\ndf.set_index('celltype').plot(kind='bar')\nplt.xticks(rotation=45)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x and label the x axis as \"X\"\n# Make both the x axis ticks and the axis label red\n# SOLUTION START\nplt.plot(x, y)\nplt.xlabel(\"X\", color='red')\nplt.tick_params(axis='x', colors='red')\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x and label the x axis as \"X\"\n# Make the line of the x axis red\n# SOLUTION START\nplt.plot(x, y, color='red')\nplt.xlabel('X')\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# plot y over x with tick font size 10 and make the x tick labels vertical\n# SOLUTION START\nplt.plot(x, y)\nplt.xticks(fontsize=10, rotation='vertical')\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\n\n# draw vertical lines at [0.22058956, 0.33088437, 2.20589566]\n# SOLUTION START\nx_values = [0.22058956, 0.33088437, 2.20589566]\n\nfor x in x_values:\n    plt.axvline(x=x, color='r')\n\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\nimport numpy\n\nxlabels = list(\"ABCD\")\nylabels = list(\"CDEF\")\nrand_mat = numpy.random.rand(4, 4)\n\n# Plot of heatmap with data in rand_mat and use xlabels for x-axis labels and ylabels as the y-axis labels\n# Make the x-axis tick labels appear on top of the heatmap and invert the order or the y-axis labels (C to F from top to bottom)\n# SOLUTION START\nfig, ax = plt.subplots()\nheatmap = ax.imshow(rand_mat, cmap='hot', interpolation='nearest')\n\n# Move x-axis to top and invert y-axis\nax.xaxis.tick_top()\nax.invert_yaxis()\n\n# Set the x-axis and y-axis labels\nax.set_xticklabels(xlabels)\nax.set_yticklabels(ylabels)\n\n# Show the plot\nplt.show()\n# SOLUTION END\n```",
        "```python\n# SOLUTION START\nfig = plt.figure()\nax = fig.add_subplot(111)\nline1, = ax.plot(time, Swdown, \"-\", label=\"Swdown\")\nline2, = ax.plot(time, Rn, \"-\", label=\"Rn\")\nax2 = ax.twinx()\nline3, = ax2.plot(time, temp, \"-r\", label=\"temp\")\n\n# Create a legend for the whole figure\nlines = [line1, line2, line3]\nlabels = [l.get_label() for l in lines]\nax.legend(lines, labels, loc=0)\n\nax.grid()\nax.set_xlabel(\"Time (h)\")\nax.set_ylabel(r\"Radiation ($MJ\\,m^{-2}\\,d^{-1}$)\")\nax2.set_ylabel(r\"Temperature ($^\\circ$C)\")\nax2.set_ylim(0, 35)\nax.set_ylim(-20, 100)\nplt.show()\nplt.clf()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# make two side-by-side subplots and and in each subplot, plot y over x\n# Title each subplot as \"Y\"\n# SOLUTION START\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\n\n# Plotting on the first subplot\naxs[0].plot(x, y)\naxs[0].set_title('Y')\n\n# Plotting on the second subplot\naxs[1].plot(x, y)\naxs[1].set_title('Y')\n\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = sns.load_dataset(\"penguins\")[\n    [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n]\n\n# make a seaborn scatter plot of bill_length_mm and bill_depth_mm\n# use markersize 30 for all data points in the scatter plot\n# SOLUTION START\nsns.scatterplot(data=df, x=\"bill_length_mm\", y=\"bill_depth_mm\", size=30)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\na = [2.56422, 3.77284, 3.52623]\nb = [0.15, 0.3, 0.45]\nc = [58, 651, 393]\n\n# make scatter plot of a over b and annotate each data point with correspond numbers in c\n# SOLUTION START\nplt.scatter(a, b)\n\nfor i, txt in enumerate(c):\n    plt.annotate(txt, (a[i], b[i]))\n\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x in a line chart and label the line \"y over x\"\n# Show legend of the plot and give the legend box a title\n# SOLUTION START\nplt.plot(x, y, label='y over x')\nplt.legend(title='Legend')\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x in a line chart and label the line \"y over x\"\n# Show legend of the plot and give the legend box a title  \"Legend\"\n# Bold the legend title\n# SOLUTION START\nplt.plot(x, y, label=\"y over x\")\nplt.legend(title=\"Legend\", title_fontsize='bold')\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.random.rand(10)\ny = np.random.rand(10)\n\n# Make a histogram of x and show outline of each bar in the histogram\n# Make the outline of each bar has a line width of 1.2\n# SOLUTION START\nplt.hist(x, edgecolor='black', linewidth=1.2)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Make two subplots. Make the first subplot three times wider than the second subplot but they should have the same height.\n# SOLUTION START\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4), gridspec_kw={'width_ratios': [3, 1]})\nax1.plot(x, y)\nax2.plot(x, y)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.random.rand(10)\ny = np.random.rand(10)\nbins = np.linspace(-1, 1, 100)\n\n# Plot two histograms of x and y on a single chart with matplotlib\n# Set the transparency of the histograms to be 0.5\n# SOLUTION START\nplt.hist(x, bins, alpha=0.5, label='x')\nplt.hist(y, bins, alpha=0.5, label='y')\nplt.legend(loc='upper right')\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.random.rand(10)\ny = np.random.rand(10)\n\n# Plot a grouped histograms of x and y on a single chart with matplotlib\n# Use grouped histograms so that the histograms don't overlap with each other\n# SOLUTION START\n\n# Create a dataframe from x and y\ndf = pd.DataFrame({'x': x, 'y': y})\n\n# Plot the grouped histograms\ndf.plot.hist(alpha=0.5, bins=10)\n\nplt.show()\n\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\n\na, b = 1, 1\nc, d = 3, 4\n\n# draw a line that pass through (a, b) and (c, d)\n# do not just draw a line segment\n# set the xlim and ylim to be between 0 and 5\n# SOLUTION START\n# calculate the slope and intercept of the line\nslope = (d - b) / (c - a)\nintercept = b - slope * a\n\n# create a range of x values\nx = range(0, 6)\n\n# calculate the corresponding y values\ny = [slope * i + intercept for i in x]\n\n# plot the line\nplt.plot(x, y)\n\n# set the xlim and ylim\nplt.xlim(0, 5)\nplt.ylim(0, 5)\n\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.random.random((10, 10))\ny = np.random.random((10, 10))\n\n# make two colormaps with x and y and put them into different subplots\n# use a single colorbar for these two subplots\n# SOLUTION START\n\nfig, axs = plt.subplots(1, 2, figsize=(10, 4), constrained_layout=True)\n\n# Plotting the first colormap\nc1 = axs[0].imshow(x)\naxs[0].set_title('x')\n\n# Plotting the second colormap\nc2 = axs[1].imshow(y)\naxs[1].set_title('y')\n\n# Creating a colorbar\nfig.colorbar(c1, ax=axs, location='right', shrink=0.6)\n\nplt.show()\n\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.random.random((10, 2))\n\n# Plot each column in x as an individual line and label them as \"a\" and \"b\"\n# SOLUTION START\nplt.plot(x[:, 0], label='a')\nplt.plot(x[:, 1], label='b')\nplt.legend()\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\nz = np.arange(10)\na = np.arange(10)\n\n# plot y over x and z over a in two different subplots\n# Set \"Y and Z\" as a main title above the two subplots\n# SOLUTION START\n\nfig, axs = plt.subplots(2)\nfig.suptitle('Y and Z')\n\naxs[0].plot(x, y)\naxs[0].set_title('Y over X')\n\naxs[1].plot(a, z)\naxs[1].set_title('Z over A')\n\nplt.show()\n\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\npoints = [(3, 5), (5, 10), (10, 150)]\n\n# plot a line plot for points in points.\n# Make the y-axis log scale\n# SOLUTION START\nx = [point[0] for point in points]\ny = [point[1] for point in points]\n\nplt.plot(x, y)\nplt.yscale('log')\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# plot y over x\n# use font size 20 for title, font size 18 for xlabel and font size 16 for ylabel\n# SOLUTION START\nplt.plot(x, y)\nplt.title('Plot of y over x', fontsize=20)\nplt.xlabel('x', fontsize=18)\nplt.ylabel('y', fontsize=16)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.arange(10)\ny = np.arange(10)\n\nf = plt.figure()\nax = f.add_subplot(111)\n\n# plot y over x, show tick labels (from 1 to 10)\n# use the `ax` object to set the tick labels\n# SOLUTION START\nax.plot(x, y)\nax.set_xticks(np.arange(1, 11))\nax.set_yticks(np.arange(1, 11))\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nlines = [[(0, 1), (1, 1)], [(2, 3), (3, 3)], [(1, 2), (1, 3)]]\nc = np.array([(1, 0, 0, 1), (0, 1, 0, 1), (0, 0, 1, 1)])\n\n# Plot line segments according to the positions specified in lines\n# Use the colors specified in c to color each line segment\n# SOLUTION START\nfor i in range(len(lines)):\n    line = lines[i]\n    color = c[i]\n    plt.plot([line[0][0], line[1][0]], [line[0][1], line[1][1]], color=color)\n\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(0, 1000, 50)\ny = np.arange(0, 1000, 50)\n\n# plot y over x on a log-log plot\n# mark the axes with numbers like 1, 10, 100. do not use scientific notation\n# SOLUTION START\nplt.loglog(x, y)\nplt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: int(x)))\nplt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: int(y)))\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(\n    np.random.randn(50, 4),\n    index=pd.date_range(\"1/1/2000\", periods=50),\n    columns=list(\"ABCD\"),\n)\ndf = df.cumsum()\n\n# make four line plots of data in the data frame\n# show the data points  on the line plot\n# SOLUTION START\nplt.figure(figsize=(10,6))\nfor column in df.columns:\n    plt.plot(df.index, df[column], marker='o', label=column)\nplt.legend()\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\n\ndata = [1000, 1000, 5000, 3000, 4000, 16000, 2000]\n\n# SOLUTION START\n# Make a histogram of data and renormalize the data to sum up to 1\nweights = np.ones_like(data) / len(data)\nplt.hist(data, weights=weights, bins=7)\n\n# Format the y tick labels into percentage and set y tick labels as 10%, 20%, etc.\nplt.gca().yaxis.set_major_formatter(mticker.PercentFormatter(1))\nplt.yticks(np.arange(0, 1.1, 0.1))\n\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x in a line plot\n# Show marker on the line plot. Make the marker have a 0.5 transparency but keep the lines solid.\n# SOLUTION START\nplt.plot(x, y, marker='o', markersize=8, markerfacecolor='blue', alpha=0.5, linestyle='solid', linewidth=2, color='blue')\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\na = np.arange(10)\nz = np.arange(10)\n\n# Plot y over x and a over z in two side-by-side subplots.\n# Label them \"y\" and \"a\" and make a single figure-level legend using the figlegend function\n# SOLUTION START\n\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\n\n# Plot y over x\naxs[0].plot(x, y, label='y')\n\n# Plot a over z\naxs[1].plot(z, a, label='a')\n\n# Set labels for subplots\naxs[0].set_title('y')\naxs[1].set_title('a')\n\n# Create a figure-level legend\nfig.legend(loc='upper right')\n\nplt.show()\n\n# SOLUTION END\n```",
        "```python\n# SOLUTION START\nfig, axs = plt.subplots(2, 1, sharex=False)\n\nsns.regplot(x=\"bill_length_mm\", y=\"bill_depth_mm\", data=df, ax=axs[0])\nsns.regplot(x=\"bill_length_mm\", y=\"flipper_length_mm\", data=df, ax=axs[1])\n\nplt.tight_layout()\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\nfig, ax = plt.subplots(1, 1)\nplt.xlim(1, 10)\nplt.xticks(range(1, 10))\nax.plot(y, x)\n\n# change the second x axis tick label to \"second\" but keep other labels in numerical\n# SOLUTION START\nlabels = [item.get_text() for item in ax.get_xticklabels()]\nlabels[1] = 'second'\nax.set_xticklabels(labels)\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x\n# Show legend and use the greek letter lambda as the legend label\n# SOLUTION START\nplt.plot(x, y, label='$\\lambda$')\nplt.legend()\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\nplt.plot(y, x)\nplt.xticks(range(0, 10, 2))\n\n# Add extra ticks [2.1, 3, 7.6] to existing xticks\n# SOLUTION START\nextra_ticks = [2.1, 3, 7.6]\nplt.xticks(list(plt.xticks()[0]) + extra_ticks)\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(2010, 2020)\ny = np.arange(10)\nplt.plot(x, y)\n\n# Rotate the xticklabels to -60 degree. Set the xticks horizontal alignment to left.\n# SOLUTION START\nplt.xticks(rotation=-60, ha='left')\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(2010, 2020)\ny = np.arange(10)\nplt.plot(x, y)\n\n# Rotate the yticklabels to -60 degree. Set the xticks vertical alignment to top.\n# SOLUTION START\nplt.yticks(rotation=-60)\nplt.xticks(va='top')\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(2010, 2020)\ny = np.arange(10)\nplt.plot(x, y)\n\n# Set the transparency of xtick labels to be 0.5\n# SOLUTION START\nfor label in plt.gca().get_xticklabels():\n    label.set_alpha(0.5)\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\nplt.plot(x, y)\n\n# Remove the margin before the first xtick but use greater than zero margin for the yaxis\n# SOLUTION START\nplt.margins(x=-0.05, y=0.1)\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\nplt.plot(x, y)\n\n# Remove the margin before the first ytick but use greater than zero margin for the xaxis\n# SOLUTION START\nplt.margins(x=0.1, y=0)\nplt.ylim(bottom=0)\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# make a two columns and one row subplots. Plot y over x in each subplot.\n# Give the plot a global title \"Figure\"\n# SOLUTION START\n\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\nfig.suptitle('Figure')\n\naxs[0].plot(x, y)\naxs[1].plot(x, y)\n\nplt.show()\n\n# SOLUTION END\n```",
        "```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nvalues = [[1, 2], [3, 4]]\ndf = pd.DataFrame(values, columns=[\"Type A\", \"Type B\"], index=[\"Index 1\", \"Index 2\"])\n\n# Plot values in df with line chart\n# label the x axis and y axis in this plot as \"X\" and \"Y\"\n# SOLUTION START\ndf.plot(kind='line')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Make a scatter plot with x and y\n# Use vertical line hatch for the marker and make the hatch dense\n# SOLUTION START\nplt.scatter(x, y, marker='o', s=100, hatch='||||')\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Make a scatter plot with x and y and remove the edge of the marker\n# Use vertical line hatch for the marker\n# SOLUTION START\nplt.scatter(x, y, edgecolors='none', hatch='|')\nplt.show()\n# SOLUTION END\n```\nPlease note that the `hatch` parameter is not supported in `scatter` function of matplotlib. The `hatch` parameter is used to add a pattern inside the marker. But in scatter plot, the markers are usually too small to add a pattern inside. So, it is not supported.",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Make a scatter plot with x and y\n# Use star hatch for the marker\n# SOLUTION START\nplt.scatter(x, y, marker='*')\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Make a scatter plot with x and y and set marker size to be 100\n# Combine star hatch and vertical line hatch together for the marker\n# SOLUTION START\nplt.scatter(x, y, s=100, marker='*')\nplt.scatter(x, y, s=100, marker='|')\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndata = np.random.random((10, 10))\n\n# Set xlim and ylim to be between 0 and 10\n# Plot a heatmap of data in the rectangle where right is 5, left is 1, bottom is 1, and top is 4.\n# SOLUTION START\nplt.imshow(data, extent=[0, 10, 0, 10], origin='lower')\nplt.colorbar()\nplt.xlim(1, 5)\nplt.ylim(1, 4)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(0.1, 2 * np.pi, 41)\ny = np.exp(np.sin(x))\n\n# make a stem plot of y over x and set the orientation to be horizontal\n# SOLUTION START\nplt.stem(y, x, orientation='horizontal')\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\n\nd = {\"a\": 4, \"b\": 5, \"c\": 7}\nc = {\"a\": \"red\", \"c\": \"green\", \"b\": \"blue\"}\n\n# Make a bar plot using data in `d`. Use the keys as x axis labels and the values as the bar heights.\n# Color each bar in the plot by looking up the color in colors\n# SOLUTION START\nplt.bar(d.keys(), d.values(), color=c.values())\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\n\n# Make a solid vertical line at x=3 and label it \"cutoff\". Show legend of this plot.\n# SOLUTION START\nplt.axvline(x=3, color='r', linestyle='-', label='cutoff')\nplt.legend()\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\n\nlabels = [\"a\", \"b\"]\nheight = [3, 4]\n\n# Use polar projection for the figure and make a bar plot with labels in `labels` and bar height in `height`\n# SOLUTION START\nfig = plt.figure()\nax = fig.add_subplot(111, polar=True)\ntheta = [0, 1]\nbars = ax.bar(theta, height, width=0.5, bottom=0.0)\n\n# Set the rotation of the labels\nax.set_xticks(theta)\nax.set_xticklabels(labels)\n\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\n\nl = [\"a\", \"b\", \"c\"]\ndata = [225, 90, 50]\n\n# Make a donut plot of using `data` and use `l` for the pie labels\n# Set the wedge width to be 0.4\n# SOLUTION START\nplt.pie(data, labels = l, wedgeprops=dict(width=0.4))\nplt.gca().set_aspect(\"equal\")  # To ensure pie is drawn as a circle.\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x and show blue dashed grid lines\n# SOLUTION START\nplt.plot(x, y)\nplt.grid(color='blue', linestyle='--', linewidth=0.5)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x\n# Turn minor ticks on and show gray dashed minor grid lines\n# Do not show any major grid lines\n# SOLUTION START\nplt.plot(x, y)\n\n# Turn minor ticks on\nplt.minorticks_on()\n\n# Show gray dashed minor grid lines\nplt.grid(which='minor', linestyle='--', color='gray')\n\n# Do not show any major grid lines\nplt.grid(which='major', linestyle='', color='')\n\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\n\nlabels = [\"Walking\", \"Talking\", \"Sleeping\", \"Working\"]\nsizes = [23, 45, 12, 20]\ncolors = [\"red\", \"blue\", \"green\", \"yellow\"]\n\n# Make a pie chart with data in `sizes` and use `labels` as the pie labels and `colors` as the pie color.\n# Bold the pie labels\n# SOLUTION START\nplt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%')\nplt.gca().set_prop_cycle(None) # Reset the color cycle\nfor text in plt.gca().texts:\n    text.set_fontweight('bold') # Make the labels bold\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\n\nlabels = [\"Walking\", \"Talking\", \"Sleeping\", \"Working\"]\nsizes = [23, 45, 12, 20]\ncolors = [\"red\", \"blue\", \"green\", \"yellow\"]\n\n# Make a pie chart with data in `sizes` and use `labels` as the pie labels and `colors` as the pie color.\n# Bold the pie labels\n# SOLUTION START\nplt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%')\nplt.gca().set_prop_cycle(None) # Reset the color cycle\nfor text in plt.gca().texts: # For each label (percentage is also a label)\n    text.set_fontweight('bold') # Make the text bold\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x in a line chart but use transparent marker with non-transparent edge\n# SOLUTION START\nplt.plot(x, y, marker='o', markerfacecolor='none', markeredgecolor='blue', linestyle='-')\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = sns.load_dataset(\"penguins\")[\n    [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n]\nsns.distplot(df[\"bill_length_mm\"], color=\"blue\")\n\n# Plot a vertical line at 55 with green color\n# SOLUTION START\nplt.axvline(55, color='green')\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Specify the values of blue bars (height)\nblue_bar = (23, 25, 17)\n# Specify the values of orange bars (height)\norange_bar = (19, 18, 14)\n\n# Plot the blue bar and the orange bar side-by-side in the same bar plot.\n# Make  sure the bars don't overlap with each other.\n# SOLUTION START\n# Specify the positions of the blue bars on the x-axis\nr1 = np.arange(len(blue_bar))\n# Specify the positions of the orange bars on the x-axis\nr2 = [x + 0.25 for x in r1]\n\n# Plot bars\nplt.bar(r1, blue_bar, color='b', width=0.25, edgecolor='grey', label='blue')\nplt.bar(r2, orange_bar, color='orange', width=0.25, edgecolor='grey', label='orange')\n\n# Adding xticks\nplt.xlabel('groups', fontweight='bold')\nplt.xticks([r + 0.125 for r in range(len(blue_bar))], ['A', 'B', 'C'])\n\nplt.legend()\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.random.rand(10)\nz = np.random.rand(10)\na = np.arange(10)\n\n# Make two subplots\n# Plot y over x in the first subplot and plot z over a in the second subplot\n# Label each line chart and put them into a single legend on the first subplot\n# SOLUTION START\n\nfig, axs = plt.subplots(2)\n\n# Plot y over x in the first subplot\naxs[0].plot(x, y, label='y over x')\n\n# Plot z over a in the second subplot\naxs[1].plot(a, z, label='z over a')\n\n# Put a legend on the first subplot\naxs[0].legend()\n\nplt.show()\n\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\n\nx = np.arange(10)\ny = np.linspace(0, 1, 10)\n\n# Plot y over x with a scatter plot\n# Use the \"Spectral\" colormap and color each data point based on the y-value\n# SOLUTION START\nplt.scatter(x, y, c=y, cmap='Spectral')\nplt.colorbar(label='y-value')\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# plot y over x\n# use a tick interval of 1 on the a-axis\n# SOLUTION START\nplt.plot(x, y)\nplt.xticks(np.arange(min(x), max(x)+1, 1))\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = sns.load_dataset(\"penguins\")[[\"bill_length_mm\", \"species\", \"sex\"]]\n\n# Use seaborn factorpot to plot multiple barplots of \"bill_length_mm\" over \"sex\" and separate into different subplot columns by \"species\"\n# Do not share y axis across subplots\n# SOLUTION START\ng = sns.factorplot(x=\"sex\", y=\"bill_length_mm\", col=\"species\", data=df, kind=\"bar\", sharey=False)\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\n\n# draw a circle centered at (0.5, 0.5) with radius 0.2\n# SOLUTION START\ncircle = plt.Circle((0.5, 0.5), 0.2, fill = False)\nfig, ax = plt.subplots()\nax.add_artist(circle)\nax.set_xlim(0, 1)\nax.set_ylim(0, 1)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x and use the greek letter phi for title. Bold the title and make sure phi is bold.\n# SOLUTION START\nplt.plot(x, y)\nplt.title(r'$\\boldsymbol{\\phi}$', fontsize=20)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x with a legend of \"Line\"\n# Adjust the spacing between legend markers and labels to be 0.1\n# SOLUTION START\nplt.plot(x, y, label=\"Line\")\nplt.legend(handlelength=0.1)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x with a legend of \"Line\"\n# Adjust the length of the legend handle to be 0.3\n# SOLUTION START\nplt.plot(x, y, label='Line')\nplt.legend(handlelength=0.3)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\nplt.plot(x, y, label=\"Line\")\nplt.plot(y, x, label=\"Flipped\")\n\n# Show a two columns legend of this plot\n# SOLUTION START\nplt.legend(ncol=2)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\nplt.plot(x, y, marker=\"*\", label=\"Line\")\n\n# Show a legend of this plot and show two markers on the line\n# SOLUTION START\nplt.legend()\nplt.scatter([x[3], x[7]], [y[3], y[7]], color='red')  # add two markers on the line\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndata = np.random.random((10, 10))\n\n# plot the 2d matrix data with a colorbar\n# SOLUTION START\nplt.imshow(data, cmap='hot', interpolation='nearest')\nplt.colorbar()\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x. Give the plot a title \"Figure 1\". bold the word \"Figure\" in the title but do not bold \"1\"\n# SOLUTION START\nplt.plot(x, y)\nplt.title(r'$\\bf{Figure}$' + ' 1')  # Using LaTeX to bold the word \"Figure\"\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\ndf = pd.DataFrame(\n    {\n        \"id\": [\"1\", \"2\", \"1\", \"2\", \"2\"],\n        \"x\": [123, 22, 356, 412, 54],\n        \"y\": [120, 12, 35, 41, 45],\n    }\n)\n\n# Use seaborn to make a pairplot of data in `df` using `x` for x_vars, `y` for y_vars, and `id` for hue\n# Hide the legend in the output figure\n# SOLUTION START\nsns.pairplot(df, x_vars=[\"x\"], y_vars=[\"y\"], hue=\"id\", plot_kws={'legend': False})\nplt.legend([],[], frameon=False)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x and invert the x axis\n# SOLUTION START\nplt.plot(x, y)\nplt.gca().invert_xaxis()\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(11)\ny = np.arange(11)\nplt.xlim(0, 10)\nplt.ylim(0, 10)\n\n# Plot a scatter plot x over y and set both the x limit and y limit to be between 0 and 10\n# Turn off axis clipping so data points can go beyond the axes\n# SOLUTION START\nplt.scatter(x, y, clip_on=False)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot a scatter plot with values in x and y\n# Plot the data points to have red inside and have black border\n# SOLUTION START\nplt.scatter(x, y, color='red', edgecolor='black')\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# plot y over x on a 2 by 2 subplots with a figure size of (15, 15)\n# repeat the plot in each subplot\n# SOLUTION START\nfig, axs = plt.subplots(2, 2, figsize=(15, 15))\n\nfor i in range(2):\n    for j in range(2):\n        axs[i, j].plot(x, y)\n\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.random.rand(100) * 10\n\n# Make a histogram of x\n# Make the histogram range from 0 to 10\n# Make bar width 2 for each bar in the histogram and have 5 bars in total\n# SOLUTION START\nplt.hist(x, bins=5, range=(0,10))\nplt.show()\n# SOLUTION END\n```",
        "```python\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nx = np.arange(10)\ny = np.arange(1, 11)\nerror = np.random.random(y.shape)\n\n# Plot y over x and show the error according to `error`\n# Plot the error as a shaded region rather than error bars\n# SOLUTION START\nplt.plot(x, y, 'k-')\nplt.fill_between(x, y-error, y+error, alpha=0.5, edgecolor='#CC4F1B', facecolor='#FF9848')\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nxvec = np.linspace(-5.0, 5.0, 100)\nx, y = np.meshgrid(xvec, xvec)\nz = -np.hypot(x, y)\nplt.contourf(x, y, z)\n\n# draw x=0 and y=0 axis in my contour plot with white color\n# SOLUTION START\nplt.axhline(0, color='white') # y=0 line\nplt.axvline(0, color='white') # x=0 line\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nbox_position, box_height, box_errors = np.arange(4), np.ones(4), np.arange(1, 5)\nc = [\"r\", \"r\", \"b\", \"b\"]\nfig, ax = plt.subplots()\nax.bar(box_position, box_height, color=\"yellow\")\n\n# Plot error bars with errors specified in box_errors. Use colors in c to color the error bars\n# SOLUTION START\nfor i in range(len(box_position)):\n    ax.errorbar(box_position[i], box_height[i], yerr=box_errors[i], color=c[i], fmt='o')\n# SOLUTION END\nplt.show()\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\nz = np.arange(10)\na = np.arange(10)\n\n# Plot y over x and z over a in two side-by-side subplots\n# Make \"Y\" the title of the first subplot and \"Z\" the title of the second subplot\n# Raise the title of the second subplot to be higher than the first one\n# SOLUTION START\n\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\n\naxs[0].plot(x, y)\naxs[0].set_title('Y')\n\naxs[1].plot(a, z)\naxs[1].set_title('Z', y=1.05)\n\nplt.show()\n\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# make 4 by 4 subplots with a figure size (5,5)\n# in each subplot, plot y over x and show axis tick labels\n# give enough spacing between subplots so the tick labels don't overlap\n# SOLUTION START\n\nfig, axs = plt.subplots(4, 4, figsize=(5,5))\nplt.subplots_adjust(hspace=0.5, wspace=0.5) # Adjust the spacing between subplots\n\nfor i in range(4):\n    for j in range(4):\n        axs[i, j].plot(x, y)\n        axs[i, j].set_xticks(x)\n        axs[i, j].set_yticks(y)\n\nplt.show()\n\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nd = np.random.random((10, 10))\n\n# Use matshow to plot d and make the figure size (8, 8)\n# SOLUTION START\nplt.figure(figsize=(8, 8))\nplt.matshow(d, fignum=1)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = sns.load_dataset(\"penguins\")[\n    [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n].head(10)\n\n# Plot df as a matplotlib table. Set the bbox of the table to [0, 0, 1, 1]\n# SOLUTION START\nfig, ax = plt.subplots(1, 1)\n\ntable_data = []\nfor row in df.itertuples():\n    table_data.append(row[1:])\n\ntable = ax.table(cellText=table_data, colLabels=df.columns, loc='center')\ntable.set_fontsize(14)\ntable.scale(1, 1.5)\nax.axis('off')\n\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x in a line chart. Show x axis tick labels on both top and bottom of the figure.\n# SOLUTION START\nplt.plot(x, y)\nplt.tick_params(axis='x', which='both', bottom=True, top=True, labelbottom=True, labeltop=True)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x in a line chart. Show x axis ticks on both top and bottom of the figure.\n# SOLUTION START\nplt.plot(x, y)\nplt.tick_params(axis='x', which='both', bottom=True, top=True)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x in a line chart. Show x axis tick labels but hide the x axis ticks\n# SOLUTION START\nplt.plot(x, y)\nplt.tick_params(axis='x', which='both', length=0) # hide the x axis ticks\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = sns.load_dataset(\"exercise\")\n\n# Make catplots of scatter plots by using \"time\" as x, \"pulse\" as y, \"kind\" as hue, and \"diet\" as col\n# Change the subplots titles to \"Group: Fat\" and \"Group: No Fat\"\n# SOLUTION START\ng = sns.catplot(x=\"time\", y=\"pulse\", hue=\"kind\", col=\"diet\", data=df, kind=\"scatter\")\n\n# Change the subplots titles\ntitles = [\"Group: Fat\", \"Group: No Fat\"]\nfor ax, title in zip(g.axes.flat, titles):\n    ax.set_title(title)\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = sns.load_dataset(\"exercise\")\n\n# Make catplots of scatter plots by using \"time\" as x, \"pulse\" as y, \"kind\" as hue, and \"diet\" as col\n# Change the xlabels to \"Exercise Time\" and \"Exercise Time\"\n# SOLUTION START\ng = sns.catplot(x=\"time\", y=\"pulse\", hue=\"kind\", col=\"diet\", data=df, kind=\"scatter\")\ng.set_axis_labels(\"Exercise Time\", \"Pulse\")\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = sns.load_dataset(\"exercise\")\n\n# Make catplots of scatter plots by using \"time\" as x, \"pulse\" as y, \"kind\" as hue, and \"diet\" as col\n# Do not show any ylabel on either subplot\n# SOLUTION START\ng = sns.catplot(x=\"time\", y=\"pulse\", hue=\"kind\", col=\"diet\", data=df, kind=\"scatter\")\ng.set_axis_labels(\"\", \"\")\ng.set_titles(\"{col_name}\")\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# plot y over x with label \"y\"\n# make the legend fontsize 8\n# SOLUTION START\nplt.plot(x, y, label='y')\nplt.legend(fontsize=8)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x with figsize (5, 5) and dpi 300\n# SOLUTION START\nplt.figure(figsize=(5, 5), dpi=300)\nplt.plot(x, y)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x with label \"y\" and show legend\n# Remove the border of frame of legend\n# SOLUTION START\nplt.plot(x, y, label='y')\nlegend = plt.legend(frameon = 1)\nframe = legend.get_frame()\nframe.set_edgecolor('none')\nplt.show()\n# SOLUTION END\n```",
        "```python\nfrom numpy import *\nimport math\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nt = linspace(0, 2 * math.pi, 400)\na = sin(t)\nb = cos(t)\nc = a + b\n\n# Plot a, b, c in the same figure\n# SOLUTION START\nplt.figure(figsize=(10,6))\nplt.plot(t, a, label='sin(t)')\nplt.plot(t, b, label='cos(t)')\nplt.plot(t, c, label='sin(t) + cos(t)')\nplt.legend()\nplt.title('Plot of sin(t), cos(t), and sin(t) + cos(t)')\nplt.xlabel('t')\nplt.ylabel('Value')\nplt.grid(True)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = sns.load_dataset(\"penguins\")[[\"bill_length_mm\", \"species\", \"sex\"]]\n\n# Make a stripplot for the data in df. Use \"sex\" as x, \"bill_length_mm\" as y, and \"species\" for the color\n# Remove the legend from the stripplot\n# SOLUTION START\nstrip_plot = sns.stripplot(x=\"sex\", y=\"bill_length_mm\", hue=\"species\", data=df)\nstrip_plot.legend_.remove()\nplt.show()\n# SOLUTION END\n```",
        "```python\n# SOLUTION START\ng = sns.FacetGrid(df, row=\"b\")\ng.map(sns.pointplot, \"a\", \"c\")\n\n# Set xticks with intervals of 1\nfor ax in g.axes.flat:\n    ax.set_xticks(np.arange(0, 10, 1))\n\n# Set xtick labels with intervals of 2\nfor ax in g.axes.flat:\n    ax.set_xticklabels(np.arange(1, 11, 2))\n\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\n\nx = np.random.random(10)\ny = np.random.random(10)\nz = np.random.random(10)\n\n# Make a 3D scatter plot of x,y,z\n# change the view of the plot to have 100 azimuth and 50 elevation\n# SOLUTION START\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(x, y, z)\nax.view_init(azim=100, elev=50)\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x in a line chart and name axis with labels (\"x\" and \"y\")\n# Hide tick labels but keep axis labels\n# SOLUTION START\nplt.plot(x, y)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.xticks([]) # Hide x-axis tick labels\nplt.yticks([]) # Hide y-axis tick labels\nplt.show()\n# SOLUTION END\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.random.random((10, 10))\nfrom matplotlib import gridspec\n\nnrow = 2\nncol = 2\n\nfig = plt.figure(figsize=(ncol + 1, nrow + 1))\n\n# Make a 2x2 subplots with fig and plot x in each subplot as an image\n# Remove the space between each subplot and make the subplot adjacent to each other\n# Remove the axis ticks from each subplot\n# SOLUTION START\n\ngs = gridspec.GridSpec(nrow, ncol, wspace=0.0, hspace=0.0)\n\nfor i in range(nrow):\n    for j in range(ncol):\n        ax = plt.subplot(gs[i, j])\n        ax.imshow(x, cmap='viridis')\n        ax.set_xticks([])\n        ax.set_yticks([])\n\nplt.show()\n\n# SOLUTION END\n```"
    ],
    "Tensorflow": [
        "[Missing Code]\n```python\nx.assign(1)\n```",
        "[Missing Code]\n```python\nx.assign(114514)\n```",
        "[Missing Code]\n```python\nlabels_tensor = tf.constant(labels)\nresult = tf.one_hot(labels_tensor, depth=10, dtype=tf.int32)\n```",
        "[Missing Code]\n```python\nlabels_tensor = tf.constant(labels, dtype=tf.int32)\none_hot_labels = tf.one_hot(labels_tensor, depth=10, dtype=tf.int32)\nresult = tf.math.subtract(1, one_hot_labels)\n```",
        "[Missing Code]\n```python\nlabels_tensor = tf.constant(labels, dtype=tf.int32)\nresult = tf.one_hot(labels_tensor, depth=10, on_value=0, off_value=1, dtype=tf.int32)\nresult = tf.reverse(result, axis=[1])\n```",
        "[Missing Code]\n```python\nlabels = tf.constant(labels, dtype=tf.int32)\nresult = tf.one_hot(labels, depth=10)\n```",
        "[Missing Code]\n```python\nlabels_tensor = tf.constant(labels, dtype=tf.int32)\none_hot = tf.one_hot(labels_tensor, depth=10)\nresult = tf.cast(tf.math.logical_not(one_hot), tf.int32)\n```",
        "[Solution Code]\n```python\nimport tensorflow as tf\n\n\ntf.compat.v1.disable_eager_execution()\ninput = [10, 20, 30]\n# [Begin of Missing Code]\ndef my_map_func(i):\n  return [i, i+1, i+2]\n\nds = tf.data.Dataset.from_tensor_slices(input)\nds = ds.map(map_func=lambda input: tf.compat.v1.py_func(\n  func=my_map_func, inp=[input], Tout=[tf.int64, tf.int64, tf.int64]\n))\nds = ds.flat_map(tf.data.Dataset.from_tensor_slices)\nelement = tf.compat.v1.data.make_one_shot_iterator(ds).get_next()\nresult = []\nwith tf.compat.v1.Session() as sess:\n  for _ in range(9):\n    result.append(sess.run(element))\n# [End of Missing Code]\nprint(result)\n```",
        "[Solution Code]\n```python\nimport tensorflow as tf\ntf.compat.v1.disable_eager_execution()\n\nexample_input = [10, 20, 30]\ndef f(input=example_input):\n    # [Begin of Missing Code]\n    def my_map_func(i):\n        return [i, i+1, i+2]\n\n    ds = tf.data.Dataset.from_tensor_slices(input)\n    ds = ds.flat_map(lambda x: tf.data.Dataset.from_tensor_slices(my_map_func(x)))\n    iterator = tf.compat.v1.data.make_one_shot_iterator(ds)\n    result = []\n    with tf.compat.v1.Session() as sess:\n        for _ in range(9):\n            result.append(sess.run(iterator.get_next()))\n    # [End of Missing Code]\n    return result\n```",
        "[Missing Code]\n```python\nlengths = tf.constant(lengths)\nmax_length = 8\nresult = tf.sequence_mask(lengths, max_length)\nresult = tf.cast(result, tf.int32)\n```",
        "[Missing Code]\n```python\nlengths = tf.constant(lengths)\nmax_length = 8\nresult = tf.sequence_mask(lengths, max_length)\nresult = tf.cast(result, tf.int32)\nresult = 1 - result\n```",
        "[Missing Code]\n```python\nlengths = tf.constant(lengths)\nmax_length = 8\nrange_tensor = tf.range(max_length)\nmask = tf.less(range_tensor, lengths[:, None])\nresult = tf.cast(mask, tf.float32)\n```",
        "[Missing Code]\n```python\n    lengths = tf.constant(lengths)\n    max_length = tf.constant(8)\n    range_tensor = tf.range(max_length)\n    mask = tf.less(range_tensor, lengths[:, None])\n    result = tf.cast(mask, tf.int32)\n```",
        "[Missing Code]\n```python\nlengths = tf.constant(lengths, dtype=tf.int32)\ntotal_length = 8\nmask = tf.sequence_mask(lengths, total_length)\nresult = tf.cast(mask, tf.float32)\nresult = tf.reverse(result, axis=[1])\n```",
        "[Missing Code]\n```python\na = tf.expand_dims(a, 1)\nb = tf.expand_dims(b, 0)\nresult = tf.stack(tf.meshgrid(a, b), -1)\n```",
        "[Missing Code]\n```python\n    a = tf.expand_dims(a, -1)\n    b = tf.expand_dims(b, 0)\n    result = tf.stack(tf.meshgrid(a, b), -1)\n```",
        "[Solution Code]\n```python\nimport tensorflow as tf\nimport numpy as np\n\nnp.random.seed(10)\na = tf.constant(np.random.rand(50, 100, 1, 512))\n# [Begin of Missing Code]\nresult = tf.reshape(a, (50, 100, 512))\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\nresult = tf.expand_dims(a, axis=2)\n```",
        "[Missing Code]\n```python\nresult = tf.reshape(a, [1, 50, 100, 1, 512])\n```",
        "[Missing Code]\n```python\nresult = tf.reduce_sum(A, axis=1)\n```",
        "[Missing Code]\n```python\nresult = tf.reduce_prod(A, axis=1)\n```",
        "[Missing Code]\n```python\nresult = tf.math.reciprocal(A)\n```",
        "[Missing Code]\n```python\ndiff = tf.subtract(a, b)\nsquared_diff = tf.square(diff)\nresult = tf.reduce_sum(squared_diff, axis=1)\n```",
        "[Missing Code]\n```python\ndiff = tf.square(tf.subtract(a, b))\nresult = tf.reduce_sum(diff, axis=0)\n```",
        "```python\nimport tensorflow as tf\n\nexample_a = tf.constant([\n  [1,1,1],\n  [1,1,1]\n])\nexample_b = tf.constant([\n  [0,0,0],\n  [1,1,1]\n])\ndef f(A=example_a,B=example_b):\n    # [Begin of Missing Code]\n    diff = tf.subtract(A, B)\n    square_diff = tf.square(diff)\n    result = tf.reduce_sum(square_diff, axis=1)\n    # [End of Missing Code]\n    return result\n```",
        "[Missing Code]\n```python\nindices = tf.stack([y, z], axis=1)\nresult = tf.gather_nd(x, indices)\n```",
        "[Missing Code]\nindices = tf.stack([row, col], axis=-1)\nresult = tf.gather_nd(x, indices)\n[End of Missing Code]",
        "```python\nimport tensorflow as tf\n\nexample_x = [[1,2,3],[4,5,6]]\nexample_y = [0,1]\nexample_z = [1,2]\nexample_x = tf.constant(example_x)\nexample_y = tf.constant(example_y)\nexample_z = tf.constant(example_z)\ndef f(x=example_x,y=example_y,z=example_z):\n    # [Begin of Missing Code]\n    indices = tf.stack([y, z], axis=-1)\n    result = tf.gather_nd(x, indices)\n    # [End of Missing Code]\n    return result\n```",
        "```python\nimport tensorflow as tf\nimport numpy as np\n\n\nnp.random.seed(10)\nA = tf.constant(np.random.randint(low=0, high=5, size=(10, 20, 30)))\nB = tf.constant(np.random.randint(low=0, high=5, size=(10, 20, 30)))\n# [Begin of Missing Code]\nA = tf.transpose(A, perm=[1, 0, 2])\nB = tf.transpose(B, perm=[1, 0, 2])\nresult = tf.tensordot(A, B, axes=[[2], [2]])\nresult = tf.transpose(result, perm=[1, 2, 0])\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\nresult = tf.tensordot(A, B, axes=[[2], [2]])\n```",
        "```python\nimport tensorflow as tf\n\n\nx=[b'\\xd8\\xa8\\xd9\\x85\\xd8\\xb3\\xd8\\xa3\\xd9\\x84\\xd8\\xa9',\n    b'\\xd8\\xa5\\xd9\\x86\\xd8\\xb4\\xd8\\xa7\\xd8\\xa1',\n    b'\\xd9\\x82\\xd8\\xb6\\xd8\\xa7\\xd8\\xa1',\n    b'\\xd8\\xac\\xd9\\x86\\xd8\\xa7\\xd8\\xa6\\xd9\\x8a',\n    b'\\xd8\\xaf\\xd9\\x84\\xd9\\x8a']\n# [Begin of Missing Code]\nx_tensor = tf.constant(x)\nresult = tf.strings.unicode_decode(x_tensor, 'UTF-8')\n# [End of Missing Code]\nprint(result)```",
        "[Missing Code]\n```python\n    tensor_x = tf.constant(x)\n    result = tf.strings.unicode_decode(tensor_x, 'UTF-8')\n```",
        "```python\nimport tensorflow as tf\n\n\nx = [[[[1, 2, 3], [2, 3, 4], [0, 0, 0]],\n      [[1, 2, 3], [2, 0, 4], [3, 4, 5]],\n      [[1, 2, 3], [0, 0, 0], [0, 0, 0]],\n      [[1, 2, 3], [1, 2, 3], [0, 0, 0]]],\n     [[[1, 2, 3], [0, 1, 0], [0, 0, 0]],\n      [[1, 2, 3], [2, 3, 4], [0, 0, 0]],\n      [[1, 2, 3], [0, 0, 0], [0, 0, 0]],\n      [[1, 2, 3], [1, 2, 3], [1, 2, 3]]]]\nx = tf.convert_to_tensor(x, dtype=tf.float32)\n# [Begin of Missing Code]\nnon_zero_mask = tf.cast(tf.not_equal(x, 0), tf.float32)\nnon_zero_count = tf.reduce_sum(non_zero_mask, axis=-2, keepdims=True)\nnon_zero_sum = tf.reduce_sum(x, axis=-2, keepdims=True)\nresult = non_zero_sum / non_zero_count\nresult = tf.squeeze(result, axis=-2)\n# [End of Missing Code]\nprint(result)\n```",
        "```python\nimport tensorflow as tf\n\nx = [[[[1, 2, 3], [2, 3, 4], [0, 0, 0]],\n      [[1, 2, 3], [2, 0, 4], [3, 4, 5]],\n      [[1, 2, 3], [0, 0, 0], [0, 0, 0]],\n      [[1, 2, 3], [1, 2, 3], [0, 0, 0]]],\n     [[[1, 2, 3], [0, 1, 0], [0, 0, 0]],\n      [[1, 2, 3], [2, 3, 4], [0, 0, 0]],\n      [[1, 2, 3], [0, 0, 0], [0, 0, 0]],\n      [[1, 2, 3], [1, 2, 3], [1, 2, 3]]]]\nx = tf.convert_to_tensor(x, dtype=tf.float32)\n# [Begin of Missing Code]\nmask = tf.cast(tf.not_equal(x, 0), tf.float32)\nmean = tf.reduce_sum(x, axis=-2) / tf.reduce_sum(mask, axis=-2)\nmean = tf.where(tf.math.is_nan(mean), tf.zeros_like(mean), mean)\nvariance = tf.reduce_sum(mask * (x - mean[..., None, :]) ** 2, axis=-2) / tf.reduce_sum(mask, axis=-2)\nresult = tf.where(tf.math.is_nan(variance), tf.zeros_like(variance), variance)\n# [End of Missing Code]\nprint(result)\n```",
        "[Begin of Missing Code]\nnon_zero_mask = tf.cast(tf.not_equal(x, 0), tf.float32)\nnon_zero_count = tf.reduce_sum(non_zero_mask, axis=-2, keepdims=True)\nnon_zero_sum = tf.reduce_sum(x * non_zero_mask, axis=-2, keepdims=True)\nresult = non_zero_sum / non_zero_count\n[End of Missing Code]",
        "[Solution Code]\n```python\nimport tensorflow as tf\n# [Begin of Missing Code]\ntf.random.set_seed(10)\nA = tf.random.normal([100,100])\nB = tf.random.normal([100,100])\nresult = tf.reduce_sum(tf.matmul(A,B)).numpy()\n# [End of Missing Code]\nprint(result)\n```",
        "[Solution Code]\n```python\nimport tensorflow as tf\n\n\na = tf.constant(\n    [[0.3232, -0.2321, 0.2332, -0.1231, 0.2435, 0.6728],\n     [0.2323, -0.1231, -0.5321, -0.1452, 0.5435, 0.1722],\n     [0.9823, -0.1321, -0.6433, 0.1231, 0.023, 0.0711]]\n)\n# [Begin of Missing Code]\nresult = tf.argmax(a, axis=1)\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\nresult = tf.argmax(a, axis=0)\n```",
        "[Missing Code]\nresult = tf.argmax(a, axis=1)\n[End of Missing Code]",
        "[Missing Code]\n```python\nresult = tf.argmin(a, axis=0)\n```",
        "[Begin of Missing Code]\ntf.saved_model.save(model, 'my_model')\n[End of Missing Code]",
        "[Missing Code]\n```python\ntf.random.set_seed(seed_x)\nresult = tf.random.uniform(shape=[10], minval=1, maxval=5, dtype=tf.int32)\n```",
        "[Missing Code]\n```python\ntf.random.set_seed(seed_x)\nresult = 2 + tf.random.uniform(shape=[114], minval=0, maxval=4, dtype=tf.int32)\n```",
        "[Missing Code]\n```python\ntf.random.set_seed(seed_x)\nresult = tf.random.uniform(shape=[10], minval=1, maxval=5, dtype=tf.int32)\n```",
        "[Missing Code]\n```python\nresult = tf.__version__\n```"
    ],
    "Scipy": [
        "[Missing Code]\n```python\nlogx = np.log(x)\nresult = np.polyfit(logx, y, 1)\n```",
        "[Missing Code]\n```python\nlogx = np.log(x)\np = np.polyfit(logx, y, 1)\nresult = np.flip(p)\n```",
        "[Missing Code]\n```python\ndef func(x, A, B, C):\n    return A * np.exp(B * x) + C\n\npopt, pcov = scipy.optimize.curve_fit(func, x, y, p0)\nresult = np.array(popt)\n```",
        "[Missing Code]\n```python\nstatistic, p_value = stats.ks_2samp(x, y)\n```",
        "[Missing Code]\n```python\nD, p_value = stats.ks_2samp(x, y)\nresult = p_value < alpha\n```",
        "[Missing Code]\ndef f(x):\n    a, b, c = x\n    return ((a+b-c)-2)**2 + ((3*a-b-c))**2 + sin(b) + cos(b) + 4\n\nresult = optimize.minimize(f, initial_guess)\n[End of Missing Code]",
        "[Missing Code]\n```python\np_values = scipy.stats.norm.sf(abs(z_scores))\n```",
        "[Missing Code]\n```python\np_values = scipy.stats.norm.sf(np.array(z_scores))\n```",
        "[Missing Code]\n```python\nz_scores = [-scipy.stats.norm.ppf(p) for p in p_values]\n```",
        "[Begin of Missing Code]\ns = np.exp(mu)\nscale = np.exp(stddev**2)\ndist = stats.lognorm(s=s, scale=scale)\nresult = dist.cdf(x)\n[End of Missing Code]",
        "[Missing Code]\n```python\n# Create a lognormal distribution with the given parameters\ndist = stats.lognorm(s=stddev, scale=np.exp(mu))\n\n# Calculate the expected value and median of the distribution\nexpected_value = dist.mean()\nmedian = dist.median()\n```",
        "[Begin of Missing Code]\nsb = sparse.csr_matrix(np.array([0,1,2]).reshape(1,-1))\nresult = sa.multiply(sb)\n[End of Missing Code]",
        "```python\nfrom scipy import sparse\nimport numpy as np\nexample_sA = sparse.csr_matrix(np.array([[1,2,3],[4,5,6],[7,8,9]]))\nexample_sB = sparse.csr_matrix(np.array([0,1,2]))\ndef f(sA = example_sA, sB = example_sB):\n    # [Begin of Missing Code]\n    sB = sB.transpose()\n    result = sA.multiply(sB)\n    # [End of Missing Code]\n    return result\n```",
        "[Begin of Missing Code]\ninterpolator = scipy.interpolate.LinearNDInterpolator(points, V)\nresult = interpolator(request)\n[End of Missing Code]",
        "[Begin of Missing Code]\ninterpolator = scipy.interpolate.LinearNDInterpolator(points, V)\nresult = interpolator(request)\n[End of Missing Code]",
        "[Missing Code]\n```python\ndata_rot = rotate(data_orig, angle)\ncenter = np.array(data_orig.shape) / 2. - 0.5\noriginal = np.array([x0, y0])\nrelative = original - center\nrotated = np.dot(relative, [[np.cos(angle), np.sin(angle)], [-np.sin(angle), np.cos(angle)]])\nxrot, yrot = rotated + center\n```",
        "[Missing Code]\n```python\nresult = M.diagonal()\n```",
        "[Begin of Missing Code]\nresult = stats.kstest(times, 'uniform', args=(0, T))\n[End of Missing Code]",
        "[Begin of Missing Code]\n    times = np.array(times)\n    times = times / T\n    result = stats.kstest(times, 'uniform')\n[End of Missing Code]",
        "```python\n# [Begin of Missing Code]\n# Normalize the times to the range [0, 1]\ntimes = np.array(times) / T\n# Perform the Kolmogorov-Smirnov test\nD, p_value = stats.kstest(times, 'uniform')\n# If the p-value is greater than 0.05, we cannot reject the null hypothesis that the data is uniformly distributed\nresult = p_value > 0.05\n# [End of Missing Code]\n```",
        "[Missing Code]\nFeature = sparse.hstack((c1, c2))\n[End of Missing Code]",
        "[Missing Code]\nFeature = sparse.hstack((c1, c2))\n[End of Missing Code]",
        "[Missing Code]\nFeature = sparse.vstack((c1, c2))\n#print(Feature)",
        "[Missing Code]\ndistances = scipy.spatial.distance.cdist(points1, points2)\nresult = scipy.optimize.linear_sum_assignment(distances)\nresult = result[1]\n[End of Missing Code]",
        "[Missing Code]\ndistances = scipy.spatial.distance.cdist(points1, points2, 'cityblock')\nresult = scipy.optimize.linear_sum_assignment(distances)\nresult = result[1]\n[End of Missing Code]",
        "```python\nfrom scipy import sparse\nimport numpy as np\na = np.ones((2, 2))\nb = sparse.csr_matrix(a)\n# [Begin of Missing Code]\nb.setdiag(0)\nb.eliminate_zeros()\n# [End of Missing Code]\nprint(b)\n```",
        "[Missing Code]\n```python\nlabeled_array, num_features = ndimage.label(img > threshold)\nresult = num_features\n```",
        "[Missing Code]\n```python\nimg = img < threshold\nlabel_im, nb_labels = ndimage.label(img)\nresult = nb_labels\n```",
        "[Missing Code]\nlabeled_array, num_features = ndimage.label(img > threshold)\nresult = num_features\n[End of Missing Code]",
        "[Missing Code]\n```python\nlabeled, nr_objects = ndimage.label(img > threshold) \nregions = ndimage.find_objects(labeled)\nresult = []\nfor region in regions:\n    center_of_mass = ndimage.center_of_mass(img, labeled, region)\n    distance = np.sqrt(center_of_mass[0]**2 + center_of_mass[1]**2)\n    result.append(distance)\n```",
        "[Missing Code]\n```python\nM = (M + M.T)/2\nM = M.tolil()\n```",
        "[Missing Code]\n```python\n    sA = sA + sA.T - np.diag(sA.diagonal())\n```",
        "[Missing Code]\n```python\neroded_square = scipy.ndimage.binary_erosion(square)\nreconstructed_square = scipy.ndimage.binary_dilation(eroded_square)\nindex = np.logical_and(square, np.logical_not(reconstructed_square))\nsquare[index] = 0\n```",
        "```python\n# [Begin of Missing Code]\nstructure = np.ones((3, 3))\nlabels, n = scipy.ndimage.label(square, structure)\ncounts = np.bincount(labels.ravel())\nsquare[labels == np.where(counts == 1)[0]] = 0\n# [End of Missing Code]\n```",
        "[Missing Code]\n```python\nmean = col.sum() / col.shape[0]\nstandard_deviation = np.sqrt((col.power(2).sum() / col.shape[0]) - (mean ** 2))\n```\n[End of Missing Code]",
        "[Missing Code]\n```python\nMax = col.max()\nMin = col.min()\n```",
        "[Missing Code]\n```python\nfrom scipy import stats\n\n# Convert the sparse matrix to a 1D numpy array\ncol_arr = col.toarray().flatten()\n\n# Calculate the median\nMedian = np.median(col_arr)\n\n# Calculate the mode\nMode = stats.mode(col_arr)[0][0]\n```",
        "[Missing Code]\n```python\ndef fourier(x, *a):\n    ret = a[0] * np.cos(np.pi / tau * x)\n    for deg in range(1, len(a)):\n        ret += a[deg] * np.cos((deg+1) * np.pi / tau * x)\n    return ret\n\np0 = [1.0] * degree\npopt, pcov = curve_fit(fourier, z, Ua, p0=p0)\n```\n[End of Missing Code]",
        "[Begin of Missing Code]\n# Get unique IDs\nunique_ids = np.unique(example_array)\nunique_ids = unique_ids[unique_ids != 0]\n\n# Get coordinates of each cell for each unique ID\ncoords = {uid: np.column_stack(np.where(example_array == uid)) for uid in unique_ids}\n\n# Calculate pairwise distances and get minimum\nresult = np.zeros((len(unique_ids), len(unique_ids)))\nfor i, uid1 in enumerate(unique_ids):\n    for j, uid2 in enumerate(unique_ids):\n        if uid1 != uid2:\n            result[i, j] = np.min(scipy.spatial.distance.cdist(coords[uid1], coords[uid2]))\n[End of Missing Code]",
        "```python\n# [Begin of Missing Code]\n# Get unique IDs\nunique_ids = np.unique(example_array)\n\n# Initialize result array\nresult = np.zeros((len(unique_ids), len(unique_ids)))\n\n# Calculate pairwise Manhattan distances\nfor i, id1 in enumerate(unique_ids):\n    for j, id2 in enumerate(unique_ids):\n        if id1 != id2:\n            y1, x1 = np.where(example_array == id1)\n            y2, x2 = np.where(example_array == id2)\n            distances = scipy.spatial.distance.cdist(np.column_stack((y1, x1)), np.column_stack((y2, x2)), metric='cityblock')\n            result[i, j] = np.min(distances)\n# [End of Missing Code]\n```",
        "[Missing Code]\n```python\n    unique_ids = np.unique(example_array)\n    unique_ids = unique_ids[unique_ids != 0]  # Exclude 0 if it exists\n    result = np.zeros((len(unique_ids), len(unique_ids)))\n    for i, id1 in enumerate(unique_ids):\n        for j, id2 in enumerate(unique_ids):\n            if i != j:\n                coords1 = np.array(np.where(example_array == id1)).T\n                coords2 = np.array(np.where(example_array == id2)).T\n                result[i, j] = np.min(scipy.spatial.distance.cdist(coords1, coords2))\n    return result\n```",
        "[Begin of Missing Code]\nresult = np.zeros((5, 100))\nfor i in range(5):\n    tck = interpolate.splrep(x[:, i], y[:, i], k = 2, s = 4)\n    result[i] = interpolate.splev(x_val, tck, der = 0, ext = 0)\n[End of Missing Code]",
        "[Missing Code]\nstatistic, critical_values, significance_level = ss.anderson_ksamp([x1, x2, x3, x4])",
        "[Missing Code]\n```python\nresult = ss.anderson_ksamp([x1, x2])\nresult = result.significance_level < 0.05\n```",
        "```python\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\ndf = pd.DataFrame([[1, 5, 2], [2, 4, 4], [3, 3, 1], [4, 2, 2], [5, 1, 4]], \n                 columns=['A', 'B', 'C'], index = [1, 2, 3, 4, 5])\n# [Begin of Missing Code]\ndef rolling_kendall(df, window):\n    result = pd.DataFrame()\n    for col1 in df.columns:\n        for col2 in df.columns:\n            if col1 != col2:\n                result[col1+col2] = df[[col1, col2]].rolling(window).apply(lambda x: stats.kendalltau(x[col1], x[col2])[0], raw=False)\n    return pd.concat([df, result], axis=1)\n\ndf = rolling_kendall(df, 3)\n# [End of Missing Code]\nprint(df)\n```",
        "[Missing Code]\n```python\nresult = sa.nnz == 0\n```",
        "[Missing Code]\n```python\nresult = sa.nnz == 0\n```",
        "[Missing Code]\n```python\nresult = block_diag(*a)\n```",
        "[Missing Code]\nresult = stats.ranksums(pre_course_scores, during_course_scores)\np_value = result.pvalue\n[End of Missing Code]",
        "[Missing Code]\n```python\nresult = stats.ranksums(pre_course_scores, during_course_scores)\np_value = result.pvalue\n```",
        "[Missing Code]\n```python\nmean = np.mean(a)\nstd_dev = np.std(a)\nkurtosis_result = np.mean((a - mean) ** 4) / (std_dev ** 4)\n```",
        "[Missing Code]\n```python\nkurtosis_result = scipy.stats.kurtosis(a, fisher=True, bias=False)\n```",
        "[Missing Code]\n```python\ninterpolated = scipy.interpolate.interp2d(x, y, z, kind='cubic')\nresult = interpolated(s, t)\n```",
        "[Missing Code]\ninterp = scipy.interpolate.interp2d(x, y, z, kind='cubic')\nresult = interp(s, t)\n[End of Missing Code]",
        "```python\nimport scipy.spatial\npoints = [[0,0], [1,4], [2,3], [4,1], [1,1], [2,2], [5,3]]\nvor = scipy.spatial.Voronoi(points)\nextraPoints = [[0.5,0.2], [3, 0], [4,0],[5,0], [4,3]]\n# [Begin of Missing Code]\nresult = []\nfor extraPoint in extraPoints:\n    dist = scipy.spatial.distance.cdist([extraPoint], points)\n    result.append(dist.argmin())\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\ndef voronoi_finite_polygons_2d(vor, radius=None):\n    if vor.points.shape[1] != 2:\n        raise ValueError(\"Requires 2D input\")\n    new_regions = []\n    new_vertices = vor.vertices.tolist()\n    center = vor.points.mean(axis=0)\n    if radius is None:\n        radius = vor.points.ptp().max()*2\n    for region in vor.regions:\n        if not -1 in region:\n            new_regions.append(region)\n            continue\n        poly = [vor.vertices[i] for i in region if i != -1]\n        hull = scipy.spatial.ConvexHull(poly)\n        for i in range(hull.nsimplex):\n            t = hull.transform[i,:2]\n            t0 = np.dot(t,hull.points[hull.vertices[i],:]) - 1\n            t = np.linalg.norm(t, axis=0)\n            r = np.array([-t[1], t[0]])\n            dt0 = np.dot(r,center)\n            if dt0 < 0:\n                r *= -1\n            far_point = np.dot(t,r)*radius + center\n            new_vertices.append(far_point.tolist())\n            region.append(len(new_vertices) - 1)\n        new_regions.append(region)\n    return new_regions, np.asarray(new_vertices)\n\ndef point_in_hull(point, hull, tolerance=1e-12):\n    return all((np.dot(eq[:-1], point) + eq[-1] <= tolerance) for eq in hull.equations)\n\ndef points_in_voronoi(vor, points):\n    regions, vertices = voronoi_finite_polygons_2d(vor)\n    hulls = [scipy.spatial.ConvexHull(vertices[region]) for region in regions]\n    return np.array([next((i for i, hull in enumerate(hulls) if point_in_hull(point, hull)), -1) for point in points])\n\nresult = points_in_voronoi(vor, extraPoints)\n```\n[End of Missing Code]",
        "```python\nimport numpy as np\nimport scipy.sparse as sparse\n\nnp.random.seed(10)\nmax_vector_size = 1000\nvectors = [np.random.randint(100,size=900),np.random.randint(100,size=max_vector_size),np.random.randint(100,size=950)]\n# [Begin of Missing Code]\nresult = sparse.vstack([sparse.csr_matrix(np.pad(v, (0, max_vector_size - len(v)))) for v in vectors])\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\nb = scipy.ndimage.median_filter(a, size=(3,3), mode='constant', cval=0.0, origin=(0,1))\n```",
        "[Missing Code]\nresult = M[row, column]",
        "[Missing Code]\n```python\nresult = [M[i, j] for i, j in zip(row, column)]\n```",
        "[Missing Code]\n```python\nnew_array = scipy.interpolate.interp1d(x, array, axis=0)(x_new)\n```",
        "[Begin of Missing Code]\ndef NormalDistro(u,o2,x):\n    dev = abs((x-u)/o2)\n    P_inner, _ = scipy.integrate.quad(NDfx,-dev,dev)\n    P_outer = 1 - P_inner\n    P = P_inner + P_outer/2\n    return(P)\n\nprob = NormalDistro(u,o2,x)\n[End of Missing Code]",
        "[Begin of Missing Code]\ndev = abs((x-u)/o2)\nP_inner, _ = scipy.integrate.quad(NDfx,-dev,dev)\nP_outer = 1 - P_inner\nprob = P_inner + P_outer/2\n[End of Missing Code]",
        "[Missing Code]\n```python\ndef dctmtx(N):\n    x,y = np.meshgrid(range(N), range(N))\n    D = np.sqrt(2.0/N) * np.cos(np.pi * (2*x+1) * y / (2.0 * N))\n    D[0] /= np.sqrt(2)\n    return D\n\nresult = dctmtx(N)\n```",
        "[Missing Code]\n```python\n# The diags function takes the diagonals in the order they are given, \n# so we need to reverse the order of the diagonals in the matrix.\nmatrix = matrix[::-1]\nresult = sparse.diags(matrix, [-1, 0, 1], (5, 5)).toarray()\n```\n[End of Missing Code]",
        "```python\nimport numpy as np\nimport scipy.stats\nN = 3\np = 0.5\n# [Begin of Missing Code]\nresult = np.zeros((N+1, N+1))\ni = np.arange(N+1).reshape(-1, 1)\nj = np.arange(N+1)\nmask = j <= i\nresult[mask] = scipy.stats.binom.pmf(j[mask], i[mask], p)\n# [End of Missing Code]\nprint(result)\n```",
        "```python\nimport pandas as pd\nimport io\nfrom scipy import stats\n\ntemp=u\"\"\"probegenes,sample1,sample2,sample3\n1415777_at Pnliprp1,20,0.00,11\n1415805_at Clps,17,0.00,55\n1415884_at Cela3b,47,0.00,100\"\"\"\ndf = pd.read_csv(io.StringIO(temp),index_col='probegenes')\n# [Begin of Missing Code]\nresult = df.apply(stats.zscore, axis=1)\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\nresult = df.apply(stats.zscore)\n```",
        "[Missing Code]\n```python\ndf_zscore = df.apply(stats.zscore, axis=1)\ndf_zscore.index = df.index + ' zscore'\nresult = pd.concat([df, df_zscore]).sort_index()\n```",
        "[Missing Code]\n```python\ndf_zscore = df.apply(stats.zscore)\ndf_zscore.index = df.index + ' zscore'\ndf.index = df.index + ' data'\nresult = pd.concat([df, df_zscore]).sort_index()\nresult = result.round(3)\n```",
        "[Begin of Missing Code]\nresult = scipy.optimize.line_search(test_func, test_grad, np.array(starting_point), np.array(direction))\n[End of Missing Code]",
        "[Missing Code]\n```python\ny, x = np.indices(shape)\ncenter = np.array([(shape[0]-1)/2, (shape[1]-1)/2])\nresult = distance.cdist(np.column_stack([y.ravel(), x.ravel()]), center.reshape(1, -1)).reshape(shape)\n```",
        "[Missing Code]\n```python\ncenter = np.array([(x - shape[0] // 2, y - shape[1] // 2) for x in range(shape[0]) for y in range(shape[1])])\nresult = distance.cdist(center, [center[shape[0] * shape[1] // 2]], 'cityblock').reshape(shape)\n```\n[End of Missing Code]",
        "[Missing Code]\n```python\n    y, x = np.indices(shape)\n    center = np.array(shape) / 2.\n    result = distance.cdist(np.column_stack([y.ravel(), x.ravel()]), center.reshape(1, -1)).reshape(shape)\n```",
        "[Missing Code]\n```python\nzoom = [shape_dim / x_dim for shape_dim, x_dim in zip(shape, x.shape)]\nresult = scipy.ndimage.zoom(x, zoom, order=1)\n```",
        "[Begin of Missing Code]\ndef func(x):\n    return np.sum((a.dot(x ** 2) - y) ** 2)\nout = scipy.optimize.minimize(func, x0)\n[End of Missing Code]",
        "[Begin of Missing Code]\ndef func(x, a, y):\n    return np.sum((a.dot(x ** 2) - y) ** 2)\n\nout = scipy.optimize.minimize(func, x0, args=(a, y), method='L-BFGS-B', bounds=scipy.optimize.Bounds(x_lower_bounds, np.inf))\n[End of Missing Code]",
        "[Missing Code]\ndef dN1_dt(t, N1):\n    return -100 * N1 + np.sin(t)\nsol = scipy.integrate.solve_ivp(fun=dN1_dt, t_span=time_span, y0=[N0,])",
        "[Missing Code]\ndef dN1_dt(t, N1):\n    if 0 < t < 2*np.pi:\n        return -100 * N1 + t - np.sin(t)\n    else:\n        return -100 * N1 + 2*np.pi\nsol = scipy.integrate.solve_ivp(fun=dN1_dt, t_span=time_span, y0=[N0,])\n[End of Missing Code]",
        "[Missing Code]\ndef dN1_dt(t, N1):\n    return -100 * N1 - np.cos(t)\nsol = scipy.integrate.solve_ivp(fun=dN1_dt, t_span=time_span, y0=[N0,])\n[End of Missing Code]",
        "[Begin of Missing Code]\nfor t in range (4):\n    cons.append({'type':'ineq', 'fun': lambda x, t=t: x[t]})\n[End of Missing Code]",
        "[Missing Code]\n```python\nresult = sparse.vstack((sa, sb))\n```",
        "[Missing Code]\n```python\nresult = sparse.hstack((sa, sb))\n```",
        "[Begin of Missing Code]\nresults = []\nfor i in range(c):\n    result, error = scipy.integrate.quad(lambda x: 2*x*i, low, high)\n    results.append(result)\n[End of Missing Code]",
        "[Missing Code]\nresult, error = scipy.integrate.quad(lambda x: 2*c*x, low, high)\n[End of Missing Code]",
        "[Missing Code]\n```python\nfor key in V.keys():\n    V[key] += x\n```\n[End of Missing Code]",
        "[Missing Code]\n```python\nV.data += x\n```\n[End of Missing Code]",
        "[Missing Code]\n```python\nV.data += x\nV.data += y\n```\n[End of Missing Code]",
        "[Missing Code]\nfor Col in range(sa.shape[1]):\n    Column = sa[:,Col].copy()\n    List = [x**2 for x in Column.data]\n    Len = math.sqrt(sum(List))\n    sa[:,Col] = sa[:,Col] / Len\n[End of Missing Code]",
        "[Missing Code]\n```python\nfor i in range(sa.shape[1]):\n    col = sa[:, i].toarray()\n    col_len = np.linalg.norm(col)\n    sa[:, i] = sa[:, i] / col_len\n```\n[End of Missing Code]",
        "[Missing Code]\na = (a > 0).astype(int)",
        "[Missing Code]\na = (a > 0).astype(int)",
        "[Missing Code]\n```python\ndistances = scipy.spatial.distance.cdist(centroids, data)\nresult = np.argmin(distances, axis=1)\n```",
        "[Missing Code]\n```python\ndistances = scipy.spatial.distance.cdist(centroids, data)\nclosest = np.argmin(distances, axis=1)\nresult = data[closest]\n```",
        "[Missing Code]\n```python\ndistances = scipy.spatial.distance.cdist(centroids, data)\nsorted_indices = np.argsort(distances, axis=1)\nresult = sorted_indices[:, k-1]\n```",
        "[Missing Code]\nresult = []\nfor x, b in zip(xdata, bdata):\n    result.append(fsolve(lambda a: eqn(x, a, b), x0=0.5))\nresult = np.array(result)\n[End of Missing Code]",
        "[Missing Code]\n```python\nresult = []\nfor x, a in zip(xdata, adata):\n    roots = fsolve(lambda b: eqn(x, a, b), x0=[0.5])\n    roots.sort()\n    result.append(roots)\nresult = np.array(result)\n```\n",
        "[Missing Code]\n```python\ndef cdf(x):\n    return integrate.quad(lambda x: bekkers(x, estimated_a, estimated_m, estimated_d), range_start, x)[0]\n\nresult = sp.stats.kstest(sample_data, cdf)\n```\n[End of Missing Code]",
        "[Missing Code]\n```python\n# Define the cumulative distribution function\ndef cdf_bekkers(x, a, m, d):\n    return integrate.quad(lambda x: bekkers(x, a, m, d), range_start, x)[0]\n\n# Calculate the cumulative distribution function values for the sample data\ncdf_sample_data = [cdf_bekkers(x, estimated_a, estimated_m, estimated_d) for x in sample_data]\n\n# Perform the Kolmogorov-Smirnov test\nD, p_value = sp.stats.kstest(cdf_sample_data, 'uniform')\n\n# Check if the null hypothesis can be rejected at the 95% confidence level\nresult = p_value < 0.05\n```\n[End of Missing Code]",
        "[Missing Code]\n```python\ndf['Time'] = pd.to_datetime(df['Time'], format='%Y-%m-%d-%H:%M:%S')\ndf.set_index('Time', inplace=True)\ndf['integral'] = df.rolling('25S').apply(lambda x: integrate.trapz(x, x.index.astype(int)), raw=False)\nintegral_df = df['integral']\n```",
        "```python\nimport scipy.interpolate\nx = [(2,2), (1,2), (2,3), (3,2), (2,1)]\ny = [5,7,8,10,3]\neval = [(2.7, 2.3)]\n# [Begin of Missing Code]\ngrid_z0 = scipy.interpolate.griddata(x, y, eval, method='linear')\nresult = grid_z0[0]\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\ndef multinomial(params):\n    return -np.sum(a['A1']*np.log(params))\n\nx0 = np.ones(12)/12\nbounds = [(0.001, 1) for _ in range(12)]\nconstraints = {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}\n\nresult = sciopt.minimize(multinomial, x0, bounds=bounds, constraints=constraints)\nweights = result.x\n```\n[End of Missing Code]",
        "[Begin of Missing Code]\nresult = sciopt.minimize(e, [0.5, 0.5], bounds=[(0.5, 1.5), (0.7, 1.8)], args=(x,y))\n[End of Missing Code]",
        "[Missing Code]\n```python\nresult = signal.argrelextrema(arr, np.less_equal, order=n)\n```",
        "[Missing Code]\n```python\nresult = []\nfor i in range(arr.shape[0]):\n    for j in range(n, arr.shape[1]-n):\n        if all(arr[i][j] <= arr[i][k] for k in range(j-n, j+n+1)):\n            result.append([i, j])\n```",
        "[Begin of Missing Code]\nnumeric_cols = df.select_dtypes(include=[np.number]).columns\ndf = df[(np.abs(stats.zscore(df[numeric_cols])) < 3).all(axis=1)]\n[End of Missing Code]"
    ],
    "Sklearn": [
        "[Missing Code]\ndata1 = pd.DataFrame(data=np.c_[data['data'], data['target']],\n                     columns=data['feature_names'] + ['target'])",
        "[Missing Code]\n```python\ndata1 = pd.DataFrame(data=np.c_[data['data'], data['target']],\n                     columns=data['feature_names'] + ['target'])\n```",
        "[Missing Code]\nDataFrame(data.data, columns=data.feature_names)\n[End of Missing Code]",
        "[Missing Code]\n```python\ndf = pd.DataFrame(data=data.data, columns=data.feature_names)\nresult = df\n```",
        "[Missing Code]\n```python\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nmlb = MultiLabelBinarizer()\ndf_out = df.join(pd.DataFrame(mlb.fit_transform(df.pop('Col3')),\n                          columns=mlb.classes_,\n                          index=df.index))\n```",
        "[Missing Code]\n```python\n# get all unique values in the list of lists\nunique_values = pd.unique(df['Col3'].explode())\n\n# create new columns for each unique value\nfor value in unique_values:\n    df[value] = np.where(df['Col3'].apply(lambda x: value in x), 1, 0)\n\ndf_out = df\n```",
        "[Missing Code]\n```python\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nmlb = MultiLabelBinarizer()\ndf_out = df.join(pd.DataFrame(mlb.fit_transform(df.pop('Col4')),\n                          columns=mlb.classes_,\n                          index=df.index))\n```",
        "[Missing Code]\n```python\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nmlb = MultiLabelBinarizer()\ndf_out = df.join(pd.DataFrame(mlb.fit_transform(df.pop(df.columns[-1])),\n                          columns=mlb.classes_,\n                          index=df.index))\n```",
        "[Missing Code]\n```python\n# Get the unique elements in the last column\nunique_elements = pd.unique(df[df.columns[-1]].explode())\n\n# Create a new dataframe with the unique elements as columns\ndf_out = pd.DataFrame(columns=unique_elements)\n\n# Iterate over the rows of the original dataframe\nfor index, row in df.iterrows():\n    # For each unique element, check if it is in the list in the last column of the current row\n    # If it is, set the corresponding cell in the new dataframe to 0, otherwise set it to 1\n    for element in unique_elements:\n        df_out.loc[index, element] = 0 if element in row[df.columns[-1]] else 1\n\n# Concatenate the original dataframe (without the last column) with the new dataframe\ndf_out = pd.concat([df[df.columns[:-1]], df_out], axis=1)\n```",
        "[Solution Code]\n```python\nimport numpy as np\nimport pandas as pd\nimport sklearn.svm as suppmach\nfrom sklearn.calibration import CalibratedClassifierCV\nX, y, x_test = load_data()\nassert type(X) == np.ndarray\nassert type(y) == np.ndarray\nassert type(x_test) == np.ndarray\n# Fit model:\nsvmmodel=suppmach.LinearSVC()\n# [Begin of Missing Code]\nsvmmodel.fit(X, y)\ncalibrated_clf = CalibratedClassifierCV(svmmodel, cv=5)\ncalibrated_clf.fit(X, y)\nproba = calibrated_clf.predict_proba(x_test)\n# [End of Missing Code]\nprint(proba)\n```",
        "[Missing Code]\n```python\nfrom sklearn.calibration import CalibratedClassifierCV\n\nmodel = svm.LinearSVC()\ncalibrated_clf = CalibratedClassifierCV(model, method='sigmoid', cv=5)\ncalibrated_clf.fit(X, y)\nproba = calibrated_clf.predict_proba(x_predict)\n```",
        "[Missing Code]\n```python\n# Convert the sparse matrix to a dense numpy array\ndense_output = transform_output.toarray()\n\n# Convert the numpy array to a dataframe\ndf_transformed = pd.DataFrame(dense_output)\n\n# Concatenate the original dataframe with the transformed dataframe\ndf = pd.concat([df_origin, df_transformed], axis=1)\n```",
        "[Missing Code]\n```python\n# Convert the csr_matrix to a DataFrame\ndf_transformed = pd.DataFrame.sparse.from_spmatrix(transform_output)\n\n# Merge the transformed DataFrame with the original DataFrame\ndf = pd.concat([df_origin, df_transformed], axis=1)\n```",
        "[Missing Code]\n```python\n    transform_output_df = pd.DataFrame(transform_output.toarray())\n    result = pd.concat([df, transform_output_df], axis=1)\n```",
        "[Missing Code]\ndel clf.steps[1]\n[End of Missing Code]",
        "[Missing Code]\ndel clf.steps[1]\n[End of Missing Code]",
        "[Missing Code]\ndel clf.named_steps['pOly']\n[End of Missing Code]",
        "[Missing Code]\nclf.steps.insert(1, ('poly', PolynomialFeatures()))\n[End of Missing Code]",
        "[Missing Code]\nclf.steps.insert(1, ('new_step', SVC()))\n[End of Missing Code]",
        "[Begin of Missing Code]\nsteps = list(clf.steps)\nsteps.insert(1, ('t1919810', PCA()))\nclf = Pipeline(steps)\n[End of Missing Code]",
        "[Begin of Missing Code]\nfit_params = {\"early_stopping_rounds\":42, \n              \"eval_metric\" : \"mae\", \n              \"eval_set\" : [(testX, testY)]}\n\nmodel = xgb.XGBRegressor()\nparamGrid = {'max_depth': [3, 5, 7], 'min_child_weight': [1, 3, 5]}\n\ncv = TimeSeriesSplit(n_splits=5)\n\ngridsearch = GridSearchCV(estimator=model, \n                          param_grid=paramGrid, \n                          cv=cv, \n                          verbose=1, \n                          fit_params=fit_params)\n\ngridsearch.fit(trainX, trainY)\n# [End of Missing Code]",
        "[Begin of Missing Code]\nmodel = xgb.XGBRegressor()\nparamGrid = {'max_depth': [3, 5, 7], 'n_estimators': [100, 500, 1000]}\nfit_params={\"early_stopping_rounds\":42, \"eval_metric\" : \"mae\", \"eval_set\" : [[testX, testY]]}\ngridsearch = GridSearchCV(model, paramGrid, verbose=1, cv=TimeSeriesSplit(n_splits=3).get_n_splits([trainX, trainY]), n_jobs=1, iid=False)\ngridsearch.fit(trainX, trainY, **fit_params)\n[End of Missing Code]",
        "[Missing Code]\n```python\nproba = []\nfor train, test in cv:\n    logreg.fit(X[train], y[train])\n    proba.extend(logreg.predict_proba(X[test]))\nproba = np.array(proba)\n```",
        "[Missing Code]\n```python\nproba = []\nfor train, test in cv:\n    logreg.fit(X[train], y[train])\n    proba.extend(logreg.predict_proba(X[test]))\nproba = np.array(proba)\n```",
        "[Begin of Missing Code]\n# run regression model\nmodel = SomeRegressionModel()\nmodel.fit(scaled)\n\n# check score\nscore = model.score(scaled)\n\n# predict t'\npredicted = model.predict(scaled)\n\n# check predicted t' with real time value(inverse StandardScaler)\ninversed = scaler.inverse_transform(predicted)\n[End of Missing Code]",
        "[Missing Code]\n```python\nfrom sklearn.linear_model import LinearRegression\n\n# Separate features and target\nX = scaled[:, 1:]\ny = scaled[:, 0]\n\n# Fit the model\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Predict\npredictions = model.predict(X)\n\n# Inverse transform the predictions\ninversed = scaler.inverse_transform(np.column_stack((predictions, X)))\n```",
        "[Missing Code]\nmodel_name = model.__class__.__name__",
        "[Begin of Missing Code]\nmodel_name = model.__class__.__name__\n[End of Missing Code]",
        "[Solution Code]\n```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.svm import LinearSVC\nmodel = LinearSVC()\n# [Begin of Missing Code]\nmodel_name = model.__class__.__name__\n# [End of Missing Code]\nprint(model_name)\n```",
        "[Begin of Missing Code]\ntf_idf = pipe.named_steps[\"tf_idf\"]\ntf_idf_out = tf_idf.fit_transform(data)\n[End of Missing Code]",
        "[Begin of Missing Code]\npipe.fit(data.test)\ntf_idf_out = pipe.named_steps['tf_idf'].transform(data.test)\n[End of Missing Code]",
        "[Missing Code]\n```python\npipe.fit(data, target)\nselect_out = pipe.named_steps['select'].transform(data)\n```",
        "[Begin of Missing Code]\nclf = GridSearchCV(bc, param_grid)\nclf = clf.fit(X_train, y_train)\n[End of Missing Code]",
        "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\n\nX, y, X_test = load_data()\nassert type(X) == np.ndarray\nassert type(y) == np.ndarray\nassert type(X_test) == np.ndarray\n# [Begin of Missing Code]\nX = X.reshape(-1, 1)\nX_test = X_test.reshape(-1, 1)\nregressor = RandomForestRegressor(n_estimators=150, min_samples_split=1.0, random_state=42)\nregressor.fit(X, y)\n# [End of Missing Code]\npredict = regressor.predict(X_test)\nprint(predict)\n```",
        "[Begin of Missing Code]\nX = X.reshape(-1, 1)\ny = y.reshape(-1, 1)\nX_test = X_test.reshape(-1, 1)\n\nregressor = RandomForestRegressor(n_estimators=150, min_samples_split=1.0, random_state=42)\nrgr = regressor.fit(X,y.ravel())\n[End of Missing Code]",
        "[Missing Code]\n```python\ndef preprocess(s):\n    return s.upper()\n\ntfidf = TfidfVectorizer(preprocessor=preprocess)\n```",
        "[Missing Code]\n```python\ndef prePro(text):\n    return text.lower()\n\ntfidf = TfidfVectorizer(preprocessor=prePro)\n```",
        "[Missing Code]\n```python\nscaled_data = preprocessing.scale(data)\ndf_out = pd.DataFrame(scaled_data, index=data.index, columns=data.columns)\n```",
        "[Missing Code]\n```python\nscaled_data = preprocessing.scale(data)\ndf_out = pd.DataFrame(scaled_data, index=data.index, columns=data.columns)\n```",
        "[Solution Code]\n```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nX, y = load_data()\nassert type(X) == np.ndarray\nassert type(y) == np.ndarray\npipe = Pipeline([\n    (\"scale\", StandardScaler()),\n    (\"model\", SGDClassifier(random_state=42))\n])\ngrid = GridSearchCV(pipe, param_grid={\"model__alpha\": [1e-3, 1e-2, 1e-1, 1]}, cv=5)\n# [Begin of Missing Code]\ngrid.fit(X, y)\ncoef = grid.best_estimator_.named_steps['model'].coef_\n# [End of Missing Code]\nprint(coef)\n```",
        "[Missing Code]\n```python\ngrid.fit(X, y)\ncoef = grid.best_estimator_.named_steps['model'].coef_\n```",
        "[Missing Code]\n```python\nmodel = SelectFromModel(clf, prefit=True)\nX_new = model.transform(X)\nmask = model.get_support() #list of booleans for selected features\nnew_features = [] # The list of your K best features\n\nfor bool, feature in zip(mask, X.columns):\n    if bool:\n        new_features.append(feature)\ncolumn_names = new_features\n```\n[End of Missing Code]",
        "[Missing Code]\n```python\nmodel = SelectFromModel(clf, prefit=True)\nX_new = model.transform(X)\nfeature_idx = model.get_support()\ncolumn_names = X.columns[feature_idx]\n```",
        "[Missing Code]\n```python\nmodel = SelectFromModel(clf, prefit=True)\nX_new = model.transform(X)\nfeature_idx = model.get_support()\ncolumn_names = X.columns[feature_idx]\n```",
        "[Missing Code]\n```python\nmodel = SelectFromModel(clf, prefit=True)\nX_new = model.transform(X)\nmask = model.get_support() #list of booleans for selected features\nnew_features = [] # The list of your K best features\n\nfor bool, feature in zip(mask, X.columns):\n    if bool:\n        new_features.append(feature)\ncolumn_names = new_features\n```",
        "[Missing Code]\n```python\nkm.fit(X)\ndistances = km.transform(X)\ndistances_to_p = distances[:, p]\nclosest_50_indices = np.argsort(distances_to_p)[:50]\nclosest_50_samples = X[closest_50_indices]\n```",
        "[Missing Code]\n```python\nkm.fit(X)\ndistances = km.transform(X)[:, p]\nclosest_50_indices = np.argsort(distances)[:50]\nclosest_50_samples = X[closest_50_indices]\n```",
        "[Missing Code]\n```python\nkm.fit(X)\ndistances = km.transform(X)\ndistances_to_p = distances[:, p]\nclosest_100_indices = np.argsort(distances_to_p)[:100]\nclosest_100_samples = X[closest_100_indices]\n```",
        "[Missing Code]\n```python\nkm.fit(X)\ndistances = km.transform(X)[:, p]\nindices = np.argsort(distances)[:50]\nsamples = X[indices]\n```",
        "[Begin of Missing Code]\n# Convert categorical variable to matrix and merge back with original training data\nX_train = pd.get_dummies(X_train, columns=[0])\n[End of Missing Code]",
        "[Begin of Missing Code]\n# Convert categorical variable to dummy variables\nX_train = pd.get_dummies(X_train, columns=[0])\n[End of Missing Code]",
        "[Missing Code]\n```python\nfrom sklearn.svm import SVR\nmodel = SVR(kernel='rbf')\nmodel.fit(X, y)\npredict = model.predict(X)\n```",
        "[Missing Code]\n```python\nfrom sklearn.svm import SVR\n\n# create a SVM regression model with a gaussian kernel\nmodel = SVR(kernel='rbf')\n\n# fit the model with the data\nmodel.fit(X, y)\n\n# predict the output for the same data\npredict = model.predict(X)\n```",
        "[Missing Code]\n```python\nfrom sklearn.svm import SVR\nmodel = SVR(kernel='poly', degree=2)\nmodel.fit(X, y)\npredict = model.predict(X)\n```",
        "[Missing Code]\n```python\nfrom sklearn.svm import SVR\n\n# create a SVM regression model with polynomial kernel of degree 2\nmodel = SVR(kernel='poly', degree=2)\n\n# fit the model with the data\nmodel.fit(X, y)\n\n# predict the output for the same data\npredict = model.predict(X)\n```",
        "[Missing Code]\n```python\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ncosine_similarities_of_queries = []\nfor query in queries:\n    query_tfidf = tfidf.transform([query])\n    cosine_similarities = cosine_similarity(query_tfidf, tfidf.transform(documents))\n    cosine_similarities_of_queries.append(cosine_similarities[0])\ncosine_similarities_of_queries = np.array(cosine_similarities_of_queries)\n```\n[End of Missing Code]",
        "[Missing Code]\n```python\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ncosine_similarities_of_queries = []\nfor query in queries:\n    query_tfidf = tfidf.transform([query])\n    cosine_similarities = cosine_similarity(query_tfidf, tfidf.transform(documents))\n    cosine_similarities_of_queries.append(cosine_similarities)\ncosine_similarities_of_queries = np.array(cosine_similarities_of_queries)\n```\n[End of Missing Code]",
        "[Missing Code]\n```python\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ncosine_similarities_of_queries = []\nfor query in queries:\n    query_vector = tfidf.transform([query])\n    cosine_similarities = cosine_similarity(query_vector, tfidf.transform(documents))\n    cosine_similarities_of_queries.append(cosine_similarities[0])\ncosine_similarities_of_queries = np.array(cosine_similarities_of_queries)\n```",
        "[Missing Code]\n```python\nfrom sklearn.preprocessing import MultiLabelBinarizer\nmlb = MultiLabelBinarizer()\nnew_features = mlb.fit_transform(features)\nnew_features = pd.DataFrame(new_features,columns=mlb.classes_)\n```",
        "[Missing Code]\n```python\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nmlb = MultiLabelBinarizer()\nnew_f = pd.DataFrame(mlb.fit_transform(f),columns=mlb.classes_, index=['r'+str(i+1) for i in range(len(f))])\n```",
        "[Missing Code]\n```python\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nmlb = MultiLabelBinarizer()\nnew_features = mlb.fit_transform(features)\nnew_features = pd.DataFrame(new_features,columns=mlb.classes_)\n```",
        "[Missing Code]\n```python\nfrom sklearn.preprocessing import MultiLabelBinarizer\nmlb = MultiLabelBinarizer()\nnew_features = mlb.fit_transform(features)\nnew_features = pd.DataFrame(new_features,columns=mlb.classes_)\n```",
        "[Missing Code]\n```python\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nmlb = MultiLabelBinarizer()\nnew_features = pd.DataFrame(mlb.fit_transform(features), columns=mlb.classes_, index=['r'+str(i+1) for i in range(len(features))])\n```",
        "[Missing Code]\n```python\n# Create an object of AgglomerativeClustering\nagg_clustering = sklearn.cluster.AgglomerativeClustering(n_clusters=2, affinity='precomputed', linkage='average')\n\n# Fit the data and predict the cluster labels\ncluster_labels = agg_clustering.fit_predict(data_matrix)\n```",
        "[Missing Code]\n```python\n# Create a model and fit it\nmodel = sklearn.cluster.AgglomerativeClustering(n_clusters=2, affinity='precomputed', linkage='average')\nmodel.fit(data_matrix)\n# Get cluster assignments\ncluster_labels = model.labels_.tolist()\n```",
        "[Missing Code]\n```python\n# Convert the similarity matrix to a distance matrix\ndistM = 1 - np.array(simM)\n\n# Perform hierarchical clustering\ncluster = sklearn.cluster.AgglomerativeClustering(n_clusters=2, affinity='precomputed', linkage='average')\ncluster_labels = cluster.fit_predict(distM)\n```",
        "[Missing Code]\n```python\nZ = scipy.cluster.hierarchy.linkage(data_matrix, 'ward')\ncluster_labels = scipy.cluster.hierarchy.fcluster(Z, 2, criterion='maxclust')\n```",
        "[Missing Code]\n```python\nZ = scipy.cluster.hierarchy.linkage(data_matrix, 'ward')\ncluster_labels = scipy.cluster.hierarchy.fcluster(Z, 2, criterion='maxclust')\n```",
        "[Missing Code]\n```python\nZ = scipy.cluster.hierarchy.linkage(simM, 'ward')\ncluster_labels = scipy.cluster.hierarchy.fcluster(Z, 2, criterion='maxclust')\n```",
        "[Missing Code]\n```python\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ncentered_scaled_data = scaler.fit_transform(data)\n```",
        "[Missing Code]\n```python\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\ncentered_scaled_data = scaler.fit_transform(data)\n```",
        "[Missing Code]\n```python\nfrom sklearn.preprocessing import PowerTransformer\npt = PowerTransformer(method='box-cox')\nbox_cox_data = pt.fit_transform(data)\n```",
        "[Missing Code]\n```python\nfrom sklearn.preprocessing import PowerTransformer\npt = PowerTransformer(method='box-cox')\nbox_cox_data = pt.fit_transform(data)\n```",
        "[Missing Code]\n```python\nfrom sklearn.preprocessing import PowerTransformer\npt = PowerTransformer(method='yeo-johnson')\nyeo_johnson_data = pt.fit_transform(data)\n```",
        "[Missing Code]\n```python\nfrom sklearn.preprocessing import PowerTransformer\npt = PowerTransformer(method='yeo-johnson')\nyeo_johnson_data = pt.fit_transform(data)\n```",
        "[Missing Code]\n```python\nvectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'\")\ntransformed_text = vectorizer.fit_transform([text])\n```",
        "[Missing Code]\n```python\nfrom sklearn.model_selection import train_test_split\n\n# Split the dataset into features and target variable\nX = dataset.iloc[:, :-1]\ny = dataset.iloc[:, -1]\n\n# Split the dataset into training and testing sets\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n```",
        "[Missing Code]\n```python\nfrom sklearn.model_selection import train_test_split\n\n# Split the data into features and target\nX = data.iloc[:, :-1]\ny = data.iloc[:, -1]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n```",
        "[Missing Code]\n```python\nfrom sklearn.model_selection import train_test_split\n\n# Split the dataset into training and testing sets\ntrain_set, test_set = train_test_split(dataset, test_size=0.4, random_state=42)\n\n# Split the training set into x (all columns except the last one) and y (the last column)\nx_train = train_set.iloc[:, :-1]\ny_train = train_set.iloc[:, -1]\n\n# Split the testing set into x (all columns except the last one) and y (the last column)\nx_test = test_set.iloc[:, :-1]\ny_test = test_set.iloc[:, -1]\n```",
        "[Missing Code]\n```python\nfrom sklearn.model_selection import train_test_split\n\n# Split the data into training and testing sets\ntrain, test = train_test_split(data, test_size=0.2, random_state=42)\n\n# Split the training set into x (features) and y (target)\nx_train = train.iloc[:, :-1]\ny_train = train.iloc[:, -1]\n\n# Split the testing set into x (features) and y (target)\nx_test = test.iloc[:, :-1]\ny_test = test.iloc[:, -1]\n```",
        "[Missing Code]\n```python\nf1 = df['mse'].values\nf1 = f1.reshape(-1,1)\nkmeans = KMeans(n_clusters=2).fit(f1)\nlabels = kmeans.predict(f1)\n```",
        "[Missing Code]\n```python\nimport numpy as np\nimport pandas as pd\n\ndf = pd.read_csv(\"file.csv\", parse_dates=[\"date\"])\nf1 = df['mse'].values\nf2 = list(range(0, len(f1)))\nX = np.array(list(zip(f1, f2)))\nkmeans = KMeans(n_clusters=2).fit(X)\nlabels = kmeans.predict(X)\ncentroids = kmeans.cluster_centers_\n```",
        "[Missing Code]\n```python\nlsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\nmodel = sklearn.feature_selection.SelectFromModel(lsvc, prefit=True)\nX_new = model.transform(X)\nselected_feature_names = np.asarray(vectorizer.get_feature_names())[model.get_support()]\n```\n[End of Missing Code]",
        "[Missing Code]\n```python\n# Create a LinearSVC model with l1 penalty\nmodel = LinearSVC(penalty='l1', dual=False)\nmodel.fit(X, y)\n\n# Get the coefficients of the model\ncoef = model.coef_\n\n# Get the indices of the features selected by the model\nselected_indices = np.where(coef != 0)[1]\n\n# Get the names of the selected features\nselected_feature_names = np.asarray(vectorizer.get_feature_names())[selected_indices]\n```",
        "[Missing Code]\n```python\n    lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n    model = sklearn.feature_selection.SelectFromModel(lsvc, prefit=True)\n    X_new = model.transform(X)\n    selected_features = model.get_support(indices=True)\n    selected_feature_names = np.asarray(vectorizer.get_feature_names())[selected_features]\n```",
        "[Missing Code]\n```python\nvocabulary={'Jscript','.Net','TypeScript','SQL', 'NodeJS','Angular','Mongo','CSS','Python','PHP','Photoshop','Oracle','Linux','C++',\"Java\",'TeamCity','Frontend','Backend','Full stack', 'UI Design', 'Web','Integration','Database design','UX'}\nvectorizer = CountVectorizer(stop_words=\"english\",binary=True,lowercase=False,vocabulary=vocabulary)\nX = vectorizer.fit_transform(corpus)\nfeature_names = vectorizer.get_feature_names_out()\nX = X.toarray()\n```",
        "[Missing Code]\n```python\nvocabulary={'Jscript','.Net','TypeScript','NodeJS','Angular','Mongo','CSS','Python','PHP','Photoshop','Oracle','Linux','C++',\"Java\",'TeamCity','Frontend','Backend','Full stack', 'UI Design', 'Web','Integration','Database design','UX'}\nvectorizer = CountVectorizer(stop_words=\"english\",binary=True,lowercase=False,vocabulary=vocabulary)\nX = vectorizer.fit_transform(corpus)\nfeature_names = vectorizer.get_feature_names_out()\nX = X.toarray()\n```",
        "[Missing Code]\nvectorizer = CountVectorizer(stop_words=\"english\",binary=True,lowercase=False,vocabulary={'Jscript','.Net','TypeScript','SQL', 'NodeJS','Angular','Mongo','CSS','Python','PHP','Photoshop','Oracle','Linux','C++',\"Java\",'TeamCity','Frontend','Backend','Full stack', 'UI Design', 'Web','Integration','Database design','UX'})\nX = vectorizer.fit_transform(corpus)\nfeature_names = vectorizer.get_feature_names_out()\nX = X.toarray()\nX = np.where(X==0, 1, X)\n[End of Missing Code]",
        "[Missing Code]\nvectorizer = CountVectorizer(stop_words=\"english\",binary=True,lowercase=False,vocabulary={'Jscript','.Net','TypeScript','NodeJS','Angular','Mongo','CSS','Python','PHP','Photoshop','Oracle','Linux','C++',\"Java\",'TeamCity','Frontend','Backend','Full stack', 'UI Design', 'Web','Integration','Database design','UX'})\nX = vectorizer.fit_transform(corpus)\nfeature_names = vectorizer.get_feature_names_out()\nX = X.toarray()\nX = np.where(X>0,1,X)\n[End of Missing Code]",
        "[Missing Code]\n```python\nslopes = []\nfor col in df1.columns[1:]:\n    df2 = df1[~np.isnan(df1[col])]\n    df3 = df2[['Time',col]]\n    npMatrix = np.matrix(df3)\n    X, Y = npMatrix[:,0], npMatrix[:,1]\n    slope = LinearRegression().fit(X,Y)\n    m = slope.coef_[0]\n    slopes.append(m[0,0])\n```",
        "[Begin of Missing Code]\nslopes = []\nfor col in df1.columns[1:]:\n    df2 = df1[~np.isnan(df1[col])]\n    df3 = df2[['Time',col]]\n    npMatrix = np.matrix(df3)\n    X, Y = npMatrix[:,0], npMatrix[:,1]\n    slope = LinearRegression().fit(X,Y)\n    m = slope.coef_[0]\n    slopes.append(m[0,0])\n[End of Missing Code]",
        "[Begin of Missing Code]\nle = LabelEncoder()\ndf['Sex'] = le.fit_transform(df['Sex'])\ntransformed_df = df\n[End of Missing Code]",
        "[Missing Code]\n```python\nle = LabelEncoder()\ndf['Sex'] = le.fit_transform(df['Sex'])\ntransformed_df = df\n```",
        "[Missing Code]\n```python\nle = LabelEncoder()\ndf['Sex'] = le.fit_transform(df['Sex'])\ntransformed_df = df\n```",
        "[Begin of Missing Code]\nElasticNet = linear_model.ElasticNet() # create a lasso instance\nElasticNet.fit(X_train, y_train) # fit data\n\ntraining_set_score = ElasticNet.score(X_train, y_train)\ntest_set_score = ElasticNet.score(X_test, y_test)\n# [End of Missing Code]",
        "[Missing Code]\n```python\nscaler = MinMaxScaler()\nreshaped = np_array.reshape(-1, 1)\ntransformed = scaler.fit_transform(reshaped)\ntransformed = transformed.reshape(np_array.shape)\n```",
        "[Missing Code]\n```python\nscaler = MinMaxScaler()\nreshaped = np_array.reshape(-1,1)\ntransformed = scaler.fit_transform(reshaped)\ntransformed = transformed.reshape(np_array.shape)\n```",
        "[Missing Code]\n```python\nscaler = MinMaxScaler()\nreshaped = a.reshape(-1,1)\nscaled = scaler.fit_transform(reshaped)\nnew_a = scaled.reshape(a.shape)\n```",
        "[Begin of Missing Code]\nclose_buy1 = close.values[:-1]\nm5 = ma50.values[:-1]\nm10 = ma100.values[:-1]\nma20 = ma200.values[:-1]\nb = np.concatenate([close_buy1, m5, m10, ma20], axis=1)\n\npredict = clf.predict(b)\n[End of Missing Code]",
        "```python\n# [Begin of Missing Code]\ndf = pd.DataFrame(X, columns=['feature1', 'feature2'])\ndf['feature1'] = df['feature1'].astype('category').cat.codes\nnew_X = df.values\n# [End of Missing Code]\n```",
        "[Begin of Missing Code]\n# Convert the list to a DataFrame\ndf = pd.DataFrame(X, columns=['feature1', 'feature2'])\n\n# Use LabelEncoder to convert string values to numeric\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\n# Apply LabelEncoder to the DataFrame\nnew_X = df.apply(le.fit_transform)\n[End of Missing Code]",
        "[Begin of Missing Code]\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nnew_X = np.array(X)\nnew_X[:, 0] = le.fit_transform(new_X[:, 0])\nnew_X = new_X.astype(float)\n[End of Missing Code]",
        "[Begin of Missing Code]\n# Seperating the data into dependent and independent variables\nX = dataframe.iloc[:, :-1].values.astype(float)\ny = dataframe.iloc[:, -1].values\n\nlogReg = LogisticRegression()\nlogReg.fit(X, y)\n[End of Missing Code]",
        "[Begin of Missing Code]\nX = dataframe.iloc[:, :-1].astype(float)\ny = dataframe.iloc[:, -1]\nlogReg = LogisticRegression()\nlogReg.fit(X, y)\n[End of Missing Code]",
        "[Begin of Missing Code]\ntrain_size = int(len(features_dataframe) * 0.2)\ntrain_dataframe = features_dataframe[:train_size]\ntest_dataframe = features_dataframe[train_size:]\n[End of Missing Code]",
        "[Begin of Missing Code]\ntrain_size = int(0.8 * len(features_dataframe))\ntrain_dataframe = features_dataframe.sort_values(by=['date']).iloc[train_size:]\ntest_dataframe = features_dataframe.sort_values(by=['date']).iloc[:train_size]\n[End of Missing Code]",
        "[Missing Code]\n```python\ntrain_size = int(len(features_dataframe) * 0.2)\ntrain_dataframe = features_dataframe[:train_size]\ntest_dataframe = features_dataframe[train_size:]\n```",
        "[Begin of Missing Code]\nfor col in ['X2', 'X3']:\n    df[col + '_scale'] = df.groupby('Month')[col].transform(lambda x: scaler.fit_transform(x.values.reshape(-1,1)))\n[End of Missing Code]",
        "[Begin of Missing Code]\nfor col in ['A2', 'A3']:\n    myData['new_' + col] = myData.groupby('Month')[col].transform(lambda x: scaler.fit_transform(x.values.reshape(-1,1)).flatten())\n[End of Missing Code]",
        "[Solution Code]\n```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nwords = load_data()\n# [Begin of Missing Code]\ncount = CountVectorizer(lowercase = False, token_pattern = r\"(?u)\\b\\w\\w+\\b|@[\\w]+|#[\\w]+\")\nvocabulary = count.fit_transform([words])\nfeature_names = count.get_feature_names()\n# [End of Missing Code]\nprint(feature_names)\n```",
        "[Missing Code]\n```python\ncount = CountVectorizer(lowercase = False, token_pattern = '[^\\s]+')\nvocabulary = count.fit_transform([words])\nfeature_names = count.get_feature_names_out()\n```",
        "[Missing Code]\n```python\n# Convert to Dataframe\nfull_results = pd.DataFrame(GridSearch_fitted.cv_results_)\n```",
        "[Missing Code]\n```python\n# Convert to Dataframe\nfull_results = pd.DataFrame(GridSearch_fitted.cv_results_)\n\n# Sort by mean_fit_time\nfull_results = full_results.sort_values(by='mean_fit_time')\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.externals import joblib\n\nfitted_model = load_data()\n# Save the model in the file named \"sklearn_model\"\n# [Begin of Missing Code]\njoblib.dump(fitted_model, 'sklearn_model.pkl')\n# [End of Missing Code]\n```",
        "[Missing Code]\ntfidf_matrix = tfidf.fit_transform(df['description'])\ncosine_similarity_matrix = (1 - sklearn.metrics.pairwise.cosine_similarity(tfidf_matrix))\n[End of Missing Code]"
    ],
    "Pytorch": [
        "[Solution Code]\n```python\nimport numpy as np\nimport pandas as pd\nimport torch\noptim = load_data()\n# [Begin of Missing Code]\nfor g in optim.param_groups:\n    g['lr'] = 0.001\n# [End of Missing Code]\n```",
        "[Missing Code]\n```python\nfor g in optim.param_groups:\n    g['lr'] = 0.001\n```",
        "[Missing Code]\n```python\nfor g in optim.param_groups:\n    g['lr'] = 0.0005\n```",
        "[Missing Code]\n```python\n# To change the learning rate of the optimizer, you can use the following code:\nfor g in optim.param_groups:\n    g['lr'] = 0.0005\n\n# As for choosing the learning rate, it depends on the situation. \n# If the loss on the training set is increasing, it means that the learning rate might be too high. \n# In this case, you should try a smaller learning rate like 0.0005. \n# On the other hand, if the training process is very slow, you might want to try a larger learning rate like 0.05.\n```",
        "[Missing Code]\n```python\nweights = torch.FloatTensor(word2vec.wv.vectors)\nembedding = torch.nn.Embedding.from_pretrained(weights)\nembedded_input = embedding(input_Tensor)\n```",
        "[Missing Code]\n```python\nweights = torch.FloatTensor(word2vec.wv.vectors)\nembedding = torch.nn.Embedding.from_pretrained(weights)\nembedded_input = embedding(input_Tensor)\n```",
        "[Missing Code]\n```python\nx = torch.rand(4,4)\npx = pd.DataFrame(x.numpy())\n```",
        "[Missing Code]\n```python\nx = torch.rand(4,4)\npx = pd.DataFrame(x.numpy())\n```",
        "[Begin of Missing Code]\nx = x.numpy()\npx = pd.DataFrame(x)\n[End of Missing Code]",
        "[Missing Code]\nA_log = torch.ByteTensor([1, 0, 1]) # the logical index\nB = torch.LongTensor([[1, 2, 3], [4, 5, 6]])\nC = B[:, A_log.nonzero().squeeze()]",
        "[Missing Code]\n```python\nA_logical = A_logical.nonzero().squeeze()\nC = B[:, A_logical]\n```",
        "[Missing Code]\n```python\nC = B[:, A_log.nonzero().squeeze()]\n```",
        "[Missing Code]\n```python\nA_log = A_log.bool()\nC = B[:, A_log]\n```",
        "[Missing Code]\n```python\nA_log = A_log.nonzero().squeeze()\nC = B[:, A_log]\n```",
        "[Missing Code]\n```python\nA_log = torch.ByteTensor([0, 0, 1]) # the logical index\nB = torch.LongTensor([[999, 777, 114514], [9999, 7777, 1919810]])\n\n# Convert ByteTensor to LongTensor for indexing\nA_log = A_log.nonzero().squeeze()\n\n# Use the LongTensor for indexing\nC = B[:, A_log]\n```",
        "[Missing Code]\n```python\nC = torch.index_select(B, 1, idx)\n```",
        "[Missing Code]\n```python\nx_tensor = torch.Tensor(np.vstack(x_array).astype(np.float32))\n```",
        "[Missing Code]\n```python\nx_tensor = torch.from_numpy(np.vstack(x_array).astype(np.float))\n```",
        "[Missing Code]\n```python\nt = torch.tensor([np.array(a[i], dtype=np.float32) for i in range(len(a))])\n```",
        "[Missing Code]\n```python\nmax_len = max(lens)\nmask = torch.zeros(len(lens), max_len).long()\nfor idx, length in enumerate(lens):\n    mask[idx, :length] = 1\n```",
        "[Missing Code]\n```python\nmax_len = max(lens)\nmask = torch.arange(max_len).expand(len(lens), max_len) < torch.LongTensor(lens).unsqueeze(1)\n```",
        "[Missing Code]\n```python\nmax_len = max(lens)\nmask = torch.zeros(len(lens), max_len).long()\nfor idx, length in enumerate(lens):\n    mask[idx, :length] = 1\n```",
        "[Missing Code]\n```python\nmax_len = max(lens)\nmask = torch.zeros(len(lens), max_len).long()\nfor idx, length in enumerate(lens):\n    mask[idx, :length] = 1\n```",
        "[Missing Code]\n```python\nTensor_3D = torch.stack([torch.diag(Tensor_2D[i]) for i in range(Tensor_2D.shape[0])])\n```",
        "[Missing Code]\n```python\nresult = []\nfor i in range(t.shape[0]):\n    result.append(torch.diag(t[i]))\nresult = torch.stack(result)\n```",
        "[Missing Code]\n```python\nb = b.unsqueeze(0)\nab = torch.cat((a, b), 0)\n```",
        "[Missing Code]\n```python\nab = torch.cat((a, b), 0)\n```",
        "[Missing Code]\n```python\nb = b.unsqueeze(0)\nab = torch.cat((a, b), 0)\n```",
        "[Missing Code]\n```python\nfor i, length in enumerate(lengths):\n    a[i, length:, :] = 0\n```",
        "[Missing Code]\n```python\nfor i, length in enumerate(lengths):\n    a[i, length:, :] = 2333\n```",
        "[Missing Code]\n```python\nfor i, length in enumerate(lengths):\n    a[i, :length, :] = 0\n```",
        "[Missing Code]\nfor i, length in enumerate(lengths):\n    a[i, :length, :] = 2333",
        "[Missing Code]\n```python\nlist_of_tensors = [ torch.randn(3), torch.randn(3), torch.randn(3)]\ntensor_of_tensors = torch.stack(list_of_tensors)\n```",
        "[Missing Code]\nnew_tensors = torch.stack(list)\n[End of Missing Code]",
        "[Missing Code]\n```python\ntt = torch.stack(lt)\n```",
        "[Missing Code]\n```python\ntensor_of_tensors = torch.stack(list_of_tensors)\n```",
        "[Missing Code]\n```python\nresult = t[torch.arange(len(t)), torch.from_numpy(idx)]\n```",
        "[Missing Code]\n```python\nresult = t[torch.arange(t.size(0)), torch.from_numpy(idx)]\n```",
        "[Missing Code]\n```python\nidx = torch.from_numpy(idx)\nresult = torch.gather(t, 1, idx.view(-1,1)).squeeze()\n```",
        "[Missing Code]\n```python\nresult = x.gather(1, ids.unsqueeze(-1).expand(-1, -1, x.size(-1))).squeeze(1)\n```",
        "[Begin of Missing Code]\nresult = x.gather(1, ids.unsqueeze(-1).expand(-1, -1, x.size(2))).squeeze(1)\n[End of Missing Code]",
        "```python\nimport numpy as np\nimport pandas as pd\nimport torch\nids, x = load_data()\n# [Begin of Missing Code]\nids = torch.tensor(ids)\nx = torch.tensor(x)\nresult = torch.zeros(ids.shape[0], x.shape[2])\nfor i in range(ids.shape[0]):\n    for j in range(ids.shape[1]):\n        if ids[i][j] == 1:\n            result[i] = x[i][j]\n# [End of Missing Code]\nprint(result)\n```",
        "[Missing Code]\n```python\n_, y = torch.max(softmax_output, dim=1)\ny = y.view(-1, 1)\n```",
        "[Missing Code]\n```python\n_, y = torch.max(softmax_output, dim=1)\ny = y.view(-1, 1)\n```",
        "[Missing Code]\n```python\n_, y = torch.min(softmax_output, dim=1)\ny = y.view(-1, 1)\n```",
        "[Missing Code]\n```python\n_, y = torch.max(softmax_output, dim=1)\ny = y.view(-1, 1)\n```",
        "[Solution Code]\n```python\nimport numpy as np\nimport pandas as pd\nimport torch\nsoftmax_output = load_data()\ndef solve(softmax_output):\n    # [Begin of Missing Code]\n    _, y = torch.min(softmax_output, dim=1)\n    # [End of Missing Code]\n    return y\ny = solve(softmax_output)\nprint(y)\n```",
        "[Begin of Missing Code]\ndef cross_entropy2d(input, target, weight=None, size_average=True):\n    # input: (n, c, h, w), target: (n, h, w)\n    n, c, h, w = input.size()\n    # log_p: (n, c, h, w)\n    log_p = F.log_softmax(input, dim=1)\n    # log_p: (n*h*w, c)\n    log_p = log_p.transpose(1, 2).transpose(2, 3).contiguous().view(-1, c)\n    log_p = log_p[target.view(n, h, w, 1).repeat(1, 1, 1, c).view(-1, c) >= 0]\n    log_p = log_p.view(-1, c)\n    # target: (n*h*w,)\n    mask = target >= 0\n    target = target[mask]\n    loss = F.nll_loss(log_p, target.view(-1), weight=weight, size_average=False)\n    if size_average:\n        loss /= mask.data.sum()\n    return loss\n\nimages = Variable(torch.randn(5, 7, 4, 4))\nlabels = Variable(torch.LongTensor(5, 4, 4).random_(7))\nloss = cross_entropy2d(images, labels)\n# [End of Missing Code]",
        "[Missing Code]\n```python\ncnt_equal = torch.sum(A == B).item()\n```",
        "[Missing Code]\n```python\ncnt_equal = torch.sum(A == B).item()\n```",
        "[Missing Code]\n```python\ncnt_not_equal = torch.sum(A != B).item()\n```",
        "[Missing Code]\n```python\ncnt_equal = torch.sum(A == B).item()\n```",
        "[Missing Code]\n```python\nx = A.shape[0] // 2\ncnt_equal = torch.sum(A[-x:] == B[-x:]).item()\n```",
        "[Missing Code]\n```python\nx = A.shape[0] // 2\ncnt_not_equal = torch.sum(A[-x:] != B[-x:]).item()\n```",
        "[Missing Code]\n```python\ntensors_31 = [a[..., i:i+chunk_dim, :] for i in range(a.shape[3] - chunk_dim + 1)]\n```",
        "```python\nimport numpy as np\nimport pandas as pd\nimport torch\na = load_data()\nassert a.shape == (1, 3, 40, 10, 1)\nchunk_dim = 10\n# [Begin of Missing Code]\ntensors_31 = [a[:,:,i:i+chunk_dim,:,:] for i in range(a.shape[2]-chunk_dim+1)]\n# [End of Missing Code]\nfor tensor in tensors_31:\n    print(tensor)\n```",
        "[Solution Code]\n```python\nimport numpy as np\nimport pandas as pd\nimport torch\nmask, clean_input_spectrogram, output= load_data()\n# [Begin of Missing Code]\nmask = mask.unsqueeze(2).expand_as(clean_input_spectrogram)\noutput = torch.where(mask == 1, clean_input_spectrogram, output)\n# [End of Missing Code]\nprint(output)\n```",
        "[Solution Code]\n```python\nimport numpy as np\nimport pandas as pd\nimport torch\nmask, clean_input_spectrogram, output= load_data()\n# [Begin of Missing Code]\noutput[mask == 0] = clean_input_spectrogram[mask == 0]\n# [End of Missing Code]\nprint(output)\n```",
        "[Solution Code]\n```python\nimport numpy as np\nimport pandas as pd\nimport torch\nx, y = load_data()\n# [Begin of Missing Code]\nsign_x = torch.sign(x)\nsign_y = torch.sign(y)\nmin_abs = torch.min(torch.abs(x), torch.abs(y))\nsigned_min = torch.where(torch.abs(x) == min_abs, sign_x * min_abs, sign_y * min_abs)\n# [End of Missing Code]\nprint(signed_min)\n```",
        "[Missing Code]\n```python\n# Compute the signs of x and y\nsign_x = torch.sign(x)\nsign_y = torch.sign(y)\n\n# Compute the absolute values of x and y\nabs_x = torch.abs(x)\nabs_y = torch.abs(y)\n\n# Compute the maximum absolute values\nmax_abs = torch.max(abs_x, abs_y)\n\n# Compute the signs of the maximum absolute values\nsign_max_abs = torch.where(abs_x >= abs_y, sign_x, sign_y)\n\n# Multiply the signs with the maximum absolute values\nsigned_max = sign_max_abs * max_abs\n```",
        "[Missing Code]\n```python\nsign_x = torch.sign(x)\nsign_y = torch.sign(y)\nmin_abs = torch.min(torch.abs(x), torch.abs(y))\nsign_min = torch.where(torch.abs(x) == min_abs, sign_x, sign_y)\nsigned_min = sign_min * min_abs\n```",
        "[Missing Code]\n```python\ndef predict_allCharacters(input):\n    output = MyNet(input)\n    softmax = torch.nn.Softmax(dim=1)\n    output = softmax(output)\n    conf, classes = torch.max(output.reshape(1, 3), 1)\n    class_names = '012'\n    return conf, class_names[classes.item()]\n\nconfidence_score = predict_allCharacters(input)\n```\n[End of Missing Code]",
        "[Missing Code]\n```python\n# Create a new tensor by concatenating 'a' and 'b' along the second axis (columns)\nc = torch.cat((a, b), dim=1)\n\n# Calculate the average of the overlapping columns\navg_col = (a[:, -1] + b[:, 0]) / 2\n\n# Replace the overlapping columns in 'c' with the average column\nc[:, 2] = avg_col\n\nresult = c\n```",
        "[Missing Code]\n```python\n    overlap = (a[:,-1] + b[:,0]) / 2\n    result = torch.cat((a[:,:-1], overlap.unsqueeze(1), b[:,1:]), dim=1)\n```",
        "[Missing Code]\n```python\n# Create a tensor of zeros with the same shape as t\nzeros = torch.zeros_like(t)\n\n# Concatenate the zeros tensor and t tensor along the second dimension\nresult = torch.cat((zeros, t, zeros), dim=1)\n\n# Add zeros at the beginning and end of the tensor\nresult = torch.cat((torch.zeros(1, result.shape[1], result.shape[2]), result, torch.zeros(1, result.shape[1], result.shape[2])), dim=0)\n```",
        "[Begin of Missing Code]\n# Create a tensor of zeros with the same size as t\nzeros = torch.zeros_like(t)\n\n# Create a tensor of zeros with the same size as t but with an additional row and column\npadded_zeros = torch.zeros(t.size(0), t.size(1)+2, t.size(2)+2)\n\n# Copy the original tensor t into the center of the padded_zeros tensor\npadded_zeros[:, 1:-1, 1:-1] = t\n\n# Concatenate the zeros tensor and the padded_zeros tensor along the first dimension\nresult = torch.cat((zeros, padded_zeros, zeros), dim=1)\n[End of Missing Code]",
        "[Missing Code]\n```python\nnew = torch.full((1, 4, 4), -1)\nnew[:, 1:-1, 1:-1] = t\nresult = new\n```",
        "[Begin of Missing Code]\nW = W.view(hid_dim, 1)\nresult = torch.bmm(data, W).squeeze()\nresult = result.view(10, 2, 3)\n# [End of Missing Code]"
    ]
}