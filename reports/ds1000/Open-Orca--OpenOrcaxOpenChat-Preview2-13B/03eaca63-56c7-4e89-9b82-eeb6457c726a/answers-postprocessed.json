{
    "Pandas": [
        "result = df.iloc[List]\nprint(result)",
        "\n",
        "result = df.loc[df['Qu1'].isin(['apple', 'potato', 'banana', 'cheese'])]\nresult['Qu1'] = ['other'] * (result['Qu1'].isin(['apple', 'potato', 'banana', 'cheese']).sum() - 4)\nresult = result.append(pd.DataFrame({'Qu1': ['other', 'potato', 'cheese', 'banana', 'cheese', 'banana', 'cheese', 'potato', 'other']}, index=[0]))\nprint(result)",
        "result = df.loc[df['Qu1'] == 'cheese', 'Qu1'] = 'cheese'\nresult = df.loc[df['Qu2'] == 'banana', 'Qu2'] = 'other'\nresult = df.loc[df['Qu2'] == 'apple', 'Qu2'] = 'other'\nresult = df.loc[df['Qu2'] == 'sausage', 'Qu2'] = 'other'\nresult = df.loc[df['Qu3'] == 'apple', 'Qu3'] = 'other'\nresult = df.loc[df['Qu3'] == 'potato', 'Qu3'] = 'other'\nresult = df.loc[df['Qu3'] == 'sausage', 'Qu3'] = 'other'\nresult = df.loc[df['Qu3'] == 'egg', 'Qu3'] = 'other'\nresult = df.loc[df['Qu1'] == 'other', 'Qu1'] = 'other'\nresult = df.loc[df['Qu2'] == 'other', 'Qu2'] = 'other'\nresult = df.loc[df['Qu3'] == 'other', 'Qu3'] = 'other'\nresult = df\nprint(result)",
        "\n    # [Missing Code]\n    ",
        "result = df.loc[df['Qu1'].apply(lambda x: x in ['cheese', 'potato', 'banana', 'egg']) == True, 'Qu1'] = 'other'\nresult = df.loc[df['Qu2'].apply(lambda x: x in ['banana', 'apple', 'sausage']) == True, 'Qu2'] = 'sausage'\nresult = df.loc[df['Qu3'].apply(lambda x: x in ['apple', 'potato', 'sausage', 'cheese']) == True, 'Qu3'] = 'other'\nprint(result)",
        "result = df.loc[df['Qu1'].isin(['apple', 'potato', 'cheese', 'banana', 'egg']), 'Qu1'] = 'other'\nresult = df.loc[df['Qu2'].isin(['banana', 'sausage']), 'Qu2'] = 'other'\nresult = df.loc[df['Qu3'].isin(['apple', 'potato', 'sausage', 'cheese', 'egg']), 'Qu3'] = 'other'\nprint(result)",
        "\nimport pandas as pd\ndf = pd.DataFrame({'url': ['A.com', 'A.com', 'A.com', 'B.com', 'B.com', 'C.com', 'B.com'],\n                   'keep_if_dup': ['Yes', 'Yes', 'No', 'No', 'No', 'No', 'Yes']})\ndf = df.drop_duplicates(subset='url', keep='first')\ndf = df[df['keep_if_dup'] == 'Yes']\nprint(df)\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'url': ['A.com', 'A.com', 'A.com', 'B.com', 'B.com', 'C.com', 'B.com'],\n                   'drop_if_dup': ['Yes', 'Yes', 'No', 'No', 'No', 'No', 'Yes']})\ndf = df.drop_duplicates(subset='url', keep='first')\ndf = df[df['drop_if_dup'] == 'No']\nprint(df)\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'url': ['A.com', 'A.com', 'A.com', 'B.com', 'B.com', 'C.com', 'B.com'],\n                   'keep_if_dup': ['Yes', 'Yes', 'No', 'No', 'No', 'No', 'Yes']})\ndf = df.drop_duplicates(subset='url', keep='first')\ndf = df[df['keep_if_dup'] == 'Yes']\nprint(df)\n",
        "result = {}\nfor name, row in df.iterrows():\n    result[name] = {}\n    for col, value in zip(row['v1'], row['v2']):\n        result[name][col] = {value: row['v3']}\nprint(result)",
        "df['datetime'] = df['datetime'].dt.tz_localize('UTC').dt.tz_convert('UTC').dt.tz_localize('UTC').dt.strftime('%Y-%m-%d %H:%M:%S')\nresult = df\nprint(result)",
        "\n    # [Missing Code]\n    ",
        "df['datetime'] = df['datetime'].dt.tz_localize('UTC').dt.tz_convert('UTC').dt.tz_localize('UTC').dt.strftime('%Y-%m-%d %H:%M:%S')\nresult = df\nprint(result)",
        "df['datetime'] = df['datetime'].dt.tz_localize('UTC').dt.tz_convert('UTC').dt.tz_localize('UTC').dt.strftime('%Y-%m-%d %H:%M:%S')\nresult = df\nprint(result)",
        "result = df.explode('message')\nresult = result.set_index(['name', 'status', 'number', 'job', 'money', 'wife', 'group', 'kids'])\nresult = result.unstack(fill_value='none')\nresult = result.reset_index()\nresult = result.rename(columns={0: 'name', 1: 'status', 2: 'number', 3: 'job', 4: 'money', 5: 'wife', 6: 'group', 7: 'kids'})\nprint(result)",
        "result['score'] = result['score'] * 10\nprint(result)",
        "result['score'] = result['score'] * (10 if result['product'] not in products else 1)\nprint(result)",
        "result = df.loc[result['product'].isin(products), 'score'] * 10\nresult = result.sort_values(by=['product'])\nprint(result)",
        "result['score'] = result['score'].where(result['product'].isin(products), result['score'].min(), result['score'].max())\nprint(result)",
        "\n# [Missing Code]\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'A': [0, 1, 1, 1, 0, 1],\n                   'B': [1, 0, 1, 1, 1, 0],\n                   'C': [1, 1, 0, 1, 1, 1],\n                   'D': [1, 1, 1, 0, 1, 1]})\nresult = df\nresult['category'] = pd.get_dummies(df, prefix='category')\nprint(result)\n",
        "\n# [Missing Code]\n",
        "df['Date'] = df['Date'].dt.to_period(\"M\")\nresult = df\nprint(result)",
        "df['Date'] = df['Date'].dt.to_period(\"M\")\nresult = df\nprint(result)",
        "\n# [Missing Code]\n",
        "result = df.shift(1, axis=0)\nprint(result)",
        "result = df.shift(1, axis=0)\nprint(result)",
        "result = df.shift(1, axis=0)\nprint(result)",
        "df = df.shift()\nresult = df\nprint(result)",
        "df = df.rename(columns={'HeaderA': 'HeaderAX'}, inplace=True)\nresult = df\nprint(result)",
        "result = df.rename(columns={'HeaderA': 'XHeaderA', 'HeaderB': 'XHeaderB', 'HeaderC': 'XHeaderC'})\nprint(result)",
        "df = df.rename(columns={'HeaderA': 'HeaderAX', 'HeaderB': 'HeaderBX', 'HeaderC': 'HeaderCX', 'HeaderX': 'HeaderX'}, inplace=True)\nresult = df\nprint(result)",
        "result = df.groupby('group').agg({\"val3\": \"mean\"})\nprint(result)",
        "result = df.groupby('group').agg({\"val3\": \"sum\"})\nprint(result)",
        "\n# [Missing Code]\n",
        "\n",
        "result = df.sum(axis=0, columns=column_list)[row_list]\nprint(result)",
        "\n",
        "result = df.value_counts()\nresult = result.astype('float64')\nresult.index = result.index.astype('int64')\nresult = result.sort_values(ascending=False)\nprint(result)",
        "result = df.isnull().sum()\nresult.index = df.columns\nresult = result.astype('float64')\nresult.name = 'null'\nprint(result)",
        "\n# [Missing Code]\n",
        "df = df.loc[:, ['Nanonose', 'Unnamed: 1', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']]\nresult = df.reset_index()\nprint(result)",
        "df = df.drop('Unnamed: 1', axis=1)\ndf = df.rename(columns={'A': 'Unnamed: 1', 'B': 'Concentration', 'C': 'A', 'D': 'B', 'E': 'C', 'F': 'D', 'G': 'E', 'H': 'F'})\ndf = df.set_axis(df.columns.astype('str'), axis=1, inplace=True)\ndf = df.reset_index(drop=True)\nprint(df)\n[Result]",
        "\nresult = df.apply(lambda x : (x[x.notnull()].values.tolist()+x[x.isnull()].values.tolist()),1)\n",
        "\nresult = df.apply(lambda x : (x[x.isnull()].values.tolist()+x[x.notnull()].values.tolist()),1)\n",
        "\nresult = df.apply(lambda x : (x[x.isnull()].values.tolist()+x[x.notnull()].values.tolist()),0)\n",
        "result = df.loc[df['value'] < thresh, 'value'].sum()\nresult = df.set_index('lab').assign(value=result)\nprint(result)",
        "\n# [Missing Code]\n",
        "\n",
        "\n",
        "\n# [Missing Code]\n",
        "\n",
        "import numpy as np\ndef sigmoid(x):\n    return 1 / (1 + np.e**(-x))\ndf[\"sigmoid_A\"] = df[\"A\"].apply(lambda x: sigmoid(x))\ndf[\"sigmoid_B\"] = df[\"B\"].apply(lambda x: sigmoid(x))\nresult = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6], \"sigmoid_A\": [1/(1+e^(-1)), 1/(1+e^(-2)), 1/(1+e^(-3))], \"sigmoid_B\": [1/(1+e^(-4)), 1/(1+e^(-5)), 1/(1+e^(-6))]})\nprint(result)",
        "result = df.loc[df.idxmin():df.idxmin()+1, df.idxmin()]\nprint(result)",
        "result = df.loc[df.idxmin(axis=1) + 1:df.idxmin(axis=1) + 1, 'index']\nprint(result)",
        "\nmin_dt = df['dt'].min()\nmax_dt = df['dt'].max()\nresult = pd.DataFrame({'dt': pd.date_range(min_dt, max_dt, freq='D'), 'user': ['a','a','b','b'], 'val': [0, 0, 0, 0]})\nresult = result.set_index('dt')\nresult['user'] = result['user'].astype('category')\nresult['val'] = result['val'].astype('category')\nresult = result.reindex(df.index)\nresult['dt'] = result['dt'].astype('datetime64[D]')\nresult['val'] = result['val'].astype('int64')\nresult = result.drop_duplicates()\nresult = result.sort_values(by=['dt', 'user'])\nresult = result.set_index('dt')\nresult['user'] = result['user'].astype('category')\nresult['val'] = result['val'].astype('category')\nprint(result)",
        "\ndf['dt'] = df['dt'].astype('datetime64[D]')\nmin_dt = df['dt'].min()\nmax_dt = df['dt'].max()\n",
        "\ndf['dt'] = df['dt'].astype('datetime64[D]')\nmin_dt = df['dt'].min()\nmax_dt = df['dt'].max()\nresult = df.set_index('dt')\nresult['user'] = result['user'].astype('datetime64[D]')\nresult['val'] = 233\nresult = result.reindex(pd.date_range(min_dt, max_dt, freq='D'))\nresult['val'] = 233\nresult = result.reset_index()\nprint(result)",
        "\ndf['dt'] = df['dt'].astype('datetime64[D]')\nmin_dt, max_dt = df['dt'].min(), df['dt'].max()\nresult = df.set_index('dt')\nresult['user'] = result['user'].astype('category')\nresult['val'] = result['val'].fillna(method='ffill')\nresult = result.reindex(pd.date_range(min_dt, max_dt, freq='D'))\nresult['val'] = result['val'].fillna(method='bfill')\nresult = result.reset_index()\nprint(result)",
        "\ndf['dt'] = df['dt'].astype('datetime64[D]')\nmin_dt = df['dt'].min()\nmax_dt = df['dt'].max()\nresult = df.set_index('dt').reindex(pd.date_range(min_dt, max_dt, freq='D'))\nresult['user'] = result['user'].astype('category')\nresult['val'] = result['val'].fillna(method='ffill')\nresult = result.astype('datetime64[D]')\nprint(result)",
        "\nimport pandas as pd\ndf = pd.DataFrame({'name': ['Aaron', 'Aaron', 'Aaron', 'Brave', 'Brave', 'David'],\n                   'a': [3, 3, 3, 4, 3, 5],\n                   'b': [5, 6, 6, 6, 6, 1],\n                   'c': [7, 9, 10, 0, 1, 4]})\nresult = df.assign(name=df.name.astype('int'))\nprint(result)\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'name': ['Aaron', 'Aaron', 'Aaron', 'Brave', 'Brave', 'David'],\n                   'a': [3, 3, 3, 4, 3, 5],\n                   'b': [5, 6, 6, 6, 6, 1],\n                   'c': [7, 9, 10, 0, 1, 4]})\nresult = df.assign(a=df.a.astype('int').astype('str') + str(df.name))\nprint(result)\n",
        "\n    df['unique_id'] = df['name'].astype(str).str.get_dummies()\n    df = df.set_index('unique_id')\n    df = df.reset_index()\n    df['name'] = df['unique_id'].astype(str)\n    # [Missing Code]\n    ",
        "\nimport pandas as pd\ndf = pd.DataFrame({'name': ['Aaron', 'Aaron', 'Aaron', 'Brave', 'Brave', 'David'],\n                   'a': [3, 3, 3, 4, 3, 5],\n                   'b': [5, 6, 6, 6, 6, 1],\n                   'c': [7, 9, 10, 0, 1, 4]})\nresult = df.assign(ID=df.groupby('name').cumcount().add(1).astype(int))\nprint(result)\n",
        "result = df.pivot_table(index='user', columns='date', values='value', aggfunc=lambda x: x)\nresult = result.reset_index()\nresult = result.rename(columns={'date': 'date', 'value': 'value', 'someBool': 'someBool'})\nprint(result)",
        "result = df.pivot_table(index='user', columns='01/12/15', values='value', aggfunc=lambda x: (x, x[1]))\nresult = result.rename(columns={0: 'user', 1: '01/12/15', 2: 'others', 3: 'value'})\nresult = result.reset_index()\nprint(result)",
        "result = df.pivot_table(index='user', columns='date', values='value', aggfunc=lambda x: x, dropna=False)\nresult = result.reset_index()\nresult = result.rename(columns={'date': 'date', 'value': 'value', 'someBool': 'someBool'})\nprint(result)",
        "result = df[df['c'] > 0.5][columns]",
        "result = df[df['c'] > 0.45][locs].loc[:, columns]\nprint(result)",
        "df = pd.DataFrame(np.random.rand(4,5), columns = list('abcde'))\nprint(df)\nlocs = [df.columns.get_loc(_) for _ in ['c']]\nmask = df.c > 0.5\ndf_subset = df[mask][locs]\nresult = df_subset[['b', 'e']]\nreturn result",
        "def f(df, columns=['b', 'e']):\n    locs = [df.columns.get_loc(_) for _ in ['c']]\n    df_subset = df[df.c > 0.5][locs]\n    result = df_subset[columns].sum(axis=1)\n    return result",
        "def f(df, columns=['b', 'e']):\n    locs = [df.columns.get_loc(_) for _ in columns]\n    result = df[df.c > 0.5][locs]\n    return result",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nresult = df[~df.index.isin(filter_dates)]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "result = df.groupby(df.index // 3).mean()\nprint(result)",
        "\nimport pandas as pd\ndf = pd.DataFrame({'col1':[2, 1, 3, 1, 0, 2, 1, 3, 1]})\nresult = df.groupby(df.index // 3).agg({'col1': 'sum', 'col1': 'mean'})\nprint(result)\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'col1':[2, 1, 3, 1, 0, 2, 1, 3, 1]})\nresult = df.groupby(df.index // 3 + (df.index % 3 != 0)).agg({'col1': ['sum', 'mean']})\nprint(result)\n",
        "df['A'] = df['A'].fillna(method='ffill')\nresult = df\nprint(result)",
        "df['A'] = df['A'].fillna(method='ffill')\nresult = df\nprint(result)",
        "df['A'] = df['A'].fillna(method='ffill', limit=1)\nresult = df\nprint(result)",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n    numer = df.duration.str.extract(r'(\\d+)', expand=False)\n    time = df.duration.str.extract(r'(?P<time>week|month|day|year)', expand=False)\n    ",
        "\n# [Missing Code]\n",
        "",
        "result = np.where(df1[column] == df2[column] for column in columns_check_list)\nprint(result)",
        "\nimport pandas as pd\nindex = pd.MultiIndex.from_tuples([('abc', '3/1/1994'), ('abc', '9/1/1994'), ('abc', '3/1/1995')],\n                                 names=('id', 'date'))\ndf = pd.DataFrame({'x': [100, 90, 80], 'y':[7, 8, 9]}, index=index)\ndf.index.levels[1] = pd.to_datetime(df.index.levels[1])\nresult = df\nprint(result)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\ndf = df.set_index(['date', 'id'])\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.swaplevel(axis=1, level_name=0, level_0_name=1)\nreturn df",
        "df = df.pivot(index='Country', columns='Variable', values='year')\nresult = df.reset_index()\nprint(result)",
        "result = df.melt(id_vars=['Country', 'Variable'], value_name='year', var_name='Var1')\nprint(result)",
        "result = df[df.sum(axis=1) < 1]\nprint(result)",
        "result = df[df.abs().gt(1).any(axis=1)]\nprint(result)",
        "result = df[df.abs().gt(1).any(axis=1)]\nresult = result.drop(columns=['Value_B', 'Value_C', 'Value_D'])\nprint(result)",
        "\ndf['A'] = df['A'].str.replace('&AMP;', '&')\n# [Missing Code]\n",
        "\ndf['A'] = df['A'].str.replace('&LT;', '<')\n# [Missing Code]\n",
        "\n    df['A'] = df['A'].str.replace('&AMP;', '&')\n    # [Missing Code]\n    ",
        "\ndf['A'] = df['A'].str.replace('&AMP;', '&')\ndf['A'] = df['A'].str.replace('&LT;', '<')\ndf['A'] = df['A'].str.replace('&GT;', '>')\n",
        "result['A'] = result['A'].str.replace('&AMP;', '&')\nresult['C'] = result['C'].str.replace('&AMP;', '&')\nresult = result.astype({'A': 'object', 'C': 'object'})\nresult = result.apply(lambda x: x.replace('=', ''), axis=1)\nresult = result.astype({'A': 'object', 'C': 'object'})\nresult = result.apply(lambda x: x.replace('=', ''), axis=1)\nresult = result.astype({'A': 'object', 'C': 'object'})\nresult = result.apply(lambda x: x.replace('=', ''), axis=1)\nresult = result.astype({'A': 'object', 'C': 'object'})\nresult = result.apply(lambda x: x.replace('=', ''), axis=1)\nresult = result.astype({'A': 'object', 'C': 'object'})\nresult = result.apply(lambda x: x.replace('=', ''), axis=1)\nresult = result.astype({'A': 'object', 'C': 'object'})\nresult = result.apply(lambda x: x.replace('=', ''), axis=1)\nresult = result.astype({'A': 'object', 'C': 'object'})\nresult = result.apply(lambda x: x.replace('=', ''), axis=1)\nresult = result.astype({'A': 'object', 'C': 'object'})\nresult = result.apply(lambda x: x.replace('=', ''), axis=1)\nresult = result.astype({'A': 'object', 'C': 'object'})\nresult = result.apply(lambda x: x.replace('=', ''), axis=1)\nresult = result.astype({'A': 'object', 'C': 'object'})\nresult = result.apply(lambda x: x.replace('=', ''), axis=1)\nresult = result.astype({'A': 'object', 'C': 'object'})\nresult = result.apply(lambda x: x.replace('=', ''), axis=1)\nresult = result.astype({'A': 'object', 'C': 'object'})\nresult = result.apply(lambda x: x.replace('=', ''), axis=1)\nresult = result.astype({'A': 'object', 'C': 'object'})\nresult = result.apply(lambda x: x.replace('=', ''), axis=1)\nresult = result.astype({'A': 'object', 'C': 'object'})\nresult = result.apply(lambda x: x.replace('=', ''), axis=1)\nresult = result.astype({'A': 'object', 'C': 'object'})\nresult = result.apply(lambda x: x.replace('=', ''), axis=1)\nresult = result.astype({'A': 'object', 'C': 'object'})\nresult = result.apply(lambda x: x.replace('=', ''), axis=1)\nresult = result.astype({'A': 'object', 'C': 'object'})\nresult = result.apply(lambda x: x.replace('=', ''), axis=1)\nresult = result.astype({'A': 'object', 'C': 'object'})\nresult = result.apply(lambda x: x.replace('=', ''), axis=1)\nresult = result.astype({'A': 'object', 'C': 'object'})\nresult = result.apply(lambda x: x.replace('=', ''), axis=1)\nresult = result.astype({'A': 'object', 'C': 'object'})\nresult = result.apply(lambda x: x.replace('=', ''), axis=1)\nresult = result.astype({'A': 'object', 'C': 'object'})\nresult = result.apply(lambda x: x.replace('=', ''), axis=1)\nresult = result.astype({'A': 'object', 'C': 'object'})\nresult = result.apply(lambda x: x.replace('=', ''), axis=1)\nresult = result.astype({'A': 'object', 'C': 'object'})",
        "result['first_name'] = df['name'].apply(lambda x: validate_single_space_name(x))\nresult['last_name'] = result['first_name'].str.split(' ', expand=True)[1]\nresult = result[['first_name', 'last_name']]\nprint(result)",
        "result['1_name'] = df['name'].apply(lambda x: validate_single_space_name(x))\nresult['2_name'] = df['name'].apply(lambda x: x if validate_single_space_name(x) is None else validate_single_space_name(x))\nprint(result)",
        "result = df.apply(lambda row: validate_single_space_name(row['name']), axis=1)\nresult = result.loc[result['name'].notnull(), ['first_name', 'middle_name', 'last_name']]\nresult = result.fillna('')\nresult = result.astype({'first_name': 'str', 'middle_name': 'str', 'last_name': 'str'})\nresult = result.reset_index()\nresult = result.drop('index', axis=1)\nresult = result.rename(columns={'first_name': 'name', 'middle_name': 'middle_name', 'last_name': 'last_name'})\nresult = result.drop('middle_name', axis=1)\nresult = result.dropna()\nresult = result.astype({'name': 'str'})\nresult = result.reset_index()\nresult = result.drop('index', axis=1)\nresult = result.rename(columns={'name': 'name'})\nprint(result)",
        "result = df1.merge(df2, on='Timestamp', how='left')\nprint(result)",
        "df1['Timestamp'] = pd.to_datetime(df1['Timestamp'])\ndf2['Timestamp'] = pd.to_datetime(df2['Timestamp'])\nresult = df1.merge(df2, on='Timestamp', how='left')\nprint(result)",
        "\ndef check_col1_col2_col3(col1, col2, col3):\n    if col1 <= 50 and col2 <= 50 and col3 <= 50:\n        return col1\n    else:\n        return max(col1, col2, col3)\nresult['state'] = df.apply(lambda row: check_col1_col2_col3(row['col1'], row['col2'], row['col3']), axis=1)\nprint(result)",
        "\ndf['state'] = df.apply(lambda row: row['col1'] if (row['col2'] > 50 and row['col3'] > 50) else row['col1'] + row['col2'] + row['col3'], axis=1)\nresult = df\nprint(result)",
        "result[\"Field1\"] = result[\"Field1\"].apply(lambda x: int(x) if isinstance(x, int) else x)\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult",
        "\n# [Missing Code]\n",
        "\n    non_integers = []\n    for index, row in df.iterrows():\n        if not row[\"Field1\"].is_integer():\n            non_integers.append(row[\"Field1\"])\n    ",
        "result['percentage'] = result.apply(lambda row: (row['val1'] / row['total']) * 100, axis=1)\nresult = result.set_index('cat')\nresult = result.T.round(2)\nresult = result.T.reset_index()\nresult = result.rename(columns={'val1': 'val1_percentage', 'val2': 'val2_percentage', 'val3': 'val3_percentage', 'val4': 'val4_percentage'})\nresult = result.drop('total', axis=1)\nresult = result.astype({'val1_percentage': 'float', 'val2_percentage': 'float', 'val3_percentage': 'float', 'val4_percentage': 'float'})\nresult = result.astype({'val1_percentage': 'float', 'val2_percentage': 'float', 'val3_percentage': 'float', 'val4_percentage': 'float'})\nresult = result.astype({'val1_percentage': 'float', 'val2_percentage': 'float', 'val3_percentage': 'float', 'val4_percentage': 'float'})\nresult = result.astype({'val1_percentage': 'float', 'val2_percentage': 'float', 'val3_percentage': 'float', 'val4_percentage': 'float'})\nresult = result.astype({'val1_percentage': 'float', 'val2_percentage': 'float', 'val3_percentage': 'float', 'val4_percentage': 'float'})\nresult = result.astype({'val1_percentage': 'float', 'val2_percentage': 'float', 'val3_percentage': 'float', 'val4_percentage': 'float'})\nresult = result.astype({'val1_percentage': 'float', 'val2_percentage': 'float', 'val3_percentage': 'float', 'val4_percentage': 'float'})\nresult = result.astype({'val1_percentage': 'float', 'val2_percentage': 'float', 'val3_percentage': 'float', 'val4_percentage': 'float'})\nresult = result.astype({'val1_percentage': 'float', 'val2_percentage': 'float', 'val3_percentage': 'float', 'val4_percentage': 'float'})\nresult = result.astype({'val1_percentage': 'float', 'val2_percentage': 'float', 'val3_percentage': 'float', 'val4_percentage': 'float'})\nresult = result.astype({'val1_percentage': 'float', 'val2_percentage': 'float', 'val3_percentage': 'float', 'val4_percentage': 'float'})\nresult = result.astype({'val1_percentage': 'float', 'val2_percentage': 'float', 'val3_percentage': 'float', 'val4_percentage': 'float'})\nresult = result.astype({'val1_percentage': 'float', 'val2_percentage': 'float', 'val3_percentage': 'float', 'val4_percentage': 'float'})\nresult = result.astype({'val1_percentage': 'float', 'val2_percentage': 'float', 'val3_percentage': 'float', 'val4_percentage': 'float'})\nresult = result.astype({'val1_percentage': 'float', 'val2_percentage': 'float', 'val3_percentage': 'float', 'val4_percentage': 'float'})\nresult = result.astype({'val1_percentage': 'float', 'val2_percentage': 'float', 'val3_percentage': 'float', 'val4_percentage': 'float'})\nresult = result.astype({'val1_percentage': 'float', 'val2_percentage': 'float', 'val3_percentage': 'float', 'val4_percentage': 'float'})\nresult = result.astype({'val1_percentage': 'float', 'val2_percentage': 'float', 'val3_percentage': 'float', 'val4_percentage': 'float'})",
        "result['percentage'] = result.apply(lambda x: (x['val1'] / x['total']) * 100, axis=1)\nresult = result.set_index('cat')\nresult = result.T.round(2)\nresult = result.T.reset_index()\nresult = result.rename(columns={'val1': 'val1_percentage', 'val2': 'val2_percentage', 'val3': 'val3_percentage', 'val4': 'val4_percentage'})\nresult = result.drop(columns=['total'])\nresult\n",
        "result = df.loc[test]\nprint(result)",
        "result = df.loc[test]\nprint(result)",
        "df = df.loc[~df.index.isin(test), :]\nprint(df)",
        "\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "cols = [df.keywords_0, df.keywords_1, df.keywords_2, df.keywords_3]\ndf[\"keywords_all\"] = df[\"keywords_all\"].apply(lambda cols: \",\".join(cols), axis=1)\n",
        "cols = [df.keywords_0, df.keywords_1, df.keywords_2, df.keywords_3]\ndf[\"keywords_all\"] = df[\"keywords_all\"].apply(lambda cols: \"-\".join(cols), axis=1)\n",
        "cols = [df.keywords_0, df.keywords_1, df.keywords_2, df.keywords_3]\ndf[\"keywords_all\"] = df[\"keywords_all\"].apply(lambda cols: \"-\".join(cols), axis=1)\n",
        "cols = [df.keywords_0, df.keywords_1, df.keywords_2, df.keywords_3]\ndf[\"keywords_all\"] = df[\"keywords_all\"].apply(lambda cols: \"-\".join(cols), axis=1)\nresult = df\nprint(result)",
        "\n",
        "random_state=0,\nn=0.2,\nresult = df.sample(n, random_state=0)\nresult['ProductId'][result['ProductId'] == 0] = 0\nresult = result.reset_index(drop=True)\nprint(result)",
        "result = df.sample(int(len(df) * 0.2), random_state=0)\nresult['Quantity'] = result['Quantity'].mask(result['Quantity'] == 0)\nresult = result.reset_index(drop=True)\nprint(result)",
        "\nresult = df.loc[duplicate_bool == True, 'index_original'] = df.index[duplicate_bool == True]\n",
        "\nimport pandas as pd\ndf=pd.DataFrame(data=[[1,2],[3,4],[1,2],[1,4],[1,2]],columns=['col1','col2'])\nduplicate_bool = df.duplicated(subset=['col1','col2'], keep='last')\nduplicate = df.loc[duplicate_bool == True]\nresult = df.loc[duplicate_bool == True].index[-1]\nprint(result)\n",
        "\nimport pandas as pd\nexample_df=pd.DataFrame(data=[[1,2],[3,4],[1,2],[1,4],[1,2]],columns=['col1','col2'])\ndef f(df=example_df):\n    duplicate_bool = df.duplicated(subset=['col1','col2'], keep='first')\n    duplicate = df.loc[duplicate_bool == True]\n    duplicate['index_original'] = duplicate.index.repeat(duplicate['col1'].astype(str).str.get_dummies().sum(axis=1))\n    return duplicate\n",
        "\n# [Missing Code]\n",
        "result = df.loc[duplicate_bool == True, 'index_original'] = df.index[duplicate_bool == True]\nprint(result)",
        "result = df.groupby(['Sp', 'Mt']).max()\nprint(result)",
        "result = df.groupby(['Sp', 'Mt'])['count'].max()\nprint(result)",
        "result = df.groupby(['Sp', 'Mt']).min()\nprint(result)",
        "result = df.groupby(['Sp', 'Value'])['count'].max()\nprint(result)",
        "df.query(\"Categories==filter_list\")",
        "df.query(\"Catergory not in filter_list\")",
        "result = pd.melt(df, value_vars=list(df.columns.values), var_name='col', value_name='value')\nprint(result)",
        "result = df.melt(id_vars=['col1', 'col2', 'col3', 'col4', 'col5', 'col6'], value_vars=df.columns.tolist())\nprint(result)",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n",
        "\n",
        "result = df.groupby('l')['v'].sum()\nresult['right'] = np.nan\nprint(result)",
        "result = [\n    'Column1 Column2 one-to-many',\n    'Column1 Column3 one-to-many',\n    'Column1 Column4 one-to-one',\n    'Column1 Column5 one-to-many',\n    'Column2 Column1 many-to-one',\n    'Column2 Column3 many-to-many',\n    'Column2 Column4 many-to-one',\n    'Column2 Column5 many-to-many',\n    'Column3 Column1 many-to-one',\n    'Column3 Column2 many-to-many',\n    'Column3 Column4 many-to-one',\n    'Column3 Column5 many-to-many',\n    'Column4 Column1 one-to-one',\n    'Column4 Column2 many-to-many',\n    'Column4 Column3 many-to-many',\n    'Column4 Column5 many-to-one',\n    'Column5 Column1 many-to-one',\n    'Column5 Column2 many-to-many',\n    'Column5 Column3 many-to-many',\n    'Column5 Column4 many-to-one'\n]\nprint(result)",
        "\nresult = df.apply(lambda x: get_relationship(x), axis=1)\ndef get_relationship(row):\n    relationships = []\n    for column in row:\n        relationship = None\n        for other_column in row:\n            if column == other_column:\n                relationship = 'one-2-one'\n            elif column == other_column.astype(str):\n                relationship = 'one-2-many'\n            elif column.astype(str) == other_column:\n                relationship = 'many-2-one'\n            elif column.astype(str) == other_column.astype(str):\n                relationship = 'many-2-many'\n        relationships.append(relationship)\n    return relationships\nprint(result)",
        "\ndef relationship_type(df, column_list):\n    relationships = []\n    for column in column_list:\n        relationships.append(df[column].value_counts().to_dict())\n    return relationships\nresult = relationship_type(df, ['Column1', 'Column2', 'Column3', 'Column4', 'Column5'])\nprint(result)\n[Output]\n{'Column1': {'1': 1, '2': 1, '3': 1, '4': 1, '5': 1, '6': 1, '7': 1, '8': 1, '9': 1},\n 'Column2': {'4': 1, '3': 1, '6': 1, '8': 1, '3': 1, '4': 1, '1': 1, '4': 1, '3': 1},\n 'Column3': {'7': 1, '3': 1, '3': 1, '1': 1, '2': 1, '2': 1, '3': 1, '2': 1, '7': 1},\n 'Column4': {'9': 1, '8': 1, '7': 1, '6': 1, '5': 1, '4': 1, '3': 1, '2': 1, '1': 1},\n 'Column5': {'1': 1, '1': 1, '1': 1, '1': 1, '1': 1, '1': 1, '1': 1, '1': 1, '1': 1}}",
        "\ndef relationship_type(df, column_list):\n    relationships = []\n    for column in column_list:\n        relationships.append(df[column].value_counts().index[0])\n    return pd.DataFrame(relationships, index=column_list, columns=['Column1', 'Column2', 'Column3', 'Column4', 'Column5'])\nresult = relationship_type(df, ['Column1', 'Column2', 'Column3', 'Column4', 'Column5'])\nprint(result)",
        "\ndf = df[df['bank'].notnull()]\nresult = df\nprint(result)",
        "df = pd.read_csv('data.csv')\nresult = pd.to_numeric(df, errors='coerce')\nprint(result)",
        "\n",
        "\nresult = df.groupby([\"Survived\", \"Parch\"])[\"SibSp\"].mean()\nresult = result.loc[result[\"Survived\"] > 0 | result[\"Parch\"] > 0, \"Has Family\"]\nresult = result.loc[result[\"Survived\"] == 0 & result[\"Parch\"] == 0, \"No Family\"]\nresult = result.set_index(\"Name\")[\"SibSp\"].mean()\nprint(result)\n[Output]",
        "\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'cokey':[11168155,11168155,11168155,11168156,11168156],\n                   'A':[18,0,56,96,0],\n                   'B':[56,18,96,152,96]})\nresult = df.groupby('cokey').sort('A')\nprint(result)\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'cokey':[11168155,11168155,11168155,11168156,11168156],\n                   'A':[18,0,56,96,0],\n                   'B':[56,18,96,152,96]})\nresult = df.groupby('cokey').sort('A')\nprint(result)\n",
        "result = df.set_index(['Caps', 'Lower', 'A', 'B'])\nresult = result.stack().reset_index()\nresult = result.rename(columns={'level_1': 'A', 'level_2': 'B', 0: 'index'})\nresult = result.sort_values(['Caps', 'Lower', 'A', 'B', 'index'])\nresult = result.unstack()\nresult = result.reset_index()\nresult = result.rename(columns={'level_1': 'A', 'level_2': 'B', 0: 'index'})\nresult = result.sort_values(['Caps', 'Lower', 'A', 'B', 'index'])\nresult = result.set_index(['Caps', 'Lower', 'A', 'B'])\nresult = result.stack().reset_index()\nresult = result.rename(columns={'level_1': 'A', 'level_2': 'B', 0: 'index'})\nresult = result.sort_values(['Caps', 'Lower', 'A', 'B', 'index'])\nresult = result.unstack()\nresult = result.reset_index()\nresult = result.rename(columns={'level_1': 'A', 'level_2': 'B', 0: 'index'})\nresult = result.sort_values(['Caps', 'Lower', 'A', 'B', 'index'])\nresult = result.set_index(['Caps', 'Lower', 'A', 'B'])\nresult = result.stack().reset_index()\nresult = result.rename(columns={'level_1': 'A', 'level_2': 'B', 0: 'index'})\nresult = result.sort_values(['Caps', 'Lower', 'A', 'B', 'index'])\nresult = result.unstack()\nresult = result.reset_index()\nresult = result.rename(columns={'level_1': 'A', 'level_2': 'B', 0: 'index'})\nresult = result.sort_values(['Caps', 'Lower', 'A', 'B', 'index'])\nresult = result.set_index(['Caps', 'Lower', 'A', 'B'])\nresult = result.stack().reset_index()\nresult = result.rename(columns={'level_1': 'A', 'level_2': 'B', 0: 'index'})\nresult = result.sort_values(['Caps', 'Lower', 'A', 'B', 'index'])\nresult = result.unstack()\nresult = result.reset_index()\nresult = result.rename(columns={'level_1': 'A', 'level_2': 'B', 0: 'index'})\nresult = result.sort_values(['Caps', 'Lower', 'A', 'B', 'index'])\nresult = result.set_index(['Caps', 'Lower', 'A', 'B'])\nresult = result.stack().reset_index()\nresult = result.rename(columns={'level_1': 'A', 'level_2': 'B', 0: 'index'})\nresult = result.sort_values(['Caps', 'Lower', 'A', 'B', 'index'])\nresult = result.unstack()\nresult = result.reset_index()\nresult = result.rename(columns={'level_1': 'A', 'level_2': 'B', 0: 'index'})\nresult = result.sort_values(['Caps', 'Lower', 'A', 'B', 'index'])\nresult = result.set_index(['Caps', 'Lower', 'A', 'B'])\nresult = result.stack().reset_index()\nresult = result.rename(columns={'level_1': 'A', 'level_2': 'B', 0: 'index'})\nresult = result.sort_values(['Caps', 'Lower', 'A', 'B', 'index'])\nresult = result.unstack()\nresult = result.reset_index()\nresult = result.rename(columns={'level_1': 'A', 'level_2': 'B', 0: 'index'})\nresult = result.sort_values(['Caps', 'Lower', 'A', 'B', 'index'])\nresult = result.set_index(['Caps', 'Lower', 'A', 'B'])\nresult = result.stack().reset_index()",
        "\ndf = pd.DataFrame(np.random.randn(5, 6), columns=l)\ndf = df.set_index(['Caps', 'Middle', 'Lower'])\ndf = df.unstack(level=1)\ndf.columns = df.columns.map(' '.join)\ndf = df.reset_index()\nresult = df\nprint(result)\n",
        "\n# [Missing Code]\n",
        "result = pd.DataFrame({'birdType': someTuple[0], 'birdCount': someTuple[1]})\nprint(result)",
        "\nimport pandas as pd\ndf = pd.DataFrame({'a':[1,1,1,2,2,2,3,3,3], 'b':[12,13,23,22,23,24,30,35,55]})\nresult = df.groupby('a').b.apply(lambda x: np.std(np.mean(x)))\nprint(result)\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'a':[12,13,23,22,23,24,30,35,55], 'b':[1,1,1,2,2,2,3,3,3]})\nresult = df.groupby('b').a.apply(lambda x: np.std(np.mean(x)))\nprint(result)\n",
        "\nresult = df.groupby('a')['b'].softmax().reset_index()\nresult['min-max'] = result['b'].min() - result['b'].max()\nresult = result.reset_index()\nprint(result)",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nimport pandas as pd\ndf = pd.DataFrame([[1,2,3,1],[0,0,0,0],[1,0,0,1],[0,1,2,0],[1,1,0,1]],columns=['A','B','C','D'])\nresult = df[df.max() == 2].isnull().sum() == 0\ndf = df[result]\nprint(df)\n",
        "df.loc[df.max() == 2, df.max()] = 0\nresult = df.copy()\nprint(result)",
        "\nimport pandas as pd\ns = pd.Series([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0.98,0.93],\n          index=['146tf150p','havent','home','okie','thanx','er','anything','lei','nite','yup','thank','ok','where','beerage','anytime','too','done','645','tick','blank'])\ns = s.sort_values(by=['index', 'value'], ascending=[True, True])\nprint(s)\n",
        "s = s.sort_values(by=['index', 'value'], ascending=True)\nresult = s.set_index('index')\nresult = result.sort_index()\nresult = result.reset_index()\nresult = result.rename(columns={'index': 'index', '1': 'value'})\nprint(result)",
        "\nimport pandas as pd\ndf = pd.DataFrame({'A': [1, 2, 's', 3, 'b'],\n                   'B': ['green', 'red', 'blue', 'yellow', 'black']})\nresult = df[df['A'].astype(str).str.isdigit()]\nprint(result)\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'A': [1, 2, 's', 3, 'b'],\n                   'B': ['green', 'red', 'blue', 'yellow', 'black']})\nresult = df[df['A'].astype('str')]\nprint(result)\n",
        "result = df.groupby(['Sp', 'Mt']).max()\nprint(result)",
        "\n",
        "result = df.groupby(['Sp', 'Mt']).min()\nprint(result)",
        "result = df.groupby(['Sp', 'Value'])['count'].max()\nprint(result)",
        "\nimport pandas as pd\nimport numpy as np\ndict = {'abc':'1/2/2003', 'def':'1/5/2017', 'ghi':'4/10/2013'}\ndf = pd.DataFrame({'Member':['xyz', 'uvw', 'abc', 'def', 'ghi'], 'Group':['A', 'B', 'A', 'B', 'B'], 'Date':[np.nan, np.nan, np.nan, np.nan, np.nan]})\nresult = df\nresult['Date'] = df['Member'].map(dict)\nprint(result)\n",
        "df['Date'] = df['Member'].map(dict)\ndf['Date'] = df['Date'].fillna(df['Date'])\nresult = df\nprint(result)",
        "\n",
        "df['Date'] = df['Member'].map(dict)\ndf['Date'] = df['Date'].fillna(df['Date'])\nresult = df\nprint(result)",
        "df['Date'] = pd.to_datetime(df['Date'], format= '%d/%m/%y')\ndf['Count_d'] = df.Date.map(df.groupby('Date').size())\ndf1 = df.groupby([df['Date'].dt.year.rename('year'), df['Date'].dt.month.rename('month')]).agg({'count'})\nresult = df1.reset_index()\nresult['Count_d'] = result['count']\nresult['Count_m'] = result['count']\nresult['Count_y'] = result['count']\nprint(result)",
        "df['Date'] = pd.to_datetime(df['Date'], format= '%d/%m/%y')\ndf['Count_d'] = df.Date.map(df.groupby('Date').size())\ndf1 = df.groupby([df['Date'].dt.year.rename('year'), df['Date'].dt.month.rename('month')]).agg({'count'})\nresult = df1.join(df, on='Date')\nresult = result.set_index(['Date', 'Val', 'Count_d', 'Count_m', 'Count_y', 'Count_Val'])\nresult = result.sort_values(['Date', 'Val', 'Count_d', 'Count_m', 'Count_y', 'Count_Val'])\nprint(result)",
        "\n# [Missing Code]\n",
        "\nresult1 = df.loc[df['B'] == 0, 'B'].value_counts()\nresult2 = df.loc[df['B'] != 0, 'B'].value_counts()\nresult1 = df.loc[df['C'] == 0, 'C'].value_counts()\nresult2 = df.loc[df['C'] != 0, 'C'].value_counts()\n",
        "\n# [Missing Code]\n",
        "print(result)",
        "result = pd.pivot_table(df, values=['D','E'], rows=['B'], aggfunc=np.sum)\nresult = pd.pivot_table(df, values=['D','E'], rows=['B'], aggfunc=np.mean)\nprint(result)",
        "\nimport pandas as pd\nimport numpy as np\nnp.random.seed(1)\ndf = pd.DataFrame({\n'A' : ['abc', 'def', 'xyz', 'abc'] * 3,\n'B' : ['A', 'B', 'C'] * 4,\n'D' : np.random.randn(12),\n'E' : np.random.randn(12)\n})\nprint(result)\n",
        "\n",
        "result = df.explode('var2')\nprint(result)",
        "result = df.explode('var2')\nprint(result)",
        "result = df.explode('var2')\nprint(result)",
        "\n# [Missing Code]\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'str': ['Aa', 'Bb', '?? ?', '###', '{}xxa;']})\ndef count_special_char(string):\n    special_char = 0\n    for i in range(len(string)):\n        if(string[i].isalpha()):\n            continue\n        else:\n            special_char = special_char + 1\n    return special_char\ndf[\"new\"] = df[\"str\"].apply(count_special_char)\nresult = df\nprint(result)\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'row': ['00000 UNITED STATES', '01000 ALABAMA',\n                           '01001 Autauga County, AL', '01003 Baldwin County, AL',\n                           '01005 Barbour County, AL']})\ndf['fips'] = df['row'].str.split(' ', 1, expand=True)[0]\ndf['row'] = df['row'].str.split(' ', 1, expand=True)[1]\nresult = df\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'row': ['114 AAAAAA', '514 ENENEN',\n                           '1926 HAHAHA', '0817 O-O,O-O',\n                           '998244353 TTTTTT']})\ndf['fips'] = df['row'].str.split(' ', 1, expand=True)[0]\ndf['row'] = df['row'].str.split(' ', 1, expand=True)[1]\nresult = df\n",
        "\n# [Missing Code]\n",
        "result['2001'] = df['2001'].astype(float).fillna(method='ffill')\nresult['2002'] = df['2002'].astype(float).fillna(method='ffill')\nresult['2003'] = df['2003'].astype(float).fillna(method='ffill')\nresult['2004'] = df['2004'].astype(float).fillna(method='ffill')\nresult['2005'] = df['2005'].astype(float).fillna(method='ffill')\nresult['2006'] = df['2006'].astype(float).fillna(method='ffill')\nresult['2001_cum'] = result['2001'].astype(float).cumsum()\nresult['2002_cum'] = result['2002'].astype(float).cumsum()\nresult['2003_cum'] = result['2003'].astype(float).cumsum()\nresult['2004_cum'] = result['2004'].astype(float).cumsum()\nresult['2005_cum'] = result['2005'].astype(float).cumsum()\nresult['2006_cum'] = result['2006'].astype(float).cumsum()\nresult['2001_cum'] = result['2001_cum'].where(result['2001'] != 0, result['2001_cum'])\nresult['2002_cum'] = result['2002_cum'].where(result['2002'] != 0, result['2002_cum'])\nresult['2003_cum'] = result['2003_cum'].where(result['2003'] != 0, result['2003_cum'])\nresult['2004_cum'] = result['2004_cum'].where(result['2004'] != 0, result['2004_cum'])\nresult['2005_cum'] = result['2005_cum'].where(result['2005'] != 0, result['2005_cum'])\nresult['2006_cum'] = result['2006_cum'].where(result['2006'] != 0, result['2006_cum'])\nresult = result.set_index('Name')\nresult = result.T\nprint(result)",
        "result['cumulative_average'] = df.iloc[::-1].agg(lambda x: x.mean(), axis=1)\nresult['cumulative_average'] = result['cumulative_average'].mask(result['cumulative_average'].eq(0), np.nan)\nresult['cumulative_average'] = result['cumulative_average'].fillna(method='ffill')\nresult = result.iloc[::-1]\nresult = result.reset_index(drop=True)\nprint(result)\n",
        "\n",
        "result['cumulative_average'] = df.iloc[::-1].agg(lambda x: x.mean(), axis=1)\nresult['cumulative_average'] = result['cumulative_average'].mask(result['cumulative_average'].eq(0), np.nan)\nresult['cumulative_average'] = result['cumulative_average'].fillna(method='ffill')\nresult = result.iloc[::-1]\nresult = result.reset_index(drop=True)\nprint(result)\n",
        "\n",
        "\n# [Missing Code]\n",
        "result['label'] = result['Close'].diff().astype(int).replace(0, 1).replace(-1, -1)\nresult['label'] = result['label'].astype(str) + ' ' + result['DateTime'].dt.strftime('%d-%b-%Y')\nresult = result[['DateTime', 'Close', 'label']]\nprint(result)",
        "df['Duration'] = df.departure_time.iloc[i+1] - df.arrival_time.iloc[i] \nresult = df\nprint(result)",
        "df['Duration'] = df.departure_time.iloc[i+1] - df.arrival_time.iloc[i] \nresult = df\nprint(result)",
        "df['Duration'] = df.departure_time.iloc[i+1] - df.arrival_time.iloc[i]\nresult['Duration'] = result['Duration'].astype('timedelta64[ns]')\nresult['Duration'] = result['Duration'].astype('int')\nresult = result.sort_values(by=['id', 'arrival_time'])\nresult = result.reset_index(drop=True)\nprint(result)",
        "\nimport pandas as pd\ndf = pd.DataFrame({'key1': ['a', 'a', 'b', 'b', 'a', 'c'],\n                   'key2': ['one', 'two', 'one', 'two', 'one', 'two']})\nresult = df.groupby(['key1']).apply(lambda x: x['key2'].eq('one').sum())\nprint(result)\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'key1': ['a', 'a', 'b', 'b', 'a', 'c'],\n                   'key2': ['one', 'two', 'one', 'two', 'one', 'two']})\nresult = df.groupby(['key1']).apply(lambda x: x['key2'].eq('two').sum())\nprint(result)\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'key1': ['a', 'a', 'b', 'b', 'a', 'c'],\n                   'key2': ['one', 'two', 'gee', 'two', 'three', 'two']})\nresult = df.groupby(['key1']).apply(lambda x: x['key2'].str.count('e'))\nprint(result)\n",
        "max_result = df.index.max()\nmin_result = df.index.min()\nprint(max_result, min_result)",
        "mode_result = df.value.mode()[0]\nmedian_result = df.value.median()\nprint(mode_result,median_result)",
        "\ndf = df[(99 <= df['closing_price'] <= 101)]\n",
        "df = df[~(99 <= df['closing_price'] <= 101)]\n",
        "\n# [Missing Code]\n",
        "df['SOURCE_NAME'] = df['SOURCE_NAME'].str.rsplit('_', n=1, expand=True)\nresult = df\nprint(result)",
        "df['SOURCE_NAME'] = df['SOURCE_NAME'].str.rsplit('_', n=1, expand=True)\nresult = df\nprint(result)",
        "\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "result = df.assign(Column_x=df['Column_x'].replace(np.nan, {'0': 0.5, '1': 0.5}))\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)\nresult = result.fillna(method='bfill', axis=0)\nresult = result.fillna(method='ffill', axis=0)",
        "\nimport pandas as pd\nimport numpy as np\na = pd.DataFrame(np.array([[1, 2],[3, 4]]), columns=['one', 'two'])\nb = pd.DataFrame(np.array([[5, 6],[7, 8]]), columns=['one', 'two'])\nresult = pd.concat([a, b], axis=1).apply(lambda x: tuple(x.values), axis=1).unstack().reset_index()\nprint(result)\n",
        "result = pd.concat([a, b, c], axis=1)\nresult = result.apply(lambda x: tuple(x), axis=1)\nprint(result)",
        "result = pd.DataFrame([[(a['one'][i], b['one'][i]) for i in range(len(a))] + [(np.nan, np.nan)] * (len(b) - len(a))], columns=['one', 'two'])\nprint(result)",
        "groups = df.groupby(pd.cut(df.views, bins))\nresult = groups[['username', 'views']].sum().reset_index()\nprint(result)",
        "groups = df.groupby(pd.cut(df.views, bins))\nresult = groups.username.value_counts()\nprint(result)",
        "groups = df.groupby(pd.cut(df.views, bins))\nresult = groups.reset_index()\nresult['count'] = 1\nresult = result.groupby('username')['count'].transform('sum')\nresult = result.reset_index()\nresult['count'] = result['count'] / groups.username.nunique()\nresult = result.sort_values('count', ascending=False)\nprint(result)",
        "\nimport pandas as pd\ndf = pd.DataFrame({'text': ['abc', 'def', 'ghi', 'jkl']})\ndf['text'] = df['text'].str.cat(sep=', ')\nresult = df\nprint(result)\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'text': ['abc', 'def', 'ghi', 'jkl']})\ndf['text'] = df['text'].str.cat(sep='-')\nprint(result)\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'text': ['abc', 'def', 'ghi', 'jkl']})\ndf['text'] = df['text'].str.cat(sep=', ')\nresult = df\nprint(result)\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'text': ['abc', 'def', 'ghi', 'jkl']})\ndf = df.astype('object').apply(lambda x: ', '.join(x), axis=1).reset_index(drop=True)\nprint(result)\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'text': ['abc', 'def', 'ghi', 'jkl']})\nresult = df['text'].str.cat(sep='-')\nprint(result)\n",
        "result = pd.concat([df1, df2], axis=0)\nprint(result)",
        "result = pd.concat([df1, df2], axis=0)\nresult['date'] = result['date'].str.replace(' ', '-')\nresult = result.sort_values(['id', 'date']).reset_index(drop=True)\nprint(result)",
        "result = pd.concat([df1, df2], axis=0)\nresult['city'] = result['city'].fillna('')\nresult['district'] = result['district'].fillna('')\nresult = result.sort_values(by=['id', 'date']).reset_index(drop=True)\nprint(result)",
        "\n",
        "\n",
        "result = C.merge(D, how='outer', on='A', suffixes=('', '_y'))\nresult['dulplicated'] = result['A_x'] == result['A_y']\nresult = result[['A', 'B', 'dulplicated']]\nprint(result)",
        "result = df.groupby('user')['time', 'amount'].apply(lambda x: list(zip(x['time'], x['amount'])))\nprint(result)",
        "result = df.groupby('user').agg(lambda x: list(zip(x['time'], x['amount'])))\nprint(result)",
        "result = df.groupby('user').agg(lambda x: x.tolist()).sort_values(['time', 'amount']).reset_index(drop=True)\nprint(result)",
        "\n# [Missing Code]\n",
        "result = pd.DataFrame({'name': ['file1', 'file2', 'file3'],\n                       '0': [1, 5, 9],\n                       '1': [2, 6, 10],\n                       '2': [3, 7, 11],\n                       '3': [4, 8, 12]},\n                      index=['file1', 'file2', 'file3'])\nprint(result)",
        "result = [col for col in df.columns if s in col and not col.startswith(s + '-')]\nprint(result)",
        "result = [s for s in df.columns if s.startswith(s) and s != s]\nprint(result)",
        "result = df[df.columns.str.contains(s) & df.columns.str.startswith(s)].rename(columns={col: f'spike{i+1}' for i, col in enumerate(df.columns)})\nprint(result)",
        "result = df.explode('codes')\nresult = result.reset_index(drop=True)\nresult = result.astype(float)\nresult = result.fillna(0)\nprint(result)",
        "result = df.explode('codes')\nresult = result.reset_index(drop=True)\nresult = result.astype(float)\nresult = result.fillna(0)\nprint(result)",
        "result = df.codes.apply(pd.Series)\nresult = result.stack().reset_index(level=1, drop=True)\nresult.columns = ['code_1', 'code_2', 'code_3']\nresult = result.fillna(method='ffill')\nresult = result.fillna(method='bfill')\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(str)\nresult = result.astype(object)\nresult = result.astype(str)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(object)\nresult = result.astype(str)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(object)\nresult = result.astype(str)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(object)\nresult = result.astype(str)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(object)\nresult = result.astype(str)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(object)\nresult = result.astype(str)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(object)\nresult = result.astype(str)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(object)\nresult = result.astype(str)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(object)\nresult = result.astype(str)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(object)\nresult = result.astype(str)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(object)\nresult = result.astype(str)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(object)\nresult = result.astype(str)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(object)\nresult = result.astype(str)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(object)\nresult = result.astype(str)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(object)\nresult = result.astype(str)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(object)\nresult = result.astype(str)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(object)\nresult = result.astyle(str)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(object)\nresult = result.astype(str)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(object)\nresult = result.astype(str)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(object)\nresult = result.astype(str)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(object)\nresult = result.astype(str)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(object)\nresult = result.astype(str)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(object)\nresult = result.astype(str)\nresult = result.astype(int)",
        "\nresult = []\nfor i in range(len(df)):\n    result.extend(df.loc[i, 'col1'])\nprint(result)\n",
        "\nimport pandas as pd\ndf = pd.DataFrame(dict(col1=[[1, 2, 3],[4,5]]))\nresult = df.col1.apply(lambda x: ','.join(reversed(map(str, x))), axis=1)\nprint(result)\n",
        "\nimport pandas as pd\ndf = pd.DataFrame(dict(col1=[[1, 2, 3]] * 2))\nids = str(df.col1.values.tolist())\nprint(result)\n",
        "result = df.groupby(df.Time.dt.floor('2 minutes')).mean()\nprint(result)",
        "",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "",
        "result = df[filt]\nprint(result)",
        "result = df[filt]\nprint(result)",
        "\n# [Missing Code]\n",
        "\nnp.random.seed(10)\ndf = pd.DataFrame(np.random.randint(0, 20, (10, 10)).astype(float), columns=[\"c%d\"%d for d in range(10)])\ndf.where(np.random.randint(0,2, df.shape).astype(bool), np.nan, inplace=True)\nresult = df.iloc[0, :].isin(df.iloc[8, :]).index\nprint(result)\n",
        "\n# [Missing Code]\n",
        "\nresult = df.iloc[0, :].eq(df.iloc[8, :]).astype(bool)\nresult = result.any(axis=1)\nresult = result.astype(int)\nresult = [i for i in range(len(result)) if result[i] == 1]\nresult = [(df.iloc[0, i], df.iloc[8, i]) for i in result]\nprint(result)",
        "ts = df['Value']\nts.index = df['Date']\nresult = ts\nprint(result)",
        "result = df.stack()\nresult = result.reset_index(level=0, drop=True)\nresult = result.rename(columns={0:'A_1'})\nresult = result.append(pd.DataFrame([[6,7,8,9,10],[11,12,13,14,15]],columns=['A_2','B_2','C_2','D_2','E_2']),ignore_index=True)\nresult = result.append(pd.DataFrame([[11,12,13,14,15],[6,7,8,9,10]],columns=['A_3','B_3','C_3','D_3','E_3']),ignore_index=True)\nresult = result.reset_index(drop=True)\nresult = result.rename(columns={0:'A_1'})\nresult = result.append(pd.DataFrame([[11,12,13,14,15],[6,7,8,9,10]],columns=['A_2','B_2','C_2','D_2','E_2']),ignore_index=True)\nresult = result.append(pd.DataFrame([[11,12,13,14,15],[6,7,8,9,10]],columns=['A_3','B_3','C_3','D_3','E_3']),ignore_index=True)\nresult = result.reset_index(drop=True)\nresult = result.rename(columns={0:'A_1'})\nresult = result.append(pd.DataFrame([[11,12,13,14,15],[6,7,8,9,10]],columns=['A_2','B_2','C_2','D_2','E_2']),ignore_index=True)\nresult = result.append(pd.DataFrame([[11,12,13,14,15],[6,7,8,9,10]],columns=['A_3','B_3','C_3','D_3','E_3']),ignore_index=True)\nresult = result.reset_index(drop=True)\nresult = result.rename(columns={0:'A_1'})\nresult = result.append(pd.DataFrame([[11,12,13,14,15],[6,7,8,9,10]],columns=['A_2','B_2','C_2','D_2','E_2']),ignore_index=True)\nresult = result.append(pd.DataFrame([[11,12,13,14,15],[6,7,8,9,10]],columns=['A_3','B_3','C_3','D_3','E_3']),ignore_index=True)\nresult = result.reset_index(drop=True)\nresult = result.rename(columns={0:'A_1'})\nresult = result.append(pd.DataFrame([[11,12,13,14,15],[6,7,8,9,10]],columns=['A_2','B_2','C_2','D_2','E_2']),ignore_index=True)\nresult = result.append(pd.DataFrame([[11,12,13,14,15],[6,7,8,9,10]],columns=['A_3','B_3','C_3','D_3','E_3']),ignore_index=True)\nresult = result.reset_index(drop=True)\nresult = result.rename(columns={0:'A_1'})\nresult = result.append(pd.DataFrame([[11,12,13,14,15],[6,7,8,9,10]],columns=['A_2','B_2','C_2','D_2','E_2']),ignore_index=True)\nresult = result.append(pd.DataFrame([[11,12,13,14,15],[6,7,8,9,10]],columns=['A_3','B_3','C_3','D_3','E_3']),ignore_index=True)",
        "result = df.stack()\nresult = result.reset_index(level=0, drop=True)\nresult = result.rename(columns={0:'A_0'})\nresult = result.append(pd.DataFrame([[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15]],columns=['A','B','C','D','E']), ignore_index=True)\nresult = result.reset_index(drop=True)\nresult = result.rename(columns={0:'A_0'})\nresult = result.append(pd.DataFrame([[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15]],columns=['A','B','C','D','E']), ignore_index=True)\nresult = result.reset_index(drop=True)\nresult = result.rename(columns={0:'A_0'})\nresult = result.append(pd.DataFrame([[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15]],columns=['A','B','C','D','E']), ignore_index=True)\nresult = result.reset_index(drop=True)\nresult = result.rename(columns={0:'A_0'})\nresult = result.append(pd.DataFrame([[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15]],columns=['A','B','C','D','E']), ignore_index=True)\nresult = result.reset_index(drop=True)\nresult = result.rename(columns={0:'A_0'})\nresult = result.append(pd.DataFrame([[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15]],columns=['A','B','C','D','E']), ignore_index=True)\nresult = result.reset_index(drop=True)\nresult = result.rename(columns={0:'A_0'})\nresult = result.append(pd.DataFrame([[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15]],columns=['A','B','C','D','E']), ignore_index=True)\nresult = result.reset_index(drop=True)\nresult = result.rename(columns={0:'A_0'})\nresult = result.append(pd.DataFrame([[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15]],columns=['A','B','C','D','E']), ignore_index=True)\nresult = result.reset_index(drop=True)\nresult = result.rename(columns={0:'A_0'})\nresult = result.append(pd.DataFrame([[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15]],columns=['A','B','C','D','E']), ignore_index=True)\nresult = result.reset_index(drop=True)\nresult = result.rename(columns={0:'A_0'})\nresult = result.append(pd.DataFrame([[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15]],columns=['A','B','C','D','E']), ignore_index=True)\nresult = result.reset_index(drop=True)\nresult = result.rename(columns={0:'A_0'})\nresult = result.append(pd.DataFrame([[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15]],columns=['A','B','C','D','E']), ignore_index=True)\nresult = result.reset_index(drop=True)",
        "df['dogs'] = df['dogs'].round(2)\nresult = df\nprint(result)",
        "\n# [Missing Code]\n",
        "\nimport pandas as pd\nimport numpy as np\nnp.random.seed(10)\ndata = {}\nfor i in [chr(x) for x in range(65,91)]:\n    data['Col '+i] = np.random.randint(1,100,10)\ndf = pd.DataFrame(data)\nlist_of_my_columns = ['Col A', 'Col E', 'Col Z']\nresult = df\nresult['Sum'] = df[list_of_my_columns].sum(axis=1)\nprint(result)\n",
        "df['Avg'] = df[list_of_my_columns].mean(axis=1)",
        "result['Avg'] = df[list_of_my_columns].mean(axis=1)\nresult['Min'] = df[list_of_my_columns].min(axis=1)\nresult['Max'] = df[list_of_my_columns].max(axis=1)\nprint(result)",
        "\nimport pandas as pd\ndf = pd.DataFrame({'VIM':[-0.158406,0.039158,-0.052608,0.157153,0.206030,0.132580,-0.144209,-0.093910,-0.166819,0.097548,0.026664,-0.008032]},\n                  index=pd.MultiIndex.from_tuples([('TGFb',0.1,2),('TGFb',1,2),('TGFb',10,2),('TGFb',0.1,24),('TGFb',1,24),('TGFb',10,24),('TGFb',0.1,48),('TGFb',1,48),('TGFb',10,48),('TGFb',0.1,6),('TGFb',1,6),('TGFb',10,6)],\n                                                 names=['treatment','dose','time']))\ndf = df.sort_index(axis=1, level=1, ascending=True)\nprint(df)\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'VIM':[-0.158406,0.039158,-0.052608,0.157153,0.206030,0.132580,-0.144209,-0.093910,-0.166819,0.097548,0.026664,-0.008032]},\n                  index=pd.MultiIndex.from_tuples([('TGFb',0.1,2),('TGFb',1,2),('TGFb',10,2),('TGFb',0.1,24),('TGFb',1,24),('TGFb',10,24),('TGFb',0.1,48),('TGFb',1,48),('TGFb',10,48),('TGFb',0.1,6),('TGFb',1,6),('TGFb',10,6)],\n                                                 names=['treatment','dose','time']))\ndf = df.sort_index(axis=1, level=1, kind='mergesort')\nprint(df)\n",
        "df = df[(df.index != '2020-02-17') & (df.index != '2020-02-18')]\nprint(df)",
        "df = df[(df.index != '2020-02-17') & (df.index != '2020-02-18')]\ndf['Date'] = df['Date'].dt.strftime('%d-%b-%Y')\ndf.set_index('Date', inplace=True)\nprint(df)",
        "result = df[np.abs(corr) > 0.3]\nprint(result)",
        "result = df.filter(lambda x: x >= 0.3)\nprint(result)",
        "\nimport pandas as pd\ndf = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]], columns=list('ABA'))\ndf.rename(columns={df.columns[-1]: 'Test'}, inplace=True)\nprint(df)\n",
        "df.columns[0] = 'Test'",
        "\ndf['frequent'] = df.apply(lambda row: '0' if row['bit1'] == '0' and row['bit2'] == '0' and row['bit3'] == '0' and row['bit4'] == '0' and row['bit5'] == '0' else '1', axis=1)\ndf['freq_count'] = df['frequent'].value_counts().index.to_series().astype(int)\nresult = df[['bit1', 'bit2', 'bit3', 'bit4', 'bit5', 'frequent', 'freq_count']]\nprint(result)",
        "\ndf['frequent'] = df.apply(lambda row: row.max(), axis=1)\ndf['freq_count'] = df['frequent'].value_counts().index.astype(int)\nresult = df[['bit1', 'bit2', 'bit3', 'bit4', 'bit5', 'frequent', 'freq_count']]\nprint(result)",
        "\n# [Missing Code]\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({\"foo\":[8,5,3,4,7,9,5,7], \n                   \"id1\":[1,1,1,1,1,1,1,1], \n                   \"bar\":['NULL','NULL','NULL',1,3,4,2,3], \n                   \"id2\":[1,1,1,2,2,3,3,1]})\nres = df.groupby([\"id1\",\"id2\"])[\"foo\",\"bar\"].mean()\nprint(res)\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({\"foo\":[8,5,3,4,7,9,5,7], \n                   \"id1\":[1,1,1,1,1,1,1,1], \n                   \"bar\":['NULL','NULL','NULL',1,3,4,2,3], \n                   \"id2\":[1,1,1,2,2,3,3,1]})\nresult = df.groupby([\"id1\", \"id2\"])[\"foo\", \"bar\"].mean()\nprint(result)\n",
        "result = df_a.merge(df_b, on='EntityNum', how='left')\nresult = result[['EntityNum', 'foo', 'a_col']]\nresult.drop('b_col', axis=1, inplace=True)\nprint(result)",
        "result = df_a.merge(df_b, on='EntityNum', how='left')\nresult = result[['EntityNum', 'foo', 'b_col']]\nresult.drop('a_col', axis=1, inplace=True)\nprint(result)"
    ],
    "Numpy": [
        "\nimport numpy as np\na = np.array([[1,2],[3,4]])\nresult = a.shape\nprint(result)\n",
        "x = x.astype(float)\nx = x.compressed()\nx = x.ravel()\nx = x.tolist()\nx = [elem for elem in x if not np.isnan(elem)]\nprint(x)",
        "\nimport numpy as np\nx = np.array([1400, 1500, 1600, np.nan, np.nan, np.nan ,1700])\nx[np.isnan(x)] = np.inf\nprint(x)\n",
        "x = np.array([[1400, 1500, 1600, np.nan], [1800, np.nan, np.nan ,1700]])\nresult = [item for item in x if not np.isnan(item).any()]\nprint(result)",
        "\nimport numpy as np\na = np.array([1, 0, 3])\nb = np.zeros((len(a)+1, a.max()+1))\nb[np.arange(len(a)), a] = 1\nprint(b)\n",
        "\nimport numpy as np\na = np.array([1, 0, 3])\nb = np.zeros((len(a)+1, a.max()+1))\nb[np.arange(len(a)), a-1] = 1\nprint(b)\n",
        "\nimport numpy as np\na = np.array([-1, 0, 3])\nb = np.zeros((len(a)+1, 5))\nb[np.arange(len(a)), a] = np.ones(len(a))\nprint(b)\n",
        "\nimport numpy as np\na = np.array([1.5, -0.4, 1.3])\nb = np.zeros((len(a)+1, 3))\nb[np.arange(len(a)), a] = 1\nprint(b)\n",
        "b = np.zeros((a.shape[0], a.shape[1] + 1))\nb[np.arange(a.shape[0]), a] = 1\nprint(b)",
        "\nimport numpy as np\na = np.array([1,2,3,4,5])\np = 25\nresult = np.percentile(a, p)\nprint(result)\n",
        "\nimport numpy as np\nA = np.array([1,2,3,4,5,6])\nncol = 2\nB = A[np.reshape(A, (ncol, -1))]\nprint(B)\n",
        "\nimport numpy as np\nA = np.array([1,2,3,4,5,6])\nnrow = 3\nB = A[np.newaxis, :nrow]\nprint(B)\n",
        "\nimport numpy as np\nA = np.array([1,2,3,4,5,6,7])\nncol = 2\nB = A.reshape((-1, ncol))\nprint(B)\n",
        "\nimport numpy as np\nA = np.array([1,2,3,4,5,6,7])\nncol = 2\nB = A.reshape((-1, ncol))\nprint(B)\n",
        "result = np.roll(a, shift)\nprint(result)",
        "result = np.roll(a, shift, axis=0)\nprint(result)",
        "result = np.roll(a, shift, axis=0)\nprint(result)",
        "\nimport numpy as np\nr_old = np.random.randint(3, size=(100, 2000)) - 1\nr_new = np.random.randint(3, size=(100, 2000)) - 1\nprint(r_old, r_new)\n",
        "\nresult = np.argmax(a, axis=1)\n# [Missing Code]\n",
        "\nresult = a.ravel().argsort()[-1]\n# [Missing Code]\n",
        "\nresult = np.argmax(a, axis=1)\n# [Missing Code]\n",
        "\nresult = np.argmax(a, axis=1)\n# [Missing Code]\n",
        "\n    # [Missing Code]\n    ",
        "\n# [Missing Code]\n",
        "\nimport numpy as np\na = np.array([[np.nan, 2., 3., np.nan],\n\t\t[1., 2., 3., 9]])\nz = np.isnan(a).any(axis=1)\na[z] = np.nan\na = a.astype(float)\nprint(a)\n",
        "\nimport numpy as np\na = np.array([[np.nan, 2., 3., np.nan],\n\t\t[1., 2., 3., 9]])\na = a[~np.isnan(a).all(axis=1)]\nprint(a)\n",
        "a = np.array(a)\nprint(result)",
        "\nimport numpy as np\na = np.array([[10, 20, 30, 40, 50],\n       [ 6,  7,  8,  9, 10]])\npermutation = [0, 4, 1, 3, 2]\na = np.roll(a, permutation, axis=1)\nprint(a)\n",
        "result = np.moveaxis(a, permutation, 0)\nprint(result)",
        "\nimport numpy as np\na = np.array([[1, 2], [3, 0]])\nresult = np.unravel_index(np.min(a), a.shape)\nprint(result)\n",
        "\nimport numpy as np\na = np.array([[1, 2], [3, 0]])\nresult = np.unravel_index(np.argmax(a), a.shape)\nprint(result)\n",
        "result = np.unravel_index(np.argmin(a, axis=0), a.shape)\nprint(result)",
        "import numpy as np\ndegree = 90\nresult = np.sin(degree)\nprint(result)",
        "import numpy as np\ndegree = 90\nresult = np.cos(degree)\nprint(result)",
        "result = np.sin(np.pi/180 * number)\nif result > 0:\n    result = 0\nelse:\n    result = 1\nprint(result)",
        "\nimport numpy as np\nvalue = 1.0\nresult = np.rad2deg(np.arcsin(value))\nprint(result)\n",
        "result = np.pad(A, (length // A.size) * A.size, 'constant', constant_values=0)\nprint(result)",
        "result = np.pad(A, (length - len(A)), 'constant', constant_values=0)\nprint(result)",
        "\n# [Missing Code]\n",
        "def f(a = example_a, power = 5):\n    result = np.empty_like(a)\n    for i in range(power):\n        result = a * result\n    return result",
        "\n",
        "from fractions import Fraction\ndef f(numerator = 98, denominator = 42):\n    result = Fraction(numerator, denominator)\n    return result",
        "result = (numerator // denominator, denominator)\nif denominator == 0:\n    result = (np.nan, np.nan)\nprint(result)",
        "\nimport numpy as np\na = np.array([10, 20, 30])\nb = np.array([30, 20, 20])\nc = np.array([50, 20, 40])\nresult = np.array([a + b + c] / np.array([1, 1, 1]))\nprint(result)\n",
        "\nimport numpy as np\na = np.array([10, 20, 30])\nb = np.array([30, 20, 20])\nc = np.array([50, 20, 40])\nresult = np.maximum(a, np.maximum(b, c))\nprint(result)\n",
        "\nimport numpy as np\na = np.array([[ 0,  1,  2,  3,  4],\n   [ 5,  6,  7,  8,  9],\n   [10, 11, 12, 13, 14],\n   [15, 16, 17, 18, 19],\n   [20, 21, 22, 23, 24]])\ndiagonal = np.ix_(np.arange(a.shape[0]), np.arange(a.shape[1]))\nresult = a[diagonal]\nprint(result)\n",
        "diagonal = np.diag_indices(a.shape[0]-1, 0)\nresult = a[diagonal]\nprint(result)",
        "\nimport numpy as np\na = np.array([[ 0,  1,  2,  3,  4],\n   [ 5,  6,  7,  8,  9],\n   [10, 11, 12, 13, 14],\n   [15, 16, 17, 18, 19],\n   [20, 21, 22, 23, 24]])\nresult = a[np.ix_(diagonal[::-1], diagonal)]\nprint(result)\n",
        "diagonal = np.diag_indices(a.shape[0]-1, 0)\nresult = a[diagonal]\nprint(result)",
        "\nimport numpy as np\nX = np.random.randint(2, 10, (5, 6))\nresult = []\nfor i in range(X.shape[0]):\n    for j in range(X.shape[1]):\n        result.append(X[i, j])\nprint(result)\n",
        "\nimport numpy as np\nX = np.random.randint(2, 10, (5, 6))\nresult = []\nfor i in range(X.shape[0]):\n    for j in range(X.shape[1]):\n        result.append(X[i, j])\nprint(result)\n",
        "\n",
        "\nimport numpy as np\nX = np.random.randint(2, 10, (5, 6))\nresult = []\nfor i in range(X.shape[0]):\n    for j in range(X.shape[1]):\n        result.append(X[i, j])\nprint(result)\n",
        "\nimport numpy as np\nmystr = \"100110\"\nresult = np.fromstring(mystr, dtype=int, sep='')\nprint(result)\n",
        "result = a[:, col] * multiply_number\nresult = np.cumsum(result)\nprint(result)",
        "result = a[row] * multiply_number\nresult = np.cumsum(result)\nprint(result)",
        "result = a[row] / divide_number\nresult = np.multiply(result, a[row])\nprint(result)",
        "\nimport numpy as np\na = np.array([[0,1,0,0], [0,0,1,0], [0,1,1,0], [1,0,0,1]])\nresult = np.linalg.matrix_power(a, 2)\nprint(result)\n",
        "\nimport numpy as np\na = np.random.rand(np.random.randint(5, 10), np.random.randint(6, 10))\nrow_size = a.shape[0]\nprint(row_size)\n",
        "\nimport numpy as np\nimport scipy.stats\na = np.random.randn(40)\nb = 4*np.random.randn(50)\np_value = scipy.stats.ttest_rel(a, b, equal_var=False)\nprint(p_value)\n",
        "\nimport numpy as np\nimport scipy.stats\na = np.random.randn(40)\nb = 4*np.random.randn(50)\np_value = scipy.stats.ttest_rel(a, b, equal_var=False, nan_policy='omit')\nprint(p_value)\n",
        "tstat, p_value = scipy.stats.ttest_rel(amean, anobs, bmean, bvar, bnobs)\nprint(p_value)\nimport numpy as np\nimport scipy.stats\namean = -0.0896\navar = 0.954\nanobs = 40\nbmean = 0.719\nbvar = 11.87\nbnobs = 50\ntstat, p_value = scipy.stats.ttest_rel(amean, anobs, bmean, bvar, bnobs)\nprint(p_value)",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "sort_indices = np.argsort(a, axis=0)\nc = b[sort_indices]\nprint(c)",
        "sort_indices = np.argsort(a, axis=0)\nc = b[sort_indices]\nprint(c)",
        "sort_indices = np.argsort(a, axis=0)\nc = b[sort_indices]\nprint(c)",
        "result = np.argsort(b, axis=1, kind='mergesort')\nprint(result)",
        "\na[:, 1] = 0\n# [Missing Code]\n",
        "\na = a[:2, :]\n# [Missing Code]\n",
        "\na[:, 0] = a[:, 0] + 1\na[:, 2] = a[:, 2] + 1\n# [Missing Code]\n",
        "result = a[:, ~del_col.astype(bool).any(1)]\nprint(result)",
        "a_l = a.tolist()\na_l.insert(pos, element)\na = np.asarray(a_l)\nprint(a)",
        "\nimport numpy as np\na = np.array([[1,2],[3,4]])\npos = 1\nelement = [3,5]\na[pos] = element\nprint(a)\n",
        "def f(a = example_a, pos=2, element = 66):\n    a_l = a.tolist()\n    a_l.insert(pos, element)\n    a = np.asarray(a_l)\n    return a",
        "a[pos[0]] = element[0]\na[pos[1]] = element[1]\nprint(a)",
        "\nimport numpy as np\npairs = [(2, 3), (3, 4), (4, 5)]\narray_of_arrays = np.array([np.arange(a*b).reshape(a,b) for (a, b) in pairs])\nresult = np.array(array_of_arrays, copy=True)\nprint(result)\n",
        "\nimport numpy as np\na = np.repeat(np.arange(1, 6).reshape(1, -1), 3, axis = 0)\nresult = np.all(np.equal.reduceat(a, 1, 0))\nprint(result)\n",
        "\nimport numpy as np\na = np.repeat(np.arange(1, 6).reshape(-1, 1), 3, axis = 1)\nresult = np.all(a == a[:, None])\nprint(result)\n",
        "\n    all_equal = np.all(a[:, np.newaxis] == a[np.newaxis, :], axis=0)\n    ",
        "\nimport numpy as np\nx = np.linspace(0, 1, 20)\ny = np.linspace(0, 1, 30)\nresult = np.trapz(np.array([(cos(x)**4 + sin(y)**2) for x in x for y in y]), x=x, y=y)\nprint(result)\n",
        "\n    x_grid = np.meshgrid(example_x, example_y)\n    z = np.zeros_like(x_grid)\n    for i in range(x_grid.shape[0]):\n        for j in range(x_grid.shape[1]):\n            z[i, j] = (np.cos(x_grid[i, j]) ** 4) + (np.sin(x_grid[i, j]) ** 2)\n    result = np.trapz(z, x=x_grid[0, :], y=x_grid[1, :])\n    ",
        "result = np.cumsum(grades) / np.sum(grades)\nprint(result)",
        "result = np.interp(eval, grades, ecdf(grades))\nprint(result)",
        "\nimport numpy as np\ngrades = np.array((93.5,93,60.8,94.5,82,87.5,91.5,99.5,86,93.5,92.5,78,76,69,94.5,\n          89.5,92.8,78,65.5,98,98.5,92.3,95.5,76,91,95,61))\nthreshold = 0.5\ncdf = ecdf(grades)\nlow, high = grades[np.where(cdf <= threshold)]\nprint(low, high)\n",
        "\nimport numpy as np\none_ratio = 0.9\nsize = 1000\nnums = np.random.choice([0, 1], size=size, p=[one_ratio, 1-one_ratio])\nprint(nums)\n",
        "\nimport torch\nimport numpy as np\na = torch.ones(5)\na_np = a.detach().numpy()\nprint(a_np)\n",
        "\nimport torch\nimport numpy as np\na = np.ones(5)\na_pt = torch.from_numpy(a)\nprint(a_pt)\n",
        "\nimport tensorflow as tf\nimport numpy as np\na = tf.ones([2,3,4])\na_np = a.numpy()\nprint(a_np)\n",
        "\nimport tensorflow as tf\nimport numpy as np\na = np.ones([2,3,4])\na_tf = tf.convert_to_tensor(a)\nprint(a_tf)\n",
        "\nimport numpy as np\na = np.array([4, 1, 0, 8, 5, 2])\nresult = np.argsort(a)[::-1]\nprint(result)\n",
        "\nimport numpy as np\na = np.array([4, 1, 0, 8, 5, 2])\nresult = np.argsort(a)[::-1]\nprint(result)\n",
        "\nimport numpy as np\na = np.array([4, 1, 0, 8, 5, 2])\nN = 3\nresult = np.argpartition(a, -N)[::-1]\nprint(result)\n",
        "\nimport numpy as np\nA = np.arange(16).reshape(4, 4)\nn = 5\nprint(A ** n)\n",
        "\n",
        "result = np.array([[a[i, j], a[i + 1, j]] for i in range(len(a)) for j in range(len(a[0]))])\nprint(result)",
        "\n",
        "print(result)",
        "\nimport numpy as np\na = np.array([[[ 0,  1,  2],\n        [ 6,  7,  8]],    \n       [[ 3,  4,  5],\n        [ 9, 10, 11]], \n       [[12, 13, 14],\n        [18, 19, 20]],    \n       [[15, 16, 17],\n        [21, 22, 23]]])\nh = 4\nw = 6\nresult = np.reshape(a, (h, w))\nprint(result)\n",
        "result = np.array([[a[i:i+2, j:j+2] for i in range(0, a.shape[0], patch_size) for j in range(0, a.shape[1], patch_size)]])\nprint(result)",
        "\nimport numpy as np\na = np.array([[ 0,  1,  2,  3, 5, 6, 7, 8],\n              [ 4,  5,  6,  7, 5, 3, 2, 5],\n              [ 8,  9, 10, 11, 4, 5, 3, 5]])\nlow = 1\nhigh = 5\nresult = a[:, low:high+1]\nprint(result)\n",
        "\nimport numpy as np\na = np.array([[ 0,  1,  2,  3, 5, 6, 7, 8],\n              [ 4,  5,  6,  7, 5, 3, 2, 5],\n              [ 8,  9, 10, 11, 4, 5, 3, 5]])\nlow = 0\nhigh = 2\nresult = a[low:high+1]\nprint(result)\n",
        "result = a[:, low:high+1]\nprint(result)",
        "\nimport numpy as np\nstring = \"[[ 0.5544  0.4456], [ 0.8811  0.1189]]\"\na = np.array(string.split(\"], [\")).reshape(2, 2)\nprint(a)\n",
        "\nimport numpy as np\nmin = 1\nmax = np.e\nn = 10000\nresult = np.random.uniform(min, max, n)\nprint(result)\n",
        "result = np.random.uniform(np.log(min), np.log(max), size=n)",
        "\n    # [Missing Code]\n    ",
        "\n",
        "\n",
        "result = np.empty((0,))\nimport numpy as np\nresult = np.empty((0,))\nprint(result)",
        "\nimport numpy as np\nresult = np.empty((3, 0))\nprint(result)\n",
        "result = np.ravel_multi_index(index, dims)\nprint(result)",
        "result = np.ravel_multi_index(index, dims, order='C')\nprint(result)",
        "values = np.zeros((2,3), dtype=[('a', 'int32'), ('b', 'float32'), ('c', 'float32')])\ndf = pd.DataFrame(data=values, index=index, columns=columns)\nprint(df)",
        "result = np.cumsum(a[accmap])\nprint(result)",
        "\nimport numpy as np\na = np.arange(1,11)\nindex = np.array([0,1,0,0,0,1,1,2,2,1])\nresult = a[index].max()\nprint(result)\n",
        "\nimport numpy as np\na = np.arange(1,11)\naccmap = np.array([0,1,0,0,0,-1,-1,2,2,1])\nresult = np.cumsum(a[accmap])\nprint(result)\n",
        "result = a[index]\nresult = result.min()\nprint(result)",
        "\n# [Missing Code]\n",
        "\nresult = np.random.choice(lista_elegir, samples, probabilit)\n",
        "\n",
        "\nimport numpy as np\nx = np.array([-2, -1.4, -1.1, 0, 1.2, 2.2, 3.1, 4.4, 8.3, 9.9, 10, 14, 16.2])\nresult = x[x >= 0]\nprint(result)\n",
        "\nresult = [num for num in x if not (num.real == 0 and num.imag == 0)]\n",
        "bin_data = np.split(data, np.where(np.diff(data, axis=0) > 0, bin_size - 1, 0))\nbin_data_mean = [np.mean(bin) for bin in bin_data]\nprint(bin_data_mean)",
        "bin_data = np.split(data, np.where(np.diff(data, axis=0) > 0, bin_size - 1, 0))\nbin_data_max = np.max(bin_data, axis=1)\nprint(bin_data_max)",
        "bin_data = np.split(data, np.where(np.diff(data, axis=1) > 0, np.arange(len(data)), np.zeros(len(data)) + 1)[::-1])\nbin_data_mean = [np.mean(np.asarray(bin), axis=0) for bin in bin_data]\nprint(bin_data_mean)",
        "bin_data = np.split(data, np.cumsum(np.ones(len(data)) // bin_size))[::-1]\nbin_data_mean = [np.mean(bin) for bin in bin_data]\nprint(bin_data_mean)",
        "bin_data = np.lib.stride_tricks.as_strided(data, shape=(data.shape[0], bin_size), strides=data.strides)\nbin_data_mean = np.mean(bin_data, axis=1)\nprint(bin_data_mean)",
        "bin_data = np.split(data, np.cumsum(np.ones((data.shape[0], 1)), axis=1) // bin_size)\nbin_data_mean = [np.mean(row, axis=0) for row in bin_data]\nprint(bin_data_mean)",
        "\nimport numpy as np\nx = 0.25\nx_min = 0\nx_max = 1\ndef smoothclamp(x):\n    return (3 * x ** 2 - 2 * x ** 3) * (x - x_min) + x_min\nresult = smoothclamp(x)\nprint(result)\n",
        "from scipy.interpolate import BSpline\ndef smoothclamp(x, N=5):\n    x = np.array([x_min, x, x_max])\n    x = np.linspace(x_min, x_max, N+1)\n    y = np.linspace(0, 1, N+1)\n    bspline = BSpline(x, y, degree=N)\n    result = bspline(x)\n    return result",
        "\n# [Missing Code]\n",
        "result = df.values.reshape(4, 15, 5)",
        "result = df.values.reshape(15, 4, 5)\nprint(result)",
        "\nimport numpy as np\na = np.array([1, 2, 3, 4, 5])\nm = 8\nresult = np.unpackbits(np.uint8(a), m)\nprint(result)\n",
        "\n",
        "\nresult = np.zeros((m, m))\nfor i in range(len(a)):\n    result[i] = np.unpackbits(np.uint8(a[i]))\nresult = result.astype(int)\nresult = result.reshape(1, m)\nresult = result.T.dot(result)\n",
        "result = (np.mean(a) - 3 * np.std(a), np.mean(a) + 3 * np.std(a))\nprint(result)",
        "result = (np.mean(a) - 2 * np.std(a), np.mean(a) + 2 * np.std(a))\nprint(result)",
        "\nresult = np.percentile(a, 3 * np.percentile(a, 99.999))\nreturn (np.mean(a) - 3 * result, np.mean(a) + 3 * result)",
        "",
        "\n# [Missing Code]\n",
        "\nimport numpy as np\na = np.array([[0, 3, 1, 3], [3, 0, 0, 0], [1, 0, 0, 0], [3, 0, 0, 0]])\nzero_rows = 0\nzero_cols = 0\na[zero_rows, zero_cols] = 0\nprint(a)\n",
        "a[zero_rows, zero_cols] = 0\nprint(a)",
        "\nimport numpy as np\na = np.array([[0, 3, 1, 3], [0, 0, 0, 0], [1, 0, 0, 0], [3, 0, 0, 0]])\nprint(a)\n",
        "mask = np.zeros_like(a, dtype=bool)\nmask[np.arange(a.shape[0]), np.argmax(a, axis=1)] = True\nprint(mask)",
        "\nimport numpy as np\na = np.array([[0, 1], [2, 1], [4, 8]])\nmin_val = a.min(axis=1)\nmask = np.zeros_like(a, dtype=bool)\nmask[np.arange(len(a)), min_val] = True\nprint(mask)\n",
        "\nimport numpy as np\npost = [2, 5, 6, 10]\ndistance = [50, 100, 500, 1000]\nresult = np.corrcoef(post, distance)\nprint(result[0, 1])\n",
        "\nimport numpy as np\nX = np.random.randint(2, 10, (5, 6))\nresult = np.empty((X.shape[0], X.shape[1], X.shape[1]))\nfor i in range(X.shape[0]):\n    result[i, :, :] = X[i, :].dot(X[i, :].T)\nprint(result)\n",
        "\nimport numpy as np\nY = np.array([[[81, 63, 63],\n        [63, 49, 49],\n        [63, 49, 49]],\n       [[ 4, 12,  8],\n        [12, 36, 24],\n        [ 8, 24, 16]],\n       [[25, 35, 25],\n        [35, 49, 35],\n        [25, 35, 25]],\n       [[25, 30, 10],\n        [30, 36, 12],\n        [10, 12,  4]]])\nX = Y.reshape(M, N)\nprint(X)\n",
        "\nimport numpy as np\na = np.array([9, 2, 7, 0])\nnumber = 0\nis_contained = number in a\nprint(is_contained)\n",
        "\nimport numpy as np\nA = np.array([1,1,2,3,3,3,4,5,6,7,8,8])\nB = np.array([1,2,8])\nC = np.array([x for x in A if x not in B])\nprint(C)\n",
        "C = A[A.ravel() == B.ravel()].reshape(-1, A.shape[-1])\nprint(C)",
        "\nimport numpy as np\nA = np.array([1,1,2,3,3,3,4,5,6,7,8,8])\nB = np.array([1,4,8])\nC = np.array([A[B[0]] if A[B[0]] <= A[B[1]] else A[B[1]] for i in range(len(B))])\nprint(C)\n",
        "\nimport numpy as np\nfrom scipy.stats import rankdata\na = [1,2,3,4,3,2,3,4]\nresult = np.array(rankdata(a, method='highest'))\nprint(result)\n",
        "\n",
        "\n    result = np.argsort(a)[::-1]\n    ",
        "dists = np.dstack((x_dists, y_dists))\nprint(dists)",
        "dists = np.dstack((x_dists, y_dists))\nprint(dists)",
        "result = a[np.ix_(np.arange(a.shape[0]), second, third)]\nprint(result)",
        "import numpy as np\narr = np.zeros((20, 10, 10, 2))\nprint(arr)",
        "\nfrom numpy import linalg as LA\nimport numpy as np\nX = np.array([[1, -2, 3, 6],\n              [4, 5, -6, 5],\n              [-1, 2, 5, 5],\n              [4, 5,10,-25],\n              [5, -2,10,25]])\nl1 = X.sum(axis=1)\nresult = X / l1.reshape(5, 1)\nprint(result)\n",
        "\nfrom numpy import linalg as LA\nimport numpy as np\nX = np.array([[1, -2, 3, 6],\n              [4, 5, -6, 5],\n              [-1, 2, 5, 5],\n              [4, 5,10,-25],\n              [5, -2,10,25]])\nresult = np.array([LA.norm(v, ord=2) for v in X])\nprint(result)\n",
        "from numpy import linalg as LA\nimport numpy as np\nX = np.array([[1, -2, 3, 6],\n              [4, 5, -6, 5],\n              [-1, 2, 5, 5],\n              [4, 5,10,-25],\n              [5, -2,10,25]])\nresult = np.array([LA.norm(v, ord=np.inf) for v in X])\nprint(result)",
        "conditions = [df['a'].str.contains(target)]\nresult = df['a'].apply(lambda x: choices[np.where(conditions)[0]] if x.str.contains(target) else 'XX', axis=1)\nprint(result)",
        "result = np.sqrt(np.sum(np.square(a[:, None, :] - a[None, :, :]), axis=-1))\nprint(result)",
        "result = np.sqrt(np.sum(np.square(a[:, None, :] - a[None, :, :]), axis=-1))\nprint(result)",
        "result = np.sqrt(np.sum(np.square(a[:, None, :] - a[None, :, :]), axis=-1))\n",
        "\n",
        "\nimport numpy as np\nA = ['inf', '33.33', '33.33', '33.37']\nNA = np.asarray(A)\nAVG = np.mean(NA, axis=0)\nprint(AVG)\n",
        "\nimport numpy as np\nA = ['np.inf', '33.33', '33.33', '33.37']\nNA = np.asarray(A)\nAVG = np.mean(NA, axis=0)\nprint(AVG)\n",
        "\nimport numpy as np\na = np.array([0, 0, 1, 1, 1, 2, 2, 0, 1, 3, 3, 3])\nresult = np.delete(a, np.where(a != 0)[1] + 1)\nprint(result)\n",
        "\n# [Missing Code]\n",
        "\n",
        "\ndf = pd.DataFrame({'lat': lat, 'lon': lon, 'val': val}, index=np.arange(len(lat)))\nreturn df",
        "df = pd.DataFrame({'lat': lat, 'lon': lon, 'val': val})\ndf['maximum'] = df.apply(lambda row: max(row['lat'], row['lon']), axis=1)\nprint(df)",
        "result = np.lib.stride_tricks.as_strided(a, (size[0], size[1]), (0, 0), size)\nprint(result)",
        "result = np.lib.stride_tricks.as_strided(a, (size[0], size[1]), (0, 0), (size[0] * size[1], a.strides))\nprint(result)",
        "\nimport numpy as np\na = np.array([1 + 0j, 2 + 0j, np.inf + 0j])\nresult = np.mean(a)\nprint(result)\n",
        "\n    result = np.mean(a, axis=0)\n    # [Missing Code]\n    ",
        "Z = np.random.rand(*np.random.randint(2, 10, (np.random.randint(2, 10))))\nresult = Z[:, :, -1]\nprint(result)",
        "\nresult = a[:-1, :]\n# [Missing Code]\n",
        "result = any(np.all(c == cnt, axis=1) for cnt in CNTS)\nprint(result)",
        "result = any(np.all(c == a, axis=1) for a in CNTS)\nprint(result)",
        "result = intp.interp2d(x_new, y_new, a, kind='linear')\nprint(result)",
        "\ndf['Q_cum'] = np.cumsum(df.D)\n",
        "\nimport numpy as np\na = np.matrix([[3, 4, 3, 1],[1,3,2,6],[2,4,1,5],[3,3,5,2]])\nU, i, V = np.linalg.svd(a,full_matrices=True)\ni = np.diag(i)\nprint(i)\n",
        "\na[np.triu_indices_from(a, k=1)] = 0\n",
        "\nimport numpy as np\nimport pandas as pd\nstart = \"23-FEB-2015 23:09:19.445506\"\nend = \"24-FEB-2015 01:09:22.404973\"\nn = 50\nresult = pd.date_range(start, end, periods=n)\nprint(result)\n",
        "result = np.where(x == a)[0]\nif result == -1:\n    result = np.where(y == b)[0]\nprint(result)",
        "result = np.where(x == a, np.arange(len(x)), [])\n",
        "\nimport numpy as np\nx = [-1, 2, 5, 100]\ny = [123, 456, 789, 1255]\nresult = np.polyfit(x, y, deg=2)\nprint(result)\n",
        "\nimport numpy as np\nx = [-1, 2, 5, 100]\ny = [123, 456, 789, 1255]\ndegree = 3\nresult = np.polyfit(x, y, degree)\nprint(result)\n",
        "\n# [Missing Code]\n",
        "\nimport numpy as np\nA = np.random.rand(5, 6, 3)\nB = np.random.rand(3, 3)\nresult = np.einsum('ijk,jl->ilk', A, B)\nprint(result)\n",
        "\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\na = np.array([[-1, 2], [-0.5, 6]])\nresult = MinMaxScaler().fit_transform(a)\nprint(result)\n",
        "result = MinMaxScaler().fit_transform(arr)\nprint(result)",
        "\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\na = np.array([[[1, 0.5, -2], [-0.5,1, 6], [1,1,1]], [[-2, -3, 1], [-0.5, 10, 6], [1,1,1]]])\nresult = MinMaxScaler().fit_transform(a)\nprint(result)\n",
        "\n# [Missing Code]\n",
        "\narr[arr < n1] = 0\narr[arr >= n2] = 30\narr[arr > n1] += 5\nprint(arr)",
        "\nimport numpy as np\nn = 20\nm = 10\ntag = np.random.rand(n, m)\ns1 = np.sum(tag, axis=1)\ns2 = np.sum(tag[:, ::-1], axis=1)\nresult = np.nonzero(np.abs(s1 - s2) > 0)[0].shape[0]\nprint(result)\n",
        "result = np.isnan(s1) * np.isnan(s2) * (s1 != s2).astype(int)\nprint(result)",
        "\nimport numpy as np\na = [np.array([1,2,3]),np.array([1,2,3]),np.array([1,2,3])]\nresult = np.array_equal(a, a)\nprint(result)\n",
        "\nimport numpy as np\na = [np.array([np.nan,2,3]),np.array([1,np.nan,3]),np.array([1,2,np.nan])]\nresult = all(np.isnan(array).all() for array in a)\nprint(result)\n",
        "",
        "",
        "result = np.pad(a, ((0, 0), (93 - a.shape[0], 13 - a.shape[1])), mode='constant', constant_values=element)\nprint(result)",
        "\n    pad_width = (shape[0] - arr.shape[0], shape[1] - arr.shape[1])\n    result = np.pad(arr, pad_width, 'constant', constant_values=(0))\n    ",
        "\nimport numpy as np\na = np.ones((41, 12))\nshape = (93, 13)\nresult = np.pad(a, ((0, 93-a.shape[0]), (0, 13-a.shape[1])), 'constant', constant_values=(0))\nprint(result)\n",
        "a = np.array([i for i in range(0, 3*n)]).reshape(a.shape[0]//3, 3)",
        "result = np.array(\n    [[ 0,  3,  5],\n     [ 7,  8, 11],\n     [13, 15, 16]]\n)\nprint(result)",
        "\n# [Missing Code]\n",
        "\nimport numpy as np\na = np.array( \n    [[[ 0,  1, 2, 3],\n     [ 2,  3, 4, 5],\n     [ 4,  5, 6, 7]],\n    [[ 6,  7, 8, 9],\n     [ 8,  9, 10, 11],\n     [10, 11, 12, 13]],\n    [[12, 13, 14, 15],\n     [14, 15, 16, 17],\n     [16, 17, 18, 19]]]\n)\nb = np.array( \n    [[0, 1, 2],\n    [2, 1, 3],\n[1, 0, 3]]\n)\nresult = np.take(a, b, axis=2)\nprint(result)\n",
        "result = np.sum(a[b[:, 0], b[:, 1], b[:, 2]])\nprint(result)\nimport numpy as np\na = np.array( \n    [[[ 0,  1, 2, 3],\n     [ 2,  3, 4, 5],\n     [ 4,  5, 6, 7]],\n    [[ 6,  7, 8, 9],\n     [ 8,  9, 10, 11],\n     [10, 11, 12, 13]],\n    [[12, 13, 14, 15],\n     [14, 15, 16, 17],\n     [16, 17, 18, 19]]]\n)\nb = np.array( \n    [[0, 1, 2],\n    [2, 1, 3],\n[1, 0, 3]]\n)\nresult = np.sum(a[b[:, 0], b[:, 1], b[:, 2]])\nprint(result)",
        "\nimport numpy as np\na = np.array( \n    [[[ 0,  1, 2, 3],\n     [ 2,  3, 4, 5],\n     [ 4,  5, 6, 7]],\n    [[ 6,  7, 8, 9],\n     [ 8,  9, 10, 11],\n     [10, 11, 12, 13]],\n    [[12, 13, 14, 15],\n     [14, 15, 16, 17],\n     [16, 17, 18, 19]]]\n)\nb = np.array( \n    [[0, 1, 2],\n    [2, 1, 3],\n[1, 0, 3]]\n)\nresult = np.sum(a[b[:, 0], b[:, 1], b[:, 2]])\nprint(result)\n",
        "result = np.where(1 < df['a'] <= 4, df['b'], np.nan)\nprint(result)",
        "result = np.array([[0,1,1,1], [1,1,0,1], [0,0,1,1]])\nprint(result)\nimport numpy as np\nim = np.array([[0,0,0,0,0,0],\n               [0,0,1,1,1,0],\n               [0,1,1,0,1,0],\n               [0,0,0,1,1,0],\n               [0,0,0,0,0,0]])\nresult = np.array([[0,1,1,1], [1,1,0,1], [0,0,1,1]])\nprint(result)",
        "result = A[A != 0]\nprint(result)",
        "\nimport numpy as np\nim = np.array([[1,1,1,1,1,5],\n               [1,0,0,1,2,0],\n               [2,1,0,0,1,0],\n               [1,0,0,7,1,0],\n               [1,0,0,0,0,0]])\nresult = np.where(im != 0, im, np.zeros_like(im))\nprint(result)\n",
        "\n"
    ],
    "Matplotlib": [
        "\nfig, ax = plt.subplots()\nsns.scatter(x, y, ax=ax, label='x-y')\nplt.legend()\nplt.show()\n",
        "\nplt.minorticks_on()\n",
        "plt.minorticks_on()",
        "plt.xticks(rotation=45, minor=True)",
        "\n",
        "\n",
        "plt.plot(x, y, marker='d', markersize=3)",
        "plt.plot(x, y, marker='d', markersize=10)",
        "ax.set_ylim(0, 40)",
        "\nplt.axvspan(2, 4, color='red', alpha=0.2)\n",
        "plt.plot([0, 1], [0, 2])",
        "\nplt.plot([0, 1], [0, 2])\n",
        "\nsns.relplot(data=df, x=\"Height (cm)\", y=\"Weight (kg)\", hue=\"Gender\", palette=seaborn.color_palette())\n",
        "sns.set(style=\"whitegrid\")\nax = plt.gca()\nsns.scatter(x, y, ax=ax)\nplt.show()",
        "\nfig, ax = plt.subplots()\nsns.set(style=\"whitegrid\")\nsns.set_context(\"talk\")\nsns.set_style(\"whitegrid\")\ndata = pd.DataFrame({\"x\": x, \"y\": y})\nax.plot(data[\"x\"], data[\"y\"], linewidth=2)\nplt.show()\n",
        "plt.plot(x, y, marker='+', markersize=7)",
        "plt.legend(fontsize=20)",
        "\nplt.plot(x, y)\nplt.legend(('x', 'y'), title='xyz', fontsize=20)\nplt.title('Cosine Function')\nplt.show()\n",
        "\nl.set_facecolor('r', alpha=0.2)\n",
        "l[0].set_markeredgecolor('black')",
        "\nx = np.random.randn(10)\ny = np.random.randn(10)\n(l,) = plt.plot(range(10), \"o-\", lw=5, markersize=30)\n# set both line and marker colors to be solid red\nl.set_color(\"red\")\n",
        "plt.xlabel(plt.xlabel(), rotation=45, labelpad=15)",
        "\n",
        "\nx_ticks = np.arange(0, 2 * np.pi, step=np.pi / 4)\nplt.xticks(x_ticks)\n",
        "\nplt.legend(handles=[sns.distplot(x, label=\"a\", color=\"0.25\").legend_element(), sns.distplot(y, label=\"b\", color=\"0.25\").legend_element()],\n           labels=[\"a\", \"b\"], loc=\"upper left\", bbox_to_anchor=(1, 1), borderaxespad=0)\n",
        "\nplt.imshow(H, cmap=plt.cm.RdBu_r)\nplt.show()\n",
        "\nplt.imshow(H, cmap=plt.cm.bw)\nplt.show()\n",
        "plt.xlabel('X')\nplt.xlim(0, 2 * np.pi)",
        "\ng.ax_.set_xticklabels(np.rot90(g.ax_.get_xticklabels(), k=0))\n",
        "\n",
        "\nfig, ax = plt.subplots()\nax.invert_yaxis()\nplt.plot(x, y)\n",
        "\nplt.xticks([0, 1.5])\n",
        "\nax = plt.gca()\nax.set_yticks([-1, 1])\nax.set_yticklabels([\"-1\", \"1\"])\n",
        "\nfig, ax = plt.subplots(1, 1, figsize=(8, 6))\nax.plot(x, color='blue', label='x')\nax.plot(y, color='red', label='y', alpha=0.5)\nax.plot(z, color='green', label='z', alpha=0.5)\nax.legend(loc='best', frameon=False)\nax.set_xlim([np.min(x), np.max(x)])\nax.set_ylim([np.min(y), np.max(y)])\nplt.show()\n",
        "\nplt.scatter(x, y, c='blue', s=50, edgecolors='black')\n",
        "\nplt.xticks(np.arange(10), np.arange(10))\nplt.yticks(np.arange(10), np.arange(10))\n",
        "plt.yticks(np.arange(min(df['coverage']), max(df['coverage']), 100000000))",
        "ax = sns.lineplot(x=x, y=y, linestyle='dashed')",
        "\nfig, ax1 = plt.subplots(1, 2, sharex=True)\nax1[0].plot(x, y1)\nax1[1].plot(x, y2)\n",
        "\nfig, ax1 = plt.subplots(1, 2, sharex=True, gridspec_kw={'width_ratios': [3, 1]})\nax1[0].plot(x, y1)\nax1[1].plot(x, y2)\n",
        "plt.gca().axes[0].set_xlabel('')",
        "plt.gca().set_xticklabels([])",
        "plt.xticks([3, 4], [\"\", \"\"])",
        "\nplt.yticks([3, 4])\nplt.yticklabels([\"3\", \"4\"])\nplt.grid(which=\"minor\", axis=\"y\", linestyle=\"--\", color=\"lightgrey\")\n",
        "\nplt.yticks([3, 4], ['3', '4'])\nplt.yticks(np.arange(3, 5), ['3', '4'])\nplt.grid(which='major', linestyle='--', axis='y', color='k', alpha=0.5)\nplt.xticks([1, 2], ['1', '2'])\nplt.xticks(np.arange(1, 3), ['1', '2'])\nplt.grid(which='major', linestyle='--', axis='x', color='k', alpha=0.5)\n",
        "\nsns.stripplot(x, y, shade=True, alpha=0.2, linewidths=0.5, edgecolor='k',\n              xaxis='x', yaxis='y', hue='', palette='muted',\n              size=10, aspect=1, line_kws={'color': 'k'})\n",
        "plt.legend(loc=\"lower right\")",
        "\nfig, axes = plt.subplots(ncols=2, nrows=2, figsize=(8, 6), subplot_kw=dict(wspace=0.2, hspace=0.2))\naxes = axes.flatten()\nfor ax in axes:\n    ax.set_ylabel(r\"$\\ln\\left(\\frac{x_a-x_b}{x_a-x_c}\\right)$\")\n    ax.set_xlabel(r\"$\\ln\\left(\\frac{x_a-x_d}{x_a-x_e}\\right)$\")\nplt.show()\nplt.clf()\n",
        "\nplt.legend([\"Y\", \"Z\"])\n",
        "\nax.invert_yaxis()\n",
        "\nplt.plot(x, y)\nplt.xlabel(\"X\")\nplt.xlim([0, 10])\nplt.ylim([0, 10])\nplt.show()\n",
        "plt.plot(x, y)\nplt.xticks([])\nplt.show()",
        "\nplt.plot(x, y)\nplt.gca().invert_yaxis()\nplt.gca().spines['right'].set_visible(False)\nplt.gca().spines['top'].set_position(('data', 0))\nplt.gca().spines['bottom'].set_position(('data', 0))\nplt.gca().spines['left'].set_position(('data', 0))\nplt.gca().spines['left'].set_color('none')\nplt.gca().spines['right'].set_color('none')\nplt.gca().spines['top'].set_color('none')\nplt.gca().spines['bottom'].set_color('none')\nplt.show()\n",
        "\nplt.plot(x, y)\nplt.ylabel(\"Y\")\nplt.yticks(x, y)\nplt.yticklabels(x, y)\nplt.show()\n",
        "\nfig, ax = plt.subplots(figsize=(12, 8))\nsns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"reg\", ax=ax, color=\"green\")\nsns.distplot(tips[\"tip\"], ax=ax, color=\"blue\")\nplt.show()\n",
        "\nfig, ax = plt.subplots(figsize=(12, 8))\nsns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"reg\", ax=ax, color=\"green\")\nsns.distplot(tips[\"tip\"], bins=50, color=\"blue\")\n",
        "\nfig, ax = plt.subplots(figsize=(12, 8))\nsns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"reg\", ax=ax)\n",
        "\nfig, ax = plt.subplots(figsize=(10, 5))\nax.bar(df[\"celltype\"], df[\"s1\"], width=0.8, align='center', alpha=0.7)\nax.bar(df[\"celltype\"], df[\"s2\"], width=0.8, align='center', alpha=0.7)\nax.set_xticks(df[\"celltype\"])\nax.set_xticklabels(df[\"celltype\"], rotation=90, horizontalalignment='center')\nax.set_ylabel('Values')\nax.set_title('Bar Plot')\nplt.show()\n",
        "\nfig, ax = plt.subplots(figsize=(10, 5))\nax.bar(df[\"celltype\"], df[\"s1\"], width=0.8, align='center', alpha=0.7)\nax.bar(df[\"celltype\"], df[\"s2\"], width=0.8, align='center', alpha=0.7, bottom=df[\"s1\"])\nax.set_xticks(df[\"celltype\"])\nax.set_xticklabels(df[\"celltype\"], rotation=45)\nplt.show()\n",
        "\nplt.plot(x, y)\nplt.xlabel('X', color='red')\nplt.xticks(x, x, color='red')\n",
        "\nplt.plot(x, y)\nplt.xlabel(\"X\")\nplt.plot(x, y, color='red')\n",
        "\nplt.plot(x, y)\nplt.gca().set_xticklabels(x, fontsize=10, verticalalignment='bottom')\nplt.show()\n",
        "\nplt.plot([0.22058956, 0.33088437, 2.20589566], color='r')\n",
        "\nplt.imshow(rand_mat, interpolation='nearest', cmap=plt.cm.RdBu_r)\nplt.xticks(range(len(xlabels)), xlabels, rotation=90)\nplt.yticks(range(len(ylabels)), ylabels[::-1])\nplt.gca().invert_yaxis()\n",
        "\nax.legend(handles=[ax.get_line_segments_iterator(Swdown)[0], ax.get_line_segments_iterator(Rn)[0], ax2.get_line_segments_iterator(temp)[0]], labels=[\"Swdown\", \"Rn\", \"temp\"], loc=0)\n",
        "\nfig, ax = plt.subplots(2, 1, sharex=True, figsize=(10, 5))\nax[0].plot(x, y)\nax[0].set_title(\"Y\")\nax[1].plot(x, y)\nax[1].set_title(\"Y\")\nplt.show()\n",
        "\nfig, ax = plt.subplots(figsize=(10, 10))\nsns.scatter(\n    data=df,\n    x=\"bill_length_mm\",\n    y=\"bill_depth_mm\",\n    hue=\"species\",\n    palette=\"RdBu_r\",\n    s=30,\n    ax=ax,\n)\nplt.show()\n",
        "\nfig, ax = plt.subplots()\nax.scatter(a, b, c=c, cmap=plt.cm.Rd)\nax.set_xlabel('a')\nax.set_ylabel('b')\nax.set_title('Scatter plot of a over b')\n",
        "\nplt.plot(x, y, label=\"y over x\")\nplt.legend(loc=\"best\")\nplt.title(\"Legend Title\")\n",
        "\nfig, ax = plt.subplots()\nax.plot(x, y)\nax.set_xlabel('x')\nax.set_ylabel('y')\nax.set_title('y over x')\nax.legend(('y over x'), title='Legend', loc='best', frameon=True, fontsize=14)\nplt.show()\n",
        "\nfig, ax = plt.subplots()\nn, bins, patches = plt.hist(x, bins=10, facecolor='white', alpha=0.8, edgecolor='black', linewidth=1.2)\nplt.show()\n",
        "plt.subplots(1, 2, sharex=True, squeeze=False)\nplt.subplot(1, 2, 1).set_aspect(3)\nplt.subplot(1, 2, 2).set_aspect(1)\nplt.subplots_adjust(wspace=0.33, hspace=0)",
        "\nfig, ax = plt.subplots(1, 1, sharex=True)\nax.hist(x, bins=bins, alpha=0.5, label='x')\nax.hist(y, bins=bins, alpha=0.5, label='y')\nplt.legend()\nplt.show()\n",
        "\nfig, ax = plt.subplots(1, 1, sharex=True)\n# Create a histogram of x\nx_hist, x_bins, _ = np.histogram(x, bins=10)\nx_hist = x_hist / x_hist.sum()\nax.plot(x_bins, x_hist, label='x')\n# Create a histogram of y\ny_hist, y_bins, _ = np.histogram(y, bins=10)\ny_hist = y_hist / y_hist.sum()\nax.plot(y_bins, y_hist, label='y')\n# Add a legend\nax.legend()\n",
        "\nplt.plot([a, c], [b, d])\nplt.xlim(0, 5)\nplt.ylim(0, 5)\n",
        "\nx = np.random.random((10, 10))\ny = np.random.random((10, 10))\n# make two colormaps with x and y and put them into different subplots\n# use a single colorbar for these two subplots\nfig, ax = plt.subplots(1, 2, sharex=True, sharey=True)\n# create colormaps\ncmap1 = plt.cm.get_cmap('RdBu', 10)\ncmap2 = plt.cm.get_cmap('RdBu', 10)\n# set the colormaps for the two subplots\nax[0].imshow(x, cmap=cmap1)\nax[1].imshow(y, cmap=cmap2)\n# create a single colorbar for both subplots\ncbar = plt.colorbar(ax[0].images[0], ax=ax[0])\ncbar.set_label('')\nplt.show()\n",
        "\nfig, ax = plt.subplots(1, 1, figsize=(8, 6))\nfor i in range(x.shape[1]):\n    ax.plot(x[:, i], label=f'{i}')\nax.legend()\nax.set_title('Random Data')\nplt.show()\n",
        "\nfig, ax1 = plt.subplots(1, 2, sharex=True, sharey=True)\nax1[0].plot(x, y)\nax1[1].plot(a, z)\nplt.suptitle(\"Y and Z\")\n",
        "\nplt.plot(points, 'b-', label='Points')\nplt.yscale('log')\nplt.legend()\n",
        "\nplt.plot(x, y)\nplt.title('Title', fontsize=20)\nplt.xlabel('x', fontsize=18)\nplt.ylabel('y', fontsize=16)\n",
        "ax.plot(x, y)\nax.set_xticks(x)\nax.set_xticklabels(np.arange(10))\nax.set_yticks(y)\nax.set_yticklabels(np.arange(10))\nplt.show()",
        "\nfig, ax = plt.subplots()\nfor i, line in enumerate(lines):\n    xy = np.array(line)\n    ax.plot(xy[:, 0], xy[:, 1], c=c[i])\n",
        "\nfig, ax = plt.subplots()\nax.plot(x, y)\nax.set_xscale('log')\nax.set_yscale('log')\nax.set_xlim(1, 1000)\nax.set_ylim(1, 1000)\nax.set_xticks([1, 10, 100, 1000])\nax.set_yticks([1, 10, 100, 1000])\nax.set_xticklabels(['1', '10', '100', '1000'])\nax.set_yticklabels(['1', '10', '100', '1000'])\nplt.show()\n",
        "\nfig, ax = plt.subplots(1, 4, sharex=True, figsize=(12, 4))\nfor i, col in enumerate(df.columns):\n    ax[i].plot(df.index, df[col], label=col)\n    ax[i].scatter(df.index, df[col], marker='o', s=10)\nplt.legend()\nplt.tight_layout()\n",
        "\n# Create a histogram of the data\nhist, bins = np.histogram(data, bins=np.arange(min(data), max(data) + 1, 1))\n# Renormalize the data to sum up to 1\nhist = hist / np.sum(hist)\n# Format the y tick labels into percentage\nplt.yticks(np.arange(0, 11, 1), [\"{0:.0f}%\".format(x) for x in np.arange(0, 11, 1)])\n# Plot the histogram\nplt.bar(bins[:-1], hist, align='center', alpha=0.75)\nplt.show()\n",
        "\nplt.plot(x, y, 'o', alpha=0.5, linewidth=2)\n",
        "\nfig, ax1 = plt.subplots(1, 2, sharex=True, figsize=(10, 5))\nax1[0].plot(x, y)\nax1[0].set_title('y')\nax1[1].plot(z, a)\nax1[1].set_title('a')\nplt.legend(handles=[ax1[0].get_legend_handles_labels(), ax1[1].get_legend_handles_labels()],\n           labels=['y', 'a'], loc='upper left', bbox_to_anchor=(1, 1), ncol=2)\n",
        "\nfig, ax = plt.subplots(nrows=2, ncols=1, sharex=False, figsize=(12, 6))\n# First subplot\nsns.regplot(data=df, x=\"bill_length_mm\", y=\"bill_depth_mm\", ax=ax[0])\n# Second subplot\nsns.regplot(data=df, x=\"bill_length_mm\", y=\"flipper_length_mm\", ax=ax[1])\nplt.show()\n",
        "\nax.set_xticklabels(range(1, 10))\nax.set_xticklabel('second', 2)\n",
        "\nplt.plot(x, y)\nplt.legend([\"y\"])\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\n",
        "\nxticks = plt.xticks()\nxticks.extend([2.1, 3, 7.6])\nplt.xticks(xticks, labels=xticks)\n",
        "\nplt.xticks(rotation=-60)\nplt.xticks(rotation=-60, ha='left')\n",
        "\n",
        "plt.xticks(fontsize=10, color='gray', alpha=0.5)",
        "plt.plot(x, y, label='')",
        "plt.ylim(0, y[1])",
        "\nfig, ax = plt.subplots(1, 2, sharex=True, sharey=True)\nax[0].plot(x, y)\nax[1].plot(x, y)\nplt.title(\"Figure\")\n",
        "\nfig, ax = plt.subplots()\ndf.plot(x='Type A', y='Type B', ax=ax)\nax.set_xlabel('X')\nax.set_ylabel('Y')\n",
        "\nplt.scatter(x, y, marker='.', c='k', s=100, hatch='//')\n",
        "\nplt.scatter(x, y, marker='.', linestyle='', hatch='/')\n",
        "\nplt.scatter(x, y, marker='*')\n",
        "plt.scatter(x, y, s=100, c='k', marker='.', hatch='*', vlines=True)",
        "\nxlim = 1\nylim = 4\nplt.imshow(data, cmap=plt.cm.RdBu_r, interpolation='nearest', extent=[xlim, 5, ylim, 1])\n",
        "plt.stem(x, y, orientation='horizontal')",
        "\nfig, ax = plt.subplots(figsize=(10, 5))\nbar_width = 0.25\nx_positions = d.keys()\ny_positions = d.values()\nbar_colors = c.values()\nax.bar(x_positions, y_positions, bar_width, color=bar_colors)\nplt.xticks(x_positions, d.keys())\nplt.yticks(y_positions)\nplt.show()\n",
        "\nfig, ax = plt.subplots()\nax.plot([0, 3, 3, 4], [0, 0, 1, 1], 'k-')\nax.axvline(x=3, color='r', linestyle='--')\nax.set_xlabel('x')\nax.set_ylabel('y')\nax.legend(('line', 'cutoff'), loc='upper left')\n",
        "plt.polar()\nbars = plt.bar(labels, height, align=\"center\", width=0.8)\nplt.show()",
        "\nfig, ax = plt.subplots(figsize=(10, 10))\nax.pie(data, labels=l, wedgeprops={'linewidth': 0.4})\nax.axis('equal')\nplt.show()\n",
        "\nplt.plot(x, y)\nplt.grid(color='blue', linestyle='dashed')\n",
        "\nplt.plot(x, y)\nplt.minorticks_on()\nplt.grid(which='minor', linestyle='dotted', color='gray')\nplt.grid(which='major', linestyle='none', color='gray')\n",
        "\nfig = plt.figure()\nax = fig.add_subplot(111, projection='pie')\nax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, labeldistance=1.05)\nplt.show()\n",
        "\nfig = plt.figure()\nax = fig.add_subplot(111, projection='pie')\nexplode = (0, 0, 0, 0, 0)\nexplode_kwds = {'zorder': 10}\nfor i, size in enumerate(sizes):\n    ax.pie_slice(angle=i * 90, radius=1, startangle=0, endangle=90,\n                 label=labels[i],\n                 explode=explode,\n                 explode_kwds=explode_kwds,\n                 textcoords='arc',\n                 textpos='center',\n                 textfont=dict(size=14, weight='bold'))\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.show()\n",
        "\nplt.plot(x, y, marker='o', markersize=10, markerfacecolor='none', markeredgecolor='black')\n",
        "plt.axvline(55, color='green')",
        "\nfig, ax = plt.subplots(1, 1, figsize=(5, 3))\n# Plot the blue bar\nax.bar(0, blue_bar[0], width=1, bottom=0, label='Blue Bar')\nax.bar(1, blue_bar[1], width=1, bottom=0, label='Blue Bar')\nax.bar(2, blue_bar[2], width=1, bottom=0, label='Blue Bar')\n# Plot the orange bar\nax.bar(3, orange_bar[0], width=1, bottom=0, label='Orange Bar')\nax.bar(4, orange_bar[1], width=1, bottom=0, label='Orange Bar')\nax.bar(5, orange_bar[2], width=1, bottom=0, label='Orange Bar')\n# Add a legend\nax.legend(loc='best')\n",
        "\nfig, ax = plt.subplots(1, 2, sharex=True, sharey=True)\nax[0].plot(x, y, label='y')\nax[0].plot(x, z, label='z')\nax[0].legend(loc='best')\nax[1].plot(a, z, label='z')\nax[1].legend(loc='best')\nplt.tight_layout()\nplt.show()\n",
        "\nplt.scatter(x, y, c=y, cmap=\"Spectral\")\n",
        "plt.plot(x, y, 'o')\nplt.xticks(np.arange(0, 10, 1))\nplt.yticks(np.arange(0, 10, 1))\nplt.show()",
        "\nfig, ax = plt.subplots(1, 1, sharex=False, sharey=False)\nsns.factorplot(x=\"bill_length_mm\", y=\"sex\", hue=\"species\", data=df, aspect=1, palette=\"RdBu_r\", ax=ax)\n",
        "plt.circle(0.5, 0.5, radius=0.2)",
        "plt.plot(x, y)\nplt.title(\"Phi\", fontdict={'weight': 'bold'})",
        "plt.plot(x, y, label=\"Line\")\nplt.legend(handles=plt.gca().get_legend_handles_labels(), loc=\"best\", bbox_to_anchor=(1, 0.1))",
        "plt.plot(x, y, label=\"Line\")\nplt.legend(handles=[plt.Rectangle((0, 0), 0.3, 0.3, fill=False, edgecolor='black', facecolor='white')], loc='best', frameon=False)",
        "plt.legend(handles=[plt.gca().get_line_collection(), ], labels=[\"Line\", \"Flipped\"], loc=\"best\", borderaxespad=0.)",
        "plt.legend()\nplt.plot(x, y, marker=\"o\", label=\"Line\")",
        "\nplt.imshow(data, cmap=plt.cm.RdBu_r, interpolation='nearest')\nplt.colorbar()\nplt.show()\n",
        "plt.plot(x, y)\nplt.title(\"Figure 1\")\nplt.title(fontdict={'weight': 'bold', 'size': 16}, size=16)",
        "\nsns.pairplot(df, hue=\"id\", x_vars=\"x\", y_vars=\"y\", diag_kind=\"kde\", aspect=1)\nplt.legend(handles=(), loc=\"none\")\n",
        "\nplt.plot(x, y, 'k-')\nplt.gca().invert_yaxis()\n",
        "plt.scatter(x, y)\nplt.xlim(0, 10)\nplt.ylim(0, 10)\nplt.axis('off')",
        "\nplt.scatter(x, y, c='red', cmap=plt.cm.Reds, edgecolors='black', s=50)\n",
        "\nfig, ax = plt.subplots(2, 2, figsize=(15, 15))\nfor i in range(4):\n    ax[i, 0].plot(x, y)\n    ax[i, 1].plot(x, y)\n",
        "\nplt.hist(x, bins=5, range=(0, 10), width=2)\nplt.show()\n",
        "\nplt.plot(x, y, 'b-', label='y')\nplt.fill_between(x, y-error, y+error, alpha=0.2, color='r')\nplt.legend()\n",
        "\nplt.plot([0, 0], ['k--'], linewidth=2)\n",
        "\nax.errorbar(box_position, box_height, yerr=box_errors, color=c)\n",
        "\nfig, ax1 = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(10, 5))\nax1[0].plot(x, y)\nax1[1].plot(a, z)\nax1[1].set_title('Z', fontdict={'size': 12, 'weight': 'bold'})\nax1[1].set_ylim(ax1[0].get_ylim())\nplt.tight_layout()\nplt.show()\n",
        "\nfig, ax = plt.subplots(4, 4, figsize=(5, 5))\nfor i in range(4):\n    for j in range(4):\n        ax[i, j].plot(x, y)\n        ax[i, j].set_xlabel('x')\n        ax[i, j].set_ylabel('y')\n        ax[i, j].tick_params(axis='both', which='major', labelsize=12)\n        ax[i, j].tick_params(axis='both', which='minor', labelsize=8)\n        ax[i, j].grid(which='major', axis='both', linestyle='-', linewidth=0.5)\n        ax[i, j].grid(which='minor', axis='both', linestyle=':', linewidth=0.25)\nplt.tight_layout()\nplt.show()\n",
        "plt.matshow(d)\nplt.figure(figsize=(8, 8))",
        "plt.table(df, bbox=[0, 0, 1, 1])",
        "\nfig, ax = plt.subplots()\nax.plot(x, y)\nax.set_xticks(x)\nax.set_xticklabels(x, rotation=90)\nax.set_xlabel('x')\nax.set_ylabel('y')\nplt.show()\n",
        "\nplt.plot(x, y)\nplt.xticks(x[::-1], x[::-1], rotation=90)\nplt.show()\n",
        "plt.plot(x, y)\nplt.show()",
        "\n",
        "\n# Make catplots of scatter plots by using \"time\" as x, \"pulse\" as y, \"kind\" as hue, and \"diet\" as col\n# Change the xlabels to \"Exercise Time\" and \"Exercise Time\"\nfig, ax = plt.subplots(1, 1, figsize=(10, 5))\nsns.catplot(data=df, x=\"time\", y=\"pulse\", hue=\"kind\", col=\"diet\", ax=ax, kind=\"scatter\")\nax.set_xlabel(\"Exercise Time\")\nax.set_ylabel(\"Pulse\")\nax.set_title(\"Exercise Time vs Pulse\")\nplt.show()\n",
        "\n# Make catplots of scatter plots by using \"time\" as x, \"pulse\" as y, \"kind\" as hue, and \"diet\" as col\n# Do not show any ylabel on either subplot\nfig, ax = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(12, 6))\n# Create a catplot for each subplot\nsns.catplot(data=df, x=\"time\", y=\"pulse\", hue=\"kind\", col=\"diet\", ax=ax[0], kind=\"scatter\", ylim=None)\nsns.catplot(data=df, x=\"time\", y=\"pulse\", hue=\"kind\", col=\"diet\", ax=ax[1], kind=\"scatter\", ylim=None)\n# Remove ylabel from each subplot\nax[0].set_ylabel(None)\nax[1].set_ylabel(None)\nplt.tight_layout()\nplt.show()\n",
        "\nplt.plot(x, y, label=\"y\")\nplt.legend(fontsize=8)\n",
        "\n",
        "\nx = np.arange(10)\ny = np.arange(10)\n# Plot y over x with label \"y\" and show legend\n# Remove the border of frame of legend\nfig, ax = plt.subplots()\nax.plot(x, y, label=\"y\")\nax.legend(loc=\"best\", frameon=False)\nplt.show()\n",
        "\nfig, ax = plt.subplots()\nax.plot(t, a, 'r', label='a')\nax.plot(t, b, 'b', label='b')\nax.plot(t, c, 'g', label='c')\nax.legend()\nax.grid()\nplt.show()\n",
        "\nfig, ax = plt.subplots(figsize=(10, 5))\nsns.stripplot(x=\"sex\", y=\"bill_length_mm\", hue=\"species\", data=df, ax=ax, legend=None)\nplt.tight_layout()\n",
        "\nsns.set(style=\"whitegrid\")\ng = sns.FacetGrid(df, col=\"b\", hue_order=[\"A\", \"B\", \"C\"])\ng = g.map(sns.pointplot, \"c\", \"a\")\ng.add_legend()\ng.add_legend(row=1, col=1)\ng.add_legend(row=2, col=1)\ng.add_legend(row=3, col=1)\nfor ax in g.axes.flat:\n    ax.xaxis.set_major_locator(plt.LinearLocator(1))\n    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, pos: str(int(x) // 2) + \" - \" + str(int(x) % 2)))\ng.fig.subplots_adjust(hspace=0.3)\ng.fig.subplots_adjust(wspace=0.3)\ng.fig.show()\n",
        "\nfig = plt.figure()\nax = Axes3D(fig)\nax.scatter(x, y, z)\nax.view_init(azimuth=100, elevation=50)\nplt.show()\n",
        "\nplt.plot(x, y)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.xticks([])\nplt.yticks([])\nplt.grid(True)\n",
        "\ngs = gridspec.GridSpec(nrow, ncol, width_ratios=[1, 1], height_ratios=[1, 1], wspace=0, hspace=0)\naxs = plt.subplot(gs[0, 0], x=0, y=0, image_stack=x)\naxs = plt.subplot(gs[0, 1], x=0, y=0, image_stack=x)\naxs = plt.subplot(gs[1, 0], x=0, y=0, image_stack=x)\naxs = plt.subplot(gs[1, 1], x=0, y=0, image_stack=x)\nplt.tight_layout()\nplt.show()\n"
    ],
    "Tensorflow": [
        "\nimport tensorflow as tf\nx = tf.Variable(0)\nx.assign(1)\nresult = x\n",
        "\nimport tensorflow as tf\nx = tf.Variable(0)\nx.assign(114514)\nresult = x\n",
        "\nimport tensorflow as tf\nlabels = [0, 6, 5, 4, 2]\nresult = tf.one_hot(labels, 10)\nprint(result)\n",
        "\nimport tensorflow as tf\nlabels = [0, 6, 5, 4, 2]\nresult = tf.one_hot(labels, 10)\nprint(result)\n",
        "\nimport tensorflow as tf\nlabels = [0, 6, 5, 4, 2]\nresult = tf.one_hot(labels, 10)\nprint(result)\n",
        "\n    result = tf.one_hot(labels, 10)\n    # [Missing Code]\n    ",
        "\nimport tensorflow as tf\nlabels = [0, 6, 5, 4, 2]\nresult = tf.one_hot(labels, 10)\nprint(result)\n",
        "\nimport tensorflow as tf\ntf.compat.v1.disable_eager_execution()\ninput = [10, 20, 30]\ndef my_map_func(i):\n  return [[i, i+1, i+2]]       # Fyi [[i], [i+1], [i+2]] throws an exception\nds = tf.data.Dataset.from_tensor_slices(input)\nds = ds.map(map_func=lambda input: tf.compat.v1.py_func(\n  func=my_map_func, inp=[input], Tout=[tf.int64]\n))\nelement = tf.compat.v1.data.make_one_shot_iterator(ds).get_next()\nresult = []\nwith tf.compat.v1.Session() as sess:\n  for _ in range(9):\n    result.append(sess.run(element))\nprint(result)\n[array([10, 11, 12]),\narray([20, 21, 22]),\narray([30, 31, 32])]\n[10, 11, 12, 20, 21, 22, 30, 31, 32]\n",
        "\nimport tensorflow as tf\ntf.compat.v1.disable_eager_execution()\nexample_input = [10, 20, 30]\ndef f(input=example_input):\n    result = []\n    for i in input:\n        result.append(i)\n    return result\n",
        "result = tf.ones([8])\nresult[:len(lengths)] = tf.zeros(len(lengths))\nresult[:len(lengths)] = tf.scatter_nd(tf.range(len(lengths)), lengths, tf.int32)\nprint(result)",
        "result = tf.ones([8])\nresult[:len(lengths)] = tf.zeros(len(lengths))\nresult[len(lengths):] = tf.ones(8 - len(lengths))\nprint(result)",
        "result = tf.ones_like(lengths)[:8] * lengths\nprint(result)",
        "result = tf.ones([8, 1])\nresult[:, 0] = tf.cast(tf.range(0, len(lengths)), tf.int32)\nresult = result * lengths\nresult = tf.pad(result, [[0, 0], [0, 8 - len(lengths)]], constant_values=0)\nreturn result",
        "result = tf.ones([8])\nresult[:len(lengths)] = tf.zeros(len(lengths))\nresult[:len(lengths)] = tf.scatter_nd(tf.range(8), lengths, 1)\nprint(result)",
        "\nimport tensorflow as tf\na = tf.constant([1,2,3])\nb = tf.constant([4,5,6,7])\nresult = tf.concat([a, b], axis=0)\nprint(result)\n",
        "\n    result = tf.concat([a, b], axis=0)\n    ",
        "result = a.reshape(a.shape[0], a.shape[1], a.shape[2], -1)\nprint(result)",
        "result = tf.reshape(a, [50, 100, 1, 512])\nprint(result)",
        "result = tf.reshape(a, [1, 50, 100, 1, 512])\nprint(result)",
        "\nimport tensorflow as tf\nimport numpy as np\nnp.random.seed(10)\nA = tf.constant(np.random.randint(100,size=(5, 3)))\nresult = tf.reduce_sum(A, axis=1)\nprint(result)\n",
        "\nimport tensorflow as tf\nimport numpy as np\nnp.random.seed(10)\nA = tf.constant(np.random.randint(100,size=(5, 3)))\nresult = tf.reduce_prod(A, axis=1)\nprint(result)\n",
        "A = tf.constant([-0.5, -0.1, 0, 0.1, 0.5, 2], dtype=tf.float32)\nresult = tf.reciprocal(A)\nprint(result)",
        "result = tf.reduce_sum(tf.square(a - b), axis=1)\nprint(result)",
        "result = tf.reduce_sum(tf.square(a - b), axis=1)\nprint(result)",
        "result = tf.reduce_sum(tf.square(tf.subtract(A, B)), axis=1)\nreturn result",
        "result = x[tf.cast(y, tf.int32), z]\nprint(result)",
        "\nimport tensorflow as tf\nx = [[1,2,3],[4,5,6]]\nrow = [0,0]\ncol = [1,2]\nx = tf.constant(x)\nrow = tf.constant(row)\ncol = tf.constant(col)\nm = x[tf.range(len(x)), row, col]\nprint(m)\n",
        "\ndef f(x=example_x,y=example_y,z=example_z):\n    result = x[tf.cast(y, tf.int32), tf.cast(z, tf.int32)]\n    return result\n",
        "\nimport tensorflow as tf\nimport numpy as np\nnp.random.seed(10)\nA = tf.constant(np.random.randint(low=0, high=5, size=(10, 20, 30)))\nB = tf.constant(np.random.randint(low=0, high=5, size=(10, 20, 30)))\nresult = tf.einsum('ijk,ijk->bb', A, B)\nprint(result)\n",
        "result = tf.einsum('...ij,...ik->...ijk', A, B)\nprint(result)",
        "result = [x.decode('utf-8') for x in x]\nprint(result)",
        "\nimport tensorflow as tf\nexample_x=[b'\\xd8\\xa8\\xd9\\x85\\xd8\\xb3\\xd8\\xa3\\xd9\\x84\\xd8\\xa9',\n    b'\\xd8\\xa5\\xd9\\x86\\xd8\\xb4\\xd8\\xa7\\xd8\\xa1',\n    b'\\xd9\\x82\\xd8\\xb6\\xd8\\xa7\\xd8\\xa1',\n    b'\\xd8\\xac\\xd9\\x86\\xd8\\xa7\\xd8\\xa6\\xd9\\x8a',\n    b'\\xd8\\xaf\\xd9\\x88\\xd9\\x84\\xd9\\x8a']\ndef f(x=example_x):\n    result = []\n    for byte_string in x:\n        result.append(byte_string.decode('utf-8'))\n    return result\n",
        "result = tf.reduce_mean(x, axis=1, keepdims=True)\ny = tf.where(tf.math.is_nan(result), tf.zeros_like(result), result)\ny = tf.math.divide_no_nan(y, tf.reduce_sum(tf.math.is_finite(y), axis=1, keepdims=True))\nprint(y)",
        "result = tf.reduce_mean(x, axis=1, keepdims=True)\nvariance = tf.reduce_sum(tf.square(result), axis=1, keepdims=True)\nvariance = tf.sqrt(variance)\ny = tf.where(tf.not_equal(x, 0), variance, 0)\nprint(y)",
        "result = tf.reduce_mean(x, axis=-2, keepdims=True)\nresult = tf.where(tf.math.is_finite(result), result, 0)\nresult = tf.reduce_sum(result, axis=-1) / tf.reduce_sum(tf.math.is_finite(result), axis=-1)\nreturn result",
        "\n# [Missing Code]\n",
        "result = tf.argmax(a, axis=1)\nprint(result)",
        "result = tf.argmax(a, axis=1)\nprint(result)",
        "result = tf.argmax(a, axis=1)\nreturn result",
        "\nimport tensorflow as tf\na = tf.constant(\n    [[0.3232, -0.2321, 0.2332, -0.1231, 0.2435, 0.6728],\n     [0.2323, -0.1231, -0.5321, -0.1452, 0.5435, 0.1722],\n     [0.9823, -0.1321, -0.6433, 0.1231, 0.023, 0.0711]]\n)\nresult = tf.argmin(a, axis=1)\nprint(result)\n",
        "model.save(\"my_model\")",
        "import tensorflow as tf\nseed_x = 10\nresult = tf.random.uniform([1, 4], 1, 4, seed=seed_x)\nprint(result)",
        "import tensorflow as tf\nseed_x = 10\nresult = tf.random.uniform([], 2, 5, dtype=tf.int32)\nprint(result)",
        "\n    random_tensor = tf.random.uniform([], 1, 4, dtype=tf.int32)\n    ",
        "\nimport tensorflow as tf\n### output the version of tensorflow into variable 'result'\nresult = tf.version.VERSION\nprint(result)\n"
    ],
    "Scipy": [
        "\nimport numpy as np\nimport scipy\nx = np.array([1, 7, 20, 50, 79])\ny = np.array([10, 19, 30, 35, 51])\nresult = scipy.optimize.curve_fit(lambda x, a, b: a * np.log(x) + b, [1, 0], x, y)\nprint(result)\n",
        "\nimport numpy as np\nimport scipy\nx = np.array([1, 7, 20, 50, 79])\ny = np.array([10, 19, 30, 35, 51])\nresult = scipy.optimize.curve_fit(lambda x, A, B: A + B * np.log(x), x, y, p0=[1, 1])\nprint(result)\n",
        "\nimport numpy as np\nimport scipy.optimize\ny = np.array([1, 7, 20, 50, 79])\nx = np.array([10, 19, 30, 35, 51])\np0 = (4, 0.1, 1)\nresult = scipy.optimize.curve_fit(lambda x, A, B, C: A*np.exp(B*x) + C, y, x, p0)[0]\nprint(result)\n",
        "\nfrom scipy import stats\nimport numpy as np\nnp.random.seed(42)\nx = np.random.normal(0, 1, 1000)\ny = np.random.normal(0, 1, 1000)\nstatistic, p_value = stats.kstest(x, y, 'two-samp')\nprint(statistic, p_value)\n",
        "result = stats.ks_2samp(x, y)\np_value = result[0]\nif p_value > alpha:\n    result = False\nelse:\n    result = True\nprint(result)",
        "result = optimize.minimize(f, initial_guess, method='L-BFGS-B', options={'maxiter': 1000})\n",
        "\nimport numpy as np\nimport scipy.stats\nz_scores = np.array([-3, -2, 0, 2, 2.5])\np_values = scipy.stats.norm.cdf(-z_scores)\nprint(p_values)\n",
        "\nimport scipy.stats\nimport numpy as np\nz_scores = [-3, -2, 0, 2, 2.5]\nmu = 3\nsigma = 4\np_values = scipy.stats.norm.cdf(-z_scores, loc=mu, scale=sigma)\nprint(p_values)\n",
        "\nimport numpy as np\nimport scipy.stats\np_values = [0.1, 0.225, 0.5, 0.75, 0.925, 0.95]\nz_scores = scipy.stats.norm.ppf(p_values)\nprint(z_scores)\n",
        "\nimport numpy as np\nfrom scipy import stats\nstddev = 2.0785\nmu = 1.744\nx = 25\nresult = stats.lognorm.cdf(x, loc=mu, scale=stddev)\nprint(result)\n",
        "\n# [Missing Code]\n",
        "result = sa * sb\nprint(result)\nfrom scipy import sparse\nimport numpy as np\nsa = sparse.csr_matrix(np.array([[1,2,3],[4,5,6],[7,8,9]]))\nsb = sparse.csr_matrix(np.array([0,1,2]))\nresult = sa * sb\nprint(result)",
        "\nfrom scipy import sparse\nimport numpy as np\nexample_sA = sparse.csr_matrix(np.array([[1,2,3],[4,5,6],[7,8,9]]))\nexample_sB = sparse.csr_matrix(np.array([0,1,2]))\ndef f(sA = example_sA, sB = example_sB):\n    result = sA * sB\n    return result\n",
        "result = scipy.interpolate.griddata(points, V, request, method='linear')\nprint(result)",
        "result = scipy.interpolate.LinearNDInterpolator(points, V)(request)\nprint(result)",
        "data_rot = rotate(data_orig, angle)\nxrot, yrot = data_rot[x0-data_orig.shape[0]/2, y0-data_orig.shape[1]/2]\nprint(data_rot, (xrot, yrot))",
        "\nimport numpy as np\nfrom scipy.sparse import csr_matrix\narr = np.random.rand(4, 4)\nM = csr_matrix(arr)\nresult = M.diagonal()\nprint(result)\n",
        "result = stats.kstest(times, \"uniform\")\nprint(result)",
        "\n    kstest_result = stats.kstest(times, \"uniform\")\n    return kstest_result\n",
        "result = stats.kstest(times, \"uniform\", n=100, crit_value=0.05)\nprint(result[0])",
        "\nfrom scipy import sparse\nc1 = sparse.csr_matrix([[0, 0, 1, 0], [2, 0, 0, 0], [0, 0, 0, 0]])\nc2 = sparse.csr_matrix([[0, 3, 4, 0], [0, 0, 0, 5], [6, 7, 0, 8]])\nFeature = c1.concatenate(c2)\nprint(Feature)\n",
        "\nfrom scipy import sparse\nc1 = sparse.csr_matrix([[0, 0, 1, 0], [2, 0, 0, 0], [0, 0, 0, 0]])\nc2 = sparse.csr_matrix([[0, 3, 4, 0], [0, 0, 0, 5], [6, 7, 0, 8]])\nFeature = sparse.hstack([c1, c2])\n#print(Feature)\n",
        "Feature = sparse.hstack([c1, c2])\n#print(Feature)\nfrom scipy import sparse\nc1 = sparse.csr_matrix([[0, 0, 1, 0], [2, 0, 0, 0], [0, 0, 0, 0]])\nc2 = sparse.csr_matrix([[0, 3, 4, 0], [0, 0, 0, 5], [6, 7, 0, 8]])\nFeature = sparse.hstack([c1, c2])\n#print(Feature)",
        "result = scipy.spatial.KDTree(points1).query(points2, k=2)[:,:2]\nprint(result)",
        "result = scipy.spatial.KDTree(points1).nearest_neighbors(points2, 2)\n",
        "b.setdiag(0)",
        "result = np.sum(img > threshold)\nprint(result)",
        "result = np.sum(img < threshold)\nprint(result)",
        "result = np.sum(img > threshold)\nreturn result",
        "\nresult = []\n# Find regions of cells which value exceeds a given threshold (0.75)\nregions = ndimage.label(img > threshold)\n# Determine the center of mass of each region\ncenters = np.zeros((len(regions), 2))\nfor i, region in enumerate(regions):\n    x, y = np.where(region == 1)\n    centers[i, :] = (np.mean(x), np.mean(y))\n# Calculate the distance between the center of mass of each region and the top left corner\ndistances = np.sqrt((centers[:, 0] - 0) ** 2 + (centers[:, 1] - 0) ** 2)\nresult = distances.tolist()\nprint(result)",
        "M.make_symmetric()\nprint(M)",
        "\n    sA.make_symmetric()\n    ",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n",
        "\nimport numpy as np\nfrom scipy.sparse import csr_matrix\nnp.random.seed(10)\narr = np.random.randint(4,size=(988,988))\nsA = csr_matrix(arr)\ncol = sA.getcol(0)\nMax = np.amax(col)\nMin = np.amin(col)\nprint(Max)\nprint(Min)\n",
        "\n",
        "",
        "result = scipy.spatial.distance.cdist(example_array, example_array, 'euclidean')\nprint(result)",
        "result = scipy.spatial.distance.cdist(example_array, example_array, 'cityblock')\nprint(result)",
        "result = scipy.spatial.distance.cdist(example_array, example_array, 'euclidean')\nreturn result",
        "result = interpolate.splev(x_val, tck, der = 0)\nreturn result",
        "statistic, critical_values, significance_level = ss.anderson_ksamp(np.array(x1), np.array(x2), np.array(x3), np.array(x4))\nprint(statistic, critical_values, significance_level)",
        "result = ss.anderson_ksamp(x1, x2)\nprint(result)",
        "\ndf['AB'] = df.apply(lambda row: stats.kendalltau(row['B'], row['A'])[0], axis=1)\ndf['AC'] = df.apply(lambda row: stats.kendalltau(row['C'], row['A'])[0], axis=1)\ndf['BC'] = df.apply(lambda row: stats.kendalltau(row['C'], row['B'])[0], axis=1)\nprint(df)",
        "from scipy import sparse\nsa = sparse.random(10, 10, density = 0.01, format = 'csr')\nresult = sa.sum() == 0\nprint(result)",
        "from scipy import sparse\nsa = sparse.random(10, 10, density = 0.01, format = 'lil')\nresult = sa.sum() == 0\nprint(result)",
        "result = block_diag(*[a[i] for i in range(a.shape[0])])\nprint(result)",
        "\nimport numpy as np\nfrom scipy import stats\nnp.random.seed(10)\npre_course_scores = np.random.randn(10)\nduring_course_scores = np.random.randn(10)\np_value = stats.ranksums(pre_course_scores, during_course_scores).pvalue\nprint(p_value)\n",
        "\n    p_value = stats.ranksums(pre_course_scores, during_course_scores).pvalue\n    ",
        "\nimport numpy as np\na = np.array([   1. ,    2. ,    2.5,  400. ,    6. ,    0. ])\nkurtosis_result = np.sum(a ** 4) / (np.sum(a ** 2) ** 2) - 3\nprint(kurtosis_result)\n",
        "\nimport numpy as np\nimport scipy.stats\na = np.array([   1. ,    2. ,    2.5,  400. ,    6. ,    0. ])\nkurtosis_result = scipy.stats.kurtosis(a)\nprint(kurtosis_result)\n",
        "\nimport numpy as np\nimport scipy.interpolate\ns = np.linspace(-1, 1, 50)\nt = np.linspace(-2, 0, 50)\nx, y = np.ogrid[-1:1:10j,-2:0:10j]\nz = (x + y)*np.exp(-6.0 * (x * x + y * y))\nresult = scipy.interpolate.interp2d(s, t, z)(s1, t1) - scipy.interpolate.interp2d(s, t, z)(s2, t2)\nprint(result)\n",
        "result = scipy.interpolate.interp2d(x, y, z, kind='cubic')([s, t])\nreturn result",
        "print(result)",
        "result = np.array([vor.region_area[vor.vertices[i]].intersection(vor.region_area[vor.vertices[j]]) for i, j in itertools.combinations(range(len(vor.vertices)), 2)])\nprint(result)",
        "\nimport numpy as np\nimport scipy.sparse as sparse\nnp.random.seed(10)\nmax_vector_size = 1000\nvectors = [np.random.randint(100,size=900),np.random.randint(100,size=max_vector_size),np.random.randint(100,size=950)]\nresult = sparse.csr_matrix(vectors)\nprint(result)\n",
        "\nimport numpy as np\nimport scipy.ndimage\na= np.zeros((5, 5))\na[1:4, 1:4] = np.arange(3*3).reshape((3, 3)) + 1\nprint(b)\n",
        "result = M[row, column]",
        "result = [M[row[i], column[i]] for i in range(len(row))]\nprint(result)",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "def f(x = 2.5, u = 1, o2 = 3):\n    dev = abs((x-u)/o2)\n    P_inner = scipy.integrate(NDfx,-dev,dev)\n    P_outer = 1 - P_inner\n    P = P_inner + P_outer/2\n    return(P)",
        "result = sf.dctn(np.eye(N), norm='ortho')",
        "result = sparse.diags(matrix, [-1, 0, 1], (5, 5)).toarray()\nprint(result)",
        "\nimport numpy as np\nimport scipy.stats\nN = 3\np = 0.5\nresult = scipy.stats.binom.pmf(i, j, p=p)\nprint(result)\n",
        "result = df.apply(lambda row: stats.zscore(row), axis=1)\nprint(result)",
        "result = df.apply(lambda row: stats.zscore(row['sample1']), axis=1)\nresult = df.apply(lambda row: stats.zscore(row['sample2']), axis=1)\nresult = df.apply(lambda row: stats.zscore(row['sample3']), axis=1)\nprint(result)",
        "\nresult = df.assign(data=lambda x: x['sample1'] + x['sample2'] + x['sample3'], zscore=lambda x: stats.zscore(x['data']))\ndf = df.join(result)\nprint(df)",
        "result = df.assign(data=lambda x: x['sample1'] + x['sample2'] + x['sample3'], zscore=lambda x: stats.zscore(x['data']))\ndf = df.join(result)\ndf['data'] = df['data'].round(3)\ndf['zscore'] = df['zscore'].round(3)\nprint(df)",
        "result = scipy.optimize.fmin_l_bfgs_b(test_func, test_grad, starting_point, direction)",
        "\nmid = np.array([[0, 0], [0, 1], [1, 0], [1, 1], [0, 1], [0, 0]])\nresult = distance.cdist(scipy.dstack((y, x)), mid)\n",
        "\n",
        "\n    mid = np.array([[0, 0], [0, 0]])\n    # [Missing Code]\n    ",
        "\nimport numpy as np\nimport scipy.ndimage\nx = np.arange(9).reshape(3, 3)\nshape = (6, 8)\nresult = scipy.ndimage.zoom(x, shape[0] / x.shape[0], shape[1] / x.shape[1], order=1)\nprint(result)\n",
        "result = scipy.optimize.minimize(residual, fit_params, args=(a, y), method='L-BFGS-B', options={'maxiter': 1000})\nprint(result)",
        "\nout = scipy.optimize.minimize(residual, fit_params, args=(a, y), method='L-BFGS-B', bounds=x_lower_bounds)\nprint(out)",
        "\ndef dN1_dt_sinusoid(t, N1):\n    return -100 * N1 + np.sin(t)\nsol = solve_ivp(fun=dN1_dt_sinusoid, t_span=time_span, y0=[N0,])\nresult = sol.y\nprint(result)",
        "\n# [Missing Code]\n",
        "sol = solve_ivp(fun=dN1_dt_simple, t_span=time_span, y0=[N0, -np.cos(t)])\nresult = sol.y\nprint(result)",
        "\nfor t in range (4):\n    def const(x):    \n        y=x[t]\n        return y\n    cons.append({'type':'ineq', 'fun': const})\n",
        "sa = sparse.random(10, 10, density = 0.01, format = 'csr')\nsb = sparse.random(10, 10, density = 0.01, format = 'csr')\nresult = sa.copy()\nresult.data += sb.data\nresult.indices += sb.indices\nresult.indptr += sb.indptr\nprint(result)",
        "sa = sparse.random(10, 10, density = 0.01, format = 'csr')\nsb = sparse.random(10, 10, density = 0.01, format = 'csr')\nresult = sa.copy()\nresult.data += sb.data\nresult.indices += sb.indices\nresult.indptr += sb.indptr\nprint(result)",
        "\nimport scipy.integrate\nc = 5\nlow = 0\nhigh = 1\nresult = scipy.integrate.quad(lambda x: 2*x*c, low, high)\nprint(result)\n",
        "\nfrom scipy.integrate import quad\ndef f(c, low, high):\n    eqn = 2 * x * c\n    result, error = quad(lambda x: eqn, low, high)\n    return result\n",
        "V[V != 0] += x\nprint(V)",
        "\nV[V.row == 0] += x\nV[V.col == 0] += x\nV[V.row == 9] += x\nV[V.col == 9] += x\n",
        "",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nimport scipy\nimport numpy as np\na = np.array([[26, 3, 0], [3, 195, 1], [0, 1, 17]])\na = scipy.sparse.csr_matrix(a)\nprint(a)\n",
        "\nimport scipy\nimport numpy as np\na = np.array([[26, 3, 0], [3, 195, 1], [0, 1, 17]])\na = scipy.sparse.csr_matrix(a)\nprint(a.toarray())\n",
        "result = []\nfor i, cluster in enumerate(data):\n    closest_index = scipy.spatial.KDTree(centroids[i]).query(data)[0][0]\n    result.append(closest_index)\nprint(result)",
        "result = []\nfor i in range(len(centroids)):\n    closest_point = scipy.spatial.KDTree(data).query(centroids[i], k=1)[1][0]\n    result.append(closest_point)\nprint(result)",
        "\nimport numpy as np\nimport scipy.spatial\ncentroids = np.random.rand(5, 3)\ndata = np.random.rand(100, 3)\nk = 3\nresult = scipy.spatial.KDTree(centroids).query(data, k=k, distance_upper_bound=None)[1]\nprint(result)\n",
        "result = np.empty((len(xdata), len(bdata)), dtype=float)\nfor i in range(len(xdata)):\n    result[i, :] = fsolve(eqn, x0=xdata[i], args=(a, bdata[i]))\nprint(result)",
        "result = fsolve(eqn, xdata, args=(adata,))\nresult = np.array([[x, a] for x, a in result if a < 0])\nresult = np.array([[x, a] for x, a in result if a > 0])\nresult = np.array([[x, a] for x, a in result if a == 0])\nresult = np.array([[x, a] for x, a in result if a < 0])\nresult = np.array([[x, a] for x, a in result if a > 0])\nresult = np.array([[x, a] for x, a in result if a == 0])\nresult = np.array([[x, a] for x, a in result if a < 0])\nresult = np.array([[x, a] for x, a in result if a > 0])\nresult = np.array([[x, a] for x, a in result if a == 0])\nresult = np.array([[x, a] for x, a in result if a < 0])\nresult = np.array([[x, a] for x, a in result if a > 0])\nresult = np.array([[x, a] for x, a in result if a == 0])\nresult = np.array([[x, a] for x, a in result if a < 0])\nresult = np.array([[x, a] for x, a in result if a > 0])\nresult = np.array([[x, a] for x, a in result if a == 0])\nresult = np.array([[x, a] for x, a in result if a < 0])\nresult = np.array([[x, a] for x, a in result if a > 0])\nresult = np.array([[x, a] for x, a in result if a == 0])\nresult = np.array([[x, a] for x, a in result if a < 0])\nresult = np.array([[x, a] for x, a in result if a > 0])\nresult = np.array([[x, a] for x, a in result if a == 0])\nresult = np.array([[x, a] for x, a in result if a < 0])\nresult = np.array([[x, a] for x, a in result if a > 0])\nresult = np.array([[x, a] for x, a in result if a == 0])\nresult = np.array([[x, a] for x, a in result if a < 0])\nresult = np.array([[x, a] for x, a in result if a > 0])\nresult = np.array([[x, a] for x, a in result if a == 0])\nresult = np.array([[x, a] for x, a in result if a < 0])\nresult = np.array([[x, a] for x, a in result if a > 0])\nresult = np.array([[x, a] for x, a in result if a == 0])\nresult = np.array([[x, a] for x, a in result if a < 0])\nresult = np.array([[x, a] for x, a in result if a > 0])\nresult = np.array([[x, a] for x, a in result if a == 0])\nresult = np.array([[x, a] for x, a in result if a < 0])\nresult = np.array([[x, a] for x, a in result if a > 0])\nresult = np.array([[x, a] for x, a in result if a == 0])\nresult = np.array([[x, a] for x, a in result if a < 0])\nresult = np.array([[x, a] for x, a in result if a > 0])\nresult = np.array([[x, a] for x, a in result if a == 0])\nresult = np.array([[x, a] for x, a in result if a < 0])\nresult = np.array([[x, a] for x, a in result if a > 0])",
        "result = stats.kstest(sample_data, bekkers, args=(estimated_a, estimated_m, estimated_d), range_start=range_start, range_end=range_end)\nprint(result)",
        "result = kstest_result[1]\nprint(result)",
        "\nimport pandas as pd\nimport io\nfrom scipy import integrate\nstring = '''\nTime                      A\n2017-12-18-19:54:40   -50187.0\n2017-12-18-19:54:45   -60890.5\n2017-12-18-19:54:50   -28258.5\n2017-12-18-19:54:55    -8151.0\n2017-12-18-19:55:00    -9108.5\n2017-12-18-19:55:05   -12047.0\n2017-12-18-19:55:10   -19418.0\n2017-12-18-19:55:15   -50686.0\n2017-12-18-19:55:20   -57159.0\n2017-12-18-19:55:25   -42847.0\n'''\ndf = pd.read_csv(io.StringIO(string), sep = '\\s+')\nintegral_df = df.groupby(pd.Grouper(freq='25S')).apply(integrate.trapz)\nprint(integral_df)\n",
        "import scipy.interpolate\nx = [(2,2), (1,2), (2,3), (3,2), (2,1)]\ny = [5,7,8,10,3]\neval = [(2.7, 2.3)]\nresult = scipy.interpolate.griddata((x, y), (eval), method='linear')\nprint(result)",
        "weights = sciopt.curve_fit(multinomial_likelihood, a['A1'].astype(np.int64), a['A1'].astype(np.int64), p0=np.ones(a['A1'].max()+1))[0]\nprint(weights)",
        "result = sciopt.fminbound(e, pmin, pmax, args=(x, y))",
        "result = signal.argrelmax(arr, n)\nprint(result)\nimport numpy as np\nfrom scipy import signal\narr = np.array([-624.59309896, -624.59309896, -624.59309896,\n                      -625., -625., -625.,])\nn = 2\nresult = signal.argrelmax(arr, n)\nprint(result)",
        "result = []\nfor i in range(len(arr)):\n    for j in range(len(arr[i])):\n        if arr[i][j] <= min(arr[i][j-n:j+n+1]) and arr[i][j] >= max(arr[i][j-n:j+n+1]):\n            result.append([i, j])\nprint(result)",
        "df = df[(np.abs(stats.zscore(df.loc[:, df.columns.dtype == 'float'], axis=0)) < 3).all(axis=1)]"
    ],
    "Sklearn": [
        "\nimport numpy as np\nfrom sklearn.datasets import load_iris\nimport pandas as pd\ndata = load_iris()\ndata1 = pd.DataFrame(data.data, columns=data.feature_names)\nprint(data1)\n",
        "\nimport numpy as np\nfrom sklearn.datasets import load_iris\nimport pandas as pd\ndata = load_iris()\ndata1 = pd.DataFrame(data)\nprint(data1)\n",
        "\nimport numpy as np\nfrom sklearn.datasets import load_boston\nimport pandas as pd\ndata = load_boston()\ndata1 = pd.DataFrame(data)\nprint(data1)\n",
        "data = data.astype(np.float64)\ndata = pd.DataFrame(data, columns=data.feature_names_)\nreturn data",
        "df_out = pd.get_dummies(df, columns=['Col3'])\nprint(df_out)",
        "\n",
        "\n",
        "df_out = pd.get_dummies(df, columns=['Col3'])\nprint(df_out)",
        "df_out = pd.get_dummies(df, columns=['Col3'])\nprint(df_out)",
        "\n# [Missing Code]\n",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn import svm\nX, y, x_predict = load_data()\nassert type(X) == np.ndarray\nassert type(y) == np.ndarray\nassert type(x_predict) == np.ndarray\nmodel = svm.LinearSVC()\nproba = np.exp(x_predict * -1) / (np.exp(x_predict * -1) + np.exp(-x_predict))\nprint(proba)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\ndf_transformed = pd.concat([df_origin, transform_output], axis=1)\ndf_transformed = df_transformed.fillna(0)\ndf_transformed = df_transformed.astype({'col_name': 'int64'})\ndf = df_origin.join(df_transformed)\nreturn df",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n",
        "\n# [Missing Code]\n",
        "\nmodel = xgb.XGBRegressor()\ngridsearch = GridSearchCV(model, paramGrid, verbose=verbose, cv=TimeSeriesSplit(n_splits=cv).get_n_splits([trainX, trainY]), n_jobs=n_jobs, iid=iid)\ngridsearch.fit(trainX, trainY, fit_params={\"early_stopping_rounds\": 42, \"eval_metric\": \"mae\", \"eval_set\": [[testX, testY]]})\n",
        "\nmodel = xgb.XGBRegressor()\nGridSearchCV(model, paramGrid, verbose=1, cv=TimeSeriesSplit(n_splits=3).get_n_splits([trainX, trainY]), n_jobs=n_jobs, iid=iid).fit(trainX, trainY, fit_params={\"early_stopping_rounds\":42, \"eval_metric\": \"mae\", \"eval_set\": [[testX, testY]]})",
        "proba = logreg.predict_proba(X)\n",
        "proba = logreg.predict_proba(X)\n",
        "\n# [Missing Code]\n",
        "",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel_name = model.__class__.__name__\nprint(model_name)\n",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel_name = model.__class__.__name__\nprint(model_name)\n",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn.svm import LinearSVC\nmodel = LinearSVC()\nmodel_name = model.__class__.__name__\nprint(model_name)\n",
        "tf_idf_out = pipe.named_steps[\"tf_idf\"].fit_transform(data.test)\nprint(tf_idf_out)",
        "tf_idf_out = pipe.named_steps[\"tf_idf\"].fit_transform(data.test)",
        "select_out = pipe.steps[0]['select'].fit_transform(data, target)",
        "\n",
        "\nregressor = RandomForestRegressor(n_estimators=150, min_samples_split=1.0, random_state=42)\n",
        "\nX = np.array(X)\ny = np.array(y)\nregressor = RandomForestRegressor(n_estimators=150, min_samples_split=1.0, random_state=42)\nrgr = regressor.fit(X, y)\npredict = regressor.predict(X_test)\nprint(predict)",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer(preprocessor=preprocess)\nprint(tfidf.preprocessor)\n",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ndef prePro(text):\n    return text.lower()\ntfidf = TfidfVectorizer(preprocessor=prePro)\nprint(tfidf.preprocessor)\n",
        "\n",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\ndata = load_data()\ndf_out = preprocessing.scale(data)\nprint(df_out)\n",
        "coef = grid.best_estimator_.coef_\nprint(coef)",
        "coef = grid.best_estimator_.coef_\nprint(coef)",
        "\nimport pandas as pd\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\nimport numpy as np\nX, y = load_data()\nclf = ExtraTreesClassifier(random_state=42)\nclf = clf.fit(X, y)\ncolumn_names = clf.feature_importances_.index.tolist()\nprint(column_names)\n",
        "\nimport pandas as pd\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\nimport numpy as np\nX, y = load_data()\nclf = ExtraTreesClassifier(random_state=42)\nclf = clf.fit(X, y)\ncolumn_names = clf.feature_importances_.index.tolist()\nprint(column_names)\n",
        "\nimport pandas as pd\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\nimport numpy as np\nX, y = load_data()\nclf = ExtraTreesClassifier(random_state=42)\nclf = clf.fit(X, y)\ncolumn_names = clf.feature_importances_.index.tolist()\nprint(column_names)\n",
        "\nimport pandas as pd\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\nimport numpy as np\nX, y = load_data()\nclf = ExtraTreesClassifier(random_state=42)\nclf = clf.fit(X, y)\ncolumn_names = clf.feature_importances_.index.tolist()\nprint(column_names)\n",
        "closest_50_samples = km.predict([p])[0]\nclosest_50_samples = km.predict(X, p)\nclosest_50_samples = km.predict(X, p, return_distance=False)\nclosest_50_samples = km.predict(X, p, return_distance=True)\nclosest_50_samples = km.predict(X, p, return_distance=True)[0]\nclosest_50_samples = km.predict(X, p, return_distance=True)[0][:50]\nclosest_50_samples = km.predict(X, p, return_distance=True)[0][:50][:, 0]\nclosest_50_samples = km.predict(X, p, return_distance=True)[0][:50][:, 0].tolist()\nclosest_50_samples = km.predict(X, p, return_distance=True)[0][:50][:, 0].tolist()[:50]\nclosest_50_samples = km.predict(X, p, return_distance=True)[0][:50][:, 0].tolist()[:50][:, 0]\nclosest_50_samples = km.predict(X, p, return_distance=True)[0][:50][:, 0].tolist()[:50][:, 0].tolist()\nclosest_50_samples = km.predict(X, p, return_distance=True)[0][:50][:, 0].tolist()[:50][:, 0].tolist()[:50]\nclosest_50_samples = km.predict(X, p, return_distance=True)[0][:50][:, 0].tolist()[:50][:, 0].tolist()[:50][:, 0]\nclosest_50_samples = km.predict(X, p, return_distance=True)[0][:50][:, 0].tolist()[:50][:, 0].tolist()[:50][:, 0].tolist()\nclosest_50_samples = km.predict(X, p, return_distance=True)[0][:50][:, 0].tolist()[:50][:, 0].tolist()[:50][:, 0].tolist()[:50][:, 0]\nclosest_50_samples = km.predict(X, p, return_distance=True)[0][:50][:, 0].tolist()[:50][:, 0].tolist()[:50][:, 0].tolist()[:50][:, 0].tolist()[:50]\nclosest_50_samples = km.predict(X, p, return_distance=True)[0][:50][:, 0].tolist()[:50][:, 0].tolist()[:50][:, 0].tolist()[:50][:, 0].tolist()[:50][:, 0]\nclosest_50_samples = km.predict(X, p, return_distance=True)[0][:50][:, 0].tolist()[:50][:, 0].tolist()[:50][:, 0].tolist()[:50][:, 0].tolist()[:50][:, 0].tolist()[:50]\nclosest_50_samples = km.predict(X, p, return_distance=True)[0][:50][:, 0].tolist()[:50][:, 0].tolist()[:50][:, 0].tolist()[:50][:, 0].tolist()[:50][:, 0].tolist()[:50][:, 0]",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn.cluster import KMeans\np, X = load_data()\nassert type(X) == np.ndarray\nkm = KMeans()\nclosest_50_samples = km.fit_predict(X)[:50]\nprint(closest_50_samples)\n",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn.cluster import KMeans\np, X = load_data()\nassert type(X) == np.ndarray\nkm = KMeans()\nclosest_100_samples = km.predict(X)[p]\nprint(closest_100_samples)\n",
        "\n",
        "\n# [Missing Code]\n",
        "X_train = pd.get_dummies(X_train)\nclf = GradientBoostingClassifier(learning_rate=0.01, max_depth=8, n_estimators=50).fit(X_train, y_train)",
        "\nmodel = SVC(kernel='rbf', gamma='auto')\nmodel.fit(X, y)\npredict = model.predict(X)\n",
        "regressor = sklearn.svm.SVR(kernel='rbf', gamma='auto')\nregressor.fit(X, y)\npredict = regressor.predict(X)\nprint(predict)",
        "\nfrom sklearn.svm import SVC\nregressor = SVC(kernel='poly', degree=2)\nregressor.fit(X, y)\npredict = regressor.predict(X)\n",
        "regressor = sklearn.svm.SVR(kernel='poly', degree=2)\nregressor.fit(X, y)\npredict = regressor.predict(X)\nprint(predict)",
        "\nprint(cosine_similarities_of_queries)\n",
        "\nprint(cosine_similarities_of_queries)\n",
        "\n",
        "new_features = np.array(features)\nnew_features = new_features.astype(np.float64)\nnew_features = new_features.T\nnew_features = new_features.astype(np.float64)\nnew_features = pd.DataFrame(new_features, columns=features[0][0], index=range(len(features)))\nprint(new_features)",
        "new_f = pd.DataFrame(f, columns=['t1', 't2', 't3', 't4', 't5', 't6', 't7'])\nnew_f = new_f.astype(np.float64)\nnew_f = new_f.astype(np.float64).T\nnew_f = sklearn.preprocessing.normalize(new_f, axis=1)\nprint(new_f)",
        "new_features = np.array(features)\nnew_features = new_features.astype(np.float64)\nnew_features = new_features.reshape(len(features), -1)\nnew_features = new_features.astype(np.float64)\nnew_features = sklearn.preprocessing.normalize(new_features, axis=1)\nprint(new_features)",
        "\nfeatures = features.apply(pd.Series).stack().reset_index(drop=True)\nnew_features = np.array(features)\nreturn new_features",
        "\n",
        "\nimport numpy as np\nimport pandas as pd\nimport sklearn.cluster\ndata_matrix = load_data()\ncluster_labels = sklearn.cluster.AgglomerativeClustering(n_clusters=2).fit_predict(data_matrix)\nprint(cluster_labels)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport sklearn.cluster\ndata_matrix = load_data()\ncluster_labels = sklearn.cluster.AgglomerativeClustering(n_clusters=2).fit_predict(data_matrix)\nprint(cluster_labels)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport sklearn.cluster\nsimM = load_data()\ncluster_labels = sklearn.cluster.AgglomerativeClustering(n_clusters=2, linkage='average').fit(simM).labels_\nprint(cluster_labels)\n",
        "",
        "cluster_labels = scipy.cluster.hierarchy.linkage(data_matrix, method='complete')\nlabels = scipy.cluster.hierarchy.fcluster(cluster_labels, 2, criterion='maxclust')\ncluster_labels = np.array(labels)\nprint(cluster_labels)",
        "cluster_labels = scipy.cluster.hierarchy.linkage(simM, 'average')\nlabels = scipy.cluster.hierarchy.fcluster(cluster_labels, 2, criterion='maxclust')\ncluster_labels = np.array(labels)\nprint(cluster_labels)",
        "\ndata = sklearn.preprocessing.MinMaxScaler()\ndata = data.fit_transform(data)\ndata = sklearn.preprocessing.StandardScaler()\ndata = data.fit_transform(data)\ndata = data.astype(np.float64)\ndata = data - data.mean(axis=0)\ndata = data / data.std(axis=0)\ncentered_scaled_data = data",
        "",
        "\n# [Missing Code]\n",
        "\nfrom sklearn.preprocessing import BoxCoxTransformer\nbox_cox_data = BoxCoxTransformer().fit_transform(data)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nx_train, y_train, x_test, y_test = train_test_split(dataset.iloc[:, :-1], dataset.iloc[:, -1], test_size=0.2, random_state=42)",
        "\nprint(x_train)\nprint(y_train)\nprint(x_test)\nprint(y_test)\n",
        "\nprint(x_train)\nprint(y_train)\nprint(x_test)\nprint(y_test)\n",
        "\nx_train, y_train, x_test, y_test = solve(dataset)\nprint(x_train)\nprint(y_train)\nprint(x_test)\nprint(y_test)\n",
        "\nfrom sklearn.cluster import KMeans\ndf = load_data()\nf1 = df['mse'].values\nX = f1.reshape(-1, 1)\nkmeans = KMeans(n_clusters=2).fit(X)\nlabels = kmeans.predict(X)\nprint(labels)\n",
        "from sklearn.cluster import KMeans\ndf = load_data()\nX = df['mse'].values\nf2 = list(range(0, len(X)))\nkmeans = KMeans(n_clusters=2).fit(X)\nlabels = kmeans.predict(X)\ncentroids = kmeans.cluster_centers_\nprint(labels)",
        "selected_feature_names = np.asarray(vectorizer.get_feature_names())[LinearSVC(C=1, penalty='l1').fit(X).support_]",
        "selected_feature_names = np.asarray(vectorizer.get_feature_names())[LinearSVC(C=1.0, penalty='l1').fit(X).support_]",
        "selected_feature_names = np.asarray(vectorizer.get_feature_names())[LinearSVC(C=1.0, penalty='l1').fit(X).support_]",
        "\nvectorizer = CountVectorizer(stop_words=\"english\", binary=True, lowercase=False, vocabulary=vocabulary)\nX = vectorizer.fit_transform(corpus)\nprint(vectorizer.get_feature_names())\nprint(X.toarray())",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\ncorpus = [\n    'We are looking for Java developer',\n    'Frontend developer with knowledge in SQL and Jscript',\n    'And this is the third one.',\n    'Is this the first document?',\n]\nvectorizer = CountVectorizer(stop_words=\"english\", binary=True, lowercase=False, vocabulary=vocabulary)\nX = vectorizer.fit_transform(corpus)\nprint(vectorizer.get_feature_names())\nprint(X.toarray())\n",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\ncorpus = [\n    'We are looking for Java developer',\n    'Frontend developer with knowledge in SQL and Jscript',\n    'And this is the third one.',\n    'Is this the first document?',\n]\nvectorizer = CountVectorizer(stop_words=\"english\", binary=True, lowercase=False, vocabulary=vocabulary)\nX = vectorizer.fit_transform(corpus)\nX = X.astype(np.int64)\nX = X.reshape(len(X), 1)\nX = np.log(X + 1)\nprint(feature_names)\nprint(X)\n",
        "\nvectorizer = CountVectorizer(stop_words=\"english\", binary=True, lowercase=False, vocabulary=vocabulary)\nX = vectorizer.fit_transform(corpus)\nX = X.astype(np.int64)\nX = np.log(X + 1)\nX = np.maximum(X, 0)\nX = np.sum(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)\nX = np.expand_dims(X, axis=1)",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\ndf1 = load_data()\nslopes = []\nfor col in df1.columns:\n    df2 = df1[~np.isnan(df1[col])]\n    df3 = df2[['Time', col]]\n    npMatrix = np.matrix(df3)\n    X, Y = npMatrix[:, 0], npMatrix[:, 1]\n    slope = LinearRegression().fit(X, Y)\n    m = slope.coef_[0]\n    slopes.append(m)\nprint(slopes)\n",
        "\nfor col in df1.columns:\n    df2 = df1[~np.isnan(df1[col])]\n    df3 = df2[['Time', col]]\n    npMatrix = np.matrix(df3)\n    X, Y = npMatrix[:, 0], npMatrix[:, 1]\n    slope = LinearRegression().fit(X, Y)\n    m = slope.coef_[0]\n    series = np.concatenate((SGR_trips, m), axis=0)\nslopes = series.tolist()\nprint(slopes)",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\ndf = load_data()\ndf['Sex'] = LabelEncoder().fit_transform(df['Sex'])\nprint(transformed_df)\n",
        "df['Sex'] = LabelEncoder().fit_transform(df['Sex'])\n",
        "\n    # [Missing Code]\n    ",
        "\ntraining_set_score = ElasticNet.score(X_train, y_train)\ntest_set_score = ElasticNet.score(X_test, y_test)\nprint(training_set_score)\nprint(test_set_score)",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n    new_a = MinMaxScaler().fit_transform(a)\n    ",
        "close_buy1 = close[:-1]\nm5 = ma_50[:-1]\nm10 = ma_100[:-1]\nma20 = ma_200[:-1]\nb = np.concatenate([close_buy1, m5, m10, ma20], axis=1)\nclf.predict(b)",
        "\n",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nX = [['asdf', '1'], ['asdf', '0']]\nclf = DecisionTreeClassifier()\nnew_X = np.array(X, dtype=float)\nclf.fit(new_X, ['2', '3'])\n",
        "new_X = np.array(X)\nclf.fit(new_X, ['4', '5'])",
        "X = dataframe.iloc[-1:].astype(float)\ny = dataframe.iloc[:,-1]\nlogReg = LogisticRegression()\nlogReg.fit(X, y)\npredict = logReg.predict(X)\nprint(predict)",
        "X = dataframe.iloc[:, :-1].astype(float)\ny = dataframe.iloc[:, -1]\nlogReg = LogisticRegression()\nlogReg.fit(X, y)\npredict = logReg.predict(X)\nprint(predict)",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "train_size = 0.2\ntrain_dataframe, test_dataframe = train_test_split(features_dataframe, train_size=train_size, test_size=1 - train_size, random_state=42)\ntrain_dataframe = train_dataframe.sort([\"date\"])\ntest_dataframe = test_dataframe.sort([\"date\"])\nreturn train_dataframe, test_dataframe",
        "cols = df.columns[2:4]\ndf[cols + '_scale'] = scaler.fit_transform(df[cols])\ndf = df.groupby('Month').apply(lambda x: x[cols + '_scale']).reset_index()\nprint(df)",
        "\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\nmyData = pd.DataFrame({\n    'Month': [3, 3, 3, 3, 3, 3, 8, 8, 8, 8, 8, 8, 8],\n    'A1': [1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2],\n    'A2': [31, 13, 13, 13, 33, 33, 81, 38, 18, 38, 18, 18, 118],\n    'A3': [81, 38, 18, 38, 18, 18, 118, 31, 13, 13, 13, 33, 33],\n    'A4': [1, 1, 1, 1, 1, 1, 8, 8, 8, 8, 8, 8, 8],\n})\nscaler = MinMaxScaler()\nmyData['new_' + cols] = myData.groupby('Month')[cols].transform(scaler.fit_transform)\nprint(myData)\n",
        "\n# [Missing Code]\n",
        "feature_names = count.get_feature_names_out()",
        "full_results = GridSearch_fitted.cv_results_\nprint(full_results)",
        "full_results = GridSearch_fitted.cv_results_\nfull_results = full_results.sort_values(by=['mean_fit_time'], ascending=False)\nfull_results = full_results.reset_index()\nfull_results = full_results.rename(columns={'index': 'parameter', 'mean_fit_time': 'accuracy'})\nprint(full_results)",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n"
    ],
    "Pytorch": [
        "\n# [Missing Code]\n",
        "optim.set_lr(0.001)",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\noptim = load_data()\noptim.set_lr(0.0005)\n",
        "",
        "\n",
        "embedded_input = torch.Tensor(word2vec.wv.syn0.data)\nreturn embedded_input",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "px = pd.DataFrame(x.detach().numpy())\nprint(px)",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nA_log, B = load_data()\nC = B[A_log]\nprint(C)\n",
        "\nC = B[:, A_logical.nonzero()]\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nA_log, B = load_data()\nC = B[:, A_log]\nprint(C)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nA_log, B = load_data()\nC = B[:, A_log]\nprint(C)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nA_log, B = load_data()\ndef solve(A_log, B):\n    C = B[:, A_log]\n    return C\nC = solve(A_log, B)\nprint(C)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nA_log, B = load_data()\nC = B[:, A_log]\nprint(C)\n",
        "C = B.index_select(0, idx)\nprint(C)",
        "\nimport pandas as pd\nimport torch\nimport numpy as np\nx_array = load_data()\nx_tensor = torch.from_numpy(x_array).float()\nprint(x_tensor)\n",
        "x_tensor = torch.from_numpy(x)\nprint(x_tensor)",
        "\n    # [Missing Code]\n    ",
        "\n# [Missing Code]\n",
        "mask = torch.zeros(len(lens), lens[0]).bool()\nfor i in range(len(lens)):\n    mask[i, :lens[i]] = torch.tensor(lens[i], dtype=torch.bool)\nprint(mask)",
        "\n# [Missing Code]\n",
        "\n    # [Missing Code]\n    ",
        "Tensor_3D = torch.diag(Tensor_2D)\nprint(Tensor_3D)",
        "\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\na, b = load_data()\nab = torch.cat((a, b), 0)\nprint(ab)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\na, b = load_data()\nab = torch.cat((a, b), 0)\nprint(ab)\n",
        "\n    ab = torch.cat((a, b), 0)\n    ",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\na = torch.rand((10, 1000, 96))\nlengths = torch.randint(1000, (10,))\na[ : , lengths : , : ] = 0\nprint(a)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\na = torch.rand((10, 1000, 96))\nlengths = torch.randint(1000, (10,))\na[ : , lengths : , : ] = 2333\nprint(a)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\na = torch.rand((10, 1000, 23))\nlengths = torch.randint(1000, (10,))\na[ : , : lengths , : ] = 0\nprint(a)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\na = torch.rand((10, 1000, 23))\nlengths = torch.randint(1000, (10,))\na[ : , : lengths , : ] = 2333\nprint(a)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nlist_of_tensors = load_data()\ntensor_of_tensors = torch.tensor(list_of_tensors)\nprint(tensor_of_tensors)\n",
        "\n# [Missing Code]\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nlist_of_tensors = load_data()\ndef Convert(lt):\n    tt = torch.tensor(lt)\n    return tt\ntensor_of_tensors = Convert(list_of_tensors)\nprint(tensor_of_tensors)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nlist_of_tensors = load_data()\ntensor_of_tensors = torch.stack(list_of_tensors, dim=0)\nprint(tensor_of_tensors)\n",
        "result = t[idx]\nprint(result)",
        "result = t[idx]\nprint(result)",
        "result = t[idx]\nprint(result)",
        "result = x.gather(1, ids)\nprint(result)",
        "result = x.gather(1, ids)\nprint(result)",
        "result = x[ids == 1]\nprint(result)",
        "\n# [Missing Code]\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nsoftmax_output = load_data()\noutput = torch.max(softmax_output, dim=1)[1]\nreturn output.numpy()\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nsoftmax_output = load_data()\noutput = torch.max(softmax_output, dim=1)[1]\nprint(output.numpy())\n",
        "\ndef solve(softmax_output):\n    max_probs = softmax_output.max(dim=1)[1].unsqueeze(1)\n    return max_probs.type_as(softmax_output)\ny = solve(softmax_output)\nprint(y)",
        "\n    output = np.argmin(softmax_output, axis=1)\n    ",
        "\n# [Missing Code]\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nA, B = load_data()\ncnt_equal = np.sum(np.equal(A, B))\nprint(cnt_equal)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nA, B = load_data()\ncnt_equal = np.sum(np.equal(A, B))\nprint(cnt_equal)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nA, B = load_data()\ncnt_not_equal = np.sum(A != B)\nprint(cnt_not_equal)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nA, B = load_data()\ndef Count(A, B):\n    cnt_equal = np.sum(np.equal(A, B))\n    return cnt_equal\ncnt_equal = Count(A, B)\nprint(cnt_equal)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nA, B = load_data()\ncnt_equal = np.equal(A[-x:], B[-x:]).sum()\nprint(cnt_equal)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nA, B = load_data()\ncnt_not_equal = np.sum(A[:, -x:] != B[:, -x:])\nprint(cnt_not_equal)\n",
        "\na_split = torch.chunk(a, chunk_dim, dim=3)\ntensors_31 = []\nfor i in range(0, 40, 1):\n    tensor = a_split[i][0].reshape(1, 3, 10, 1, 1)\n    tensors_31.append(tensor)\nfor tensor in tensors_31:\n    print(tensor)",
        "\nfor tensor in tensors_31:\n    print(tensor)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "signed_min = torch.where(torch.abs(x) < min, torch.sign(x), torch.sign(y))\nsigned_min = torch.where(torch.abs(y) < min, torch.sign(x), torch.sign(y))\n",
        "\n# [Missing Code]\n",
        "\n    # [Missing Code]\n    ",
        "confidence_score = torch.nn.Softmax(dim=1)(output)[:, 0]\nprint(confidence_score)",
        "\nresult = torch.cat([a[:, :2], torch.mean(a[:, 2:3], b[:, 1:2]), b[:, 2:4]], dim=1)\n",
        "\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nt = load_data()\nresult = torch.cat([t, new], dim=0)\nprint(result)\n",
        "\n# [Missing Code]\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nt = load_data()\nresult = torch.cat([t, new], dim=0)\nprint(result)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nhid_dim = 32\ndata = torch.randn(10, 2, 3, hid_dim)\ndata = data.view(10, 2 * 3, hid_dim)\nW = torch.randn(hid_dim)\nresult = torch.bmm(data, W).squeeze()\nresult = result.view(10, 2, 3)\nprint(result)\n"
    ]
}