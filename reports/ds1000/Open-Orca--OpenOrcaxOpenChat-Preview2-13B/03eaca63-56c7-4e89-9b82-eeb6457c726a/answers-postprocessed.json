{
    "Pandas": [
        "\n# [Missing Code]\n",
        "\n",
        "\n",
        "[Missing Code]\n\nresult = df.loc[df['Qu1'] == 'cheese', 'Qu1'] = 'cheese'\nresult = df.loc[df['Qu2'] == 'banana', 'Qu2'] = 'banana'\nresult = df.loc[df['Qu3'] == 'potato', 'Qu3'] = 'potato'\nresult = df.loc[df['Qu3'] == 'apple', 'Qu3'] = 'apple'\nresult = df.loc[df['Qu3'] == 'egg', 'Qu3'] = 'egg'\n\nresult = df.loc[df['Qu1'] == 'other', 'Qu1'] = 'other'\nresult = df.loc[df['Qu2'] == 'other', 'Qu2'] = 'other'\nresult = df.loc[df['Qu3'] == 'other', 'Qu3'] = 'other'\n\nresult = pd.DataFrame(result)\n```",
        "\n    # [Missing Code]\n",
        "[Missing Code]\n\nresult = df.loc[df['Qu1'].apply(lambda x: x in ['cheese', 'potato', 'banana', 'egg']) == True, 'Qu1'] = ['other']\nresult = df.loc[df['Qu2'].apply(lambda x: x in ['banana', 'apple', 'sausage']) == True, 'Qu2'] = ['sausage']\nresult = df.loc[df['Qu3'].apply(lambda x: x in ['apple', 'potato', 'sausage', 'cheese']) == True, 'Qu3'] = ['other']\n\nprint(result)",
        "[Missing Code]\n\nresult = df.loc[df['Qu1'].isin(['apple', 'potato', 'cheese', 'banana', 'egg']), 'Qu1'] = 'other'\nresult = df.loc[df['Qu2'].isin(['banana', 'sausage']), 'Qu2'] = 'other'\nresult = df.loc[df['Qu3'].isin(['apple', 'potato', 'sausage', 'cheese', 'egg']), 'Qu3'] = 'other'\n\nprint(result)",
        "\n",
        "\n",
        "\n",
        "[Missing Code]\nresult = {}\nfor name, v1, v2, v3 in zip(df['name'], df['v1'], df['v2'], df['v3']):\n    result.setdefault(name, {}).setdefault(v1, {}).setdefault(v2, {}).setdefault(v3, 0) = v3\n\nprint(result)",
        "\ndf['datetime'] = df['datetime'].dt.tz_localize('UTC').dt.tz_convert('UTC').dt.tz_localize('UTC').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n    df['datetime'] = df['datetime'].dt.tz_localize('UTC').dt.tz_convert('UTC').dt.tz_localize('UTC').dt.strftime('%Y-%m-%d %H:%M:%S')\n    # [Missing Code]\n",
        "\ndf['datetime'] = df['datetime'].dt.tz_localize('UTC').dt.tz_convert('UTC').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
        "\ndf['datetime'] = df['datetime'].dt.tz_localize('UTC').dt.tz_convert('UTC').dt.tz_localize('UTC').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
        "[Missing Code]\nresult = df.explode('message')\nresult = result.set_index(['name', 'status', 'number', 'job', 'money', 'wife', 'group', 'kids'])\nresult = result.unstack(fill_value='none')\nresult = result.reset_index()\nresult = result.rename(columns={0: 'name', 1: 'status', 2: 'number', 3: 'job', 4: 'money', 5: 'wife', 6: 'group', 7: 'kids'})\nprint(result)",
        "df['score'] = df['score'] * 10\nresult = df[['product', 'score']]\nprint(result)",
        "df['score'] = df['score'] * (10 if df['product'] not in products else 1)\nresult = df\nprint(result)",
        "df['score'] = df['score'].mask(df['product'].isin(products), df['score'] * 10)\nresult = df\nprint(result)",
        "df['score'] = df['score'].where(df['product'].isin(products), df['score'].min() - (df['score'] - df['score'].min()) * (df['product'] - min(products)).astype(float) / (max(products) - min(products)))\nresult = df\nprint(result)",
        "df1 = df.astype('category')\nresult = df1\nprint(result)",
        "df = pd.get_dummies(df, columns=['A', 'B', 'C', 'D'])\nresult = df.assign(category=df[['A', 'B', 'C', 'D']].astype('category').astype(int).astype('category'))\nprint(result)",
        "\n# [Missing Code]\n",
        "df['Date'] = df['Date'].dt.to_period(\"M\")\nresult = df\nprint(result)",
        "df['Date'] = df['Date'].dt.to_period(\"M\")\ndf['Date'] = df['Date'].dt.to_period(\"M\").str.cat(df['Date'].dt.to_period(\"Y\"), \"-\", df['Date'].dt.to_period(\"d\"))\nresult = df\nprint(result)",
        "[Missing Code]\n\nresult = df[df['Date'] >= pd.to_datetime('2019-01-17') & df['Date'] <= pd.to_datetime('2019-02-20')]\nresult['Date'] = result['Date'].dt.to_period('M')\nresult['Date'] = result['Date'].dt.strftime('%d-%b-%Y')\nresult['Date'] = result['Date'].str.replace('-', '')\nresult['Date'] = result['Date'].str.replace(' ', '')\nresult['Date'] = result['Date'].str.replace('20', '')\nresult['Date'] = result['Date'].str.replace('19', '')\nresult['Date'] = result['Date'].str.replace('18', '')\nresult['Date'] = result['Date'].str.replace('17', '')\nresult['Date'] = result['Date'].str.replace('16', '')\nresult['Date'] = result['Date'].str.replace('15', '')\nresult['Date'] = result['Date'].str.replace('14', '')\nresult['Date'] = result['Date'].str.replace('13', '')\nresult['Date'] = result['Date'].str.replace('12', '')\nresult['Date'] = result['Date'].str.replace('11', '')\nresult['Date'] = result['Date'].str.replace('10', '')\nresult['Date'] = result['Date'].str.replace('09', '')\nresult['Date'] = result['Date'].str.replace('08', '')\nresult['Date'] = result['Date'].str.replace('07', '')\nresult['Date'] = result['Date'].str.replace('06', '')\nresult['Date'] = result['Date'].str.replace('05', '')\nresult['Date'] = result['Date'].str.replace('04', '')\nresult['Date'] = result['Date'].str.replace('03', '')\nresult['Date'] = result['Date'].str.replace('02', '')\nresult['Date'] = result['Date'].str.replace('01', '')\nresult['Date'] = result['Date'].str.replace('31', '')\nresult['Date'] = result['Date'].str.replace('30', '')\nresult['Date'] = result['Date'].str.replace('29', '')\nresult['Date'] = result['Date'].str.replace('28', '')\nresult['Date'] = result['Date'].str.replace('27', '')\nresult['Date'] = result['Date'].str.replace('26', '')\nresult['Date'] = result['Date'].str.replace('25', '')\nresult['Date'] = result['Date'].str.replace('24', '')\nresult['Date'] = result['Date'].str.replace('23', '')\nresult['Date'] = result['Date'].str.replace('22', '')\nresult['Date'] = result['Date'].str.replace('21', '')\nresult['Date'] = result['Date'].str.replace('20', '')\nresult['Date'] = result['Date'].str.replace('19', '')\nresult['Date'] = result['Date'].str.replace('18', '')\nresult['Date'] = result['Date'].str.replace('17', '')\nresult['Date'] = result['Date'].str.replace('16', '')\nresult['Date'] = result['Date'].str.replace('15', '')\nresult['Date'] = result['Date'].str.replace('14', '')\nresult['Date'] = result['Date'].str.replace('13', '')\nresult['Date'] = result['Date'].str.replace('12', '')\nresult['Date'] = result['Date'].str.replace('11', '')\nresult['Date'] = result['Date'].str.replace('10', '')\nresult['Date'] = result['Date'].str.replace('09', '')\nresult['Date'] = result['Date'].str.replace('08', '')\nresult['Date'] = result['Date'].str.replace('07', '')\nresult['Date'] = result['Date'].str.replace('06', '')\nresult['Date'] = result['Date'].str.replace('05', '')\nresult['Date'] = result['Date'].str.replace('04', '')\nresult['Date'] = result['Date'].str.replace('03', '')\nresult['Date'] = result['Date'].str",
        "df = df.shift(1, axis=0)\nprint(result)",
        "df = df.shift(1, axis=0)\nprint(result)",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame({'#1': [11.6985, 43.6431, 54.9089, 63.1225, 72.4399],\n                   '#2': [126.0, 134.0, 130.0, 126.0, 120.0]},\n                  index=['1980-01-01', '1980-01-02', '1980-01-03', '1980-01-04', '1980-01-05'])\ndf = df.shift(1, axis=0)\nprint(df)\n",
        "\n# [Missing Code]\n",
        "df = pd.DataFrame(\n    {'HeaderA': [476],\n     'HeaderB': [4365],\n     'HeaderC': [457]})\nresult = df.rename(columns={'HeaderA': 'HeaderAX'}, inplace=True)\nprint(result)",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame(\n    {'HeaderA': [476],\n     'HeaderB': [4365],\n     'HeaderC': [457]})\ndf = df.rename(columns={'HeaderA': 'XHeaderA', 'HeaderB': 'XHeaderB', 'HeaderC': 'XHeaderC'})\nresult = df\nprint(result)\n",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame(\n    {'HeaderA': [476],\n     'HeaderB': [4365],\n     'HeaderC': [457],\n     \"HeaderX\": [345]})\ndf = df.rename(columns={'HeaderA': 'HeaderAX', 'HeaderB': 'HeaderBX', 'HeaderC': 'HeaderCX', 'HeaderX': 'HeaderX'}, inplace=True)\nresult = df\nprint(result)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "result = df.mean(axis=0, skipna=True, columns=column_list, index=row_list)",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame({'a':[1,1,1,1],'b':[2,2,1,0],'c':[3,3,1,0],'d':[0,4,6,0],'q':[5,5,1,0]})\nrow_list = [0,2,3]\ncolumn_list = ['a','b','d']\nresult = df.sum(axis=0, columns=column_list, index=row_list)\nprint(result)\n",
        "\nimport pandas as pd\n\ndf = pd.DataFrame({'a':[1,1,1,1],'b':[2,2,1,0],'c':[3,3,1,0],'d':[0,4,6,0],'q':[5,5,1,0]})\nrow_list = [0,2,3]\ncolumn_list = ['a','b','d']\nresult = df.sum(axis=0, columns=column_list, index=row_list)\nprint(result)\n",
        "[Missing Code]\n\nresult = df.value_counts()\nresult = result.astype('float64')\nresult.index = result.index.astype('int64')\nresult = result.sort_values(ascending=False)\nresult = result.to_series()\n\nprint(result)",
        "\n",
        "\n# [Missing Code]\n",
        "df = df.drop('Unnamed: 2', axis=1)\ndf = df.iloc[[0]].assign(Unnamed_1=df.iloc[[0]]['Nanonose'])\ndf = df.iloc[[1]].assign(Unnamed_1=df.iloc[[1]]['Nanonose'])\ndf = df.set_index('Unnamed_1').T\nresult = df.reset_index()\nprint(result)",
        "df = df.drop('Unnamed: 2', axis=1)\ndf = df.iloc[[0]].combine_first(df.iloc[[1]])\nprint(df)",
        "df = pd.DataFrame([[3,1,2],[np.nan,1,2],[np.nan,np.nan,2]],columns=['0','1','2'])\nresult = df.apply(lambda x : (x[x.notnull()].values.tolist()+x[x.isnull()].values.tolist()),1)\nprint(result)\n```\n\n[Missing Code]",
        "df = pd.DataFrame([[3,1,2],[1,2,np.nan],[2,np.nan,np.nan]],columns=['0','1','2'])\nresult = df.apply(lambda x : (x[x.isnull()].values.tolist()+x[x.notnull()].values.tolist()),1)\nprint(result)",
        "\nresult = df.apply(lambda x : (x[x.isnull()].values.tolist()+x[x.notnull()].values.tolist()),0)\nprint(result)\n",
        "df_smaller = df.loc[df['value'] < thresh]\nresult = df_smaller.sum(axis=0)\nresult.index = ['X']\nresult = result.reset_index(drop=True)\ndf = df.append(result, ignore_index=True)\nprint(df)",
        " and",
        "\nresult = df.loc[df['value'] >= section_left, 'value'].mean()\n",
        "# [Missing Code]\nresult[\"inv_A\"] = df[\"A\"].apply(lambda x: 1/x)\nresult[\"inv_B\"] = df[\"B\"].apply(lambda x: 1/x)\n\n",
        "\n# [Missing Code]\n",
        "# [Missing Code]\nresult[\"inv_A\"] = df[\"A\"].apply(lambda x: 1/x)\nresult[\"inv_B\"] = df[\"B\"].apply(lambda x: 1/x)\n\n",
        "\n# [Missing Code]\n",
        "df['idxmin'] = df.idxmin()\ndf['idxmax'] = df.apply(lambda x: x.idxmax(), axis=1)\nresult = df.loc[df['idxmin']:df['idxmax'], 'index']\nprint(result)",
        "\n",
        "df['dt'] = pd.to_datetime(df['dt'])\ndf['dt'] = df['dt'].dt.to_period('D')\ndf['dt'] = df['dt'].dt.repeat(1).dt.to_timestamp()\ndf['dt'] = df['dt'].dt.to_pydatetime()\ndf['val'] = 0\ndf = df.set_index('dt')\ndf = df.unstack(level=0)\ndf = df.sort_index()\ndf = df.reset_index()\nresult = df.drop(columns=['level_0', 'dt']).rename(columns={'user': 'user', 'val': 'val'})\nprint(result)",
        "df['dt'] = pd.to_datetime(df['dt'])\ndf['dt'] = df['dt'].dt.to_period('D')\ndf['dt'] = df['dt'].dt.repeat(1).dt.to_timestamp('s')\ndf['dt'] = df['dt'].dt.to_period('D').dt.to_timestamp('s').dt.to_period('D')\ndf['val'] = 0\ndf = df.set_index('dt')\ndf = df.unstack(level=0)\ndf = df.sort_index(axis=1)\ndf = df.reset_index()\n```\n\n[Desired Output]\n\ndt user val\n0  2022-01-01  abc    1\n1  2022-01-02  abc   14\n2  2022-01-03  abc    0\n3  2022-01-04  abc    0\n4  2022-01-05  abc    0\n5  2022-01-06  abc    0\n6  2022-01-01  efg    0\n7  2022-01-02  efg    0\n8  2022-01-03  efg    0\n9  2022-01-04  efg    0\n10 2022-01-05  efg   51\n11 2022-01-06  efg    4",
        "df['dt'] = pd.to_datetime(df['dt'])\ndf['dt'] = df['dt'].dt.to_period('D')\ndf['dt'] = df['dt'].dt.repeat(233)\ndf['val'] = 233\ndf = df.set_index('dt')\ndf = df.unstack()\ndf = df.sort_index()\ndf = df.reset_index()\nprint(df)",
        "df['dt'] = pd.to_datetime(df['dt'])\ndf['dt'] = df['dt'].dt.to_period('D')\ndf['dt'] = df['dt'].dt.repeat(1).dt.to_timestamp()\ndf['dt'] = df['dt'].dt.to_pydatetime()\ndf['val'] = df['val'].max()\ndf = df.set_index('dt')\ndf = df.unstack()\ndf = df.sort_index()\ndf = df.reset_index()\nprint(df)",
        "df['dt'] = pd.to_datetime(df['dt'])\ndf['dt'] = df['dt'].dt.to_period('D')\ndf['dt'] = df['dt'].dt.repeat(10)\ndf['val'] = df['val'].max(axis=1)\ndf = df.set_index('dt')\ndf = df.unstack()\ndf = df.sort_index()\ndf = df.reset_index()\nprint(df)",
        "df['name'] = df['name'].astype('int')\ndf['name'] = df['name'].astype('str') + str(df['name'].astype('int'))\ndf['name'] = df['name'].str.split(' ', expand=True)[0]\ndf['name'] = df['name'].astype(str).str.zfill(3)\ndf['name'] = df['name'].astype(int)\n\ndf = df.set_index('name')\ndf = df.reset_index()\ndf = df.rename(columns={'level_0': 'name'})\n\nresult = df.sort_values('name')\n```",
        "\n# [Missing Code]\n",
        "\ndef f(df=example_df):\n    df['name'] = df['name'].astype('int')\n    df['name'] = df['name'].astype('str') + str(df['name'].astype('int').astype(str).replace(' ', ''))\n    return result\n",
        "df['ID'] = df.groupby('name')['a'].transform('max') + 1\ndf = df.set_index(['name', 'ID']).unstack().reset_index()\ndf.columns = ['ID', 'b', 'c']\nprint(df)",
        "[Missing Code]\nresult = df.pivot_table(index='user', columns='date', values='value', aggfunc=lambda x: x, dropna=False)\nresult = result.reset_index()\nresult = result.rename(columns={'date': 'date', 'value': 'value', 'someBool': 'someBool'})\nprint(result)",
        "[Missing Code]\nresult = df.pivot_table(index='user', columns='01/12/15', values='value', aggfunc=lambda x: (x, x[1]))\nresult = result.rename(columns={0: 'user', 1: '01/12/15', 2: 'others', 3: 'value'})\nresult = result.reset_index(drop=True)\nprint(result)",
        "[Missing Code]\nresult = df.pivot_table(index='user', columns='date', values='value', aggfunc=lambda x: x, dropna=False)\nresult = result.reset_index()\nresult = result.rename(columns={'date': 'date', 'value': 'value', 'someBool': 'someBool'})\nprint(result)",
        "\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(np.random.rand(4,5), columns = list('abcde'))\ncolumns = ['b','e']\nlocs = [df.columns.get_loc(_) for _ in columns]\nresult = df[df.c > 0.5][locs]\nprint(result)\n",
        "\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(np.random.rand(4,5), columns = list('abcde'))\ncolumns = ['a','b','e']\nlocs = [df.columns.get_loc(_) for _ in columns]\nresult = df[df.c > 0.45][locs]\nprint(result)\n",
        "df = df[df.c > 0.5]\nresult = df[columns].values\nreturn result",
        "\n    df_subset = df[df.c > 0.5][locs]\n    result = df_subset[columns].sum(axis=1)\n",
        "\ndef f(df, columns=['b', 'e']):\n    locs = [df.columns.get_loc(_) for _ in ['b', 'e']]\n    result = df[df.c > 0.5][locs]\n    return result\n",
        "filter_dates = []\nfor index, row in df.iterrows():\n     if observation_time == 'D':\n        for i in range(1, observation_period):\n            filter_dates.append((index.date() + timedelta(days=i)))\ndf = df[~df.index.isin(filter_dates)]\n\n",
        "filter_dates = []\nfor index, row in df.iterrows():\n     if observation_time == 'D':\n        for i in range(1, observation_period):\n            filter_dates.append((index.date() + timedelta(months=i)))\ndf = df[~df.index.isin(filter_dates)]\n\n",
        "[Missing Code]\nfilter_dates = []\nfor index, row in df.iterrows():\n     if observation_time == 'D':\n        for i in range(1, observation_period):\n            filter_dates.append((index.date() + timedelta(months=i)))\ndf = df[~df.index.isin(filter_dates)]",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame({'col1':[2, 1, 3, 1, 0]})\ndf = df.groupby(df.index // 3).mean()\nprint(result)\n",
        "\ndf = pd.DataFrame({'col1':[1, 1, 4, 5, 1]})\ndf = df.groupby(df.index // 3).agg({'col1': 'sum'})\nprint(result)\n",
        "\n",
        "df = df.iloc[::3].reset_index(drop=True)\nresult = df.col1.rolling(3, min_periods=1).mean()\nprint(result)",
        " and",
        "\n\n[Solution Code]\n",
        "\nimport pandas as pd\n\n\nindex = range(14)\ndata = [1, 0, 0, 2, 0, 4, 6, 8, 0, 0, 0, 0, 2, 1]\ndf = pd.DataFrame(data=data, index=index, columns = ['A'])\ndf['A'] = df['A'].fillna(method='ffill')\nresult = df\nprint(result)\n",
        "\nimport pandas as pd\n\n\nindex = range(14)\ndata = [1, 0, 0, 2, 0, 4, 6, 8, 0, 0, 0, 0, 2, 1]\ndf = pd.DataFrame(data=data, index=index, columns = ['A'])\ndf['A'] = df['A'].fillna(method='ffill')\nresult = df\nprint(result)\n",
        "\nimport pandas as pd\n\n\nindex = range(14)\ndata = [1, 0, 0, 2, 0, 4, 6, 8, 0, 0, 0, 0, 2, 1]\ndf = pd.DataFrame(data=data, index=index, columns = ['A'])\ndf['A'] = df['A'].fillna(method='ffill', limit=1)\nresult = df\nprint(result)\n",
        "\ndf ['numer'] = df.duration.str.extract(r'(\\d+)', expand=False)\ndf ['time']= df.duration.str.extract(r'(?P<time>week|month|day|year)', expand=False)\ndf ['time_day']= df.time.replace(r'(year|month|week|day)', r'(365|30|7|1)', regex=True, inplace=True)\n\nresult = df\nprint(result)\n",
        "\n",
        "\n",
        "\n# [Missing Code]\n",
        "check = np.where([df[column] != df2[column] for column in columns_check_list])\nresult = check.any()\nprint(result)",
        "check = np.where([df[column] == df[column] for column in columns_check_list])\nresult = check.any()\nprint(result)",
        "df.index.levels[1] = pd.to_datetime(df.index.levels[1])\nresult = df\nprint(result)",
        "df.index.levels[1] = pd.to_datetime(df.index.levels[1])\nresult = df\nprint(result)",
        "[Missing Code]\n\ndf = pd.read_csv(r'path/to/file.csv', parse_dates=['date'])\ndf = df.set_index('date')\ndf = df.to_numpy()\ndf = df.astype({'x': int, 'y': int})\ndf = df.T.to_numpy()\n```\n\n[Desired Output]\n[[Timestamp('1994-03-01 00:00:00') 100 7]\n [Timestamp('1994-09-01 00:00:00') 90 8]\n [Timestamp('1995-03-01 00:00:00') 80 9]]",
        "df = pd.read_csv(io=io, sep=\" \", names=names, index_col=0)\ndf = df.set_index([\"date\", \"id\"])\ndf = df.swaplevel(axis=1, level=0, level_name=\"date\")\ndf = df.swaplevel(axis=1, level=0, level_name=\"id\")\ndf = df.reset_index(drop=True)\ndf = df.astype({\"date\": \"datetime64[ns]\", \"id\": \"object\"})\ndf = df.astype({\"x\": \"int\", \"y\": \"int\"})\ndf = df.drop(columns=[\"x\", \"y\"])\ndf = df.astype({\"date\": \"datetime64[ns]\", \"id\": \"object\"})\ndf = df.astype({\"x\": \"int\", \"y\": \"int\"})\ndf = df.drop(columns=[\"x\", \"y\"])\ndf = df.astype({\"date\": \"datetime64[ns]\", \"id\": \"object\"})\ndf = df.astype({\"x\": \"int\", \"y\": \"int\"})\ndf = df.drop(columns=[\"x\", \"y\"])\ndf = df.astype({\"date\": \"datetime64[ns]\", \"id\": \"object\"})\ndf = df.astype({\"x\": \"int\", \"y\": \"int\"})\ndf = df.drop(columns=[\"x\", \"y\"])\ndf = df.astype({\"date\": \"datetime64[ns]\", \"id\": \"object\"})\ndf = df.astype({\"x\": \"int\", \"y\": \"int\"})\ndf = df.drop(columns=[\"x\", \"y\"])\ndf = df.astype({\"date\": \"datetime64[ns]\", \"id\": \"object\"})\ndf = df.astype({\"x\": \"int\", \"y\": \"int\"})\ndf = df.drop(columns=[\"x\", \"y\"])\ndf = df.astype({\"date\": \"datetime64[ns]\", \"id\": \"object\"})\ndf = df.astype({\"x\": \"int\", \"y\": \"int\"})\ndf = df.drop(columns=[\"x\", \"y\"])\ndf = df.astype({\"date\": \"datetime64[ns]\", \"id\": \"object\"})\ndf = df.astype({\"x\": \"int\", \"y\": \"int\"})\ndf = df.drop(columns=[\"x\", \"y\"])\ndf = df.astype({\"date\": \"datetime64[ns]\", \"id\": \"object\"})\ndf = df.astype({\"x\": \"int\", \"y\": \"int\"})\ndf = df.drop(columns=[\"x\", \"y\"])\ndf = df.astype({\"date\": \"datetime64[ns]\", \"id\": \"object\"})\ndf = df.astype({\"x\": \"int\", \"y\": \"int\"})\ndf = df.drop(columns=[\"x\", \"y\"])\ndf = df.astype({\"date\": \"datetime64[ns]\", \"id\": \"object\"})\ndf = df.astype({\"x\": \"int\", \"y\": \"int\"})\ndf = df.drop(columns=[\"x\", \"y\"])\ndf = df.astype({\"date\": \"datetime64[ns]\", \"id\": \"object\"})\ndf = df.astype({\"x\": \"int\", \"y\": \"int\"})\ndf = df.drop(columns=[\"x\", \"y\"])\ndf = df.astype({\"date\": \"datetime64[ns]\", \"id\": \"object\"})\ndf = df.astype({\"x\": \"int\", \"y\": \"int\"})\ndf = df.drop(columns=[\"x\", \"y\"])\ndf = df.astype({\"date\": \"datetime64[ns]\", \"id\": \"object\"})\ndf = df.astype({\"x\": \"int\", \"y\": \"int\"})\ndf = df.drop(columns=[\"x\", \"y\"])\ndf = df.astype({\"date\": \"datetime64[ns]\", \"id\": \"object\"})\ndf = df.astype({\"x\": \"int\", \"y\": \"int\"})\ndf = df.drop(columns=[\"x\",",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "[Missing Code]\n\nresult = df[df.apply(lambda row: abs(row) < 1, axis=1).all(axis=1)]\nprint(result)",
        "[Missing Code]\n\nresult = df[df.apply(lambda x: abs(x) > 1).any(axis=1)]\nprint(result)",
        "df = df[df.apply(lambda x: abs(x) > 1).any(axis=1)]\nresult = df.drop(columns=['Value_B', 'Value_C', 'Value_D'])\nprint(result)",
        "df['A'] = df['A'].replace('&AMP;', '&')\ndf = df.replace(to_replace=['&AMP;'], value='&', regex=False, inplace=True)\nresult = df\nprint(result)",
        "df['A'] = df['A'].str.replace('&LT;', '<')\ndf['C'] = df['C'].str.replace('&LT;', '<')\nresult = df\nprint(result)",
        "\nimport pandas as pd\n\nexample_df = pd.DataFrame({'A': ['Good &AMP; bad', 'BB', 'CC', 'DD', 'Good &AMP; bad'], 'B': range(5), 'C': ['Good &AMP; bad'] * 5})\ndef f(df=example_df):\n    df = df.replace('&AMP;', '&', regex=True)\n    return result\n",
        "\n",
        "df = df.replace('&AMP;', '&', regex=True)\nresult = df\nprint(result)",
        "[Missing Code]\nresult['first_name'] = df['name'].apply(lambda x: validate_single_space_name(x))\nresult['last_name'] = result['first_name'].str.split(' ', expand=True)[1]\nresult = result[['first_name', 'last_name']]\nprint(result)",
        "\n# [Missing Code]\n",
        "[Missing Code]\nresult['first_name'], result['middle_name'], result['last_name'] = result['name'].str.split(' ', expand=True)\nresult = result[['first_name', 'middle_name', 'last_name']]\nresult = result.dropna(axis=1, how='any')\nresult = result.astype({'first_name': 'str', 'middle_name': 'str', 'last_name': 'str'})\nresult = result.rename(columns={'first_name': 'first_name', 'middle_name': 'middle_name', 'last_name': 'last_name'})\nprint(result)",
        "result = df1.merge(df2, on='Timestamp', how='left')\nprint(result)",
        "df1['data'] = df1['data'].astype('datetime64[ns]')\ndf2['stuff'] = df2['stuff'].astype('datetime64[ns]')\nresult = df1.merge(df2, on='Timestamp', how='left')\nprint(result)",
        "df['state'] = df.apply(lambda row: row['col1'] if (row['col2'] <= 50 and row['col3'] <= 50) else max(row['col1'], row['col2'], row['col3']), axis=1)\nresult = df\nprint(result)",
        "\ndf['state'] = df.apply(lambda row: 25 if (row['col2'] > 50 and row['col3'] > 50) else row['col1'] + row['col2'] + row['col3'], axis=1)\n",
        "[Missing Code]\nresult[\"Field1\"] = result[\"Field1\"].apply(lambda x: int(x) if isinstance(x, int) else x)\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult[\"Field1\"] = result[\"Field1\"].str.split(\" \")\nresult[\"Field1\"] = result[\"Field1\"].str[0]\nresult = result[result[\"Field1\"].astype(int).isna()]\nresult",
        "[Missing Code]\nresult[\"Field1\"] = result[\"Field1\"].apply(lambda x: int(x) if isinstance(x, int) else x)\nresult = result[result[\"Field1\"].astype(int)]\nresult[\"Field1\"] = result[\"Field1\"].astype(str)\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]\nresult = result[result[\"Field1\"].str.contains(\"^[0-9]$\")]\nresult = result[result[\"Field1\"].str.len() == 1]",
        "[Missing Code]\nresult = [row[\"Field1\"] for row in df.iterrows() if not pd.isnumeric(row[\"Field1\"])]\nreturn result",
        "\n# [Missing Code]\n",
        "# [Missing Code]\nresult['percentage'] = result.apply(lambda x: (x['val1'] / x['total']) * 100, axis=1)\nresult = result.set_index('cat')\nresult = result.T.round(2)\nresult = result.T.reset_index()\nresult = result.rename(columns={'val1': 'percentage_val1', 'val2': 'percentage_val2', 'val3': 'percentage_val3', 'val4': 'percentage_val4'})\nresult = result.drop('total', axis=1)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult = result.astype(float)\nresult = result.astype(int)\nresult",
        "df.loc[test]",
        "df.loc[test]",
        "df = df.loc[~df.index.isin(test), :]\nprint(df)",
        "df.loc[test]",
        "\n# Calculate the nearest neighbour for each car\ndf2 = df.groupby('car')['car'].apply(lambda x: x.nearest_neighbour(df.loc[df['car'] == x, 'car']))\ndf2['euclidean_distance'] = df2.apply(lambda x: x.euclidean_distance(df.loc[df['car'] == x['nearest_neighbour'], 'x'], df.loc[df['car'] == x['nearest_neighbour'], 'y']), axis=1)\n\n# Calculate the average of the distances for each frame\ndf3 = df2.groupby('time').agg({'euclidean_distance': 'mean'})\n\nprint(df3)\n",
        "[Missing Code]\n\n# [Missing Code]\n\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "[Missing Code]\ncols = [df.keywords_0, df.keywords_1, df.keywords_2, df.keywords_3]\ndf[\"keywords_all\"] = df[\"keywords_all\"].apply(lambda cols: \"-\".join(cols), axis=1)",
        "[Missing Code]\ncols = [df.keywords_0, df.keywords_1, df.keywords_2, df.keywords_3]\ndf[\"keywords_all\"] = df[\"keywords_all\"].apply(lambda cols: \"-\".join(cols), axis=1)",
        "random_state=0,\nsample_size=0.2,\nresult = df.sample(n=sample_size, random_state=random_state)\nresult['Quantity'] = result['Quantity'].where(result['Quantity'] != 0, 0)\nresult = result.reset_index(drop=True)\nprint(result)",
        "random_state=0,\nsample_size=0.2,\nresult = df.sample(n=sample_size, random_state=random_state)\nresult['ProductId'] = result['ProductId'].mask(result['ProductId'] == 0)\nresult = result.reset_index(drop=True)\nprint(result)",
        "# [Missing Code]\nrandom_rows = df.sample(int(len(df) * 0.2), random_state=0)\nrandom_rows['Quantity'] = 0\nresult = df.merge(random_rows, how='left', on=['UserId', 'ProductId'])\nprint(result)",
        "\nimport pandas as pd\n\n\ndf=pd.DataFrame(data=[[1,2],[3,4],[1,2],[1,4],[1,2]],columns=['col1','col2'])\ndf['index_original'] = df.index[duplicate_bool == True]\nresult = df.loc[duplicate_bool == True, ['col1', 'col2', 'index_original']]\nprint(result)\n",
        "\nimport pandas as pd\n\n\ndf=pd.DataFrame(data=[[1,2],[3,4],[1,2],[1,4],[1,2]],columns=['col1','col2'])\ndf['index_original'] = df.index[duplicate_bool == True]\nresult = df.loc[duplicate, ['col1', 'col2', 'index_original']]\nprint(result)\n",
        "\ndef f(df=example_df):\n    duplicate_bool = df.duplicated(subset=['col1','col2'], keep='first')\n    duplicate = df.loc[duplicate_bool == True]\n    duplicate['index_original'] = duplicate.index.repeat(duplicate['col1'].eq(duplicate['col2']).astype(int))\n    return result\n",
        "\nduplicate['index_original'] = duplicate.index\nresult = df.loc[duplicate['index_original'] == True]\n",
        "\n# [Missing Code]\n",
        "[Missing Code]\nresult = df.groupby(['Sp', 'Mt']).max()\nprint(result)",
        "\n",
        "[Missing Code]\nresult = df.groupby(['Sp', 'Mt']).min()\nprint(result)",
        "result = df.groupby(['Sp', 'Value'])['count'].max()\ndf = df.loc[df['count'] == result]\nprint(df)",
        "df.query(\"Catergory==filter_list\")",
        "df.query(\"Catergory not in filter_list\")",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame({'col1': {0: 'a', 1: 'b', 2: 'c'},\n                   'col2': {0: 1, 1: 3, 2: 5},\n                   'col3': {0: 2, 1: 4, 2: 6},\n                   'col4': {0: 3, 1: 6, 2: 2},\n                   'col5': {0: 7, 1: 2, 2: 3},\n                   'col6': {0: 2, 1: 9, 2: 5},\n                  })\ndf.columns = [list('AAAAAA'), list('BBCCDD'), list('EFGHIJ')]\nvalue_vars=list(df.columns.values)\npd.melt(df, value_vars=value_vars)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "result = df.groupby('l')['v'].sum()\nresult['right'] = np.nan\nprint(result)",
        "\n",
        "\n# [Missing Code]\n",
        "[Missing Code]\n\ndef analyze_relationship(df, column1, column2):\n    relationship = 'one-to-one'\n    if column1.value_counts().unique().shape[0] == 1:\n        relationship = 'one-to-one'\n    elif column1.value_counts().unique().shape[0] > 1:\n        relationship = 'many-to-one'\n    elif column2.value_counts().unique().shape[0] == 1:\n        relationship = 'many-to-one'\n    elif column2.value_counts().unique().shape[0] > 1:\n        relationship = 'many-to-many'\n    return relationship\n\nresult = []\nfor column1 in df.columns:\n    for column2 in df.columns:\n        relationship = analyze_relationship(df, df[column1], df[column2])\n        result.append(f'{column1} {column2} {relationship}')\n\nprint(result)",
        "[Missing Code]\n\ndef relationship_type(df, column1, column2):\n    relationship_types = ['one-to-one', 'one-to-many', 'many-to-one', 'many-to-many']\n    count1 = df[column1].value_counts()\n    count2 = df[column2].value_counts()\n    for value in count1.index:\n        if value in count2.index:\n            relationship_type_list.append(f'{column1} {column2} {relationship_types[count1[value] == count2[value]]}')\n\nresult = []\nfor column1 in df.columns:\n    for column2 in df.columns:\n        if column1 != column2:\n            relationship_type(df, column1, column2)\nresult = ['Column1 Column2 one-2-many',\n 'Column1 Column3 one-2-many',\n 'Column1 Column4 one-2-one',\n 'Column1 Column5 one-2-many',\n 'Column2 Column1 many-2-one',\n 'Column2 Column3 many-2-many',\n 'Column2 Column4 many-2-one',\n 'Column2 Column5 many-2-many',\n 'Column3 Column1 many-2-one',\n 'Column3 Column2 many-2-many',\n 'Column3 Column4 many-2-one',\n 'Column3 Column5 many-2-many',\n 'Column4 Column1 one-2-one',\n 'Column4 Column2 many-2-one',\n 'Column4 Column3 many-2-many',\n 'Column4 Column5 many-2-many',\n 'Column5 Column1 many-2-one',\n 'Column5 Column2 many-2-many',\n 'Column5 Column3 many-2-many',\n 'Column5 Column4 many-2-one']\nprint(result)",
        "\nresult = relationship_type(df, df.columns)\n",
        "\n# [Missing Code]\n",
        "\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.DataFrame({'firstname': ['foo Bar', 'Bar Bar', 'Foo Bar'],\n                   'lastname': ['Foo Bar', 'Bar', 'Foo Bar'],\n                   'email': ['Foo bar', 'Bar', 'Foo Bar'],\n                   'bank': [np.nan, 'abc', 'xyz']})\ndf = df[df['bank'].notnull()]\nprint(result)\n",
        "df = pd.read_csv('data.csv')\nresult = pd.to_numeric(df.astype(str).str.replace(',',''), errors='coerce')\nprint(result)",
        "\nresult = df.loc[df[\"Has Family\"] == \"Has Family\", \"Survived\"].mean()\nresult = df.loc[df[\"No Family\"] == \"No Family\", \"Survived\"].mean()\nprint(result)\n",
        "df = df.groupby([\"Survived\", \"Parch\"]).agg({\"SibSp\": \"mean\"})\nresult = df.loc[df[\"Survived\"] > 0 | df[\"Parch\"] > 0, \"SibSp\"].mean()\nresult = df.loc[df[\"Survived\"] == 0 & df[\"Parch\"] == 0, \"SibSp\"].mean()\nresult = pd.DataFrame({'Has Family': result, 'No Family': result})\nprint(result)\n```\n\n[Missing Code]",
        "df = df.groupby([\"SibSp\", \"Parch\"]).agg({\"Survived\": \"mean\"})\nresult = df.loc[df[\"SibSp\"] == 1 & df[\"Parch\"] == 1, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 0 & df[\"Parch\"] == 0, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 0 & df[\"Parch\"] == 1, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 1 & df[\"Parch\"] == 0, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 0 & df[\"Parch\"] == 1, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 1 & df[\"Parch\"] == 0, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 0 & df[\"Parch\"] == 1, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 1 & df[\"Parch\"] == 0, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 0 & df[\"Parch\"] == 1, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 1 & df[\"Parch\"] == 0, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 0 & df[\"Parch\"] == 1, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 1 & df[\"Parch\"] == 0, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 0 & df[\"Parch\"] == 1, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 1 & df[\"Parch\"] == 0, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 0 & df[\"Parch\"] == 1, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 1 & df[\"Parch\"] == 0, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 0 & df[\"Parch\"] == 1, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 1 & df[\"Parch\"] == 0, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 0 & df[\"Parch\"] == 1, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 1 & df[\"Parch\"] == 0, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 0 & df[\"Parch\"] == 1, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 1 & df[\"Parch\"] == 0, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 0 & df[\"Parch\"] == 1, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 1 & df[\"Parch\"] == 0, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 0 & df[\"Parch\"] == 1, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 1 & df[\"Parch\"] == 0, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 0 & df[\"Parch\"] == 1, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 1 & df[\"Parch\"] == 0, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 0 & df[\"Parch\"] == 1, \"Survived\"].mean()\nresult = df.loc[df[\"SibSp\"] == 1 & df[\"Parch\"] == 0, \"Survived\"].mean()\nresult = df.loc[",
        "df = pd.DataFrame({'cokey':[11168155,11168155,11168155,11168156,11168156],\n                   'A':[18,0,56,96,0],\n                   'B':[56,18,96,152,96]})\nresult = df.groupby('cokey').sort('A')\nprint(result)\n```\n\n[Missing Code]\nresult = df.groupby('cokey').sort('A')\nprint(result)\n```\n\n",
        "df = pd.DataFrame({'cokey':[11168155,11168155,11168155,11168156,11168156],\n                   'A':[18,0,56,96,0],\n                   'B':[56,18,96,152,96]})\nresult = df.groupby('cokey').sort('A')\nprint(result)\n```\n\n[Missing Code]\nresult = df.groupby('cokey').sort('A')\nprint(result)\n```\n\n",
        "[Missing Code]\nresult = df.set_index(['Caps', 'Lower', 'A', 'B']).T\nprint(result)",
        "[Missing Code]\nresult = df.set_index(['Caps', 'Middle', 'Lower'])\nresult = result.unstack(level=1)\nresult = result.reset_index()\nresult = result.rename(columns={0: 'index'})\nresult = result.sort_values(by=['Caps', 'Middle', 'Lower', 'index'])\nresult = result.reset_index(drop=True)\nresult = result.rename(columns={'index': 'Caps Lower'})\nresult = result.set_index('Caps Lower')\nresult = result.sort_index()\nresult = result.reset_index()\nresult = result.rename(columns={'Caps Lower': 'Value'})\nresult = result.set_index('Value')\nresult = result.sort_index()\nresult = result.reset_index()\nresult = result.rename(columns={'Value': 'Caps Lower'})\nresult = result.set_index('Caps Lower')\nresult = result.sort_index()\nresult = result.reset_index()\nresult = result.rename(columns={'Caps Lower': 'Value'})\nresult = result.set_index('Value')\nresult = result.sort_index()\nresult = result.reset_index()\nresult = result.rename(columns={'Value': 'Caps Lower'})\nresult = result.set_index('Caps Lower')\nresult = result.sort_index()\nresult = result.reset_index()\nresult = result.rename(columns={'Caps Lower': 'Value'})\nresult = result.set_index('Value')\nresult = result.sort_index()\nresult = result.reset_index()\nresult = result.rename(columns={'Value': 'Caps Lower'})\nresult = result.set_index('Caps Lower')\nresult = result.sort_index()\nresult = result.reset_index()\nresult = result.rename(columns={'Caps Lower': 'Value'})\nresult = result.set_index('Value')\nresult = result.sort_index()\nresult = result.reset_index()\nresult = result.rename(columns={'Value': 'Caps Lower'})\nresult = result.set_index('Caps Lower')\nresult = result.sort_index()\nresult = result.reset_index()\nresult = result.rename(columns={'Caps Lower': 'Value'})\nresult = result.set_index('Value')\nresult = result.sort_index()\nresult = result.reset_index()\nresult = result.rename(columns={'Value': 'Caps Lower'})\nresult = result.set_index('Caps Lower')\nresult = result.sort_index()\nresult = result.reset_index()\nresult = result.rename(columns={'Caps Lower': 'Value'})\nresult = result.set_index('Value')\nresult = result.sort_index()\nresult = result.reset_index()\nresult = result.rename(columns={'Value': 'Caps Lower'})\nresult = result.set_index('Caps Lower')\nresult = result.sort_index()\nresult = result.reset_index()\nresult = result.rename(columns={'Caps Lower': 'Value'})\nresult = result.set_index('Value')\nresult = result.sort_index()\nresult = result.reset_index()\nresult = result.rename(columns={'Value': 'Caps Lower'})\nresult = result.set_index('Caps Lower')\nresult = result.sort_index()\nresult = result.reset_index()\nresult = result.rename(columns={'Caps Lower': 'Value'})\nresult = result.set_index('Value')\nresult = result.sort_index()\nresult = result.reset_index()\nresult = result.rename(columns={'Value': 'Caps Lower'})\nresult = result.set_index('Caps Lower')\nresult = result.sort_index()\nresult = result.reset_index()\nresult = result.rename(columns={'Caps Lower': 'Value'})\nresult = result.set_index('Value')\nresult = result.sort_index()\nresult = result.reset_index()\nresult = result.rename(columns={'Value': 'Caps Lower'})\nresult = result.set_index('Caps Lower')\nresult = result.sort_index()\nresult = result",
        "[Missing Code]\nresult = df.set_index(['Caps', 'Middle', 'Lower'])\nresult = result.unstack(level=0)\nresult = result.reset_index()\nresult = result.rename(columns={0: 'index'})\nresult = result.sort_values(by=['Caps', 'Middle', 'Lower', 'index'])\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result.reset_index(drop=True)\nresult = result",
        "\n",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame({'a':[1,1,1,2,2,2,3,3,3], 'b':[12,13,23,22,23,24,30,35,55]})\nresult = df.groupby('a').b.apply(lambda x: np.std(np.mean(x)))\nprint(result)\n",
        "\nresult = df.groupby('b').a.apply(lambda x: np.std(np.mean(x)))\n",
        "\nresult = df.groupby('a')['b'].softmax().reset_index()\nresult['min-max'] = result['b'] / result['b'].max()\nresult = result.reset_index()\nresult\n",
        "\n",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame([[-1,-1,0,2],[0,0,0,0],[1,0,0,1],[0,1,0,0],[1,1,0,1]],columns=['A','B','C','D'])\ndf = df.loc[df.sum(axis=1) == 0, :]\nresult = df.iloc[:, 0:2]\nprint(result)\n",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame([[1,2,3,1],[0,0,0,0],[1,0,0,1],[0,1,2,0],[1,1,0,1]],columns=['A','B','C','D'])\ndf = df[df.max() <= 2]\nresult = df[['A', 'D']]\nprint(result)\n",
        "\n# [Missing Code]\n",
        "\nimport pandas as pd\n\n\ns = pd.Series([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0.98,0.93],\n          index=['146tf150p','havent','home','okie','thanx','er','anything','lei','nite','yup','thank','ok','where','beerage','anytime','too','done','645','tick','blank'])\ns = s.sort_values(by=['index', 'value'], ascending=[True, True])\nprint(result)\n",
        "s = s.sort_values(by=['index', 'value'], ascending=True)\nresult = pd.DataFrame(s, index=s.index, columns=['index', '1'])\nprint(result)",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame({'A': [1, 2, 's', 3, 'b'],\n                   'B': ['green', 'red', 'blue', 'yellow', 'black']})\ndf = df[df['A'].astype('str').str.isdigit() | df['A'].astype('str').str.isnumeric()]\nprint(result)\n",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame({'A': [1, 2, 's', 3, 'b'],\n                   'B': ['green', 'red', 'blue', 'yellow', 'black']})\ndf = df[df['A'].astype('str')]\nresult = df[['A', 'B']]\nprint(result)\n",
        "[Missing Code]\nresult = df.groupby(['Sp', 'Mt']).max()\nprint(result)",
        "\n",
        "[Missing Code]\nresult = df.groupby(['Sp', 'Mt']).min()\nprint(result)",
        "result = df.groupby(['Sp', 'Value'])['count'].max()\ndf = df.loc[df['count'] == result]\nprint(df)",
        "df['Date'] = df['Member'].map(dict)\ndf['Date'] = df['Date'].fillna(df['Date'])\nresult = df\nprint(result)",
        "df['Date'] = df['Member'].map(dict)\ndf['Date'] = df['Date'].fillna(df['Date'])\nresult = df\nprint(result)",
        "\n    result = df.assign(Date=df['Member'].map(dict))\n",
        "[Missing Code]\ndf['Date'] = df['Member'].map(dict)\ndf['Date'] = df['Date'].fillna(df['Date'])\nresult = df\nprint(result)",
        "df['Date'] = pd.to_datetime(df['Date'], format= '%d/%m/%y')\ndf['Count_d'] = df.Date.map(df.groupby('Date').size())\ndf1 = df.groupby([df['Date'].dt.year.rename('year'), df['Date'].dt.month.rename('month')]).agg({'count': 'sum'})\nresult = df1\nprint(result)",
        "df['Date'] = pd.to_datetime(df['Date'], format= '%d/%m/%y')\ndf['Count_d'] = df.Date.map(df.groupby('Date').size())\ndf1 = df.groupby([df['Date'].dt.year.rename('year'), df['Date'].dt.month.rename('month')]).agg({'Val': 'count'})\nresult = df1.join(df.set_index(['Date', 'Val']).groupby('Val').size().rename('Count_Val'))\nresult = result.join(df.set_index(['Date', 'Val']).groupby('Val').size().rename('Count_Val'))\nprint(result)",
        "\nimport pandas as pd\n\n\nd = ({'Date': ['1/1/18','1/1/18','1/1/18','2/1/18','3/1/18','1/2/18','1/3/18','2/1/19','3/1/19'],\n      'Val': ['A','A','B','C','D','A','B','C','D']})\ndf = pd.DataFrame(data=d)\ndf['Date'] = pd.to_datetime(df['Date'], format= '%d/%m/%y')\ndf['Count_d'] = df.Date.map(df.groupby('Date').size())\ndf1 = df.groupby([df['Date'].dt.year.rename('year'), df['Date'].dt.month.rename('month')]).agg({'count'})\nprint(df1)\n",
        "\n# [Missing Code]\nresult1 = df.loc[df['B'] == 0, 'B'].sum()\nresult2 = df.loc[df['B'] != 0, 'B'].sum()\nresult1 = df.loc[df['C'] == 0, 'C'].sum()\nresult2 = df.loc[df['C'] != 0, 'C'].sum()\n",
        "[Missing Code]\n\nresult1 = df.loc[:, df['B'] % 2 == 0].sum()\nresult2 = df.loc[:, df['B'] % 2 != 0].sum()\n\nprint(result1)\nprint(result2)",
        "pd.pivot_table(df, values=['D', 'E'], rows=['B'], aggfunc=lambda x: np.sum(x) if x.name == 'D' else np.mean(x) if x.name == 'E', axis=1)",
        "df = pd.DataFrame({\n          'A' : ['one', 'one', 'two', 'three'] * 6,\n          'B' : ['A', 'B', 'C'] * 8,\n          'C' : ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 4,\n          'D' : np.random.randn(24),\n          'E' : np.random.randn(24)\n})\n\nresult = pd.pivot_table(df, values=['D','E'], rows=['B'], aggfunc=np.sum)\nresult = pd.pivot_table(df, values=['D','E'], rows=['B'], aggfunc=np.mean)\n```",
        "\nimport pandas as pd\nimport numpy as np\n\n\nnp.random.seed(1)\ndf = pd.DataFrame({\n'A' : ['abc', 'def', 'xyz', 'abc'] * 3,\n'B' : ['A', 'B', 'C'] * 4,\n'D' : np.random.randn(12),\n'E' : np.random.randn(12)\n})\nresult = pd.pivot_table(df, values=['D', 'E'], rows=['B'], aggfunc=lambda x: np.sum(x) if x == 'D' else np.mean(x) if x == 'E' else x)\nprint(result)\n",
        "pd.pivot_table(df, values=['D', 'E'], rows=['B'], aggfunc=lambda x: np.max(x) if x == 'D' else np.min(x) if x == 'E' else x)",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame({'str': ['Aa', 'Bb', '?? ?', '###', '{}xxa;']})\ndf[\"new\"] = df[\"str\"].apply(count_special_char)\nprint(df)\n",
        "\n# [Missing Code]\n",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame({'row': ['00000 UNITED STATES', '01000 ALABAMA',\n                           '01001 Autauga County, AL', '01003 Baldwin County, AL',\n                           '01005 Barbour County, AL']})\ndf['fips'] = df['row'].str.split(' ', expand=True)[0]\ndf['row'] = df['row'].str.split(' ', expand=True)[1]\nresult = df\n",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame({'row': ['114 AAAAAA', '514 ENENEN',\n                           '1926 HAHAHA', '0817 O-O,O-O',\n                           '998244353 TTTTTT']})\ndf['fips'] = df['row'].str.split(' ', 1, expand=True)[0]\ndf['row'] = df['row'].str.split(' ', 1, expand=True)[1]\nresult = df\n",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame({'row': ['00000 UNITED STATES', '01000 ALAB AMA',\n                           '01001 Autauga County, AL', '01003 Baldwin County, AL',\n                           '01005 Barbour County, AL']})\ndf['fips'] = df['row'].str.split(' ', 1, expand=True)[0]\ndf['medi'] = df['row'].str.split(' ', 1, expand=True)[1]\ndf['row'] = df['row'].str.split(' ', 1, expand=True)[2]\nresult = df\n",
        "# [Missing Code]\ncumulative_average = df.pivot_table(index='Name', columns='2001:2006', aggfunc='mean', fill_value=0)\nresult = df.assign(cumulative_average=cumulative_average)\nprint(result)",
        "\n",
        "\ndef f(df=example_df):\n    df['cumulative_avg'] = df.apply(lambda row: row['2001'] if row['2001'] != 0 else 0, axis=1)\n    df['cumulative_avg'] = df['cumulative_avg'].shift().fillna(df['cumulative_avg']).cumsum()\n    df['cumulative_avg'] = df['cumulative_avg'] / df['cumulative_avg'].shift().fillna(1)\n    df['cumulative_avg'] = df['cumulative_avg'].astype(float)\n    df = df.drop('2001', axis=1)\n    df = df.drop('2002', axis=1)\n    df = df.drop('2003', axis=1)\n    df = df.drop('2004', axis=1)\n    df = df.drop('2005', axis=1)\n    df = df.drop('2006', axis=1)\n    df = df.drop('cumulative_avg', axis=1)\n    return df\n",
        "\n",
        "\n# [Missing Code]\n",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame({'DateTime': ['2000-01-04', '2000-01-05', '2000-01-06', '2000-01-07', '2000-01-08'],\n                   'Close': [1460, 1470, 1480, 1480, 1450]})\ndf['label'] = df['Close'].diff().astype(int).replace(0, 1).replace(-1, -1).fillna(1)\nresult = df\nprint(result)\n",
        "df['Close'] = df['Close'].shift()\ndf['label'] = df['Close'].sub(df['Close']).abs().astype(int)\ndf['label'][0] = -1\ndf['label'][1:] = df['label'][1:] & 1\ndf['label'] = df['label'].astype(str)\ndf['label'] = df['label'].map({0: '0', 1: '1'})\ndf = df.set_index('DateTime')\nresult = df\nprint(result)\n```\n\n[Result]\n#    DateTime  Close  label\n0  04-Jan-2000   1460     -1\n1  05-Jan-2000   1470     -1\n2  06-Jan-2000   1480      0\n3  07-Jan-2000   1480      1\n4  08-Jan-2000   1450      1",
        "\nresult = df\nprint(result)\n",
        "\nresult = df\nprint(result)\n",
        "df['Duration'] = df.departure_time.astype('datetime64[ns]') - df.arrival_time.astype('datetime64[ns]')\nresult['Duration'] = result['Duration'].dt.seconds\nresult = result.set_index('id')\nresult = result.sort_index()\nprint(result)",
        "\n",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame({'key1': ['a', 'a', 'b', 'b', 'a', 'c'],\n                   'key2': ['one', 'two', 'one', 'two', 'one', 'two']})\nresult = df.groupby(['key1']).apply(lambda x: x['key2'].eq('two').sum())\nprint(result)\n",
        "df = df.groupby(['key1']).apply(lambda x: x['key2'].str.endswith('e')).reset_index()\nresult = df.groupby('key1').size()\nprint(result)",
        "[Missing Code]\nmax_result = df.index.max()\nmin_result = df.index.min()\nprint(max_result, min_result)",
        "[Missing Code]\nmode_result = df.value.mode()[0]\nmedian_result = df.value.median()\nprint(mode_result,median_result)",
        "df = df[(99 <= df['closing_price'] <= 101)]",
        "\nimport pandas as pd\nimport numpy as np\n\n\nnp.random.seed(2)\ndf = pd.DataFrame({'closing_price': np.random.randint(95, 105, 10)})\ndf = df[~(99 <= df['closing_price'] <= 101)]\nprint(result)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n    result = df['SOURCE_NAME'].str.split('_', expand=True)\n    result = result.apply(lambda x: x[-1] if '_' in x else x, axis=1)\n    # [Missing Code]\n",
        "\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.DataFrame({'Column_x': [0,0,0,0,0,0,1,1,1,1,1,1,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan]})\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].value_counts()[0] if df['Column_x'].isnull().sum() > 0 else df['Column_x'].value_counts()[1], inplace= True)\nresult = df\nprint(result)\n",
        "# [Missing Code]\n\n",
        "\n# [Missing Code]\n",
        "\n",
        "\n",
        "\nimport pandas as pd\nimport numpy as np\n\na = pd.DataFrame(np.array([[1, 2],[3, 4]]), columns=['one', 'two'])\nb = pd.DataFrame(np.array([[5, 6],[7, 8],[9, 10]]), columns=['one', 'two'])\nresult = pd.concat([a, b], axis=1).apply(lambda x: tuple(x.values), axis=1).astype(int)\nprint(result)\n",
        "groups = df.groupby(pd.cut(df.views, bins))\nresult = groups[['username', 'views']].sum().reset_index()\nprint(result)",
        "groups = df.groupby(pd.cut(df.views, bins))\nresult = groups.username.value_counts()\nprint(result)",
        "groups = df.groupby(pd.cut(df.views, bins))\nresult = groups.username.value_counts()\nprint(result)",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame({'text': ['abc', 'def', 'ghi', 'jkl']})\ndf = df.text.str.cat(sep=', ')\nresult = df.reset_index(drop=True)\nprint(result)\n",
        "\n",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame({'text': ['abc', 'def', 'ghi', 'jkl']})\ndf['text'] = df['text'].str.cat(sep=', ')\nresult = df\nprint(result)\n",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame({'text': ['abc', 'def', 'ghi', 'jkl']})\ndf = df.astype('object').apply(lambda x: ', '.join(x), axis=1).reset_index(drop=True)\nprint(result)\n",
        "\ndf = pd.DataFrame({'text': ['jkl-ghi-def-abc']})\nprint(df)\n",
        "\n",
        "[Missing Code]\nresult = pd.concat([df1, df2], axis=0)\nresult['date'] = result['date'].str.replace('20', '0')\nresult = result.sort_values(['id', 'date']).reset_index(drop=True)\nprint(result)",
        "[Missing Code]\nresult = pd.concat([df1, df2], axis=0)\nresult = result.sort_values(by=['id', 'date']).reset_index(drop=True)\nresult = result.set_index(['id', 'date', 'city', 'district']).unstack(level=2)\nresult = result.fillna(method='ffill')\nresult = result.fillna(method='bfill')\nresult = result.reset_index()\nprint(result)",
        "C = pd.DataFrame({\"A\": [\"AB\", \"CD\", \"EF\"], \"B\": [1, 2, 3]})\nD = pd.DataFrame({\"A\": [\"CD\", \"GH\"], \"B\": [4, 5]})\nresult = pd.merge(C, D, how='outer', on='A')\nresult = result.loc[result['B_x'].isna(), 'B'] = result['B_y']\nprint(result)",
        "\nimport pandas as pd\n\n\nC = pd.DataFrame({\"A\": [\"AB\", \"CD\", \"EF\"], \"B\": [1, 2, 3]})\nD = pd.DataFrame({\"A\": [\"CD\", \"GH\"], \"B\": [4, 5]})\nresult = pd.merge(C, D, how='outer', on='A')\nprint(result)\n",
        "result = C.merge(D, how='outer', on='A', suffixes=('', '_y'))\nresult['dulplicated'] = result['A_x'] == result['A_y']\nresult = result[['A', 'B', 'dulplicated']]\nprint(result)",
        "df = df.groupby('user')['time', 'amount'].agg(lambda x: list(zip(x['time'], x['amount'])))\nresult = df.reset_index()\nprint(result)",
        "\n# [Missing Code]\nresult = df.sort_values(['user', 'amount', 'time']).reset_index(drop=True)\n",
        "df = df.groupby('user').agg(lambda x: x.tolist())\nresult = df.sort_values(['time', 'amount']).reset_index(drop=True)\nprint(result)",
        "\n# [Missing Code]\n",
        "\n",
        "result = [col for col in df.columns if s in col and not col.startswith(s + '-')]\nprint(result)",
        "\nimport pandas as pd\n\n\ndata = {'spike-2': [1,2,3], 'hey spke': [4,5,6], 'spiked-in': [7,8,9], 'no': [10,11,12]}\ndf = pd.DataFrame(data)\ns = 'spike'\nresult = df[df.columns.str.contains(s)].columns.tolist()\nprint(result)\n",
        "\n",
        "df['codes'] = df['codes'].apply(pd.Series)\nresult = df.stack().reset_index(level=1, drop=True)\nresult.columns = ['code_0', 'code_1', 'code_2']\nresult = result.fillna(method='ffill')\nprint(result)",
        "df['codes'] = df['codes'].apply(pd.Series)\nresult = df.stack().reset_index(level=1, drop=True)\nresult.columns = ['code_1', 'code_2', 'code_3']\nresult = result.fillna(method='ffill')\nprint(result)",
        "df['codes'] = df['codes'].apply(pd.Series)\nresult = df.stack().reset_index(level=1, drop=True)\nresult = result.rename(columns={0: 'code_1', 1: 'code_2', 2: 'code_3'})\nresult = result.fillna(method='ffill')\nprint(result)",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame(dict(col1=[[1, 2, 3]] * 2))\nids = df.col1.apply(lambda x: list(x)).tolist()\nprint(result)\n",
        "\nimport pandas as pd\n\ndf = pd.DataFrame(dict(col1=[[1, 2, 3],[4,5]]))\nids = str(df.col1.apply(lambda x: ''.join(reversed(x))).astype(str))\nprint(result)\n",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame(dict(col1=[[1, 2, 3]] * 2))\nids = str(df.col1.values.tolist())\nprint(result)\n",
        "result = df.groupby(df.Time.dt.floor('2 minutes')).mean()\nprint(result)",
        "[Missing Code]\nresult = result.groupby(result.Time.dt.floor('3T')).mean()\nprint(result)",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "result = df[filt]",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame({'a': [1,1,1,2,2,2,3,3,3],\n                    'b': [1,2,3,1,2,3,1,2,3],\n                    'c': range(9)}).set_index(['a', 'b'])\nfilt = pd.Series({1:True, 2:False, 3:True})\nresult = df[filt]\nprint(result)\n",
        "[Missing Code]\n\nresult = df.iloc[0, :].equals(df.iloc[8, :]).astype(int)\nprint(result)\n```\n\n",
        "[Missing Code]\n\nresult = df.iloc[0, :].equals(df.iloc[8, :])\nprint(result)\n```\n\n",
        "\n# [Missing Code]\n",
        "[Missing Code]\n\nresult = df.iloc[0, :].eq(df.iloc[8, :]).astype(bool)\nresult = result.any(axis=1)\nresult = result.astype(int)\nresult = [i for i in range(len(result)) if result[i] == 1]\nresult = [(df.iloc[0, i], df.iloc[8, i]) for i in result]\nprint(result)",
        "ts = df['Value']\nts.index = df['Date']\nresult = ts\nprint(result)",
        "df = df.stack().reset_index(level=1, drop=True)\nresult = df\nprint(result)",
        "df = df.stack().reset_index(level=1, drop=True)\nresult = df\nprint(result)",
        "df['dogs'] = df['dogs'].round(2)\nresult = df\nprint(result)",
        "\n# [Missing Code]\n",
        "df['Sum'] = df[list_of_my_columns].sum(axis=1)",
        "df['Avg'] = df[list_of_my_columns].mean(axis=1)",
        "\n# [Missing Code]\n",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame({'VIM':[-0.158406,0.039158,-0.052608,0.157153,0.206030,0.132580,-0.144209,-0.093910,-0.166819,0.097548,0.026664,-0.008032]},\n                  index=pd.MultiIndex.from_tuples([('TGFb',0.1,2),('TGFb',1,2),('TGFb',10,2),('TGFb',0.1,24),('TGFb',1,24),('TGFb',10,24),('TGFb',0.1,48),('TGFb',1,48),('TGFb',10,48),('TGFb',0.1,6),('TGFb',1,6),('TGFb',10,6)],\n                                                 names=['treatment','dose','time']))\ndf = df.sort_values(by=['treatment', 'dose', 'time'], inplace=True)\nprint(result)\n",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame({'VIM':[-0.158406,0.039158,-0.052608,0.157153,0.206030,0.132580,-0.144209,-0.093910,-0.166819,0.097548,0.026664,-0.008032]},\n                  index=pd.MultiIndex.from_tuples([('TGFb',0.1,2),('TGFb',1,2),('TGFb',10,2),('TGFb',0.1,24),('TGFb',1,24),('TGFb',10,24),('TGFb',0.1,48),('TGFb',1,48),('TGFb',10,48),('TGFb',0.1,6),('TGFb',1,6),('TGFb',10,6)],\n                                                 names=['treatment','dose','time']))\ndf = df.sort_index(axis=1, level=1, kind='mergesort')\nprint(result)\n",
        "\n# [Missing Code]\n",
        "df = df[(df.index != '2020-02-17') & (df.index != '2020-02-18')]\ndf['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date', inplace=True)\ndf['Date'] = df['Date'].dt.dayofweek\ndf['Date'] = df['Date'].astype(str) + ' ' + df['Date'].dt.strftime('%Y-%m-%d')\nprint(df)",
        "\n# [Missing Code]\n",
        "\nimport pandas as pd\nimport numpy as np\n\nnp.random.seed(10)\ndf = pd.DataFrame(np.random.rand(10,5))\ncorr = df.corr()\nresult = df.filter(lambda x: x >= 0.3)\nprint(result)\n",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]], columns=list('ABA'))\ndf.rename(columns={df.columns[-1]: 'Test'}, inplace=True)\nprint(df)\n",
        "df.columns[0] = 'Test'",
        "[Missing Code]\n\ndf['frequent'] = df.apply(lambda row: '1' if row.sum() > 1 else '0', axis=1)\ndf['freq_count'] = df['frequent'].astype(int).cumsum()\nresult = df[['bit1', 'bit2', 'bit3', 'bit4', 'bit5', 'frequent', 'freq_count']]\nprint(result)",
        "# [Missing Code]\n\n",
        "[Missing Code]\n\nresult['frequent'] = result.apply(lambda row: set(row.values), axis=1)\nresult['freq_count'] = result.apply(lambda row: len(row['frequent']), axis=1)\nresult = result[['bit1', 'bit2', 'bit3', 'bit4', 'bit5', 'bit6', 'frequent', 'freq_count']]\nprint(result)",
        "\nimport pandas as pd\n\n\ndf = pd.DataFrame({\"foo\":[8,5,3,4,7,9,5,7], \n                   \"id1\":[1,1,1,1,1,1,1,1], \n                   \"bar\":['NULL','NULL','NULL',1,3,4,2,3], \n                   \"id2\":[1,1,1,2,2,3,3,1]})\n\nresult = df.groupby([\"id1\",\"id2\"])[\"foo\",\"bar\"].mean()\nprint(result)\n",
        "\n# [Missing Code]\n",
        "\nimport pandas as pd\n\n\ndf_a = pd.DataFrame({'EntityNum':[1001.01,1002.02,1003.03],'foo':[100,50,200]})\ndf_b = pd.DataFrame({'EntityNum':[1001.01,1002.02,1003.03],'a_col':['alice','bob','777'],'b_col':[7,8,9]})\ndf_c = pd.merge(df_a, df_b, on='EntityNum', how='left')\nresult = df_c[['EntityNum', 'foo', 'a_col']]\n",
        "\n"
    ],
    "Numpy": [
        "[Missing Code]\nresult = a.shape\nprint(result)",
        "\nimport numpy as np\nx = np.array([1400, 1500, 1600, np.nan, np.nan, np.nan ,1700])\nx = x[~np.isnan(x)]\nprint(x)\n",
        "\nimport numpy as np\nx = np.array([1400, 1500, 1600, np.nan, np.nan, np.nan ,1700])\nx[np.isnan(x)] = np.inf\nprint(x)\n",
        "\nimport numpy as np\nx = np.array([[1400, 1500, 1600, np.nan], [1800, np.nan, np.nan ,1700]])\nx = x.astype(float).copy()\nx[np.isnan(x)] = [np.nan] * len(x)\nresult = x.tolist()\nprint(result)\n",
        "\n",
        "\n",
        "\n",
        "[Missing Code]\nb = np.zeros((len(a), 3))\nb[np.arange(len(a)), a] = 1\nprint(b)\n```\n\n[Missing Code]",
        "\n",
        "\nimport numpy as np\na = np.array([1,2,3,4,5])\np = 25\nresult = np.percentile(a, p)\nprint(result)\n",
        "\nimport numpy as np\nA = np.array([1,2,3,4,5,6])\nncol = 2\nB = np.reshape(A, (ncol, A.size // ncol))\nprint(B)\n",
        "\nimport numpy as np\nA = np.array([1,2,3,4,5,6])\nnrow = 3\nB = np.reshape(A, (nrow, A.size // nrow))\nprint(B)\n",
        "\nimport numpy as np\nA = np.array([1,2,3,4,5,6,7])\nncol = 2\nB = A.reshape((-1, ncol))\nprint(B)\n",
        "\nimport numpy as np\nA = np.array([1,2,3,4,5,6,7])\nncol = 2\nB = A.reshape((-1, ncol))\nprint(B)\n",
        "\nimport numpy as np\na = np.array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.])\nshift = 3\nresult = np.roll(a, shift)\nprint(result)\n",
        "\nimport numpy as np\na = np.array([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n\t\t[1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])\nshift = 3\nresult = np.roll(a, shift, axis=0)\nprint(result)\n",
        "\nimport numpy as np\na = np.array([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n\t\t[1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])\nshift = [-2, 3]\nresult = np.roll(a, shift, axis=0)\nprint(result)\n",
        "r_old = np.random.randint(3, size=(100, 2000)) - 1\nr_new = np.random.randint(3, size=(100, 2000)) - 1\nprint(r_old, r_new)",
        "\nimport numpy as np\na = np.array([[10,50,30],[60,20,40]])\nresult = np.argmax(a, axis=1)\nprint(result)\n",
        "\nimport numpy as np\na = np.array([[10,50,30],[60,20,40]])\nresult = a.argmin(axis=0)\nprint(result)\n",
        "\n",
        "\n",
        "[Missing Code]\nresult = np.argmax(a, axis=1)\nreturn result",
        "\nimport numpy as np\na = np.array([[10,50,30],[60,20,40]])\nresult = np.argmax(a, axis=1) - 1\nprint(result)\n",
        "z = np.isnan(a).any(axis=1)\na[z] = np.nan\nprint(a)",
        "\nimport numpy as np\na = np.array([[np.nan, 2., 3., np.nan],\n\t\t[1., 2., 3., 9]])\na = a[~np.isnan(a).all(axis=1)]\nprint(a)\n",
        "\nimport numpy as np\na = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] \nresult = np.array(a)\nprint(result)\n",
        "a = np.roll(a, permutation, axis=1)\nprint(a)",
        "\nimport numpy as np\na = np.array([[[10, 20],\n        [30, 40]],\n       [[6,  7],\n        [8,  9]],\n\t[[10, 11],\n\t [12, 13]]])\npermutation = [1, 0, 2]\nresult = np.moveaxis(a, permutation, 0)\nprint(result)\n",
        "\nimport numpy as np\na = np.array([[1, 2], [3, 0]])\nresult = np.unravel_index(np.min(a), a.shape)\nprint(result)\n",
        "\n",
        "\nimport numpy as np\na = np.array([[1, 0], [0, 2]])\nresult = np.unravel_index(np.min(a), a.shape)\nprint(result)\n",
        "\nimport numpy as np\ndegree = 90\nresult = np.sin(degree)\nprint(result)\n",
        "\nimport numpy as np\ndegree = 90\nresult = np.cos(degree)\nprint(result)\n",
        "result = 0\nif np.sin(number * np.pi / 180) > np.sin(number * np.pi / 180):\n    result = 1\nprint(result)",
        "\n# [Missing Code]\n",
        "\nimport numpy as np\nA = np.array([1,2,3,4,5])\nlength = 8\nresult = np.pad(A, (length // 1024) * 1024, 'constant', constant_values=0)\nprint(result)\n",
        "\nimport numpy as np\nA = np.array([1,2,3,4,5])\nlength = 8\nresult = np.pad(A, (length // A.size) * A.size, 'constant', constant_values=0)\nprint(result)\n",
        "\n# [Missing Code]\n",
        "def f(a = example_a, power = 5):\n    result = np.square(a)\n    for _ in range(power - 1):\n        result = result * a\n    return result",
        "\nimport numpy as np\nnumerator = 98\ndenominator = 42\nresult = np.fractions(numerator, denominator)\nprint(result)\n",
        "\n    result = gcd(numerator, denominator)\n    # [Missing Code]\n",
        "\nimport numpy as np\nnumerator = 98\ndenominator = 42\nresult = reduce(numerator, denominator)\nprint(result)\n",
        "result = np.array([a + b + c]) / np.array([1, 1, 1])\nprint(result)",
        "\n",
        "\nimport numpy as np\na = np.array([[ 0,  1,  2,  3,  4],\n   [ 5,  6,  7,  8,  9],\n   [10, 11, 12, 13, 14],\n   [15, 16, 17, 18, 19],\n   [20, 21, 22, 23, 24]])\ndiagonal = np.diag_indices(a.shape[0])[::-1]\nresult = a[diagonal]\nprint(result)\n",
        "\nimport numpy as np\na = np.array([[ 0,  1,  2,  3,  4, 5],\n   [ 5,  6,  7,  8,  9, 10],\n   [10, 11, 12, 13, 14, 15],\n   [15, 16, 17, 18, 19, 20],\n   [20, 21, 22, 23, 24, 25]])\ndiagonal = np.diag_indices(a.shape[0]-1, 0)\nresult = a[diagonal]\nprint(result)\n",
        "\nimport numpy as np\na = np.array([[ 0,  1,  2,  3,  4],\n   [ 5,  6,  7,  8,  9],\n   [10, 11, 12, 13, 14],\n   [15, 16, 17, 18, 19],\n   [20, 21, 22, 23, 24]])\ndiagonal = np.diag_indices(a.shape[0]-1, 0)\nresult = a[diagonal]\nprint(result)\n",
        "\nimport numpy as np\na = np.array([[ 0,  1,  2,  3,  4, 5],\n   [ 5,  6,  7,  8,  9, 10],\n   [10, 11, 12, 13, 14, 15],\n   [15, 16, 17, 18, 19, 20],\n   [20, 21, 22, 23, 24, 25]])\ndiagonal = np.diag_indices(a.shape[0])[::-1]\nresult = a[diagonal]\nprint(result)\n",
        "\n# [Missing Code]\n",
        "[Missing Code]\nresult = []\nfor i in range(X.shape[0]):\n    for j in range(X.shape[1]):\n        result.append(X[i, j])\nprint(result)",
        "\n",
        "[Missing Code]\nresult = np.empty(X.shape[0], dtype=np.object)\nfor i in range(X.shape[0]):\n    for j in range(X.shape[1]):\n        result[i] = X[i, j]\nprint(result)",
        "mystr = \"100110\"\nresult = np.fromstring(mystr, dtype=int, sep='')\nprint(result)",
        "\n",
        "\n",
        "\nimport numpy as np\na = np.random.rand(8, 5)\nrow = 2\ndivide_number = 5.2\nresult = a[row] / divide_number\nresult = np.multiply(result, a[row])\nprint(result)\n",
        "\nimport numpy as np\na = np.array([[0,1,0,0], [0,0,1,0], [0,1,1,0], [1,0,0,1]])\nresult = np.linalg.matrix_rank(a) - 1\nprint(result)\n",
        "[Missing Code]\nresult = a.shape[0]",
        "\nprint(p_value)\n",
        "\nimport numpy as np\nimport scipy.stats\na = np.random.randn(40)\nb = 4*np.random.randn(50)\nt, p_value = scipy.stats.ttest_rel(a, b, n=len(a))\nprint(p_value)\n",
        "\nprint(p_value)\n",
        "\nimport numpy as np\nA=np.asarray([[1,1,1], [1,1,2], [1,1,3], [1,1,4]])\nB=np.asarray([[0,0,0], [1,0,2], [1,0,3], [1,0,4], [1,1,0], [1,1,1], [1,1,4]])\nA_complement = np.setdiff1d(A, B)\nprint(A_complement)\n",
        "A_diff_B = A[np.logical_and(np.logical_not(np.isin(A, B)), np.isin(B, A))]\nB_diff_A = B[np.logical_and(np.logical_not(np.isin(A, B)), np.isin(B, A))]\noutput = np.concatenate((A_diff_B, B_diff_A), axis=0)\n```\n\n[Output]\n[[1, 1, 2], [1, 1, 3], [0, 0, 0], [1, 0, 2], [1, 0, 3], [1, 0, 4], [1, 1, 0]]",
        "\nimport numpy as np\na = np.random.rand(3, 3, 3)\nb = np.arange(3*3*3).reshape((3, 3, 3))\nsort_indices = np.argsort(a, axis=0)\nc = b[sort_indices]\nprint(c)\n",
        "\nimport numpy as np\na = np.random.rand(3, 3, 3)\nb = np.arange(3*3*3).reshape((3, 3, 3))\nsort_indices = np.argsort(a, axis=0)\nc = b[sort_indices]\nprint(c)\n",
        "\nimport numpy as np\na = np.random.rand(3, 3, 3)\nb = np.arange(3*3*3).reshape((3, 3, 3))\nsort_indices = np.argsort(a, axis=0)\nc = b[sort_indices]\nprint(c)\n",
        "[Missing Code]\nresult = np.argsort(b, axis=1, kind='mergesort')\nprint(result)",
        "\nimport numpy as np\na = np.arange(12).reshape(3, 4)\na[:, 1] = 0\nprint(a)\n",
        "\n# [Missing Code]\n",
        "a = np.arange(12).reshape(3, 4)\na = a[:, 1::2]\nprint(a)",
        "\nimport numpy as np\na = np.arange(12).reshape(3, 4)\ndel_col = np.array([1, 2, 4, 5])\na[~np.isin(np.arange(a.shape[1]), del_col)] = 0\nprint(result)\n",
        "a.insert(pos, element)",
        "\nimport numpy as np\na = np.array([[1,2],[3,4]])\n\npos = 1\nelement = [3,5]\na[pos] = element\nprint(a)\n",
        "example_a = np.asarray([1,2,3,4])\ndef f(a = example_a, pos=2, element = 66):\n    a_l = a.tolist()\n    a_l.insert(pos, element)\n    a = np.asarray(a_l)\n    return a\n```python",
        "\nimport numpy as np\na = np.array([[1,2],[3,4]])\npos = [1, 2]\nelement = np.array([[3, 5], [6, 6]])\na[pos[i]] = element[i]\nprint(a)\n",
        "\nimport numpy as np\npairs = [(2, 3), (3, 4), (4, 5)]\narray_of_arrays = np.array([np.arange(a*b).reshape(a,b) for (a, b) in pairs])\nc = array_of_arrays.copy()\nprint(c)\n",
        "np.all(np.array_equal(a[0], a[i]) for i in range(1, len(a))))",
        "np.all(a == a[np.newaxis, :], axis=1)",
        "\n    # [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n    result = (np.cos(x)**4 + np.sin(y)**2).sum()\n",
        "[Missing Code]\nresult = np.cumsum(grades)\nprint(result)",
        "\nimport numpy as np\ngrades = np.array((93.5,93,60.8,94.5,82,87.5,91.5,99.5,86,93.5,92.5,78,76,69,94.5,\n          89.5,92.8,78,65.5,98,98.5,92.3,95.5,76,91,95,61))\neval = np.array([88, 87, 62])\nresult = np.interp(eval, grades, ecdf(grades))\nprint(result)\n",
        "\nlow, high = np.where(ecdf(grades) < threshold)\n",
        "\nimport numpy as np\none_ratio = 0.9\nsize = 1000\nrandomLabel = np.random.choice([0, 1], p=[one_ratio, 1-one_ratio], size=size)\nprint(nums)\n",
        "\nimport torch\nimport numpy as np\na = torch.ones(5)\na_np = a.numpy()\nprint(a_np)\n",
        "\nimport torch\nimport numpy as np\na = np.ones(5)\na_pt = torch.from_numpy(a)\nprint(a_pt)\n",
        "\nimport tensorflow as tf\nimport numpy as np\na = tf.ones([2,3,4])\na_np = a.numpy()\nprint(a_np)\n",
        "\nimport tensorflow as tf\nimport numpy as np\na = np.ones([2,3,4])\na_tf = tf.convert_to_tensor(a)\nprint(a_tf)\n",
        "a = np.array([4, 1, 0, 8, 5, 2])\nresult = np.argsort(a)[::-1]\nprint(result)",
        "a = np.array([4, 1, 0, 8, 5, 2])\nresult = np.argsort(a)[::-1]\nprint(result)",
        "\nimport numpy as np\na = np.array([4, 1, 0, 8, 5, 2])\nN = 3\nresult = np.argpartition(a, N)[::-1]\nprint(result)\n",
        "\nimport numpy as np\nA = np.arange(16).reshape(4, 4)\nn = 5\nresult = A**n\nprint(result)\n",
        "\nimport numpy as np\na = np.array([[1,5,9,13],\n              [2,6,10,14],\n              [3,7,11,15],\n              [4,8,12,16]])\nresult = np.array([[a[i, j], a[i + 1, j]] for i in range(len(a)) for j in range(len(a[0]))])\nprint(result)\n",
        "\nimport numpy as np\na = np.array([[1,5,9,13],\n              [2,6,10,14],\n              [3,7,11,15],\n              [4,8,12,16]])\nresult = np.array([[a[i, j], a[i + 1, j]] for i in range(len(a)) for j in range(len(a[0]))])\nprint(result)\n",
        "\nimport numpy as np\na = np.array([[1,5,9,13],\n              [2,6,10,14],\n              [3,7,11,15],\n              [4,8,12,16]])\nresult = np.array([[a[i:i+2, j:j+2] for i in range(0, a.shape[0], 2) for j in range(0, a.shape[1], 2)]])\nprint(result)\n",
        "\npatch_size = 2\nresult = np.array([[a[i:i+2, j:j+2] for i in range(0, a.shape[0], patch_size) for j in range(0, a.shape[1], patch_size)]])\n",
        "result = np.reshape(a, (h, w))\nprint(result)",
        "\npatch_size = 2\nresult = np.array([[a[i:i+2, j:j+2] for i in range(0, a.shape[0], patch_size) for j in range(0, a.shape[1], patch_size)]])\n",
        "\nimport numpy as np\na = np.array([[ 0,  1,  2,  3, 5, 6, 7, 8],\n              [ 4,  5,  6,  7, 5, 3, 2, 5],\n              [ 8,  9, 10, 11, 4, 5, 3, 5]])\nlow = 1\nhigh = 5\nresult = a[:, low:high+1]\nprint(result)\n",
        "\nimport numpy as np\na = np.array([[ 0,  1,  2,  3, 5, 6, 7, 8],\n              [ 4,  5,  6,  7, 5, 3, 2, 5],\n              [ 8,  9, 10, 11, 4, 5, 3, 5]])\nlow = 0\nhigh = 2\nresult = a[low:high+1]\nprint(result)\n",
        "\nimport numpy as np\na = np.array([[ 0,  1,  2,  3, 5, 6, 7, 8],\n              [ 4,  5,  6,  7, 5, 3, 2, 5],\n              [ 8,  9, 10, 11, 4, 5, 3, 5]])\nlow = 1\nhigh = 10\nresult = a[:, low:high+1]\nprint(result)\n",
        "\nimport numpy as np\nstring = \"[[ 0.5544  0.4456], [ 0.8811  0.1189]]\"\na = np.array(string.split(\"], [\")).reshape(-1, 2)\nprint(a)\n",
        "\nimport numpy as np\n\nmin = 1\nmax = np.e\nn = 10000\nresult = np.random.uniform(min, max, size=n)\nprint(result)\n",
        "result = np.random.uniform(np.log(min), np.log(max), size=n)",
        "\n    # [Missing Code]\n",
        "\nB = A.copy()\nB[0] = a * A[0]\nfor t in range(1, len(A)):\n    B.iloc[t] = a * A.iloc[t] + b * B.iloc[t-1]\n",
        "\nB = A.copy()\nB[0] = a * A[0]\nB[1] = a * A[1] + b * B[0]\nfor t in range(2, len(A)):\n    B[t] = a * A[t] + b * B[t-1] + c * B[t-2]\n",
        "\nimport numpy as np\nresult = np.empty((0,))\nprint(result)\n",
        "\nimport numpy as np\nresult = np.zeros((3, 0))\nprint(result)\n",
        "\nimport numpy as np\ndims = (3, 4, 2)\na = np.random.rand(*dims)\nindex = (1, 0, 1)\nresult = np.ravel_multi_index(index, dims)\nprint(result)\n",
        "\nimport numpy as np\ndims = (3, 4, 2)\na = np.random.rand(*dims)\nindex = (1, 0, 1)\nresult = np.ravel_multi_index(index, dims, order='C')\nprint(result)\n",
        "\nprint(df)\n",
        "\nimport numpy as np\na = np.arange(1,11)\naccmap = np.array([0,1,0,0,0,1,1,2,2,1])\nresult = np.cumsum(a[accmap])\nprint(result)\n",
        "\nimport numpy as np\na = np.arange(1,11)\nindex = np.array([0,1,0,0,0,1,1,2,2,1])\nresult = a[index].max()\nprint(result)\n",
        "\nimport numpy as np\na = np.arange(1,11)\naccmap = np.array([0,1,0,0,0,-1,-1,2,2,1])\nresult = np.cumsum(a[accmap])\nprint(result)\n",
        "result = a[index]\nresult = result.min()\nprint(result)",
        "\n# [Missing Code]\n",
        "\nimport numpy as np\nprobabilit = [0.333, 0.334, 0.333]\nlista_elegir = [(3, 3), (3, 4), (3, 5)]\nsamples = 1000\nresult = np.random.choice(lista_elegir, samples, probabilit)\nprint(result)\n",
        "result = np.pad(a, [(low_index, high_index), (low_index, high_index), (low_index, high_index)], 'constant', constant_values=0)",
        "\n# [Missing Code]\n",
        "\nresult = np.delete(x, np.isreal(x))\n",
        "\nprint(bin_data_mean)\n",
        "# [Missing Code]\nbin_data = np.split(data, np.where(np.diff(data, axis=0) > 0, bin_size - 1, 0))\nbin_data_max = np.max(bin_data, axis=0)\nprint(bin_data_max)",
        "\nprint(bin_data_mean)\n",
        "# [Missing Code]\nbin_data = np.split(data, np.cumsum(np.ones(len(data)) * (bin_size - 1))[:-1])\nbin_data_mean = [np.mean(bin) for bin in bin_data]\nprint(bin_data_mean)",
        "\nbin_data = np.split(data, np.cumsum(np.ones((data.shape[0], 1)), axis=1)[:-1])\nbin_data_mean = [np.mean(x, axis=0) for x in bin_data]\n",
        "\nbin_data = np.array([[(5, 6, 7)],\n                    [(3, 5, 7)]])\nbin_data_mean = np.array([[6],\n                         [5]])\n",
        "\nresult = smoothclamp(x)\nprint(result)\n",
        "def smoothclamp(x, N=5):\n    if x < x_min:\n        return np.zeros(N)\n    elif x > x_max:\n        return np.ones(N)\n    else:\n        return np.linspace(0, 1, N)[int(N * (x - x_min) / (x_max - x_min))]\n\nresult = smoothclamp(x, N=N)\nprint(result)",
        "\nimport numpy as np\na = np.array([1,2,3,4])\nb = np.array([5, 4, 3, 2])\nresult = np.correlate(a, b, mode='valid')\nprint(result)\n",
        "\nresult = df.to_numpy()\n",
        "\nimport numpy as np\nimport pandas as pd\nnames = ['One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine', 'Ten', 'Eleven', 'Twelve', 'Thirteen', 'Fourteen', 'Fifteen']\ntimes = [pd.Timestamp('2019-01-22 18:12:00'), pd.Timestamp('2019-01-22 18:13:00'), pd.Timestamp('2019-01-22 18:14:00'), pd.Timestamp('2019-01-22 18:15:00'), pd.Timestamp('2019-01-22 18:16:00')]\ndf = pd.DataFrame(np.random.randint(10, size=(15*5, 4)), index=pd.MultiIndex.from_product([names, times], names=['major','timestamp']), columns=list('colu'))\nresult = df.to_numpy()\nprint(result)\n",
        "\nimport numpy as np\na = np.array([1, 2, 3, 4, 5])\nm = 8\nresult = np.unpackbits(np.uint8(a), m)\nprint(result)\n",
        "\nimport numpy as np\na = np.array([1, 2, 3, 4, 5])\nm = 6\nresult = np.unpackbits(np.uint8(a) << (8 - m))\nprint(result)\n",
        "[Missing Code]\nresult = np.zeros((1, m))\nfor i in range(len(a)):\n    result[0, i] = a[i]\nresult = result.astype(np.uint8)\nresult = np.unpackbits(result, m)\nresult = np.bitwise_xor.reduceat(result, 0, len(result))\nprint(result)",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nresult = np.percentile(a, 99.7)\n",
        "# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nimport numpy as np\na = np.array([[0, 3, 1, 3], [3, 0, 0, 0], [1, 0, 0, 0], [3, 0, 0, 0]])\nzero_rows = 0\nzero_cols = 0\na[zero_rows][zero_cols] = 0\nprint(a)\n",
        "\nimport numpy as np\na = np.array([[0, 3, 1, 3], [3, 0, 0, 0], [1, 0, 0, 0], [3, 0, 0, 0]])\nzero_rows = [1, 3]\nzero_cols = [1, 2]\na[zero_rows, zero_cols] = 0\nprint(a)\n",
        "\nimport numpy as np\na = np.array([[0, 3, 1, 3], [3, 0, 0, 0], [1, 0, 0, 0], [3, 0, 0, 0]])\na[1] = 0\na[0] = 0\nprint(a)\n",
        "\n# [Missing Code]\n",
        "\nimport numpy as np\na = np.array([[0, 1], [2, 1], [4, 8]])\nmin_axis = np.min(a, axis=1)\nmask = min_axis.astype(bool)\nprint(mask)\n",
        " and",
        "[Missing Code]\nresult = np.empty((X.shape[0], X.shape[1], X.shape[1]))\nfor i in range(X.shape[0]):\n    result[i, :, :] = X[i, :].dot(X[i, :].T)\n\nprint(result)",
        "X = np.dot(Y.reshape(-1, 3, 3), Y.reshape(3, -1, 3).T)\nprint(X)",
        "\nimport numpy as np\na = np.array([9, 2, 7, 0])\nnumber = 0\nis_contained = a.any(number == 0)\nprint(is_contained)\n",
        "C = A[~np.isin(A, B)]",
        "\nimport numpy as np\nA = np.array([1,1,2,3,3,3,4,5,6,7,8,8])\nB = np.array([1,2,8])\nC = A[A.ravel() == B.ravel()]\nprint(C)\n",
        "C = A[np.isin(A, B)]",
        "\nimport numpy as np\nfrom scipy.stats import rankdata\na = [1,2,3,4,3,2,3,4]\nresult = rankdata(a).astype(int)[::-1]\nprint(result)\n",
        "\nimport numpy as np\nfrom scipy.stats import rankdata\na = [1,2,3,4,3,2,3,4]\nresult = np.argsort(a)[::-1]\nprint(result)\n",
        "\n    result = np.argsort(a)[::-1]\n    # [Missing Code]\n",
        "\n# [Missing Code]\n",
        "dists = np.dstack((x_dists, y_dists))\nprint(dists)",
        "result = a[:, second, third].reshape(5, 2, 2)\nprint(result.flatten())",
        "\nimport numpy as np\narr = numpy.zeros((20,)*3 + (10,))\nprint(arr)\n",
        "l1 = X.sum(axis=1)\nprint l1\nresult = X/l1.reshape(5, 1)\nprint(result)",
        "x = np.array([LA.norm(v, ord=2) for v in X])\nresult = np.divide(x, np.linalg.norm(x, ord=2, axis=1, keepdims=True))\nprint(result)",
        "result = np.array([LA.norm(v, ord=np.inf) for v in X])\nprint(result)",
        "conditions = [df['a'].str.contains(target)]\nchoices = ['match']\na[\"page_type\"] = np.select(conditions, choices, default=np.nan)",
        "distances = np.sqrt(np.sum(np.square(a[:, np.newaxis, :] - a[np.newaxis, :, :]), axis=-1))\nresult = np.sqrt(np.sum(np.square(a[:, np.newaxis, :] - a[np.newaxis, :, :]), axis=-1))\nprint(result)",
        "\nimport numpy as np\ndim = np.random.randint(4, 8)\na = np.random.rand(np.random.randint(5, 10),dim)\nresult = pdist(a, 'euclidean')\nprint(result)\n",
        "\nimport numpy as np\ndim = np.random.randint(4, 8)\na = np.random.rand(np.random.randint(5, 10),dim)\nresult = pdist(a, 'euclidean')\nprint(result)\n",
        "AVG = np.mean(NA, axis=0)",
        "AVG = np.mean(NA, axis=0)",
        "NA = np.asarray(A)\nNA = np.asarray(A)\nAVG = np.mean(NA, axis=0)\nprint(AVG)",
        "\n",
        "\nimport numpy as np\na = np.array([0, 0, 1, 1, 1, 2, 2, 0, 1, 3, 3, 3]).reshape(-1, 1)\na = a[~np.isnan(a)].astype(int)\na = a.reshape(-1, 1)\na = a[~np.isin(a, a[1:]).any(axis=1)]\nresult = a.astype(int)\nprint(result)\n",
        "\n# [Missing Code]\n",
        "df = pd.DataFrame({'lat': lat, 'lon': lon, 'val': val})\nreturn df",
        "df = pd.DataFrame({'lat': lat, 'lon': lon, 'val': val})\ndf['maximum'] = df.apply(lambda row: max(row['lat'], row['lon']), axis=1)\nprint(df)",
        "\nimport numpy as np\na = np.array([[1,2,3,4],\n       [2,3,4,5],\n       [3,4,5,6],\n       [4,5,6,7]])\nsize = (3, 3)\nresult = np.lib.stride_tricks.as_strided(a, shape=size, strides=size)\nprint(result)\n",
        "\n",
        "\nimport numpy as np\na = np.array([1 + 0j, 2 + 0j, np.inf + 0j])\nresult = np.mean(a)\nprint(result)\n",
        "\n    result = np.mean(a, axis=0)\n    # [Missing Code]\n",
        "Z = np.random.rand(*np.random.randint(2, 10, (np.random.randint(2, 10))))\nresult = Z[:, :, -1:]\nprint(result)",
        "a = np.random.rand(*np.random.randint(2, 10, (np.random.randint(2, 10))))\nresult = a[:-1, :]\nprint(result)",
        "c in CNTS = any(np.all(c == a, axis=1) for a in CNTS)\nprint(result)",
        "[Missing Code]\nresult = any(np.isnan(c).all() for c in CNTS) or any(np.isnan(c).any() for c in CNTS)\nprint(result)",
        "\nresult = intp.interp2d(x_new, y_new, a, kind='linear')\n",
        "\n# [Missing Code]\n",
        "\nimport numpy as np\na = np.matrix([[3, 4, 3, 1],[1,3,2,6],[2,4,1,5],[3,3,5,2]])\nU, i, V = np.linalg.svd(a,full_matrices=True)\ni = np.diag(i)\nprint(i)\n",
        "a[np.triu_indices(a.shape, k=1)] = 0",
        "\nimport numpy as np\nimport pandas as pd\nstart = \"23-FEB-2015 23:09:19.445506\"\nend = \"24-FEB-2015 01:09:22.404973\"\nn = 50\nresult = pd.date_range(start, end, periods=n)\nprint(result)\n",
        "result = np.where(x == a)[0]\nif result == -1:\n    result = np.where(y == b)[0]\nprint(result)",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nimport numpy as np\nx = [-1, 2, 5, 100]\ny = [123, 456, 789, 1255]\ndegree = 3\nresult = np.polyfit(x, y, degree)\nprint(result)\n",
        "\n# [Missing Code]\n",
        "result = np.einsum('ijk,jl->ilk', A, B)",
        "\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\na = np.array([[-1, 2], [-0.5, 6]])\nresult = MinMaxScaler().fit_transform(a)\nprint(result)\n",
        "\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\narr = np.array([[1.0,2.0,3.0],[0.1, 5.1, 100.1],[0.01, 20.1, 1000.1]])\nresult = MinMaxScaler()\nresult.fit(arr)\nresult.transform(arr)\nprint(result)\n",
        "\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\na = np.array([[[1, 0.5, -2], [-0.5,1, 6], [1,1,1]], [[-2, -3, 1], [-0.5, 10, 6], [1,1,1]]])\nresult = MinMaxScaler().fit_transform(a)\nprint(result)\n",
        "\n",
        "\n",
        "\n",
        "\n# [Missing Code]\n",
        "\nimport numpy as np\na = [np.array([1,2,3]),np.array([1,2,3]),np.array([1,2,3])]\nresult = np.array_equal(a, a)\nprint(result)\n",
        "result = all(np.isnan(x) for x in a)",
        "\n",
        "\n",
        "\n",
        "\n    pad_width = (shape[0] - arr.shape[0], shape[1] - arr.shape[1])\n    result = np.pad(arr, pad_width, 'constant', constant_values=(0, 0))\n",
        "\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nimport numpy as np\na = np.array( \n    [[[ 0,  1, 2, 3],\n     [ 2,  3, 4, 5],\n     [ 4,  5, 6, 7]],\n    [[ 6,  7, 8, 9],\n     [ 8,  9, 10, 11],\n     [10, 11, 12, 13]],\n    [[12, 13, 14, 15],\n     [14, 15, 16, 17],\n     [16, 17, 18, 19]]]\n)\nb = np.array( \n    [[0, 1, 2],\n    [2, 1, 3],\n[1, 0, 3]]\n)\nresult = a[b[:, 0], b[:, 1]]\nprint(result)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n",
        "\nimport numpy as np\nim = np.array([[0,0,0,0,0,0],\n               [0,0,1,1,1,0],\n               [0,1,1,0,1,0],\n               [0,0,0,1,1,0],\n               [0,0,0,0,0,0]])\nresult = np.array([[0,1,1,1], [1,1,0,1], [0,0,1,1]])\nprint(result)\n",
        "\nimport numpy as np\nA = np.array([[0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 1, 0, 0, 0, 0],\n           [0, 0, 1, 1, 0, 0, 0],\n           [0, 0, 0, 0, 1, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0]])\nA = A[~np.isnan(A)].astype(int)\nprint(result)\n",
        "\nimport numpy as np\nim = np.array([[1,1,1,1,1,5],\n               [1,0,0,1,2,0],\n               [2,1,0,0,1,0],\n               [1,0,0,7,1,0],\n               [1,0,0,0,0,0]])\nresult = np.where(im != 0, im, np.zeros_like(im))\nprint(result)\n",
        "\nimport numpy as np\nim = np.array([[0,0,0,0,0,0],\n               [0,0,5,1,2,0],\n               [0,1,8,0,1,0],\n               [0,0,0,7,1,0],\n               [0,0,0,0,0,0]])\nresult = np.array([[0,5,1,2], [1,8,0,1], [0,0,7,1]])\nprint(result)\n"
    ],
    "Matplotlib": [
        "\nfig, ax = plt.subplots()\nsns.scatter(x, y, ax=ax, label='x-y')\nplt.legend()\nplt.show()\n",
        "\nplt.minorticks_on()\n",
        "plt.minorticks_on()",
        "plt.xticks(rotation=45, minor=True)",
        "\n\n",
        "\n\n",
        "plt.plot(x, y, marker='d', markersize=3)",
        "plt.plot(x, y, marker='d', markersize=10)",
        "ax.set_ylim(0, 40)",
        "\nplt.axvspan(2, 4, color='red', alpha=0.2)\n",
        "plt.plot([0, 1], [0, 2])",
        "plt.plot([0, 1], [0, 2])",
        "\n\nsns.relplot(data=df, x=\"Height (cm)\", y=\"Weight (kg)\", hue=\"Gender\", palette=seaborn.color_palette())\n\n",
        "sns.set(style=\"whitegrid\")\nax = plt.gca()\nsns.scatter(x, y, ax=ax)\nplt.show()",
        "\n\nfig, ax = plt.subplots()\nsns.set(style=\"whitegrid\")\nsns.set_context(\"talk\")\nsns.set_style(\"whitegrid\")\n\ndata = pd.DataFrame({\"x\": x, \"y\": y})\nsns.lineplot(data=data, x=\"x\", y=\"y\", ax=ax)\n\n",
        "plt.plot(x, y, marker='o', markersize=7)",
        "plt.legend(fontsize=20)",
        "\nplt.plot(x, y)\nplt.legend(('x', 'y'), title='xyz', fontsize=20)\nplt.title('Cosine Function')\nplt.show()\n",
        "\nl.set_facecolor('r', alpha=0.2)\n",
        "l[0].set_markeredgecolor('black')",
        "\n\nx = np.random.randn(10)\ny = np.random.randn(10)\n\n(l,) = plt.plot(range(10), \"o-\", lw=5, markersize=30)\n\n# set both line and marker colors to be solid red\nl.set_color(\"red\")\n",
        "plt.xlabel(plt.xlabel(), rotation=45, labelpad=15)",
        "\n",
        "\n\nx_ticks = np.arange(0, 2 * np.pi, step=np.pi / 2)\nplt.xticks(x_ticks)\n\n",
        "\nplt.legend(handles=[sns.distplot(x, label=\"a\", color=\"0.25\").legend_element(), sns.distplot(y, label=\"b\", color=\"0.25\").legend_element()],\n           labels=[\"a\", \"b\"], loc=\"best\", frameon=False)\n\n",
        "\nplt.imshow(H, cmap=plt.cm.RdBu_r)\nplt.show()\n",
        "\nplt.imshow(H, cmap=plt.cm.bw)\nplt.show()\n",
        "plt.xlabel('X')\nplt.xlim(0, 2 * np.pi)",
        "\ng.ax_.set_xticklabels(np.rot90(g.ax_.get_xticklabels(), k=0))\n",
        "\n\n",
        "\nfig, ax = plt.subplots()\nax.invert_yaxis()\nplt.plot(x, y)\n",
        "\nplt.xticks([0, 1.5])\n",
        "\n\ny_ticks = [-1, 1]\nplt.gca().yaxis.set_ticks(y_ticks)\nplt.gca().yaxis.set_ticklabels(y_ticks)\n\n",
        "\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 6))\nax.plot(x, color='blue', label='x')\nax.plot(y, color='red', label='y', alpha=0.5)\nax.plot(z, color='green', label='z', alpha=0.5)\n\nax.legend(loc='best', frameon=False)\nax.set_xlim(0, 1)\nax.set_ylim(0, 1)\n\nplt.show()\n\n",
        "\nplt.scatter(x, y, c='blue', s=50, edgecolors='black')\n",
        "\nplt.xticks(np.arange(10), np.arange(10))\nplt.yticks(np.arange(10), np.arange(10))\n",
        "plt.yticks(np.arange(min(df['coverage']), max(df['coverage']), 100000000))",
        "ax = sns.lineplot(x=x, y=y, linestyle='dashed')",
        "\nfig, ax1 = plt.subplots(1, 2, sharex=True)\nax1[0].plot(x, y1)\nax1[1].plot(x, y2)\n\n",
        "\nfig, ax1 = plt.subplots(1, 2, sharex=True, gridspec_kw={'width_ratios': [3, 1]})\nax1[0].plot(x, y1)\nax1[1].plot(x, y2)\n\n",
        "plt.gca().axes[0].set_xlabel('')",
        "plt.gca().set_xticklabels([])",
        "plt.xticks([3, 4], [\"\", \"\"])",
        "\n\nax = plt.gca()\nax.yaxis.set_ticks([3, 4])\nax.yaxis.set_ticklabels([])\nax.grid(which='major', axis='y', linestyle='--', linewidth=1, color='gray')\n\n",
        "\n\nplt.yticks([3, 4], ['3', '4'])\nplt.yticks(np.arange(3, 5), ['3', '4'])\nplt.grid(which='major', axis='y', linestyle='--', linewidth=0.5, color='grey')\nplt.yticks(np.arange(3, 5), ['3', '4'])\n\nplt.xticks([1, 2], ['1', '2'])\nplt.xticks(np.arange(1, 3), ['1', '2'])\nplt.grid(which='major', axis='x', linestyle='--', linewidth=0.5, color='grey')\nplt.xticks(np.arange(1, 3), ['1', '2'])\n\n",
        "\n\nsns.stripplot(x, y, shade=True, alpha=0.2, linewidths=0.5, edgecolor='k',\n              xaxis='x', yaxis='y', hue='', palette='muted',\n              size=10, aspect=1, line_kws={'color': 'k'})\n\n",
        "plt.legend(loc=\"lower right\")",
        "\n\nfig, axes = plt.subplots(ncols=2, nrows=2, figsize=(8, 6), subplot_kw=dict(wspace=0.2))\naxes = axes.flatten()\n\nfor ax in axes:\n    ax.set_ylabel(r\"$\\ln\\left(\\frac{x_a-x_b}{x_a-x_c}\\right)$\")\n    ax.set_xlabel(r\"$\\ln\\left(\\frac{x_a-x_d}{x_a-x_e}\\right)$\")\n\nplt.show()\nplt.clf()\n\n",
        "\nplt.legend([\"Y\", \"Z\"])\n",
        "\nax.invert_yaxis()\n",
        "\nplt.plot(x, y)\nplt.xlabel(\"X\")\nplt.xlim([0, 10])\nplt.ylim([0, 10])\nplt.show()\n",
        "plt.plot(x, y)\nplt.xticks([])\nplt.show()",
        "\nplt.plot(x, y)\nplt.gca().invert_yaxis()\nplt.gca().spines['right'].set_visible(False)\nplt.gca().spines['top'].set_position(('data', 0))\nplt.gca().spines['bottom'].set_position(('data', 0))\nplt.gca().spines['left'].set_position(('data', 0))\nplt.gca().spines['left'].set_color('none')\nplt.gca().spines['right'].set_color('none')\nplt.gca().spines['top'].set_color('none')\nplt.gca().spines['bottom'].set_color('none')\nplt.show()\n",
        "\nplt.plot(x, y)\nplt.ylabel(\"Y\")\nplt.yticks(x, y)\nplt.yticklabels(x, y)\nplt.show()\n",
        "\n\nfig, ax = plt.subplots(figsize=(12, 8))\n\nsns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"reg\", ax=ax, color=\"green\")\n\nsns.distplot(tips[\"tip\"], ax=ax, color=\"blue\")\n\n",
        "\n\nfig, ax = plt.subplots(figsize=(12, 8))\nsns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"reg\", ax=ax, color=\"green\")\nsns.distplot(tips[\"tip\"], bins=50, color=\"blue\")\nsns.distplot(tips[\"total_bill\"], bins=50, color=\"blue\")\n\n",
        "\n\nfig, ax = plt.subplots(figsize=(12, 8))\nsns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"reg\", ax=ax)\n\n",
        "\n\nfig, ax = plt.subplots(figsize=(10, 5))\nax.bar(df[\"celltype\"], df[\"s1\"], width=0.8, align='center', alpha=0.7)\nax.bar(df[\"celltype\"], df[\"s2\"], width=0.8, align='center', alpha=0.7, bottom=df[\"s1\"])\nax.set_xticks(df[\"celltype\"])\nax.set_xticklabels(df[\"celltype\"], rotation=90, horizontalalignment='center')\nax.set_ylabel('Values')\nax.set_title('Bar Plot')\nplt.show()\n\n",
        "\n\nfig, ax = plt.subplots(figsize=(10, 5))\n\nax.bar(df[\"celltype\"], df[\"s1\"], width=0.8, align='center', alpha=0.7)\nax.bar(df[\"celltype\"], df[\"s2\"], width=0.8, align='center', alpha=0.7, bottom=df[\"s1\"])\n\nax.set_xticks(df[\"celltype\"])\nax.set_xticklabels(df[\"celltype\"], rotation=45)\n\nplt.show()\n\n",
        "\nplt.plot(x, y)\nplt.xlabel('X', color='red')\nplt.xticks(x, x, color='red')\n",
        "\nplt.plot(x, y)\nplt.xlabel(\"X\")\nplt.plot(x, y, color='red')\n",
        "\nplt.plot(x, y)\nplt.gca().set_xticklabels(x, fontsize=10, verticalalignment='bottom')\nplt.show()\n",
        "\nplt.plot([0.22058956, 0.33088437, 2.20589566], color='r')\n",
        "\n\nplt.imshow(rand_mat, interpolation='nearest', cmap=plt.cm.RdBu_r)\nplt.xticks(range(len(xlabels)), xlabels, rotation=90)\nplt.yticks(range(len(ylabels)), ylabels[::-1])\nplt.gca().invert_yaxis()\n\n",
        "\nax.legend(handles=[ax.get_line_segments_iterator(Swdown)[0], ax.get_line_segments_iterator(Rn)[0], ax2.get_line_segments_iterator(temp)[0]], labels=[\"Swdown\", \"Rn\", \"temp\"], loc=0)\n",
        "\nfig, ax = plt.subplots(2, 1, sharex=True, figsize=(10, 5))\n\nax[0].plot(x, y)\nax[0].set_title(\"Y\")\n\nax[1].plot(x, y)\nax[1].set_title(\"Y\")\n\nplt.show()\n\n",
        "\nfig, ax = plt.subplots(figsize=(12, 8))\nsns.scatter(\n    data=df,\n    x=\"bill_length_mm\",\n    y=\"bill_depth_mm\",\n    hue=\"species\",\n    palette=\"RdBu_r\",\n    s=30,\n    ax=ax,\n)\nplt.show()\n",
        "\n\nfig, ax = plt.subplots()\nax.scatter(a, b, c=c, cmap=plt.cm.Rd)\nax.set_xlabel('a')\nax.set_ylabel('b')\nax.set_title('Scatter plot of a over b')\n\n",
        "\nplt.plot(x, y, label=\"y over x\")\nplt.legend(loc=\"best\")\nplt.title(\"Legend Title\")\n",
        "\n\nfig, ax = plt.subplots()\nax.plot(x, y)\nax.set_xlabel('x')\nax.set_ylabel('y')\nax.set_title('y over x')\nax.legend(('y over x'), title='Legend', loc='best', frameon=True, fontsize=14)\n\n",
        "\nplt.hist(x, bins=10, density=False, alpha=0.5, edgecolor='black', linewidth=1.2)\nplt.show()\n",
        "plt.subplots(1, 2, sharex=True, squeeze=False)\nplt.subplot(1, 2, 1).set_aspect(3)\nplt.subplot(1, 2, 2).set_aspect(1)\nplt.subplots_adjust(wspace=0.33, hspace=0)",
        "\n\nfig, ax = plt.subplots(1, 1, sharex=True)\nax.hist(x, bins=bins, alpha=0.5, label='x')\nax.hist(y, bins=bins, alpha=0.5, label='y')\nplt.legend()\nplt.show()\n\n",
        "\n\nfig, ax = plt.subplots(1, 1, sharex=True)\n\n# Create a histogram of x\nx_hist, x_bins, _ = np.histogram(x, bins=10)\nx_hist = x_hist / x_hist.sum()\nax.plot(x_bins, x_hist, label='x')\n\n# Create a histogram of y\ny_hist, y_bins, _ = np.histogram(y, bins=10)\ny_hist = y_hist / y_hist.sum()\nax.plot(y_bins, y_hist, label='y')\n\n# Add a legend\nax.legend()\n\n",
        "\n\nplt.plot([a, c], [b, d])\nplt.xlim(0, 5)\nplt.ylim(0, 5)\n\n",
        "\n\nx = np.random.random((10, 10))\ny = np.random.random((10, 10))\n\n# make two colormaps with x and y and put them into different subplots\n# use a single colorbar for these two subplots\n\nfig, ax = plt.subplots(1, 2, sharex=True, sharey=True)\n\n# create colormaps\ncmap1 = plt.cm.get_cmap('RdBu', 10)\ncmap2 = plt.cm.get_cmap('RdBu', 10)\n\n# set the colormaps for the two subplots\nax[0].imshow(x, cmap=cmap1)\nax[1].imshow(y, cmap=cmap2)\n\n# create a single colorbar for both subplots\ncbar = plt.colorbar(ax[0].images[0], ax=ax[0])\ncbar.set_label('')\n\nplt.show()\n",
        "\nfig, ax = plt.subplots(1, 1, figsize=(8, 6))\nfor i in range(x.shape[1]):\n    ax.plot(x[:, i], label=f'{i}')\nax.legend()\nax.set_xlabel('x')\nax.set_ylabel('y')\nplt.show()\n",
        "\n\nfig, ax1 = plt.subplots(1, 2, sharex=True, sharey=True)\nax1[0].plot(x, y)\nax1[1].plot(a, z)\n\nplt.suptitle(\"Y and Z\")\n\n",
        "\nplt.plot(points, 'o')\nplt.yscale('log')\nplt.show()\n",
        "\n\nfig, ax = plt.subplots()\nax.plot(x, y)\nax.set_title('Plot of y over x', fontsize=20)\nax.set_xlabel('x', fontsize=18)\nax.set_ylabel('y', fontsize=16)\n\n",
        "ax.plot(x, y)\nax.set_xticks(x)\nax.set_xticklabels(np.arange(10))\nax.set_yticks(y)\nax.set_yticklabels(np.arange(10))\n\nplt.show()",
        "\n",
        "\n\nfig, ax = plt.subplots()\nax.plot(x, y)\nax.set_xscale('log')\nax.set_yscale('log')\nax.set_xlim(1, 1000)\nax.set_ylim(1, 1000)\nax.set_xticks([1, 10, 100, 1000])\nax.set_yticks([1, 10, 100, 1000])\nax.set_xticklabels(['1', '10', '100', '1000'])\nax.set_yticklabels(['1', '10', '100', '1000'])\n\nplt.show()\n\n",
        "\n\nfig, ax = plt.subplots(1, 4, sharex=True, figsize=(10, 4))\n\nfor i, col in enumerate(df.columns):\n    ax[i].plot(df.index, df[col], label=col)\n    ax[i].scatter(df.index, df[col], marker='o', s=50)\n\nplt.legend()\nplt.show()\n\n",
        "\n\n# Create a histogram of the data\nhist, bins = np.histogram(data, bins=np.arange(min(data), max(data) + 1, 1))\n\n# Renormalize the data to sum up to 1\nhist = hist / np.sum(hist)\n\n# Format the y tick labels into percentage\nplt.yticks(np.arange(0, 11, 1), [\"{0:.0f}%\".format(x) for x in np.arange(0, 11, 1)])\n\n# Plot the histogram\nplt.bar(bins[:-1], hist, align='center', alpha=0.75)\nplt.show()\n\n",
        "\nplt.plot(x, y, 'o', alpha=0.5, linewidth=2)\n",
        "\n\nfig, ax1 = plt.subplots(1, 2, sharex=True, figsize=(10, 5))\nax1[0].plot(x, y, label='y')\nax1[1].plot(z, a, label='a')\n\nfiglegend = plt.figlegend(handles=[ax1[0].get_legend_handles_labels(), ax1[1].get_legend_handles_labels()],\n                         loc='best',\n                         bbox_to_anchor=(1.05, 1),\n                         ncol=2,\n                         title_text='')\n\nplt.tight_layout()\nplt.show()\n\n",
        "\n\n",
        "\n\nax.set_xticklabels(range(1, 10))\nax.set_xticklabel('second', 2)\n\n",
        "\nplt.plot(x, y)\nplt.legend([\"y\"])\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\n",
        "\n\nxticks = plt.xticks()\nxticks.extend([2.1, 3, 7.6])\nplt.xticks(xticks, labels=xticks)\n\n",
        "\nplt.xticks(rotation=-60)\nplt.xticks(rotation=-60, ha='left')\n",
        "\n\n",
        "plt.xticks(fontsize=10, weight='light', size=10)",
        "plt.plot(x, y, label='')",
        "plt.ylim(0, y[1])",
        "\n\nfig, ax = plt.subplots(1, 2, sharex=True, figsize=(10, 5))\n\nfor i, ax in enumerate(ax.flat):\n    ax.plot(x, y, label=f\"Subplot {i+1}\")\n\nplt.title(\"Figure\")\nplt.legend()\n\n",
        "\n\nfig, ax = plt.subplots()\ndf.plot(x='Type A', y='Type B', ax=ax)\nax.set_xlabel('X')\nax.set_ylabel('Y')\nplt.show()\n\n",
        "\nplt.scatter(x, y, marker='.', c='k', s=100, hatch='//')\n",
        "\nplt.scatter(x, y, marker='.', linestyle='', hatch='/')\n",
        "\nplt.scatter(x, y, marker='*')\n",
        "plt.scatter(x, y, s=100, c='k', marker='.', hatch='*', vlines=True)",
        "\n\nxlim = 1\nylim = 4\n\nplt.imshow(data, cmap=plt.cm.RdBu_r, interpolation='nearest', extent=[xlim, 5, ylim, 1])\n\n",
        "plt.stem(x, y, orientation='horizontal')",
        "\nfig, ax = plt.subplots(figsize=(10, 5))\nbar_width = 0.25\n\nx_positions = d.keys()\ny_positions = d.values()\n\nbar_colors = c.values()\n\nax.bar(x_positions, y_positions, bar_width, color=bar_colors)\n\nplt.xticks(x_positions, d.keys())\nplt.yticks(y_positions)\n\nplt.show()\n\n",
        "\n\nfig, ax = plt.subplots()\nax.plot([0, 3, 3, 4], [0, 0, 1, 0], 'k-')\nax.axvline(x=3, color='r', linestyle='--')\nax.set_xlabel('x')\nax.set_ylabel('y')\nax.legend(('line', 'cutoff'), loc='upper left')\n\n",
        "plt.polar(theta_zero=0, theta_direction='clockwise', radius=1, plot_radius=0.95)\nbars = plt.bar(np.arange(len(labels)), height, align='edge', alpha=0.75, label=labels)\nplt.legend(handles=bars, labels=labels)\nplt.show()",
        "\n\nfig, ax = plt.subplots(figsize=(10, 10))\nax.pie(data, labels=l, wedgeprops={'linewidth': 0.4})\nax.axis('equal')\nplt.show()\n\n",
        "\nplt.plot(x, y)\nplt.grid(color='blue', linestyle='dashed')\n",
        "\nplt.plot(x, y)\nplt.minorticks_on()\nplt.grid(which='minor', linestyle='dotted', color='gray')\nplt.grid(which='major', linestyle='none', color='gray')\n",
        "\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='pie')\n\nexplode = (0, 0, 0, 0, 0)\nexplode[0] = 0.1\n\nax.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow_radius=0, labeldistance=1, pctdistance=0.75)\n\nfor label in ax.get_legend_handles_labels():\n    label.set_fontweight('bold')\n\nplt.show()\n\n",
        "\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='pie')\n\nexplode = (0, 0, 0, 0, 0)\nexplode[0] = 0.1\n\nax.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow_radius=0, labeldistance=1, pctdistance=0.75)\n\nfor label in ax.get_legend_handles_labels():\n    label.set_fontweight('bold')\n\nplt.show()\n\n",
        "\nplt.plot(x, y, marker='o', markersize=10, markerfacecolor='none', markeredgecolor='black')\n",
        "plt.axvline(55, color='green')",
        "\n\nfig, ax = plt.subplots(1, 1, figsize=(5, 3))\n\n# Plot the blue bar\nax.bar(0, blue_bar[0], width=1, bottom=0, label='Blue Bar')\nax.bar(1, blue_bar[1], width=1, bottom=0, label='Blue Bar')\nax.bar(2, blue_bar[2], width=1, bottom=0, label='Blue Bar')\n\n# Plot the orange bar\nax.bar(3, orange_bar[0], width=1, bottom=0, label='Orange Bar')\nax.bar(4, orange_bar[1], width=1, bottom=0, label='Orange Bar')\nax.bar(5, orange_bar[2], width=1, bottom=0, label='Orange Bar')\n\n# Add a legend\nax.legend(loc='best')\n\n",
        "\n\nfig, ax = plt.subplots(1, 2, sharex=True, sharey=True)\nax[0].plot(x, y, label='y')\nax[0].plot(x, z, label='z')\nax[0].legend(loc='best')\nax[1].plot(a, z, label='z')\nax[1].legend(loc='best')\n\nplt.tight_layout()\nplt.show()\n\n",
        "\nplt.scatter(x, y, c=y, cmap=\"Spectral\")\n",
        "plt.plot(x, y, 'o')\nplt.xticks(np.arange(10) + 0.5, np.arange(10))",
        "\n\nfig, ax = plt.subplots(1, 1, sharex=False, sharey=False)\nsns.factorplot(x=\"bill_length_mm\", y=\"sex\", hue=\"species\", data=df, aspect=1, palette=\"RdBu_r\", ax=ax)\n\n",
        "plt.circle(0.5, 0.5, radius=0.2)",
        "plt.plot(x, y)\nplt.title(\"Phi\", fontdict={'weight': 'bold'})",
        "plt.plot(x, y, label=\"Line\")\nplt.legend(handles=plt.gca().get_legend_handles_labels(), loc=\"best\", bbox_to_anchor=(1, 0.1))",
        "\nplt.plot(x, y, label=\"Line\")\nplt.legend(handles=[plt.gca().get_legend_handles_labels()[0]], loc=\"best\", handlelength=0.3)\n",
        "plt.legend(handles=[plt.gca().get_line_collection(), ], labels=[\"Line\", \"Flipped\"], loc=\"best\", borderaxespad=0.)",
        "plt.legend()\nplt.plot(x, y, marker=\"o\", label=\"Line\")",
        "\nplt.imshow(data, cmap=plt.cm.RdBu_r, interpolation='nearest')\nplt.colorbar()\nplt.show()\n",
        "plt.plot(x, y)\nplt.title(\"Figure 1\", fontdict={'weight': 'bold', 'size': 18})",
        "\nsns.pairplot(df, hue=\"id\", x_vars=\"x\", y_vars=\"y\", diag_kind=\"kde\", aspect=1, diag_kwds={\"cmap\": \"RdBu_r\"})\nplt.legend(handles=(), loc=\"none\")\n",
        "plt.plot(x, y, invert_yaxis=True)",
        "plt.scatter(x, y)\nplt.xlim(0, 10)\nplt.ylim(0, 10)\nplt.axis('off')",
        "\nplt.scatter(x, y, c='red', cmap=plt.cm.RdBu, edgecolors='black', s=50)\n",
        "\nfig, ax = plt.subplots(2, 2, figsize=(15, 15))\nfor i in range(4):\n    ax[i, 0].plot(x, y)\n    ax[i, 1].plot(x, y)\n\n",
        "\nplt.hist(x, bins=5, range=(0, 10), width=2)\nplt.show()\n",
        "\n\nplt.plot(x, y, 'b-', label='y')\nplt.fill_between(x, y-error, y+error, alpha=0.2, color='r')\nplt.legend()\n\n",
        "\nplt.plot([0, 0], ['k--'], linewidth=2)\n",
        "\n\nax.errorbar(box_position, box_height, yerr=box_errors, color=c)\n\n",
        "\n\nfig, ax1 = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(10, 5))\nax1[0].plot(x, y)\nax1[1].plot(z, a)\nax1[1].set_title('Z', fontdict={'size': 12, 'weight': 'bold'})\nax1[1].set_ylim(ax1[0].get_ylim())\n\n",
        "\n\nfig, ax = plt.subplots(4, 4, figsize=(5, 5))\nfor i in range(4):\n    for j in range(4):\n        ax[i, j].plot(x, y)\n        ax[i, j].set_xlabel('x')\n        ax[i, j].set_ylabel('y')\n        ax[i, j].tick_params(axis='both', which='major', labelsize=12)\n        ax[i, j].tick_params(axis='both', which='minor', labelsize=8)\n        ax[i, j].grid(which='major', linestyle='-', linewidth=0.5, alpha=0.2)\n        ax[i, j].grid(which='minor', linestyle=':', linewidth=0.5, alpha=0.2)\n\nplt.tight_layout()\nplt.show()\n\n",
        "plt.matshow(d)\nplt.figure(figsize=(8, 8))",
        "plt.table(df, bbox=[0, 0, 1, 1])",
        "\nfig, ax = plt.subplots()\nax.plot(x, y)\nax.set_xticks(x)\nax.set_xticklabels(x, rotation=90)\nax.set_xlabel('x')\nax.set_ylabel('y')\nplt.show()\n",
        "\nplt.plot(x, y)\nplt.xticks(x[::-1], x[::-1], rotation=90)\nplt.show()\n",
        "plt.plot(x, y)\nplt.show()",
        "\n\n",
        "\n# Make catplots of scatter plots by using \"time\" as x, \"pulse\" as y, \"kind\" as hue, and \"diet\" as col\n# Change the xlabels to \"Exercise Time\" and \"Exercise Time\"\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 6))\nsns.catplot(data=df, x=\"time\", y=\"pulse\", hue=\"kind\", col=\"diet\", ax=ax, kind=\"scatter\")\nax.set_xlabel(\"Exercise Time\")\nax.set_ylabel(\"Pulse\")\nax.set_title(\"Exercise Time vs Pulse\")\nplt.show()\n",
        "\n# Make catplots of scatter plots by using \"time\" as x, \"pulse\" as y, \"kind\" as hue, and \"diet\" as col\n# Do not show any ylabel on either subplot\n\nfig, ax = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(12, 6))\n\n# Create a catplot for each subplot\nsns.catplot(data=df, x=\"time\", y=\"pulse\", hue=\"kind\", col=\"diet\", ax=ax[0], kind=\"scatter\", aspect=1, ylim=None)\nsns.catplot(data=df, x=\"time\", y=\"pulse\", hue=\"kind\", col=\"diet\", ax=ax[1], kind=\"scatter\", aspect=1, ylim=None)\n\n# Remove ylabel from both subplots\nax[0].set_ylabel(None)\nax[1].set_ylabel(None)\n\nplt.tight_layout()\nplt.show()\n",
        "\nplt.plot(x, y, label=\"y\")\nplt.legend(fontsize=8)\n",
        "plt.plot(x, y, figsize=(5, 5), dpi=300)",
        "\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x with label \"y\" and show legend\n# Remove the border of frame of legend\n\nfig, ax = plt.subplots()\nax.plot(x, y, label=\"y\")\nax.legend(loc=\"best\")\nax.legend(frameon=False)\nplt.show()\n",
        "\n\nfig, ax = plt.subplots()\nax.plot(t, a, 'r', label='a')\nax.plot(t, b, 'b', label='b')\nax.plot(t, c, 'g', label='c')\n\nax.legend()\nax.grid()\n\nplt.show()\n\n",
        "\n\nfig, ax = plt.subplots(figsize=(10, 5))\nsns.stripplot(x=\"sex\", y=\"bill_length_mm\", hue=\"species\", data=df, ax=ax, legend=None)\nplt.tight_layout()\n\n",
        "\n\nsns.set(style=\"whitegrid\")\ng = sns.FacetGrid(df, col=\"b\", hue_order=[\"A\", \"B\", \"C\"])\ng = g.map(sns.pointplot, \"c\", \"a\")\ng.add_legend()\ng.add_legend(row=1, col=1)\ng.add_legend(row=2, col=1)\ng.add_legend(row=3, col=1)\n\nfor ax in g.axes.flat:\n    ax.xaxis.set_major_locator(plt.LinearLocator(1))\n    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, pos: str(int(x) // 2) + \" - \" + str(int(x) % 2)))\n\ng.fig.subplots_adjust(hspace=0.3)\ng.fig.subplots_adjust(wspace=0.3)\n\ng.fig.show()\n\n",
        "\nfig = plt.figure()\nax = Axes3D(fig)\nax.scatter(x, y, z)\nax.view_init(azimuth=100, elevation=50)\nplt.show()\n",
        "\nplt.plot(x, y)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.xticks([])\nplt.yticks([])\nplt.grid(True)\n\n",
        "\n\ngs = gridspec.GridSpec(nrow, ncol, width_ratios=[1, 1, 1, 1], height_ratios=[1, 1, 1, 1])\naxs = plt.subplot(gs[0, :])\naxs.imshow(x, cmap=plt.cm.gray)\naxs = plt.subplot(gs[1, :])\naxs.imshow(x, cmap=plt.cm.gray)\naxs = plt.subplot(gs[2, :])\naxs.imshow(x, cmap=plt.cm.gray)\naxs = plt.subplot(gs[3, :])\naxs.imshow(x, cmap=plt.cm.gray)\n\n# Remove the space between each subplot and make the subplot adjacent to each other\nfor i in range(nrow):\n    for j in range(ncol):\n        plt.subplots_adjust(wspace=0, hspace=0)\n\n# Remove the axis ticks from each subplot\nfor ax in [axs, axs, axs, axs]:\n    ax.axis(\"off\")\n\n"
    ],
    "Tensorflow": [
        "\nimport tensorflow as tf\n\n\nx = tf.Variable(0)\nx.assign(1)\nresult = x\n",
        "\nimport tensorflow as tf\n\nx = tf.Variable(0)\nx.assign(114514)\nresult = x\n",
        "\nimport tensorflow as tf\n\nlabels = [0, 6, 5, 4, 2]\nresult = tf.one_hot(labels, 10)\nprint(result)\n",
        "\nimport tensorflow as tf\n\n\nlabels = [0, 6, 5, 4, 2]\nresult = tf.one_hot(labels, 10)\nprint(result)\n",
        "\nimport tensorflow as tf\n\nlabels = [0, 6, 5, 4, 2]\nresult = tf.one_hot(labels, 10)\nprint(result)\n",
        "\n    result = tf.one_hot(labels, 10)\n",
        "\nimport tensorflow as tf\n\nlabels = [0, 6, 5, 4, 2]\nresult = tf.one_hot(labels, 10)\nprint(result)\n",
        "\nimport tensorflow as tf\n\n\ntf.compat.v1.disable_eager_execution()\ninput = [10, 20, 30]\ndef my_map_func(i):\n  return [[i, i+1, i+2]]\nds = tf.data.Dataset.from_tensor_slices(input)\nds = ds.map(map_func=lambda input: tf.compat.v1.py_func(\n  func=my_map_func, inp=[input], Tout=[tf.int64]\n))\nelement = tf.compat.v1.data.make_one_shot_iterator(ds).get_next()\nresult = []\nwith tf.compat.v1.Session() as sess:\n  for _ in range(9):\n    result.append(sess.run(element))\nresult = [i for sublist in result for i in sublist]\nprint(result)\n",
        "\n",
        "result = tf.ones([8])\nresult[:lengths.shape[0], :] = tf.cast(tf.range(0, lengths.sum()), tf.int32)\nresult[:lengths.shape[0], lengths.shape[0]:] = tf.constant(0, dtype=tf.int32)\nprint(result)",
        "result = tf.ones([8])\nresult[:lengths] = tf.zeros([8])\nresult[tf.range(8), lengths] = 1\nprint(result)",
        "result = tf.ones([8]) * 0\nresult[:lengths.shape[0], lengths] = 1\nprint(result)",
        "\n",
        "result = tf.ones([8])\nresult[:len(lengths)] = tf.zeros([8])\nresult[len(lengths):] = tf.ones([8])\nresult[::-1] = result[::-1]\nprint(result)",
        "[Missing Code]\nresult = tf.concat([a[i] for i in range(len(a))], axis=0)\nresult = tf.concat([b[i] for i in range(len(b))], axis=0)\nresult = tf.concat([result, a[i] for i in range(len(a))], axis=0)\nresult = tf.concat([result, b[i] for i in range(len(b))], axis=0)\nresult = tf.concat([result, a[i] for i in range(len(a))], axis=0)\nresult = tf.concat([result, b[i] for i in range(len(b))], axis=0)\nresult = tf.concat([result, a[i] for i in range(len(a))], axis=0)\nresult = tf.concat([result, b[i] for i in range(len(b))], axis=0)\nresult = tf.concat([result, a[i] for i in range(len(a))], axis=0)\nresult = tf.concat([result, b[i] for i in range(len(b))], axis=0)\nresult = tf.concat([result, a[i] for i in range(len(a))], axis=0)\nresult = tf.concat([result, b[i] for i in range(len(b))], axis=0)\nresult = tf.concat([result, a[i] for i in range(len(a))], axis=0)\nresult = tf.concat([result, b[i] for i in range(len(b))], axis=0)\nresult = tf.concat([result, a[i] for i in range(len(a))], axis=0)\nresult = tf.concat([result, b[i] for i in range(len(b))], axis=0)\nresult = tf.concat([result, a[i] for i in range(len(a))], axis=0)\nresult = tf.concat([result, b[i] for i in range(len(b))], axis=0)\nresult = tf.concat([result, a[i] for i in range(len(a))], axis=0)\nresult = tf.concat([result, b[i] for i in range(len(b))], axis=0)\nresult = tf.concat([result, a[i] for i in range(len(a))], axis=0)\nresult = tf.concat([result, b[i] for i in range(len(b))], axis=0)\nresult = tf.concat([result, a[i] for i in range(len(a))], axis=0)\nresult = tf.concat([result, b[i] for i in range(len(b))], axis=0)\nresult = tf.concat([result, a[i] for i in range(len(a))], axis=0)\nresult = tf.concat([result, b[i] for i in range(len(b))], axis=0)\nresult = tf.concat([result, a[i] for i in range(len(a))], axis=0)\nresult = tf.concat([result, b[i] for i in range(len(b))], axis=0)\nresult = tf.concat([result, a[i] for i in range(len(a))], axis=0)\nresult = tf.concat([result, b[i] for i in range(len(b))], axis=0)\nresult = tf.concat([result, a[i] for i in range(len(a))], axis=0)\nresult = tf.concat([result, b[i] for i in range(len(b))], axis=0)\nresult = tf.concat([result, a[i] for i in range(len(a))], axis=0)\nresult = tf.concat([result, b[i] for i in range(len(b))], axis=0)\nresult = tf.concat([result, a[i] for i in range(len(a))], axis=0)\nresult = tf.concat([result, b[i] for i in range(len(b))], axis=0)\nresult = tf.concat([result, a[i] for i in range(len(a))], axis=0)\nresult = tf.concat([result, b[i] for i in range(len(b))], axis",
        "\n",
        "\nimport tensorflow as tf\nimport numpy as np\n\nnp.random.seed(10)\na = tf.constant(np.random.rand(50, 100, 1, 512))\na = tf.reshape(a, [-1, 512])\nprint(result)\n",
        "\nimport tensorflow as tf\nimport numpy as np\n\n\nnp.random.seed(10)\na = tf.constant(np.random.rand(50, 100, 512))\na = tf.reshape(a, (50, 100, 1, 512))\nprint(result)\n",
        " and",
        "result = tf.reduce_sum(A, axis=1)",
        "result = tf.reduce_prod(A, axis=1)",
        "result = tf.reciprocal(A)",
        "\nimport tensorflow as tf\n\n\na = tf.constant([\n  [1,1,1],\n  [1,1,1]\n])\nb = tf.constant([\n  [0,0,0],\n  [1,1,1]\n])\nresult = tf.reduce_sum(tf.square(a - b), axis=1)\nprint(result)\n",
        "\nimport tensorflow as tf\n\na = tf.constant([\n  [1,1,1],\n  [0,1,1]\n])\nb = tf.constant([\n  [0,0,1],\n  [1,1,1]\n])\nresult = tf.reduce_sum(tf.square(a - b), axis=1)\nprint(result)\n",
        "\n    result = tf.reduce_sum(tf.square(tf.subtract(A, B)), axis=1)\n",
        "\nimport tensorflow as tf\n\n\nx = [[1,2,3],[4,5,6]]\ny = [0,1]\nz = [1,2]\nx = tf.constant(x)\ny = tf.constant(y)\nz = tf.constant(z)\nm = x[tf.cast(y, tf.int32), tf.cast(z, tf.int32)]\nprint(m)\n",
        "\nimport tensorflow as tf\n\nx = [[1,2,3],[4,5,6]]\nrow = [0,0]\ncol = [1,2]\nx = tf.constant(x)\nrow = tf.constant(row)\ncol = tf.constant(col)\nm = x[row, col]\nprint(m)\n",
        "\ndef f(x=example_x,y=example_y,z=example_z):\n    m = tf.gather(x, tf.stack([y, z], axis=0))\n    return result\n",
        "\nimport tensorflow as tf\nimport numpy as np\n\n\nnp.random.seed(10)\nA = tf.constant(np.random.randint(low=0, high=5, size=(10, 20, 30)))\nB = tf.constant(np.random.randint(low=0, high=5, size=(10, 20, 30)))\nC = tf.einsum('ijk,ijk', A, B)\nprint(result)\n",
        "\nimport tensorflow as tf\nimport numpy as np\n\nnp.random.seed(10)\nA = tf.constant(np.random.randint(low=0, high=5, size=(10, 20, 30)))\nB = tf.constant(np.random.randint(low=0, high=5, size=(10, 20, 30)))\nC = tf.einsum('ijk,kij->ij', A, B)\nprint(result)\n",
        "\nimport tensorflow as tf\n\n\nx=[b'\\xd8\\xa8\\xd9\\x85\\xd8\\xb3\\xd8\\xa3\\xd9\\x84\\xd8\\xa9',\n    b'\\xd8\\xa5\\xd9\\x86\\xd8\\xb4\\xd8\\xa7\\xd8\\xa1',\n    b'\\xd9\\x82\\xd8\\xb6\\xd8\\xa7\\xd8\\xa1',\n    b'\\xd8\\xac\\xd9\\x86\\xd8\\xa7\\xd8\\xa6\\xd9\\x8a',\n    b'\\xd8\\xaf\\xd9\\x88\\xd9\\x84\\xd9\\x8a']\nresult = [x.decode('utf-8') for x in x]\nprint(result)\n",
        "\n",
        "y = tf.math.reduce_mean(x, axis=-2, keepdims=True)\nresult = tf.math.divide_no_nan(y, tf.cast(tf.math.reduce_sum(tf.math.cast(y, tf.float32), axis=-1), tf.float32))",
        "\n",
        "\n    # [Missing Code]\n",
        "\n",
        "\nimport tensorflow as tf\n\n\na = tf.constant(\n    [[0.3232, -0.2321, 0.2332, -0.1231, 0.2435, 0.6728],\n     [0.2323, -0.1231, -0.5321, -0.1452, 0.5435, 0.1722],\n     [0.9823, -0.1321, -0.6433, 0.1231, 0.023, 0.0711]]\n)\nresult = tf.argmax(a, axis=1)\nprint(result)\n",
        "\nimport tensorflow as tf\n\n\na = tf.constant(\n    [[0.3232, -0.2321, 0.2332, -0.1231, 0.2435, 0.6728],\n     [0.2323, -0.1231, -0.5321, -0.1452, 0.5435, 0.1722],\n     [0.9823, -0.1321, -0.6433, 0.1231, 0.023, 0.0711]]\n)\nresult = tf.argmax(a, axis=1)\nprint(result)\n",
        "\nresult = tf.argmax(a, axis=1)\nreturn result\n",
        "\nimport tensorflow as tf\n\na = tf.constant(\n    [[0.3232, -0.2321, 0.2332, -0.1231, 0.2435, 0.6728],\n     [0.2323, -0.1231, -0.5321, -0.1452, 0.5435, 0.1722],\n     [0.9823, -0.1321, -0.6433, 0.1231, 0.023, 0.0711]]\n)\nresult = tf.argmin(a, axis=1)\nprint(result)\n",
        "model.save(\"my_model\")",
        "\nimport tensorflow as tf\n\nseed_x = 10\nresult = tf.random.uniform([10], 1, 4, seed=seed_x)\nprint(result)\n",
        "\nresult = tf.random.uniform([], minval=2, maxval=5, dtype=tf.int32, seed=seed_x)\n",
        "\ndef f(seed_x=10):\n    tf.random.set_seed(seed_x)\n    random_ints = tf.random.uniform([10], 1, 4, dtype=tf.int32)\n    result = tf.reshape(random_ints, [-1])\n    return result\n",
        "\nimport tensorflow as tf\n\n### output the version of tensorflow into variable 'result'\nresult = tf.version.VERSION\nprint(result)\n"
    ],
    "Scipy": [
        "\nimport numpy as np\nimport scipy\nx = np.array([1, 7, 20, 50, 79])\ny = np.array([10, 19, 30, 35, 51])\nresult = scipy.optimize.curve_fit(lambda x, a, b: a * np.log(x) + b, [1, 7, 20, 50, 79], [10, 19, 30, 35, 51], p0=[1, 1])\nprint(result)\n",
        "\nimport numpy as np\nimport scipy\nx = np.array([1, 7, 20, 50, 79])\ny = np.array([10, 19, 30, 35, 51])\nresult = scipy.optimize.curve_fit(lambda x, A, B: A + B * np.log(x), x, y, p0=[1, 1])\nprint(result)\n",
        "\nimport numpy as np\nimport scipy.optimize\ny = np.array([1, 7, 20, 50, 79])\nx = np.array([10, 19, 30, 35, 51])\np0 = (4, 0.1, 1)\nresult = scipy.optimize.curve_fit(lambda y, x, A, B, C: A*np.exp(B*x) + C, y, x, p0)[0]\nprint(result)\n",
        "\n# [Missing Code]\n",
        "test_stat = stats.ks_2samp(x, y)\nresult = stats.ks_2samp(x, y)[1]\nprint(result)",
        "\nprint(result)\n",
        "\nimport numpy as np\nimport scipy.stats\nz_scores = np.array([-3, -2, 0, 2, 2.5])\np_values = scipy.stats.norm.sf(z_scores, 0, 1)\nprint(p_values)\n",
        "\nimport scipy.stats\nimport numpy as np\nz_scores = [-3, -2, 0, 2, 2.5]\nmu = 3\nsigma = 4\np_values = scipy.stats.norm.cdf(-z_scores, loc=mu, scale=sigma)\nprint(p_values)\n",
        "\nimport numpy as np\nimport scipy.stats\np_values = [0.1, 0.225, 0.5, 0.75, 0.925, 0.95]\nz_scores = scipy.stats.norm.ppf(p_values)\nprint(z_scores)\n",
        "\nimport numpy as np\nfrom scipy import stats\nstddev = 2.0785\nmu = 1.744\nx = 25\ndist = stats.lognorm.cdf(x, loc=mu, scale=stddev)\nresult = dist.item()\n",
        "\n# [Missing Code]\n",
        "\nfrom scipy import sparse\nimport numpy as np\nsa = sparse.csr_matrix(np.array([[1,2,3],[4,5,6],[7,8,9]]))\nsb = sparse.csr_matrix(np.array([0,1,2]))\nresult = sa * sb\nprint(result)\n",
        "\ndef f(sA = example_sA, sB = example_sB):\n    result = sA * sB\n    return result\n",
        "[Missing Code]\nresult = scipy.interpolate.interp2d(points[:, 0], points[:, 1], V)(request)",
        "[Missing Code]\nresult = scipy.interpolate.griddata((points[:, 0], points[:, 1]), V, request, method='linear')\nprint(result)",
        "data_rot = rotate(data_orig, angle)\nxrot, yrot = data_rot[x0-data_orig.shape[0]/2, y0-data_orig.shape[1]/2]\nprint(data_rot, (xrot, yrot))",
        "\nimport numpy as np\nfrom scipy.sparse import csr_matrix\n\narr = np.random.rand(4, 4)\nM = csr_matrix(arr)\nresult = M.diagonal()\nprint(result)\n",
        "[Missing Code]\nresult = stats.kstest(times, \"uniform\")\nprint(result)",
        "\n    kstest_result = stats.kstest(times, \"uniform\")\n",
        "[Missing Code]\nresult = stats.kstest(times, \"uniform\", n=100, critval=0.05)\nprint(result[1])",
        "\nfrom scipy import sparse\nc1 = sparse.csr_matrix([[0, 0, 1, 0], [2, 0, 0, 0], [0, 0, 0, 0]])\nc2 = sparse.csr_matrix([[0, 3, 4, 0], [0, 0, 0, 5], [6, 7, 0, 8]])\nFeature = c1.tolil() + c2.tolil()\nprint(Feature)\n",
        "\nfrom scipy import sparse\nc1 = sparse.csr_matrix([[0, 0, 1, 0], [2, 0, 0, 0], [0, 0, 0, 0]])\nc2 = sparse.csr_matrix([[0, 3, 4, 0], [0, 0, 0, 5], [6, 7, 0, 8]])\nFeature = sparse.hstack([c1, c2])\nprint(Feature)\n",
        "\nfrom scipy import sparse\nc1 = sparse.csr_matrix([[0, 0, 1, 0], [2, 0, 0, 0], [0, 0, 0, 0]])\nc2 = sparse.csr_matrix([[0, 3, 4, 0], [0, 0, 0, 5], [6, 7, 0, 8]])\nFeature = c1.concatenate(c2, axis=1)\n#print(Feature)\n",
        "\n# [Missing Code]\n",
        "[Missing Code]\n\npoints1 = np.array([(x, y) for x in np.linspace(-1,1,7) for y in np.linspace(-1,1,7)])\nN = points1.shape[0]\npoints2 = 2*np.random.rand(N,2)-1\n\nresult = scipy.spatial.KDTree(points1).nearest_neighbors(points2, 1)\n\nprint(result)",
        "b.setdiag(0)",
        "\nresult = ndimage.measurements.label(img > threshold)\n",
        "\nresult = ndimage.measurements.label(img > threshold)\n",
        "\n    regions = ndimage.measurements.label(img > threshold)\n",
        "[Missing Code]\n\nresult = []\nfor y in range(img.shape[0]):\n    for x in range(img.shape[1]):\n        if img[y, x] > threshold:\n            region_center = (x + y, x + y)\n            distance = np.sqrt((region_center[0] - 0) ** 2 + (region_center[1] - 0) ** 2)\n            result.append(distance)\n\nprint(result)",
        "\nimport numpy as np\nfrom scipy.sparse import lil_matrix\nfrom scipy import sparse\n\nM= sparse.random(10, 10, density=0.1, format='lil')\nM = M.make_symmetric()\nprint(M)\n",
        "\n    sA.make_symmetric()\n",
        "\n# [Missing Code]\n",
        "[Missing Code]\n\n",
        " and",
        "\nMax = np.amax(col)\nMin = np.amin(col)\n",
        "[Missing Code]\n\ncol_median = np.median(col)\ncol_mode = np.mode(col)\n\nprint(col_median)\nprint(col_mode)",
        "[Missing Code]\ncoeffs, pcov = curve_fit(fourier8, z, Ua, p0=[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0",
        "[Missing Code]\nresult = scipy.spatial.distance.cdist(example_array, example_array, 'euclidean')\nprint(result)",
        "\nresult = scipy.spatial.distance.cdist(example_array, example_array, 'cityblock')\n",
        "\nresult = scipy.spatial.distance.cdist(example_array, example_array, 'euclidean')\n",
        "\n",
        "[Missing Code]\n\nstatistic, critical_values, significance_level = ss.anderson_ksamp(x1, x2, x3, x4)\n```\n\n",
        "\nimport numpy as np\nimport scipy.stats as ss\nx1=[38.7,  41.5,  43.8,  44.5,  45.5,  46.0,  47.7,  58.0]\nx2=[39.2,  39.3,  39.7,  41.4,  41.8,  42.9,  43.3,  45.8]\nresult = ss.anderson_ksamp(x1, x2)\nprint(result)\n",
        "def tau1(x):\n    y = np.array(df['A']) #  keep one column fix and run it in the other two\n    tau, p_value = stats.kendalltau(x, y)\n    return tau\ndf['AB'] = df.rolling(3, on='B', min_periods=1).apply(lambda x: tau1(x))\nprint(df)",
        "\nfrom scipy import sparse\nsa = sparse.random(10, 10, density = 0.01, format = 'csr')\nresult = sa.sum() == 0\nprint(result)\n",
        "\nfrom scipy import sparse\nsa = sparse.random(10, 10, density = 0.01, format = 'lil')\nresult = sa.sum() == 0\nprint(result)\n",
        "\n",
        "\np_value = stats.ranksums(pre_course_scores, during_course_scores).pvalue\n",
        "p_value = stats.ranksums(pre_course_scores, during_course_scores).pvalue",
        "\nimport numpy as np\na = np.array([   1. ,    2. ,    2.5,  400. ,    6. ,    0. ])\nkurtosis_result = np.sum(a ** 4) / (4 * np.sum(a ** 2)) - 3\nprint(kurtosis_result)\n",
        "\n",
        "\nimport numpy as np\nimport scipy.interpolate\ns = np.linspace(-1, 1, 50)\nt = np.linspace(-2, 0, 50)\nx, y = np.ogrid[-1:1:10j,-2:0:10j]\nz = (x + y)*np.exp(-6.0 * (x * x + y * y))\nresult = scipy.interpolate.interp2d(s, t, z)(s1, t1) - scipy.interpolate.interp2d(s, t, z)(s2, t2)\nprint(result)\n",
        "\nimport numpy as np\nimport scipy.interpolate\nexampls_s = np.linspace(-1, 1, 50)\nexample_t = np.linspace(-2, 0, 50)\ndef f(s = example_s, t = example_t):\n    x, y = np.ogrid[-1:1:10j,-2:0:10j]\n    z = (x + y)*np.exp(-6.0 * (x * x + y * y))\n    z = scipy.interpolate.interp2d(s, t, z, kind='cubic')(s[0], t[0])\n    return result\n",
        "\nresult = [vor.region[vor.vertices_to_region[extraPoint]] for extraPoint in extraPoints]\n",
        "\nresult = [vor.region_area[vor.region_area == i].index for i, _ in enumerate(extraPoints)]\n",
        "vectors = [np.random.randint(100,size=900),np.random.randint(100,size=max_vector_size),np.random.randint(100,size=950)]\nresult = sparse.csr_matrix(np.hstack([np.zeros((max_vector_size,), dtype=vectors[0].dtype), vectors]))\nprint(result)",
        "\n# [Missing Code]\n",
        "result = M[row, column]",
        "\nimport numpy as np\nfrom scipy.sparse import csr_matrix\n\narr = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]])\nM = csr_matrix(arr)\nrow = [2, 1]\ncolumn = [3, 0]\nresult = [M[row[0], column[0]], M[row[1], column[1]]]\nprint(result)\n",
        "\nimport numpy as np\nimport scipy.interpolate\narray = np.random.randint(0, 9, size=(10, 10, 10))\nx = np.linspace(0, 10, 10)\nx_new = np.linspace(0, 10, 100)\nf = scipy.interpolate.interp1d(x, array, kind='linear')\nnew_array[:, :, :] = f(x_new)\nprint(new_array)\n",
        "\n",
        "\n    dev = abs((x-u)/o2)\n    P_inner = scipy.integrate(NDfx,-dev,dev)\n    P_outer = 1 - P_inner\n    P = P_inner + P_outer/2\n    return(P)\n```\n\n",
        "\n",
        "diags(matrix, [-1, 0, 1], (5, 5)).toarray()",
        "\nimport numpy as np\nimport scipy.stats\nN = 3\np = 0.5\nM = scipy.stats.binom.pmf(i, j, p)\nresult = np.array(M)\nprint(result)\n",
        "zscores = stats.zscore(df[['sample1', 'sample2', 'sample3']].values)\nresult = df.assign(sample1=df['sample1'] * zscores[0], sample2=df['sample2'] * zscores[1], sample3=df['sample3'] * zscores[2])\nprint(result)",
        "\nzscore_result = stats.zscore(df[['sample1', 'sample2', 'sample3']])\nresult = df.assign(sample1=df['sample1'] * zscore_result, sample2=df['sample2'] * zscore_result, sample3=df['sample3'] * zscore_result)\n",
        "[Missing Code]\n\nresult = df.assign(data=lambda x: x['sample1'] + x['sample2'] + x['sample3'], zscore=lambda x: stats.zscore(x['data']))\ndf = df.join(result)\nprint(df)",
        "[Missing Code]\n\ndf['data'] = df.apply(lambda x: x.sample1 + x.sample2 + x.sample3, axis=1)\ndf['zscore'] = stats.zscore(df['data'], ddof=1)\ndf['data'] = df['data'].round(3)\ndf['zscore'] = df['zscore'].round(3)\n\nresult = df.copy()\nresult['data'] = df['data']\nresult['zscore'] = df['zscore']\nprint(result)",
        "alpha = scipy.optimize.fmin_l_bfgs_b(test_func, test_grad, starting_point, direction)",
        "\nimport numpy as np\nfrom scipy.spatial import distance\nshape = (6, 6)\nmid = np.array([[0, 1], [1, 0]])\nresult = distance.cdist(scipy.dstack((y, x)), mid)\nprint(result)\n",
        "\nimport numpy as np\nfrom scipy.spatial import distance\nshape = (6, 6)\nmid = np.array([[0, 1], [1, 0]])\nresult = get_distance_2(y, x)\n",
        "\n    mid = np.array([[0, 0], [0, 0]])\n    # [Missing Code]\n",
        "\nimport numpy as np\nimport scipy.ndimage\nx = np.arange(9).reshape(3, 3)\nshape = (6, 8)\nresult = scipy.ndimage.zoom(x, shape[0] / shape[1], order=1)\nprint(result)\n",
        "\n",
        "[Missing Code]\nresult = scipy.optimize.minimize(residual, fit_params, args=(a, y), method='L-BFGS-B', bounds=x_lower_bounds)\nprint(result)",
        "def dN1_dt_simple(t, N1):\n    return -100 * N1 + np.sin(t)\nsol = solve_ivp(fun=dN1_dt_simple, t_span=time_span, y0=[N0,])\nresult = sol.y\nprint(result)",
        "\n# [Missing Code]\n",
        "def dN1_dt_simple(t, N1):\n    return -100 * N1\nsol = solve_ivp(fun=dN1_dt_simple, t_span=time_span, y0=[N0, -np.cos(t)])\nresult = sol.y\nprint(result)",
        "\n",
        "result = sa.copy()\nresult.data += sb.data\nresult.indices += sb.indices\nresult.indptr += sb.indptr\n```\n\n",
        "result = sa.copy()\nresult.data += sb.data\nresult.indices += sb.indices\nresult.indptr += sb.indptr\n```\n\n",
        "[Missing Code]\nresult, error = scipy.integrate.quad(lambda x: 2*x*c, low, high)\nprint(result)",
        "\nresult, error = scipy.integrate.quad(f, low, high)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\nsa.data[sa.indptr[Col]:sa.indptr[Col+1], Col] = Column / Len\n",
        "\nfor Col in xrange(sa.shape[1]):\n    Column = sa[:, Col].data\n    List = [x**2 for x in Column]\n    Len = math.sqrt(sum(List))\n    sa[:, Col] = Column / Len\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nimport numpy as np\nimport scipy.spatial\ncentroids = np.random.rand(5, 3)\ndata = np.random.rand(100, 3)\nresult = scipy.spatial.KDTree(data).query(centroids, 1)[:, 0]\nprint(result)\n",
        "\n",
        "\nimport numpy as np\nimport scipy.spatial\ncentroids = np.random.rand(5, 3)\ndata = np.random.rand(100, 3)\nk = 3\nresult = scipy.spatial.KDTree(data).query(centroids, k=k, return_distance=False, distance_upper_bound=None)[1]\nprint(result)\n",
        "def eqn(a, x, b):\n    return x + 2*a - b**2\n\nresult = np.empty((len(xdata), len(bdata)), dtype=float)\nfor i in range(len(xdata)):\n    for j in range(len(bdata)):\n        result[i, j] = fsolve(eqn, x0=xdata[i], args=(a, bdata[j]))\n\nprint(result)",
        "[Missing Code]\nresult = fsolve(eqn, xdata, args=(adata,))\n",
        "[Missing Code]\nresult = stats.kstest(sample_data, bekkers, args=(estimated_a, estimated_m, estimated_d), range_start=range_start, range_end=range_end)\nprint(result)",
        "[Missing Code]\nresult = stats.kstest(sample_data, bekkers, args=(estimated_a, estimated_m, estimated_d), 'exact', 'dof', 'nptol', 1e-10)[1]\nif result < 0.05:\n    result = True\nelse:\n    result = False",
        "\nintegral_df = df.groupby(pd.Grouper(freq='25S')).apply(integrate.trapz)\n",
        "result = scipy.interpolate.griddata((x, y), (eval), method='linear')",
        "\n",
        "result = sciopt.fminbound(e, pmin, pmax, args=(x, y))",
        "\nimport numpy as np\nfrom scipy import signal\narr = np.array([-624.59309896, -624.59309896, -624.59309896,\n                      -625., -625., -625.,])\nn = 2\nresult = np.where(np.diff(arr, axis=0) <= 0, arr[::-1][::-1], arr)\nprint(result)\n",
        "result = []\nfor i in range(len(arr)):\n    for j in range(len(arr[0])):\n        if arr[i][j] <= min(arr[i-n:i+n+1][j]) and arr[i][j] >= max(arr[i-n:i+n+1][j]):\n            result.append([i, j])\n```",
        "df = df[(np.abs(stats.zscore(df.loc[:, df.columns.dtype == 'float'], axis=0)) < 3).all(axis=1)]"
    ],
    "Sklearn": [
        "\nimport numpy as np\nfrom sklearn.datasets import load_iris\nimport pandas as pd\ndata = load_iris()\ndata1 = pd.DataFrame(data)\nprint(data1)\n",
        "\nimport numpy as np\nfrom sklearn.datasets import load_iris\nimport pandas as pd\ndata = load_iris()\ndata1 = pd.DataFrame(data)\nprint(data1)\n",
        "\nimport numpy as np\nfrom sklearn.datasets import load_boston\nimport pandas as pd\ndata = load_boston()\ndata1 = pd.DataFrame(data)\nprint(data1)\n",
        "\ndata = data.astype(np.float64)\ndf = pd.DataFrame(data, columns=data.feature_names)\n",
        "\n",
        "\n",
        "\nimport pandas as pd\nimport numpy as np\nimport sklearn\ndf = load_data()\ndf_out = pd.get_dummies(df, columns=['Col4'])\nprint(df_out)\n",
        "\n# [Missing Code]\n",
        "\nimport pandas as pd\nimport numpy as np\nimport sklearn\ndf = load_data()\ndf_out = pd.get_dummies(df, columns=['Col3'])\nprint(df_out)\n",
        "proba = 1 / (1 + np.exp(-x))",
        "\nproba = np.array([1 / (1 + np.exp(-x)) for x in predicted_test_scores])\n",
        "\nimport pandas as pd\nimport numpy as np\nfrom scipy.sparse import csr_matrix\ndf_origin, transform_output = load_data()\ndf = pd.concat([df_origin, transform_output], axis=1)\nprint(df)\n",
        "# [Missing Code]\ntransformed_matrix = csr_matrix(transform_output)\ndf_final = pd.concat([df_origin, transformed_matrix.toarray()], axis=1)\nprint(df_final)",
        "[Missing Code]\ndf_transformed = pd.concat([df_origin, transform_output], axis=1)\nreturn df_transformed",
        "\nestimators = [('reduce_dim', PCA()), ('svm', SVC())]\nclf = Pipeline(estimators)\nprint(len(clf.steps))\n",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import PolynomialFeatures\nestimators = [('reduce_poly', PolynomialFeatures()), ('dim_svm', PCA()), ('sVm_233', SVC())]\nclf = Pipeline(estimators)\nclf.steps = clf.steps[:-1]\nprint(len(clf.steps))\n",
        "clf.steps = clf.named_steps()\nclf.steps.pop(1)\nclf = Pipeline(estimators)\nprint(clf.named_steps)",
        "clf.steps = clf.named_steps()\nprint(len(clf.steps))",
        "\n# [Missing Code]\n",
        "clf.insert('t1919810', PCA()) right before 'svdm'",
        "\ngridsearch = GridSearchCV(model, paramGrid, verbose=verbose, cv=TimeSeriesSplit(n_splits=cv).get_n_splits([trainX, trainY]), n_jobs=n_jobs, iid=iid)\ngridsearch.fit(trainX, trainY, early_stopping_rounds=42, eval_metric=\"mae\", eval_set=[testX, testY])\n",
        "[Missing Code]\n\nmodel = xgb.XGBRegressor()\nGridSearchCV(model, paramGrid, verbose=1, cv=TimeSeriesSplit(n_splits=3).get_n_splits([trainX, trainY]), n_jobs=n_jobs, iid=iid).fit(trainX, trainY, fit_params={\"early_stopping_rounds\":42, \"eval_metric\": \"mae\", \"eval_set\": [[testX, testY]]})",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold\nX, y = load_data()\nassert type(X) == np.ndarray\nassert type(y) == np.ndarray\ncv = StratifiedKFold(5).split(X, y)\nlogreg = LogisticRegression()\nproba = logreg.predict_proba(X)\nprint(proba)\n",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold\nX, y = load_data()\nassert type(X) == np.ndarray\nassert type(y) == np.ndarray\ncv = StratifiedKFold(5).split(X, y)\nlogreg = LogisticRegression()\nproba = logreg.predict_proba(X)\nprint(proba)\n",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\ndata = load_data()\nscaler = StandardScaler()\nscaler.fit(data)\nscaled = scaler.transform(data)\ninversed = scaler.inverse_transform(scaled)\nprint(inversed)\n",
        "\ninversed = solve(data, scaler, scaled)\nprint(inversed)\n",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel_name = model.__class__.__name__\nprint(model_name)\n",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel_name = model.__class__.__name__\nprint(model_name)\n",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn.svm import LinearSVC\nmodel = LinearSVC()\nmodel_name = model.__class__.__name__\nprint(model_name)\n",
        "\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import NMF\nfrom sklearn.pipeline import Pipeline\nimport pandas as pd\n\ndata = load_data()\n\npipe = Pipeline([\n    (\"tf_idf\", TfidfVectorizer()),\n    (\"nmf\", NMF())\n])\n\ntf_idf_out = pipe.named_steps[\"tf_idf\"].fit_transform(data.test)\n",
        "\ntf_idf_out = pipe.fit_transform(data.test)\n",
        "select_out = pipe.steps[0]['select'].fit_transform(data, target)",
        "\n",
        "\nregressor = RandomForestRegressor(n_estimators=150, min_samples_split=1.0, random_state=42)\n",
        "\nX = np.array([233.176, 234.270, 235.270, 523.176, 237.176, 238.270, 239.270, 524.176, 241.176, 242.270, 243.270, 524.176, 245.176, 246.270, 247.270, 524.176])\ny = np.array([0.00, 1.31, 4.11, 7.87, 1.17, 1.53, 2.22, 3.23, 0.00, 1.31, 4.11, 7.87, 1.17, 1.53, 2.22, 3.23])\n",
        "\ntfidf = TfidfVectorizer(preprocessor=preprocess)\n",
        "\nprint(tfidf.preprocessor)\n",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\ndata = load_data()\ndata = preprocessing.scale(data)\nprint(df_out)\n",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\ndata = load_data()\ndf_out = preprocessing.scale(data)\nprint(df_out)\n",
        "[Missing Code]\ncoef = grid.best_estimator_.coef_\nprint(coef)",
        "[Missing Code]\ncoef = grid.best_estimator_.coef_\nprint(coef)",
        "\nimport pandas as pd\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\nimport numpy as np\n\nX, y = load_data()\nclf = ExtraTreesClassifier(random_state=42)\nclf = clf.fit(X, y)\ncolumn_names = X.columns\nselected_features = model.get_support(indices=True)\nprint(selected_features)\n",
        "\nimport pandas as pd\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\nimport numpy as np\nX, y = load_data()\nclf = ExtraTreesClassifier(random_state=42)\nclf = clf.fit(X, y)\ncolumn_names = clf.feature_importances_.index.tolist()\nprint(column_names)\n",
        "\nimport pandas as pd\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\nimport numpy as np\n\nX, y = load_data()\nclf = ExtraTreesClassifier(random_state=42)\nclf = clf.fit(X, y)\ncolumn_names = clf.feature_importances_.index.tolist()\nprint(column_names)\n",
        "\nimport pandas as pd\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\nimport numpy as np\n\nX, y = load_data()\nclf = ExtraTreesClassifier(random_state=42)\nclf = clf.fit(X, y)\ncolumn_names = X.columns.values\nselected_features = np.array(model.get_support())\nprint(selected_features)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\ndef get_samples(p, X, km):\n    centers = km.fit_predict(X)\n    samples = []\n    for i in range(len(centers)):\n        if centers[i] == p:\n            samples.extend(X[X[:, 0] == i])\n    return samples[:50]\n",
        "\n# Convert categorical variable to matrix and merge back with original training data\nX_train = pd.get_dummies(X_train)\n",
        "\n",
        "\nsvm_reg = sklearn.svm.SVR(kernel='rbf', gamma='auto')\nsvm_reg.fit(X, y)\npredict = svm_reg.predict(X)\n",
        "\nregressor = sklearn.svm.SVR(kernel='rbf', gamma='auto', coef0=0.0, degree=3, shrinking=True, tol=0.001, cache_size=200, verbose=False)\nregressor.fit(X, y)\npredict = regressor.predict(X)\n",
        "\nsvm_reg = sklearn.svm.SVR(kernel='poly', degree=2)\nsvm_reg.fit(X, y)\npredict = svm_reg.predict(X)\n",
        "\nregressor = sklearn.svm.SVR(kernel='poly', degree=2)\nregressor.fit(X, y)\npredict = regressor.predict(X)\n",
        "\nprint(cosine_similarities_of_queries)\n",
        "\nprint(cosine_similarities_of_queries)\n",
        " and",
        "features = load_data()\nX = np.array(features)\nX = sklearn.preprocessing.encode_categorical(X, dtype=np.bool)\nnew_features = np.reshape(X, (X.shape[0], -1))\nprint(new_features)",
        "\n# [Missing Code]\n",
        "features = load_data()\nX = np.array(features)\nX = sklearn.preprocessing.encode_categorical(X, dtype=np.bool)\nnew_features = np.reshape(X, (X.shape[0], -1))\nprint(new_features)",
        "\n\n# Convert the features to a 2D-array\nnew_features = np.array(features)\n\n# Reshape the array into a 2D-array\nnew_features = new_features.reshape(len(features), -1)\n\n# Convert the dtype to float\nnew_features = new_features.astype(float)\n\n# Transpose the array to get the desired format\nnew_features = new_features.T\n\n# Return the new features\nreturn new_features\n\n",
        "features = load_data()\nnew_features = np.zeros((len(features), max(features[0]) + 1))\nfor i, row in enumerate(features):\n    for j, feature in enumerate(row):\n        new_features[i, feature] = 1\nprint(new_features)",
        "\n# [Missing Code]\n",
        "\nprint(cluster_labels)\n",
        "\nprint(cluster_labels)\n",
        " and",
        "\n# [Missing Code]\n",
        " and",
        "\ncentered_scaled_data = preprocessing_transformer.fit_transform(data)\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, FunctionTransformer, LabelEncoder, OneHotEncoder\nscaler = StandardScaler()\nencoder = LabelEncoder()\nonehot = OneHotEncoder(handle_unknown='ignore')\ntransformer = FunctionTransformer(transformers=[scaler, encoder, onehot])\ndata = transformer.fit_transform(data)\ncentered_scaled_data = scaler.inverse_transform(data)\n```",
        " and",
        "\nfrom sklearn.preprocessing import BoxCox\nbox_cox_data = BoxCox().fit_transform(data)\n",
        "from sklearn.preprocessing import MinMaxScaler\n\nyeo_johnson_data = data = MinMaxScaler().fit_transform(data)\n```",
        "\n",
        "[Missing Code]\n\ntext = text.apply(lambda x: x.replace('!', '!'))\ntext = text.apply(lambda x: x.replace('?', '?'))\ntext = text.apply(lambda x: x.replace('\"', '\"'))\ntext = text.apply(lambda x: x.replace(\"'\", \"'\"))\n\n",
        "\n",
        "\n",
        "\n# Split the dataset into training and testing sets\nx_train, y_train, x_test, y_test = train_test_split(dataset, test_size=0.3, random_state=42)\n",
        "\nfrom sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans\ndf = load_data()\nX = df['mse'].values\nkmeans = KMeans(n_clusters=2).fit(X)\nlabels = kmeans.predict(X)\nprint(labels)",
        "from sklearn.cluster import KMeans\ndf = load_data()\nX = df['mse'].values\nf2 = list(range(0, len(X)))\nkmeans = KMeans(n_clusters=2).fit(X)\nlabels = kmeans.predict(X)\ncentroids = kmeans.cluster_centers_\nprint(labels)",
        "selected_feature_names = np.asarray(vectorizer.get_feature_names())[LinearSVC(C=1, penalty='l1').fit(X).support]",
        "selected_feature_names = np.asarray(vectorizer.get_feature_names())[LinearSVC(C=1, penalty='l1').fit(X).support]",
        "[Missing Code]\n\nselected_feature_names = np.asarray(vectorizer.get_feature_names())[LinearSVC(C=1, penalty='l1').fit(X).support_]",
        "\nprint(vectorizer.get_feature_names())\nprint(X.toarray())\n",
        "[Missing Code]\n\nvectorizer = CountVectorizer(stop_words=\"english\", binary=True, lowercase=False, vocabulary=vocabulary)\nX = vectorizer.fit_transform(corpus)\nprint(vectorizer.get_feature_names())\nprint(X.toarray())",
        "\n# [Missing Code]\n",
        "\nvectorizer = CountVectorizer(stop_words=\"english\", binary=True, lowercase=False, vocabulary=vocabulary)\nX = vectorizer.fit_transform(corpus)\n",
        "for col in df1.columns:\n    df2 = df1[~np.isnan(df1[col])]\n    df3 = df2[['Time', col]]\n    npMatrix = np.matrix(df3)\n    X, Y = npMatrix[:, 0], npMatrix[:, 1]\n    slope = LinearRegression().fit(X, Y)\n    m = slope.coef_[0]\n    series = np.concatenate((series, m), axis=0)\n```",
        "for col in df1.columns:\n    df2 = df1[~np.isnan(df1[col])]\n    df3 = df2[['Time', col]]\n    npMatrix = np.matrix(df3)\n    X, Y = npMatrix[:,0], npMatrix[:,1]\n    slope = LinearRegression().fit(X,Y)\n    m = slope.coef_[0]\n    series = np.concatenate((SGR_trips, m), axis = 0)\n```",
        "df['Sex'] = LabelEncoder().fit_transform(df['Sex'])",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\ndf = load_data()\ndf['Sex'] = LabelEncoder().fit_transform(df['Sex'])\nprint(transformed_df)\n",
        "\n    df['Sex'] = LabelEncoder().fit_transform(df['Sex'])\n",
        " and",
        "# [Missing Code]\ntransformed = MinMaxScaler().fit_transform(np_array)\n",
        "# [Missing Code]\ntransformed = MinMaxScaler().fit_transform(np_array)\n",
        "\n",
        "close_buy1 = close[:-1]\nm5 = ma_50[:-1]\nm10 = ma_100[:-1]\nma20 = ma_200[:-1]\nb = np.concatenate([close_buy1, m5, m10, ma20], axis=1)\n\nclf.predict(b)",
        "\n# [Missing Code]\n",
        "\n",
        "\n# [Missing Code]\n",
        "[Missing Code]\nX = dataframe.iloc[-1:].astype(float)\ny = dataframe.iloc[:,-1]\nlogReg = LogisticRegression()\nlogReg.fit(X, y)\npredict = logReg.predict(X)\nprint(predict)",
        "X = dataframe.iloc[:, :-1].astype(float)\ny = dataframe.iloc[:, -1]\nlogReg = LogisticRegression()\nlogReg.fit(X, y)\npredict = logReg.predict(X)\nprint(predict)",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "train_size = 0.2\ntrain_dataframe, test_dataframe = train_test_split(features_dataframe, train_size=train_size, test_size=1 - train_size, random_state=42)\n\ntrain_dataframe = train_dataframe.sort([\"date\"])\ntest_dataframe = test_dataframe.sort([\"date\"])\n\nreturn train_dataframe, test_dataframe",
        "\n# [Missing Code]\n",
        "cols = myData.columns[2:4]\nmyData['new_' + cols] = myData.groupby('Month')[cols].transform(scaler.fit_transform(myData[cols]))",
        "\ncount = CountVectorizer(lowercase = False)\nvocabulary = count.fit_transform(words)\nfeature_names = count.get_feature_names()\n",
        "[Missing Code]\n\ncount = CountVectorizer(lowercase = False)\nvocabulary = count.fit_transform(words)\nfeature_names = count.get_feature_names_out()\nprint(feature_names)",
        "[Missing Code]\nfull_results = GridSearch_fitted.fit(X, y).cv_results_\nprint(full_results)",
        "[Missing Code]\nfull_results = GridSearch_fitted.cv_results_\nfull_results = full_results.sort_values(by=['mean_fit_time'], ascending=False)\nfull_results = full_results.reset_index()\nfull_results = full_results.rename(columns={'index': 'parameter', 'mean_fit_time': 'accuracy'})\nprint(full_results)",
        "# Save the model in the file named \"sklearn_model\"\nwith open(\"sklearn_model\", \"wb\") as f:\n    pickle.dump(fitted_model, f)",
        "\nvectorizer = TfidfVectorizer(min_df=1, max_df=0.5, norm='l2', use_idf=True)\ntfidf_matrix = vectorizer.fit_transform(df['description'])\ncosine_similarity_matrix = np.dot(tfidf_matrix.T, tfidf_matrix) / (np.linalg.norm(tfidf_matrix, ord=2) ** 2)\n"
    ],
    "Pytorch": [
        "optim.set_lr(0.001)",
        "optim.set_lr(0.001)",
        "optim.set_lr(0.0005)",
        "optimizer = torch.optim.SGD(..., lr=0.005)\n\ndef check_lr(optimizer, epoch, loss):\n    if loss[epoch] > loss[epoch-1]:\n        optimizer.lr *= 0.9\n    else:\n        optimizer.lr *= 1.1\n\ncheck_lr(optim, 0, loss)\n```\n\nIn this solution, we have created a custom function called `check_lr` that checks the loss value of the current epoch and the previous epoch. If the loss of the current epoch is greater than the previous epoch, the learning rate is reduced by 10%. If the loss of the current epoch is less than the previous epoch, the learning rate is increased by 10%. This function is called with the given optimizer, epoch, and loss values.",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom gensim.models import Word2Vec\nfrom gensim.test.utils import common_texts\ninput_Tensor = load_data()\nword2vec = Word2Vec(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4)\nembedded_input = torch.tensor(word2vec.wv.syn0.weight).float()\nprint(embedded_input)\n",
        "\n    # [Missing Code]\n",
        "\nprint(px)\n",
        "\nimport numpy as np\nimport torch\nimport pandas as pd\nx = load_data()\nx = x.detach().numpy()\npx = pd.DataFrame(x)\nprint(px)\n",
        "\nimport numpy as np\nimport torch\nimport pandas as pd\nx = load_data()\nx = x.detach().numpy()\npx = pd.DataFrame(x)\nprint(px)\n",
        "C = B[:, A_log] # Throws error",
        "\nC = B[A_logical]\n",
        "C = B[:, A_log] # Throws error",
        "C = B[:, A_log] # Throws error",
        "\n    # [Missing Code]\n",
        "\nC = B[A_log]\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nidx, B = load_data()\nC = torch.index_select(B, 0, idx)\nC = torch.index_select(B, 1, idx)\nprint(C)\n",
        "x_array = np.array([\n   np.array([0.5, 1.0, 2.0], dtype=np.float16),\n   np.array([4.0, 6.0, 8.0], dtype=np.float16)\n], dtype=object)\n\nx_tensor = torch.from_numpy(x_array)\n\nprint(x_tensor)",
        "x_tensor = torch.from_numpy(x)",
        "\nx_tensor = torch.from_numpy(a)\n",
        "\nmask = torch.zeros(len(lens), lens[0]).long()\nfor i in range(len(lens)):\n    mask[i, :lens[i]] = torch.arange(lens[i]).long()\n",
        "\nmask = torch.zeros(len(lens), lens[0])\nfor i in range(len(lens)):\n    mask[i, :lens[i]] = torch.arange(lens[i]).type_as(mask)\n",
        "\nmask = torch.zeros(len(lens), lens[0]).cuda()\nfor i in range(len(lens)):\n    mask[i, :lens[i]] = torch.arange(lens[i]).type_as(mask).long()\n",
        "\nmask = torch.zeros(len(lens), lens[0]).long()\nfor i in range(len(lens)):\n    mask[i, :lens[i]] = torch.arange(lens[i]).long()\nreturn mask\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nTensor_2D = load_data()\nTensor_3D = torch.diag(Tensor_2D)\nprint(Tensor_3D)\n",
        "\nresult = torch.diag(Tensor_2D)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\na, b = load_data()\nab = torch.cat((a, b), 0)\nprint(ab)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\na, b = load_data()\nab = torch.cat((a, b), 0)\nprint(ab)\n",
        "\nab = torch.cat((a, b), 0)\n",
        "a[ : , lengths : , : ] = 0",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\na = torch.rand((10, 1000, 96))\nlengths = torch.randint(1000, (10,))\na[ : , lengths : , : ] = 2333\nprint(a)\n",
        "a[ : , : lengths , : ] = 0",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\na = torch.rand((10, 1000, 23))\nlengths = torch.randint(1000, (10,))\na[ : , : lengths , : ] = 2333\nprint(a)\n",
        "list_of_tensors = [ torch.randn(3), torch.randn(3), torch.randn(3)]\ntensor_of_tensors = torch.tensor(list_of_tensors)",
        "\nnew_tensors = torch.stack(list, dim=0)\n",
        "\ntt = torch.tensor(lt)\nreturn tt\n",
        "list_of_tensors = [ torch.randn(3), torch.randn(3), torch.randn(3)]\ntensor_of_tensors = torch.tensor(list_of_tensors)",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nt, idx = load_data()\nassert type(t) == torch.Tensor\nassert type(idx) == np.ndarray\nresult = t[idx]\nprint(result)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nt, idx = load_data()\nassert type(t) == torch.Tensor\nassert type(idx) == np.ndarray\nresult = t[idx]\nprint(result)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nt, idx = load_data()\nassert type(t) == torch.Tensor\nassert type(idx) == np.ndarray\nresult = t[idx]\nprint(result)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nids, x = load_data()\nresult = x.gather(1, ids)\nprint(result)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nids, x = load_data()\nresult = x.gather(1, ids)\nprint(result)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nids, x = load_data()\nresult = x[ids==1]\nprint(result)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nsoftmax_output = load_data()\ny = np.argmax(softmax_output, axis=1)\nprint(y)\n",
        "\nmax_prob = torch.max(softmax_output, dim=1)[1]\npredicted_class = max_prob.item()\n",
        "\n# [Missing Code]\n",
        "\n",
        "\n    output = torch.argmin(softmax_output, dim=1)\n",
        "\ncross_entropy2d(images, labels)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nA, B = load_data()\ncnt_equal = np.sum(A == B)\nprint(cnt_equal)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nA, B = load_data()\ncnt_equal = np.sum(A == B)\nprint(cnt_equal)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nA, B = load_data()\ncnt_not_equal = np.sum(A != B)\nprint(cnt_not_equal)\n",
        "\ndef Count(A, B):\n    cnt_equal = 0\n    for i in range(len(A)):\n        if A[i] == B[i]:\n            cnt_equal += 1\n    return cnt_equal\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nA, B = load_data()\ncnt_equal = np.sum(A[-x:] == B[-x:], axis=0)\nprint(cnt_equal)\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nA, B = load_data()\ncnt_not_equal = np.sum(A[:, -x:] != B[:, -x:], axis=1)\nprint(cnt_not_equal)\n",
        "a_split = torch.chunk(a, chunk_dim, dim=3)\ntensors_31 = []\nfor i in range(0, 40, 1):\n    tensor = a_split[i][0].reshape(1, 3, 10, 1, 1)\n    tensors_31.append(tensor)\nfor tensor in tensors_31:\n    print(tensor)",
        "a_split = torch.chunk(a, chunk_dim, dim=2)\ntensors_31 = []\nfor i in range(0, a.shape[2], 1):\n    tensor = a[:, :, i:i+chunk_dim, :, :]\n    tensors_31.append(tensor)\nfor tensor in tensors_31:\n    print(tensor)",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nmin_abs = torch.min(torch.abs(x), torch.abs(y))\nsign_x = torch.sign(x)\nsign_y = torch.sign(y)\nresult = torch.where(torch.lt(min_abs, torch.abs(x)), sign_x, sign_y)\nreturn result\n",
        "\nconfidence_score = torch.nn.Softmax(dim=1)(output)[:, 0]\n",
        "\nresult = torch.cat((a[:, :-1].float(), b[:, 1:].float(), a[:, -1].float().mean(0)), dim=1)\n",
        "\n",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nt = load_data()\nresult = torch.cat([t, new], dim=1)\nprint(result)\n",
        "t = torch.arange(4).reshape(1,2,2).float()\nprint(t)\nnew = torch.tensor([[0., 0., 0., 0.], [0., 1., 2., 0.], [0., 3., 4., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0",
        "\nimport numpy as np\nimport pandas as pd\nimport torch\nt = load_data()\nresult = torch.cat([t, new], dim=1)\nprint(result)\n",
        "\nprint(result)\n"
    ]
}