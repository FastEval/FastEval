{
    "Pandas": [
        "\nresult = df.iloc[List]\n",
        "\ndf = df.iloc[List]\n",
        "\n# [Missing Code]\n",
        "\nresult = df.apply(lambda x: x if x.value_counts() >= 3 else 'other', axis=1)\n",
        "\n    # [Missing Code]\n    ",
        "\nresult = df.apply(lambda x: x if x.value_counts() >= 2 else 'other', axis=1)\n",
        "\n# [Missing Code]\n",
        "\ndf = df.drop_duplicates(subset='url', keep='first')\n",
        "\ndf = df.drop_duplicates(subset='url', keep='first')\n",
        "\ndf = df.drop_duplicates(subset='url', keep='first')\n",
        "\nresult = {}\nfor name, v1, v2, v3 in zip(df['name'], df['v1'], df['v2'], df['v3']):\n    if name not in result:\n        result[name] = {}\n    if v1 not in result[name]:\n        result[name][v1] = {}\n    result[name][v1][v2] = v3\n",
        "\ndf['datetime'] = df['datetime'].dt.tz_localize(None)\n",
        "\n    # [Missing Code]\n    ",
        "\ndf['datetime'] = df['datetime'].dt.tz_localize('UTC')\n",
        "\ndf['datetime'] = df['datetime'].dt.tz_localize(None)\n",
        "\nresult = pd.DataFrame()\nfor i in range(len(df)):\n    message = df['message'][i]\n    key_value_pairs = message.split('[')[1].split(']')[0].split(',')\n    for key_value in key_value_pairs:\n        key, value = key_value.split(':')\n        result = pd.concat([result, pd.DataFrame({key: value}, index=[i])], axis=1)\n",
        "\ndf.loc[df['product'].isin(products), 'score'] = df.loc[df['product'].isin(products), 'score'] * 10\n",
        "\nfor i in range(len(df)):\n    if df['product'][i] in products:\n        df['score'][i] = df['score'][i] * 10\n",
        "\nfor i in range(len(products)):\n    for j in range(len(products[i])):\n        df.loc[df['product'] == products[i][j], 'score'] = df.loc[df['product'] == products[i][j], 'score'] * 10\n",
        "\ndf['score'] = df['score'] - df['score'].min()\ndf['score'] = df['score'] / (df['score'].max() - df['score'].min())\ndf['score'] = df['score'] * 1\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\ndf['category'] = df.apply(lambda row: [col for col in row if row[col] == 1], axis=1)\n",
        "\ndf['Date'] = df['Date'].dt.to_period('M')\n",
        "\ndf['Date'] = df['Date'].dt.strftime('%d-%b-%Y')\n",
        "\ndf['Date'] = df['Date'].dt.to_period('M')\ndf['Date'] = df['Date'].dt.strftime('%d-%m-%Y')\ndf['Date'] = df['Date'].str.split('-')\ndf['Date'] = df['Date'].apply(lambda x: x[0] + '-' + x[1] + '-' + x[2])\ndf['Date'] = df['Date'].apply(lambda x: x.split('-')[0] + '-' + x.split('-')[1] + '-' + x.split('-')[2])\ndf['Date'] = df['Date'].apply(lambda x: x.split('-')[0] + '-' + x.split('-')[1] + '-' + x.split('-')[2])\ndf['Date'] = df['Date'].apply(lambda x: x.split('-')[0] + '-' + x.split('-')[1] + '-' + x.split('-')[2])\ndf['Date'] = df['Date'].apply(lambda x: x.split('-')[0] + '-' + x.split('-')[1] + '-' + x.split('-')[2])\ndf['Date'] = df['Date'].apply(lambda x: x.split('-')[0] + '-' + x.split('-')[1] + '-' + x.split('-')[2])\ndf['Date'] = df['Date'].apply(lambda x: x.split('-')[0] + '-' + x.split('-')[1] + '-' + x.split('-')[2])\ndf['Date'] = df['Date'].apply(lambda x: x.split('-')[0] + '-' + x.split('-')[1] + '-' + x.split('-')[2])\ndf['Date'] = df['Date'].apply(lambda x: x.split('-')[0] + '-' + x.split('-')[1] + '-' + x.split('-')[2])\ndf['Date'] = df['Date'].apply(lambda x: x.split('-')[0] + '-' + x.split('-')[1] + '-' + x.split('-')[2])\ndf['Date'] = df['Date'].apply(lambda x: x.split('-')[0] + '-' + x.split('-')[1] + '-' + x.split('-')[2])\ndf['Date'] = df['Date'].apply(lambda x: x.split('-')[0] + '-' + x.split('-')[1] + '-' + x.split('-')[2])\ndf['Date'] = df['Date'].apply(lambda x: x.split('-')[0] + '-' + x.split('-')[1] + '-' + x.split('-')[2])\ndf['Date'] = df['Date'].apply(lambda x: x.split('-')[0] + '-' + x.split('-')[1] + '-' + x.split('-')[2])\ndf['Date'] = df['Date'].apply(lambda x: x.split('-')[0] + '-' + x.split('-')[1] + '-' + x.split('-')[2])\ndf['Date'] = df['Date'].apply(lambda x: x.split('-')[0] + '-' + x.split('-')[1] + '-' + x.split('-')[2])\ndf['Date'] = df['Date'].apply(lambda x: x.split('-')[0] + '-' + x.split('-')[1] + '-' + x.split('-')[2])",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\ndf = df.shift(1)\n",
        "\nfor col in df.columns:\n    df.rename(columns={col: col + 'X'}, inplace=True)\n",
        "\ndf.columns = [f'X{x}' for x in df.columns]\n",
        "\n# [Missing Code]\n",
        "\nresult = df.groupby('group').agg({\"group_color\": \"first\", \"val1\": \"mean\", \"val2\": \"mean\", \"val3\": \"mean\"})\n",
        "\nresult = df.groupby('group').agg({\"group_color\": \"first\", \"val1\": \"sum\", \"val2\": \"sum\", \"val3\": \"sum\"})\n",
        "\nresult = df.groupby('group').agg({\"group_color\": \"first\", \"val1\": \"sum\", \"val2\": \"mean\", \"val42\": \"mean\"})\n",
        "\nresult = df.loc[row_list,column_list].mean()\n",
        "\nresult = df.loc[row_list,column_list].sum()\n",
        "\nresult = df.loc[row_list,column_list].sum()\n",
        "\nresult = df.apply(lambda x: x.value_counts(), axis=0)\n",
        "\nresult = df.isnull().sum()\n",
        "\nresult = df.groupby('id').agg(lambda x: x.value_counts())\n",
        "\ndf = df.combine_first(df.iloc[0])\n",
        "\ndf = df.combine_first(df.iloc[0])\n",
        "\nresult = df.fillna(method='ffill')\n",
        "\nresult = df.apply(lambda x : (x[x.isnull()].values.tolist()+x[x.notnull()].values.tolist()),1)\n",
        "\nresult = df.fillna(method='ffill')\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nresult = df.apply(lambda x: x.apply(lambda y: 1/y))\n",
        "\nresult = df.apply(lambda x: x**2, axis=1)\n",
        "\nresult = df.apply(lambda x: x.apply(lambda y: 1/y if y != 0 else y), axis=1)\n",
        "\nresult = df.apply(lambda x: x.apply(lambda y: 1/(1+np.exp(-y))), axis=1)\n",
        "\nresult = df.idxmax()\nresult = result.loc[result.idxmin() < result]\n",
        "\nresult = df.idxmin()\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\ndf['id'] = df['name'].apply(lambda x: x.split()[0])\n",
        "\ndf['a'] = df['a'].astype(int)\ndf['a'] = df['a'].astype(str)\n",
        "\n    # [Missing Code]\n    ",
        "\ndf['ID'] = df['name'] + '_' + df['a'].astype(str)\ndf = df.drop('name', axis=1)\n",
        "\ndf = df.pivot(index='user', columns='date', values='value')\n",
        "\n# [Missing Code]\n",
        "\ndf = df.pivot(index='user', columns='date', values='value')\n",
        "\nresult = df[df['c'] > 0.5][columns]\n",
        "\n# [Missing Code]\n",
        "\n    # [Missing Code]\n    ",
        "\n    # [Missing Code]\n    ",
        "\n    # [Missing Code]\n    ",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\ndf['A'] = df['A'].fillna(method='ffill')\n",
        "\ndf['A'] = df['A'].fillna(method='ffill')\n",
        "\ndf['A'] = df['A'].fillna(method='ffill')\n",
        "\ndf['number'] = df['duration'].str.split(' ').str[0]\ndf['time'] = df['duration'].str.split(' ').str[1]\ndf['time_day'] = df['time'].replace(r'(year|month|week|day)', r'(365|30|7|1)', regex=True)\n",
        "\ndf['time'] = df['duration'].str.split(' ', expand=True)[0]\ndf['number'] = df['duration'].str.split(' ', expand=True)[1]\ndf['time_day'] = df['time'].replace(r'(year|month|week|day)', r'(365|30|7|1)', regex=True)\n",
        "\n    df['number'] = df['duration'].str.split(' ').str[0]\n    df['time'] = df['duration'].str.split(' ').str[1]\n    df['time_day'] = df['time'].replace(r'(year|month|week|day)', r'(365|30|7|1)', regex=True)\n    ",
        "\ndf['time'] = df['duration'].str.split(' ', expand=True)[1]\ndf['number'] = df['duration'].str.split(' ', expand=True)[0]\ndf['time_day'] = df['time'].replace(r'(year|month|week|day)', r'(365|30|7|1)', regex=True)\ndf['time_day'] = df['time_day'] * df['number']\n",
        "\nresult = [df1[column] != df2[column] for column in columns_check_list]\n",
        "\nresult = [df1[column] == df2[column] for column in columns_check_list]\n",
        "\ndf.index.levels[1] = pd.to_datetime(df.index.levels[1])\n",
        "\ndf.index.levels[1] = pd.to_datetime(df.index.levels[1])\n",
        "\n    # [Missing Code]\n    ",
        "\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index(['date', 'id'])\n    ",
        "\ndf = pd.melt(df, id_vars='Country', value_name='year', var_name='Variable')\n",
        "\ndf = df.melt(id_vars='Country', value_name='year', var_name='Variable')\ndf = df.sort_values('year', ascending=False)\n",
        "\ndf = df[abs(df.iloc[:, 1:]) < 1]\n",
        "\n# [Missing Code]\n",
        "\ndf = df.loc[abs(df.iloc[:, 1:].values) > 1, :]\ndf.columns = df.columns.str.replace('Value_', '')\n",
        "\ndf['A'] = df['A'].str.replace('&AMP;', '&')\n",
        "\ndf['A'] = df['A'].str.replace('&LT', '<')\n",
        "\n    df['A'] = df['A'].str.replace('&AMP;', '&')\n    ",
        "\ndf['A'] = df['A'].str.replace('&', '&amp;')\ndf['A'] = df['A'].str.replace('<', '&lt;')\ndf['A'] = df['A'].str.replace('>', '&gt;')\n",
        "\ndf['A'] = df['A'].str.replace('&AMP;', '&')\n",
        "\ndef split_name(name):\n    if ' ' in name:\n        first_name, last_name = name.split(' ', 1)\n        return pd.Series({'first_name': first_name, 'last_name': last_name})\n    else:\n        return pd.Series({'first_name': name})\nresult = df.apply(split_name, axis=1)\n",
        "\ndef split_name(name):\n    if ' ' in name:\n        first_name, last_name = name.split(' ')\n        return pd.Series({'1_name': first_name, '2_name': last_name})\n    else:\n        return pd.Series({'1_name': name})\nresult = df.apply(split_name, axis=1)\n",
        "\ndef split_name(name):\n    first_name, middle_name, last_name = name.split(' ')\n    return pd.Series({'first_name': first_name, 'middle_name': middle_name, 'last_name': last_name})\nresult = df.apply(split_name, axis=1)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\ndf['state'] = df.apply(lambda x: x['col1'] if x['col2'] <= 50 and x['col3'] <= 50 else x['col1'], axis=1)\n",
        "\ndf['state'] = df['col1'] + df['col2'] + df['col3']\n",
        "\nfor i in range(len(df)):\n    if not isinstance(df['Field1'][i], int):\n        result.append(df['Field1'][i])\n",
        "\nfor i in range(len(df)):\n    if isinstance(df['Field1'][i], int):\n        result.append(df['Field1'][i])\n",
        "\n    result = []\n    for i in df['Field1']:\n        if isinstance(i, int):\n            continue\n        else:\n            result.append(i)\n    ",
        "\nresult = df.apply(lambda x: x/x.sum(), axis=1)\n",
        "\nresult = df.apply(lambda x: x/x.sum(), axis=1)\n",
        "\nresult = df.loc[test]\n",
        "\nresult = df.loc[test]\n",
        "\nresult = df.loc[test]\n",
        "\n    result = df.loc[test]\n    ",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\ndf[\"keywords_all\"] = df.apply(lambda row: \",\".join(row[row.notnull()]), axis=1)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\ndf = df.sample(n=int(len(df)*0.2), random_state=0)\ndf['Quantity'] = 0\n",
        "\ndf = df.sample(n=int(len(df)*0.2), random_state=0)\ndf['ProductId'] = df['ProductId'].replace(0, 0)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\ndf['index_original'] = df.index\n",
        "\n    duplicate_bool = df.duplicated(subset=['col1','col2'], keep='first')\n    duplicate = df.loc[duplicate_bool == True]\n    duplicate['index_original'] = duplicate.index\n    ",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nresult = df.groupby(['Sp','Mt'])['count'].max()\n",
        "\nresult = df.groupby(['Sp','Mt'])['count'].max()\n",
        "\nresult = df.groupby(['Sp','Mt'])['count'].min()\n",
        "\nresult = df.groupby(['Sp','Value'])['count'].max()\n",
        "\nresult = df.query(\"Category=='{}'\".format('|'.join(filter_list)))\n",
        "\nresult = df.query(\"Category!='Foo' and Category!='Bar'\")\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\ndf['cumsum'] = df.groupby('id').cumsum(['val'])\n",
        "\ndf['cumsum'] = df['val'].cumsum()\n",
        "\ndf['cumsum'] = df.groupby('id').cumsum(['val'])\n",
        "\ndf['cummax'] = df.groupby('id').cummax(['val'])\n",
        "\ndf['cumsum'] = df.groupby('id').cumsum(['val'])\ndf['cumsum'] = df['cumsum'].apply(lambda x: 0 if x < 0 else x)\n",
        "\nresult = df.groupby('l')['v'].sum()\n",
        "\nresult = df.groupby('r')['v'].apply(lambda x: x.sum(skipna=False))\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\ns = s.astype(str).str.replace(',','')\n",
        "\nresult = df.groupby(df['SibSp'] > 0 | df['Parch'] > 0).mean()\n",
        "\ndf['HasFamily'] = (df['Survived'] > 0) | (df['Parch'] > 0)\ndf['NoFamily'] = (df['Survived'] == 0) & (df['Parch'] == 0)\n",
        "\n# [Missing Code]\n",
        "\nresult = df.groupby('cokey').sort('A')\n",
        "\nresult = df.groupby('cokey').sort('A')\n",
        "\ndf.columns = [('Caps', 'Lower')]\n",
        "\ndf.columns = [('Caps', 'Middle', 'Lower')]\n",
        "\ndf.columns = [('Caps', 'Middle', 'Lower')]\n",
        "\nresult = pd.DataFrame(someTuple, columns=['birdType', 'birdCount'])\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'a':[1,1,1,2,2,2,3,3,3], 'b':[12,13,23,22,23,24,30,35,55]})\nresult = df.groupby('a')['b'].agg({'mean':'mean', 'std':'std'})\nprint(result)\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'a':[12,13,23,22,23,24,30,35,55], 'b':[1,1,1,2,2,2,3,3,3]})\nresult = df.groupby('b')['a'].agg({'mean':'mean', 'std':'std'})\nprint(result)\n",
        "\n# [Missing Code]\n",
        "\nresult = df.drop(df.sum(axis=1) == 0, axis=0).drop(df.sum(axis=0) == 0, axis=1)\n",
        "\nresult = df.drop(df.sum(axis=1)==0, axis=0).drop(df.sum(axis=0)==0, axis=1)\n",
        "\nresult = df.loc[df.max(axis=1) == 2, df.max(axis=0) == 2]\n",
        "\nresult = df.apply(lambda x: x if x.max() == 2 else 0)\n",
        "\ns = s.sort_values(ascending=True)\n",
        "\ns = s.sort_values(ascending=True)\n",
        "\nresult = df[df['A'].astype(int).isin(df['A'])]\n",
        "\nresult = df[df['A'].astype(str) == 's']\n",
        "\nresult = df.groupby(['Sp','Mt'])['count'].max()\n",
        "\nresult = df.groupby(['Sp','Mt'])['count'].max()\n",
        "\nresult = df.groupby(['Sp','Mt'])['count'].min()\n",
        "\nresult = df.groupby(['Sp','Value'])['count'].max()\n",
        "\ndf['Date'] = df['Member'].map(dict)\n",
        "\ndf['Date'] = df['Member'].map(dict)\n",
        "\n    df['Date'] = df['Date'].fillna(df['Member'])\n    df['Date'] = df['Date'].map(dict)\n    ",
        "\ndf['Date'] = df['Member'].map(dict)\n",
        "\ndf['Date'] = pd.to_datetime(df['Date'], format= '%d/%m/%y')\ndf['Count_d'] = df.Date.map(df.groupby('Date').size())\ndf['Count_m'] = df.Date.map(df.groupby('Date').size())\ndf['Count_y'] = df.Date.map(df.groupby('Date').size())\n",
        "\ndf['Date'] = pd.to_datetime(df['Date'], format= '%d/%m/%y')\ndf['Count_d'] = df.Date.map(df.groupby('Date').size())\ndf['Count_m'] = df.Date.map(df.groupby('Date').month).map(df.groupby('Date').size())\ndf['Count_y'] = df.Date.map(df.groupby('Date').year).map(df.groupby('Date').size())\ndf['Count_Val'] = df.Val.map(df.groupby('Val').size())\n",
        "\ndf['Date'] = pd.to_datetime(df['Date'], format= '%d/%m/%y')\ndf['Count_d'] = df.Date.map(df.groupby('Date').size())\ndf['Count_m'] = df.Date.map(df.groupby('Date').size())\ndf['Count_y'] = df.Date.map(df.groupby('Date').size())\ndf['Count_w'] = df.Date.map(df.groupby('Date').size())\ndf['Count_Val'] = df.Date.map(df.groupby('Date').size())\n",
        "\nresult1 = df.groupby('Date')['B', 'C'].sum().apply(lambda x: x.where(x==0, 0))\nresult2 = df.groupby('Date')['B', 'C'].sum().apply(lambda x: x.where(x!=0, 0))\n",
        "\nresult1 = df.groupby('Date')['B', 'C'].apply(lambda x: x.apply(lambda y: y % 2 == 0))\nresult2 = df.groupby('Date')['B', 'C'].apply(lambda x: x.apply(lambda y: y % 2 != 0))\n",
        "\nresult = pd.pivot_table(df, values=['D','E'], rows=['B'], aggfunc=[np.sum, np.mean])\n",
        "\nresult = pd.pivot_table(df, values=['D','E'], rows=['B'], aggfunc=[np.sum, np.mean])\n",
        "\nresult = pd.pivot_table(df, values=['D','E'], rows=['B'], aggfunc=[np.sum, np.mean])\n",
        "\nresult = pd.pivot_table(df, values=['D','E'], rows=['B'], aggfunc=[np.max, np.min])\n",
        "\ndf['var2'] = df['var2'].apply(lambda x: x.split(','))\n",
        "\ndf['var2'] = df['var2'].apply(lambda x: x.split(','))\n",
        "\n# [Missing Code]\n",
        "\nimport pandas as pd\ndef count_special_char(string):\n    special_char = 0\n    for i in range(len(string)):\n        if(string[i].isalpha()):\n            continue\n        else:\n            special_char = special_char + 1\n    return special_char\ndf = pd.DataFrame({'str': ['Aa', 'Bb', '?? ?', '###', '{}xxa;']})\ndf[\"new\"] = df.apply(count_special_char, axis = 0)\nprint(df)\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'str': ['Aa', 'Bb', '?? ?', '###', '{}xxa;']})\ndef count_special_char(string):\n    special_char = 0\n    for i in range(len(string)):\n        if(string[i].isalpha()):\n            continue\n        else:\n            special_char = special_char + 1\n    return special_char\ndf[\"new\"]=df.apply(count_special_char, axis = 0)\nresult = df\nprint(result)\n",
        "\ndf['fips'] = df['row'].str[:2]\ndf['row'] = df['row'].str[3:]\n",
        "\ndf['fips'] = df['row'].str[:2]\ndf['row'] = df['row'].str[2:]\n",
        "\ndf['fips'] = df['row'].str[:2]\ndf['medi'] = df['row'].str[2:5]\ndf['row'] = df['row'].str[5:]\n",
        "\ndf['2001'] = df['2001'] / (df['2001'] != 0)\ndf['2002'] = df['2002'] / (df['2002'] != 0)\ndf['2003'] = df['2003'] / (df['2003'] != 0)\ndf['2004'] = df['2004'] / (df['2004'] != 0)\ndf['2005'] = df['2005'] / (df['2005'] != 0)\ndf['2006'] = df['2006'] / (df['2006'] != 0)\n",
        "\n# [Missing Code]\n",
        "\n    # [Missing Code]\n    ",
        "\ndf['2001'] = df['2001'] / 2\ndf['2002'] = df['2002'] / 2\ndf['2003'] = df['2003'] / 2\ndf['2004'] = df['2004'] / 2\ndf['2005'] = df['2005'] / 2\ndf['2006'] = df['2006'] / 2\n",
        "\ndf['label'] = 0\ndf['label'] = (df['Close'] - df['Close'].shift(1) > 1)\ndf['label'][0] = 1\n",
        "\ndf['label'] = 0\ndf['label'][0] = 1\nfor i in range(1, len(df)):\n    if df['Close'][i] - df['Close'][i-1] > 0:\n        df['label'][i] = 1\n    elif df['Close'][i] - df['Close'][i-1] == 0:\n        df['label'][i] = 0\n    else:\n        df['label'][i] = -1\n",
        "\ndf['label'] = 0\ndf['label'][0] = 1\ndf['label'] = df['label'].diff()\ndf['label'] = df['label'].fillna(0)\ndf['label'] = df['label'].apply(lambda x: 1 if x > 0 else 0 if x == 0 else -1)\ndf['label'] = df['label'].shift(1)\ndf['label'] = df['label'].apply(lambda x: 1 if x == 0 else 0 if x == 1 else -1)\ndf['label'] = df['label'].shift(1)\ndf['label'] = df['label'].apply(lambda x: 1 if x == 0 else 0 if x == 1 else -1)\ndf['label'] = df['label'].shift(1)\ndf['label'] = df['label'].apply(lambda x: 1 if x == 0 else 0 if x == 1 else -1)\ndf['label'] = df['label'].shift(1)\ndf['label'] = df['label'].apply(lambda x: 1 if x == 0 else 0 if x == 1 else -1)\ndf['label'] = df['label'].shift(1)\ndf['label'] = df['label'].apply(lambda x: 1 if x == 0 else 0 if x == 1 else -1)\ndf['label'] = df['label'].shift(1)\ndf['label'] = df['label'].apply(lambda x: 1 if x == 0 else 0 if x == 1 else -1)\ndf['label'] = df['label'].shift(1)\ndf['label'] = df['label'].apply(lambda x: 1 if x == 0 else 0 if x == 1 else -1)\ndf['label'] = df['label'].shift(1)\ndf['label'] = df['label'].apply(lambda x: 1 if x == 0 else 0 if x == 1 else -1)\ndf['label'] = df['label'].shift(1)\ndf['label'] = df['label'].apply(lambda x: 1 if x == 0 else 0 if x == 1 else -1)\ndf['label'] = df['label'].shift(1)\ndf['label'] = df['label'].apply(lambda x: 1 if x == 0 else 0 if x == 1 else -1)\ndf['label'] = df['label'].shift(1)\ndf['label'] = df['label'].apply(lambda x: 1 if x == 0 else 0 if x == 1 else -1)\ndf['label'] = df['label'].shift(1)\ndf['label'] = df['label'].apply(lambda x: 1 if x == 0 else 0 if x == 1 else -1)\ndf['label'] = df['label'].shift(1)\ndf['label'] = df['label'].apply(lambda x: 1 if x == 0 else 0 if x == 1 else -1)\ndf['label'] = df['label'].shift(1)\ndf['label'] = df['label'].apply(lambda x: 1 if x == 0 else 0 if x == 1 else -1)\ndf['label'] = df['label'].shift(1)\ndf['label'] = df['label'].apply(lambda x: 1 if x == 0 else 0 if x == 1 else -1)\ndf['label'] = df['label'].shift(1)\ndf['label'] = df['label'].apply(lambda x: 1 if x == 0 else 0 if x == 1 else -1)\ndf['label'] = df['label'].shift(1)",
        "\ndf['Duration'] = df.departure_time - df.arrival_time\n",
        "\ndf['Duration'] = df.departure_time - df.arrival_time\n",
        "\ndf['Duration'] = df.departure_time - df.arrival_time\ndf['arrival_time'] = df['arrival_time'].apply(lambda x: x.strftime('%d-%m-%Y %H:%M:%S'))\ndf['departure_time'] = df['departure_time'].apply(lambda x: x.strftime('%d-%m-%Y %H:%M:%S'))\n",
        "\nresult = df.groupby(['key1'])['key2'].apply(lambda x: x.eq('one').sum())\n",
        "\nresult = df.groupby(['key1'])['key2'].apply(lambda x: x.eq('two').sum())\n",
        "\nresult = df.groupby(['key1'])['key2'].apply(lambda x: x.str.endswith('e'))\n",
        "\nmax_result = df.index.max()\nmin_result = df.index.min()\n",
        "\nmode_result = df.mode(axis=0)[0]\nmedian_result = df.median(axis=0)\n",
        "\ndf = df[(99 <= df['closing_price'] <= 101)]\n",
        "\ndf = df[df['closing_price'] != 99]\ndf = df[df['closing_price'] != 101]\n",
        "\nresult = df.groupby(['item', 'otherstuff'])['diff'].min()\n",
        "\ndf['SOURCE_NAME'] = df['SOURCE_NAME'].str.split('_').str[-1]\n",
        "\ndf['SOURCE_NAME'] = df['SOURCE_NAME'].str.split('_').str[-1]\n",
        "\n    # [Missing Code]\n    ",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nresult = pd.DataFrame([[a[i], b[i]] for i in range(len(a))], columns=['one', 'two'])\n",
        "\nresult = pd.DataFrame([[a[i], b[i], c[i]] for i in range(len(a))], columns=['one', 'two'])\n",
        "\nresult = pd.DataFrame([[a[i], b[i]] for i in range(len(a))], columns=['one', 'two'])\n",
        "\nresult = df.groupby(['username', pd.cut(df['views'], bins)])['views'].count()\n",
        "\nresult = df.groupby(['username', pd.cut(df.views, bins)])['username'].count()\n",
        "\nresult = df.groupby(['username', pd.cut(df.views, bins)])['username'].count()\n",
        "\nresult = df['text'].apply(lambda x: ','.join(x))\n",
        "\nresult = df['text'].apply('-'.join).to_frame()\n",
        "\nresult = df['text'].apply(lambda x: ','.join(x))\n",
        "\nresult = df['text'].apply(lambda x: ','.join(x))\n",
        "\nresult = df['text'].apply(lambda x: ''.join(x))\n",
        "\ndf1['date'] = pd.to_datetime(df1['date'])\ndf2['date'] = pd.to_datetime(df2['date'])\nresult = pd.concat([df1, df2], axis=0).sort_values('date')\n",
        "\nimport pandas as pd\ndf1 = pd.DataFrame({'id': [1, 2, 3, 4, 5],\n                   'city': ['bj', 'bj', 'sh', 'sh', 'sh'],\n                   'district': ['ft', 'ft', 'hp', 'hp', 'hp'],\n                   'date': ['2019/1/1', '2019/1/1', '2019/1/1', '2019/1/1', '2019/1/1'],\n                   'value': [1, 5, 9, 13, 17]})\ndf2 = pd.DataFrame({'id': [3, 4, 5, 6, 7],\n                   'date': ['2019/2/1', '2019/2/1', '2019/2/1', '2019/2/1', '2019/2/1'],\n                   'value': [1, 5, 9, 13, 17]})\nresult = pd.concat([df1, df2], axis=0)\nresult['date'] = pd.to_datetime(result['date'])\nresult['date'] = result['date'].dt.strftime('%d-%b-%Y')\nresult['city'] = result['city'].fillna(result['city'].iloc[0])\nresult['district'] = result['district'].fillna(result['district'].iloc[0])\nresult = result.sort_values(['id', 'date'])\nprint(result)\n",
        "\ndf1['date'] = pd.to_datetime(df1['date'])\ndf2['date'] = pd.to_datetime(df2['date'])\nresult = pd.concat([df1, df2], axis=0).sort_values(['id', 'date'])\n",
        "\nresult = pd.merge(C, D, how='outer', on='A', suffixes=['_x', ''])\n",
        "\nresult = pd.merge(C, D, how='outer', on='A')\n",
        "\nresult = pd.merge(C, D, how='outer', on='A')\nresult['dulplicated'] = result['A'] == result['A']\n",
        "\nresult = df.groupby('user')['time', 'amount'].apply(lambda x: x.tolist())\n",
        "\nresult = df.groupby('user')['time', 'amount'].apply(lambda x: x.tolist())\n",
        "\n# [Missing Code]\n",
        "\ndf = pd.DataFrame(series.values.tolist())\n",
        "\ndf = pd.DataFrame(series.values, index=series.index, columns=range(len(series.values[0])))\n",
        "\nresult = [x for x in df.columns if s in x]\n",
        "\nresult = df[df.columns.str.contains(s)]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nresult = [i for i in df['col1']]\n",
        "\nresult = ','.join(str(x) for x in df['col1'])\n",
        "\nresult = ','.join(df['col1'].tolist())\n",
        "\ndf['Time'] = df['Time'].dt.floor('min')\n",
        "\ndf['Time'] = df['Time'].dt.floor('min')\n",
        "\ndf['TIME'] = pd.to_datetime(df['TIME'])\ndf['RANK'] = df.groupby('ID')['TIME'].rank(ascending=True)\n",
        "\ndf['TIME'] = pd.to_datetime(df['TIME'])\ndf['RANK'] = df.groupby('ID')['TIME'].rank(ascending=False)\n",
        "\nimport pandas as pd\ndf = pd.DataFrame({'ID': ['01', '01', '01', '02', '02'],\n                   'TIME': ['2018-07-11 11:12:20', '2018-07-12 12:00:23', '2018-07-13 12:00:00', '2019-09-11 11:00:00', '2019-09-12 12:00:00']})\ndf['TIME'] = pd.to_datetime(df['TIME'])\ndf['RANK'] = df.groupby('ID')['TIME'].rank(ascending=False)\ndf['TIME'] = df['TIME'].apply(lambda x: x.strftime('%d-%b-%Y %a %H:%M:%S'))\nresult = df\nprint(result)\n",
        "\nresult = df[filt]\n",
        "\nresult = df[filt.index.get_level_values('a') == df.index.get_level_values('a')]\n",
        "\nresult = df.iloc[0] == df.iloc[8]\n",
        "\ndef equalp(x, y):\n    return (x == y) or (math.isnan(x) and math.isnan(y))\nresult = df.iloc[0] == df.iloc[8]\n",
        "\nresult = df.loc[0].where(df.loc[0] != df.loc[8]).index.tolist()\n",
        "\nresult = []\nfor i in range(10):\n    for j in range(10):\n        if df.iloc[0, i] != df.iloc[8, i] and df.iloc[0, i] != df.iloc[8, i]:\n            result.append((df.iloc[0, i], df.iloc[8, i]))\n",
        "\nts = pd.Series(df['Value'], index=df['Date'])\n",
        "\nresult = pd.DataFrame(df.values.reshape(-1,len(df.columns)))\n",
        "\nresult = df.stack()\nresult = result.reset_index(drop=True)\nresult = result.rename(columns={i:f'{i}_0' for i in result.columns})\nresult = result.reset_index()\nresult = result.rename(columns={i:f'{i}_0' for i in result.columns})\n",
        "\ndf['dogs'] = df['dogs'].round(2)\n",
        "\ndf['dogs'] = df['dogs'].round(2)\ndf['cats'] = df['cats'].round(2)\n",
        "\n# [Missing Code]\n",
        "\nresult = df[list_of_my_columns].mean(axis=1)\n",
        "\nresult = df[list_of_my_columns].mean(axis=1)\n",
        "\ndf = df.sort_index(axis=0, level=2, ascending=True)\n",
        "\ndf = df.sort_index(axis=0, level=1, ascending=True)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nresult = corr[corr > 0.3]\n",
        "\nresult = corr.filter(lambda x: x > 0.3)\n",
        "\ndf.columns[-1] = 'Test'\n",
        "\ndf.rename(columns={'A': 'Test'}, inplace=True)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nresult = df.groupby(['id1','id2'])['foo','bar'].mean()\n",
        "\nresult = df.groupby(['id1','id2'])['foo','bar'].agg(lambda x: x.fillna(0).mean())\n",
        "\nresult = pd.merge(df_a, df_b, on='EntityNum', how='left', left_on='EntityNum', right_on='EntityNum')\n",
        "\nresult = pd.merge(df_a, df_b, on='EntityNum', how='left', left_on='EntityNum', right_on='EntityNum')\n"
    ],
    "Numpy": [
        "\nresult = a.shape\n",
        "\nx = x[~np.isnan(x)]\n",
        "\nx[np.isnan(x)] = np.inf\n",
        "\nresult = x.tolist()\nfor i in range(len(result)):\n    for j in range(len(result[i])):\n        if result[i][j] == np.nan:\n            result[i][j] = None\n",
        "\nimport numpy as np\na = np.array([1, 0, 3])\nb = np.zeros((len(a), len(a) + 1))\nb[a, 1:] = 1\nprint(b)\n",
        "\nimport numpy as np\na = np.array([1, 0, 3])\nb = np.zeros((len(a), len(a) + 1))\nfor i in range(len(a)):\n    b[i, a[i]] = 1\nprint(b)\n",
        "\nimport numpy as np\na = np.array([-1, 0, 3])\nb = np.zeros((len(a), len(a) + 1))\nb[np.arange(len(a)), a] = 1\nprint(b)\n",
        "\nimport numpy as np\na = np.array([1.5, -0.4, 1.3])\nb = np.zeros((len(a), len(a)))\nfor i in range(len(a)):\n    b[i, a[i] - a.min()] = 1\nprint(b)\n",
        "\nb = np.zeros(a.shape + (a.max()+1,))\nfor i in range(a.shape[0]):\n    for j in range(a.shape[1]):\n        b[i,j,a[i,j]] = 1\n",
        "\nresult = np.percentile(a, p)\n",
        "\nB = np.reshape(A, (ncol, len(A)/ncol))\n",
        "\nB = np.reshape(A, (nrow, len(A)//nrow))\n",
        "\nB = np.reshape(A, (len(A)//ncol, ncol))\n",
        "\nB = np.reshape(A, (ncol, len(A)//ncol))\n",
        "\nresult = np.roll(a, shift)\n",
        "\nresult = np.roll(a, shift, axis=0)\n",
        "\nresult = np.array([[a[0][0], a[0][1], a[0][2], a[0][3], a[0][4], a[0][5], a[0][6], a[0][7], a[0][8], a[0][9]],\n                   [a[0][0], a[0][1], a[0][2], a[0][3], a[0][4], a[0][5], a[0][6], a[0][7], a[0][8], a[0][9]]])\n",
        "\nr_old = np.random.randint(3, size=(100, 2000)) - 1\nr_new = np.random.randint(3, size=(100, 2000)) - 1\n",
        "\nresult = np.argmax(a)\n",
        "\nresult = np.argmin(a)\n",
        "\nresult = np.argmax(a, axis=None, out=None, keepdims=False, return_indices=True)\n",
        "\nresult = np.argmax(a, axis=None)\n",
        "\n    # [Missing Code]\n    ",
        "\nresult = np.where(a == a.max(axis=0).max())[0][1]\n",
        "\na = a[:, np.logical_not(np.isnan(a))]\n",
        "\na = a[a.isnan() == False]\n",
        "\nresult = np.array(a)\n",
        "\na = a[:, permutation]\n",
        "\nresult = a[permutation]\n",
        "\nresult = np.argmin(a)\n",
        "\nresult = np.argmax(a)\n",
        "\nresult = np.argmin(a, axis=0)\n",
        "\nresult = np.sin(degree)\n",
        "\nresult = np.cos(np.degrees(degree))\n",
        "\nif np.sin(number) > np.sin(np.radians(number)):\n    result = 0\nelse:\n    result = 1\n",
        "\nresult = np.arcsin(value)\n",
        "\nresult = np.pad(A, (0, length - A.size), 'constant', constant_values=0)\n",
        "\nresult = np.pad(A, (0, length - A.size), 'constant', constant_values=0)\n",
        "\na**power\n",
        "\n    result = a**power\n    ",
        "\nresult = (numerator, denominator)\n",
        "\n    result = (numerator, denominator)\n    ",
        "\nresult = (numerator/denominator, denominator)\n",
        "\nresult = (a + b + c) / 3\n",
        "\nresult = np.maximum(a, b)\n",
        "\nresult = a[np.diag_indices(a.shape[0], start=a.shape[0]-1)]\n",
        "\nresult = a[np.diag_indices(a.shape[0], start=a.shape[0]-1)]\n",
        "\nresult = np.diag_indices(a.shape[0], start=a.shape[0]-1)\n",
        "\nresult = np.diag_indices(a.shape[0], start=0, end=a.shape[0]-1)\n",
        "\nimport numpy as np\nX = np.random.randint(2, 10, (5, 6))\nresult = []\nfor i in range(X.shape[0]):\n    for j in range(X.shape[1]):\n        result.append(X[i, j])\nprint(result)\n",
        "\nimport numpy as np\nX = np.random.randint(2, 10, (5, 6))\nresult = []\nfor i in range(X.shape[0]):\n    for j in range(X.shape[1]):\n        result.append(X[i, j])\nprint(result)\n",
        "\n    result = []\n    for i in range(X.shape[0]):\n        for j in range(X.shape[1]):\n            result.append(X[i,j])\n    ",
        "\nimport numpy as np\nX = np.random.randint(2, 10, (5, 6))\nresult = []\nfor i in range(X.shape[0]):\n    for j in range(X.shape[1]):\n        result.append(X[i, j])\nprint(result)\n",
        "\nresult = np.fromstring(mystr, dtype=int, sep='')\n",
        "\nresult = a[:, col] * multiply_number\nresult = np.cumsum(result)\n",
        "\nresult = a[row] * multiply_number\n",
        "\nresult = a[row] / divide_number\nprint(result)\n",
        "\n# [Missing Code]\n",
        "\nresult = a.shape[0]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\np_value = scipy.stats.ttest_ind(amean, bmean, nobs1=anobs, nobs2=bnobs, equal_var=False).pvalue\n",
        "\noutput = np.array([[1,1,2], [1,1,3]])\n",
        "\noutput = np.setdiff1d(A, B)\noutput = np.append(output, np.setdiff1d(B, A))\n",
        "\nc = b[np.argsort(a, axis=0)]\n",
        "\nc = b[np.argsort(a, axis=0)]\n",
        "\nc = b[np.argsort(a, axis=0)]\n",
        "\n# [Missing Code]\n",
        "\na = a[:, :-1]\n",
        "\na = a[:2]\n",
        "\na = a[:, [1, 3]]\n",
        "\nresult = np.delete(a, del_col, axis=1)\n",
        "\na[pos] = element\n",
        "\na = np.insert(a, pos, element, axis=0)\n",
        "\n    a[pos] = element\n    ",
        "\na = np.insert(a, pos, element, axis=0)\n",
        "\n# [Missing Code]\n",
        "\nresult = np.all(a == a[0])\n",
        "\nresult = np.all(a == a[0], axis = 1)\n",
        "\n    # [Missing Code]\n    ",
        "\n# [Missing Code]\n",
        "\n    # [Missing Code]\n    ",
        "\nresult = np.sort(grades)\n",
        "\nresult = np.array([np.percentile(grades, i) for i in eval])\n",
        "\nlow, high = find_interval(grades, threshold)\n",
        "\nnums = np.random.randint(2, size=size)\nnums[nums == 0] = 1\nnums[nums == 1] = 0\n",
        "\na_np = a.numpy()\n",
        "\na_pt = torch.from_numpy(a)\n",
        "\na_np = np.array(a)\n",
        "\nimport tensorflow as tf\nimport numpy as np\na = np.ones([2,3,4])\na_tf = tf.convert_to_tensor(a)\nprint(a_tf)\n",
        "\nresult = a[a.argsort()[::-1]]\n",
        "\nresult = np.argsort(a)\n",
        "\nresult = np.argsort(a)[::-1][:N]\n",
        "\nresult = A**n\n",
        "\nresult = []\nfor i in range(0, a.shape[0]-1, 2):\n    for j in range(0, a.shape[1]-1, 2):\n        result.append(a[i:i+2, j:j+2])\n",
        "\nresult = []\nfor i in range(0, a.shape[0] - 1):\n    for j in range(0, a.shape[1] - 1):\n        result.append(a[i:i+2, j:j+2])\n",
        "\nresult = []\nfor i in range(0, a.shape[0]-1, 2):\n    for j in range(0, a.shape[1]-1, 2):\n        result.append(a[i:i+2, j:j+2])\n",
        "\nresult = []\nfor i in range(0, a.shape[0], patch_size):\n    for j in range(0, a.shape[1], patch_size):\n        result.append(a[i:i+patch_size, j:j+patch_size])\n",
        "\nresult = np.reshape(a, (h, w))\n",
        "\nresult = []\nfor i in range(0, a.shape[0], patch_size):\n    for j in range(0, a.shape[1], patch_size):\n        result.append(a[i:i+patch_size, j:j+patch_size])\n",
        "\nimport numpy as np\na = np.array([[ 0,  1,  2,  3, 5, 6, 7, 8],\n              [ 4,  5,  6,  7, 5, 3, 2, 5],\n              [ 8,  9, 10, 11, 4, 5, 3, 5]])\nlow = 1\nhigh = 5\nresult = a[:, low-1:high]\nprint(result)\n",
        "\nresult = a[low:high]\n",
        "\nresult = a[:, low-1:high]\n",
        "\nimport numpy as np\nstring = \"[[ 0.5544  0.4456], [ 0.8811  0.1189]]\"\na = np.array(eval(string))\nprint(a)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n    # [Missing Code]\n    ",
        "\nB = pd.Series(np.zeros(10))\nB[0] = a*A[0]\nfor i in range(1,10):\n    B[i] = a * A[i] + b * B[i-1]\n",
        "\nB = np.zeros(10)\nB[0] = a*A[0]\nfor i in range(1,10):\n    B[i] = a * A[i] + b * B[i-1] + c * B[i-2]\n",
        "\nresult = np.empty(0)\n",
        "\nresult = np.zeros((3,0))\n",
        "\n# [Missing Code]\n",
        "\nresult = a[index[0], index[1], index[2]]\n",
        "\nvalues = np.zeros((2,3), dtype='int32,float32')\n",
        "\nimport numpy as np\na = np.arange(1,11)\naccmap = np.array([0,1,0,0,0,1,1,2,2,1])\nresult = np.sum(a[np.arange(len(a))==accmap])\nprint(result)\n",
        "\nimport numpy as np\na = np.arange(1,11)\nindex = np.array([0,1,0,0,0,1,1,2,2,1])\nresult = np.max(a[index])\nprint(result)\n",
        "\nresult = np.array([0,0,0])\nfor i in range(len(accmap)):\n    if accmap[i] >= 0:\n        result[accmap[i]] += a[i]\n",
        "\nresult = np.min(a[index])\n",
        "\nz = np.array([[2, 2, 2],\n              [2, 2, 2],\n              [2, 2, 2]])\nfor i in range(len(x)):\n    for j in range(len(x[i])):\n        z[i][j] = elementwise_function(x[i][j], y[i][j])\n",
        "\nresult = np.random.choice(lista_elegir, samples, probabilit)\n",
        "\nresult = a[low_index:high_index+1, low_index:high_index+1]\n",
        "\nresult = x[x >= 0]\n",
        "\nresult = np.array([-2+1j, 2.2+2j])\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\ndef smoothclamp(x):\n    return np.max(np.min(x, x_min), x_max)\n",
        "\ndef smoothclamp(x, N=5):\n    return np.piecewise(x, [x < x_min, x > x_max], [lambda x: x_min, lambda x: x_max])\n",
        "\nresult = np.correlate(a, b, mode='circ')\n",
        "\nresult = df.values.reshape(4,15,5)\n",
        "\nresult = np.array(df.values)\n",
        "\nresult = np.unpackbits(np.uint8(a))\n",
        "\nresult = np.unpackbits(np.uint8(a))\n",
        "\nresult = np.array([np.unpackbits(np.uint8(i)) for i in a])\nresult = np.bitwise_or(result, axis=0)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n    # [Missing Code]\n    ",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\na[zero_rows, :] = 0\na[:, zero_cols] = 0\n",
        "\na[zero_rows, zero_cols] = 0\n",
        "\na[1, :] = 0\na[:, 0] = 0\n",
        "\nimport numpy as np\na = np.array([[0, 1], [2, 1], [4, 8]])\nmask = np.max(a, axis=1) > 0\nprint(mask)\n",
        "\nimport numpy as np\na = np.array([[0, 1], [2, 1], [4, 8]])\nmask = np.array([[True, False], [False, True], [True, False]])\nprint(mask)\n",
        "\n# [Missing Code]\n",
        "\nresult = np.array([X[:, i].dot(X[:, i].T) for i in range(X.shape[1])])\n",
        "\nX = np.dot(Y, Y.T)\n",
        "\n# [Missing Code]\n",
        "\nimport numpy as np\nA = np.array([1,1,2,3,3,3,4,5,6,7,8,8])\nB = np.array([1,2,8])\nC = np.array(A)\nfor i in range(len(A)):\n    if A[i] in B:\n        C[i] = 0\nprint(C)\n",
        "\nimport numpy as np\nA = np.array([1,1,2,3,3,3,4,5,6,7,8,8])\nB = np.array([1,2,8])\nC = np.array(A[np.in1d(A,B)])\nprint(C)\n",
        "\n# [Missing Code]\n",
        "\nresult = np.flip(rankdata(a))\n",
        "\nimport numpy as np\nfrom scipy.stats import rankdata\na = [1,2,3,4,3,2,3,4]\nresult = np.array(a)\nresult = np.flip(result)\nprint(result)\n",
        "\n    result = np.flip(rankdata(a))\n    ",
        "\ndists = np.stack([x_dists, y_dists], axis=0)\n",
        "\ndists = np.stack([x_dists, y_dists], axis=2)\n",
        "\nresult = a[..., second, third]\n",
        "\narr = np.zeros((20,10,10,2))\n",
        "\nresult = X/LA.norm(X,axis=1).reshape(X.shape[0],1)\n",
        "\nresult = X / LA.norm(X, axis=1, ord=2)\n",
        "\nresult = X / LA.norm(X, ord=np.inf)\n",
        "\nresult = np.select(df['a'].str.contains(target), choices, default=np.nan)\n",
        "\nresult = np.zeros((a.shape[0], a.shape[0]))\nfor i in range(a.shape[0]):\n    for j in range(a.shape[0]):\n        if i == j:\n            result[i, j] = 0\n        else:\n            result[i, j] = np.sqrt((a[i, 0] - a[j, 0])**2 + (a[i, 1] - a[j, 1])**2 + (a[i, 2] - a[j, 2])**2)\n",
        "\nresult = np.zeros((a.shape[0], a.shape[0]))\nfor i in range(a.shape[0]):\n    for j in range(a.shape[0]):\n        if i == j:\n            result[i, j] = 0\n        else:\n            result[i, j] = np.linalg.norm(a[i] - a[j])\n",
        "\nresult = np.zeros((a.shape[0], a.shape[0]))\nfor i in range(a.shape[0]):\n    for j in range(i, a.shape[0]):\n        result[i, j] = np.linalg.norm(a[i] - a[j])\n",
        "\nimport numpy as np\nA = ['33.33', '33.33', '33.33', '33.37']\nNA = np.asarray(A)\nAVG = np.mean(NA, axis=0)\nprint(AVG)\n",
        "\nimport numpy as np\nA = ['inf', '33.33', '33.33', '33.37']\nNA = np.asarray(A)\nAVG = np.mean(NA, axis=0)\nprint(AVG)\n",
        "\n# [Missing Code]\n",
        "\nresult = np.unique(a)\n",
        "\nresult = np.unique(a, axis=0, return_index=True)[1]\n",
        "\nimport numpy as np\nimport pandas as pd\nlat=np.array([[10, 20, 30],\n              [20, 11, 33],\n              [21, 20, 10]])\nlon=np.array([[100, 102, 103],\n              [105, 101, 102],\n              [100, 102, 103]])\nval=np.array([[17, 2, 11],\n              [86, 84, 1],\n              [9, 5, 10]])\ndf = pd.DataFrame(np.array([lat, lon, val]).T, columns=['lat', 'lon', 'val'])\nprint(df)\n",
        "\n    # [Missing Code]\n    ",
        "\nimport numpy as np\nimport pandas as pd\nlat=np.array([[10, 20, 30],\n              [20, 11, 33],\n              [21, 20, 10]])\nlon=np.array([[100, 102, 103],\n              [105, 101, 102],\n              [100, 102, 103]])\nval=np.array([[17, 2, 11],\n              [86, 84, 1],\n              [9, 5, 10]])\ndf = pd.DataFrame(np.array([lat, lon, val]).T, columns=['lat', 'lon', 'val'])\ndf['maximum'] = df.max(axis=1)\nprint(df)\n",
        "\nresult = []\nfor i in range(a.shape[0]-size[0]+1):\n    for j in range(a.shape[1]-size[1]+1):\n        result.append(a[i:i+size[0],j:j+size[1]])\n",
        "\nresult = []\nfor i in range(a.shape[0]-size[0]+1):\n    for j in range(a.shape[1]-size[1]+1):\n        result.append(a[i:i+size[0],j:j+size[1]])\n",
        "\nresult = np.mean(a)\n",
        "\n    # [Missing Code]\n    ",
        "\nresult = Z[-1:]\n",
        "\nresult = a[-1:]\n",
        "\nresult = c in CNTS\n",
        "\nresult = c in CNTS\n",
        "\nresult = intp.interp2d(a, a, a, kind='linear')(x_new, y_new)\n",
        "\ndf['Q_cum'] = df.groupby('D')['Q'].cumsum()\n",
        "\ni = np.diag(i)\n",
        "\na[np.diag_indices(a.shape[0])] = 0\n",
        "\n# [Missing Code]\n",
        "\nresult = np.where(x == a)[0][0]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\ndf['new_col'] = df.apply(lambda x: x-a, axis=1)\n",
        "\nresult = np.einsum('ijk,jl->ilk', A, B)\n",
        "\nresult = MinMaxScaler().fit_transform(a)\n",
        "\nresult = MinMaxScaler().fit(arr)\n",
        "\nresult = MinMaxScaler().fit_transform(a)\n",
        "\nmask = arr < -10\nmask2 = arr >= 15\nmask3 = mask ^ mask2\narr[mask] = 0\narr[mask3] = arr[mask3] + 5\narr[~mask2] = 30\n",
        "\nmask = arr < n1\nmask2 = arr < n2\nmask3 = mask ^ mask2\narr[mask] = 0\narr[mask3] = arr[mask3] + 5\narr[~mask2] = 30\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nresult = np.array_equal(a[0],a[1]) and np.array_equal(a[0],a[2])\n",
        "\nresult = all(np.isnan(x) for x in a)\n",
        "\nresult = np.pad(a, (0, 93-41, 0, 13-13), 'constant')\n",
        "\nresult = np.pad(a, (0, 93-41, 0, 13-12), 'constant')\n",
        "\nresult = np.pad(a, (0, 93-41, 0, 13-12), mode='constant', constant_values=element)\n",
        "\n    # [Missing Code]\n    ",
        "\n# [Missing Code]\n",
        "\na = a.reshape(a.shape[0]/3,3)\n",
        "\nresult = a[np.arange(a.shape[0])[:,None], b]\n",
        "\nresult = a[np.arange(a.shape[0])[:,None], np.arange(a.shape[1])[:,None], b]\n",
        "\nresult = a[b]\n",
        "\nresult = np.sum(a[b], axis=0)\n",
        "\nresult = np.sum(a[b], axis=2)\n",
        "\nresult = df.loc[df['a'] > 1, 'b']\n",
        "\nresult = im[1:,1:]\n",
        "\nresult = A[np.any(A, axis=0)]\n",
        "\nresult = np.array([[0, 0, 1, 2, 0],\n                   [1, 0, 0, 1, 0],\n                   [0, 0, 7, 1, 0],\n                   [0, 0, 0, 0, 0]])\n",
        "\nresult = np.array(im[1:,1:])\n"
    ],
    "Matplotlib": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\nx = np.arange(10)\ny = np.random.randn(10)\n# line plot x and y with a thin diamond marker\nplt.plot(x, y, marker='d', linestyle='-', linewidth=0.5)\n",
        "\nx = np.arange(10)\ny = np.random.randn(10)\n# line plot x and y with a thick diamond marker\nplt.plot(x, y, marker='d', linestyle='-', linewidth=2)\n",
        "\nax.set_ylim(0, 40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\nx = np.random.randn(10)\ny = np.random.randn(10)\n# in plt.plot(x, y), use a plus marker and give it a thickness of 7\nplt.plot(x, y, '+', linewidth=7)\n",
        "\nplt.legend(fontsize=20)\n",
        "\n",
        "\nl.set_facecolor('red', alpha=0.2)\n",
        "\n",
        "\nl.set_color('red')\nl.set_linestyle('-')\nl.set_markerfacecolor('red')\nl.set_markersize(30)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\ng.set_xticklabels(g.get_xticklabels(), rotation=90)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n# plot x vs y1 and x vs y2 in two subplots, sharing the x axis\nfig, ax = plt.subplots(2, 1, sharex=True)\nax[0].plot(x, y1)\nax[0].set_title('y1')\nax[1].plot(x, y2)\nax[1].set_title('y2')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\nx = np.arange(10)\ny = np.random.randn(10)\nplt.scatter(x, y)\n# show grids\nplt.grid()\n",
        "\n",
        "\nfig, axes = plt.subplots(ncols=2, nrows=2, figsize=(8, 6), tight_layout=True)\naxes = axes.flatten()\nfor ax in axes:\n    ax.set_ylabel(r\"$\\ln\\left(\\frac{x_a-x_b}{x_a-x_c}\\right)$\")\n    ax.set_xlabel(r\"$\\ln\\left(\\frac{x_a-x_d}{x_a-x_e}\\right)$\")\nplt.show()\nplt.clf()\n",
        "\nx = np.arange(10)\ny = np.arange(10, 20)\nz = np.arange(10)\nplt.plot(x, y, label='Y')\nplt.plot(x, z, label='Z')\nplt.legend()\n",
        "\n",
        "\n",
        "\nplt.plot(x, y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\nplt.plot(x, y)\nplt.xlabel(\"X\", color=\"red\")\nplt.xticks(color=\"red\")\n",
        "\nplt.plot(x, y)\nplt.xlabel(\"X\")\nplt.xaxis.set_color('red')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\nx = np.arange(10)\ny = np.arange(10)\n# make two side-by-side subplots and and in each subplot, plot y over x\n# Title each subplot as \"Y\"\nfig, ax = plt.subplots(2, 1, sharex=True)\nax[0].plot(x, y)\nax[0].set_title(\"Y\")\nax[1].plot(x, y)\nax[1].set_title(\"Y\")\n",
        "\n",
        "\n",
        "\nplt.plot(x, y, label=\"y over x\")\nplt.legend(title=\"Legend Title\")\n",
        "\nplt.plot(x, y, label=\"y over x\")\nplt.legend(title=\"Legend\", loc=\"upper left\", fontweight=\"bold\")\n",
        "\n",
        "\nfig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\nplt.hist(x, bins, alpha=0.5)\nplt.hist(y, bins, alpha=0.5)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\nplt.plot(x, y)\nplt.title(\"Title\", fontsize=20)\nplt.xlabel(\"xlabel\", fontsize=18)\nplt.ylabel(\"ylabel\", fontsize=16)\n",
        "\n",
        "\n",
        "\n",
        "\n# make four line plots of data in the data frame\n# show the data points  on the line plot\n",
        "\n# Calculate the total sum of data\ntotal_sum = sum(data)\n# Normalize the data by dividing each value by the total sum\nnormalized_data = [value / total_sum for value in data]\n# Create a histogram with the normalized data\nplt.hist(normalized_data, bins=10, edgecolor='black', color='blue')\n# Set the y-axis labels to percentages\nplt.ylabel('Percentage')\n# Set the y-axis tick labels to 10%, 20%, etc.\nplt.yticks(np.arange(0, 1.1, 0.1))\n",
        "\nplt.plot(x, y, marker='o', markersize=10, linestyle='solid', alpha=0.5)\n",
        "\n",
        "\n",
        "\n",
        "\nplt.plot(x, y)\nplt.legend([\"y\", \"x\"])\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\nfig = plt.figure()\nax1 = fig.add_subplot(1, 2, 1)\nax1.plot(x, y)\nax2 = fig.add_subplot(1, 2, 2)\nax2.plot(x, y)\nfig.suptitle(\"Figure\")\n",
        "\n# Plot values in df with line chart\n# label the x axis and y axis in this plot as \"X\" and \"Y\"\n",
        "\nplt.scatter(x, y, marker='|', s=10, c='red', alpha=0.5)\n",
        "\nplt.scatter(x, y, marker='o', edgecolor='white', hatch='|')\n",
        "\nplt.scatter(x, y, marker='*', s=10)\n",
        "\nplt.scatter(x, y, s=100, marker='s', hatch='|')\n",
        "\n",
        "\nx = np.linspace(0.1, 2 * np.pi, 41)\ny = np.exp(np.sin(x))\n# make a stem plot of y over x and set the orientation to be horizontal\nplt.stem(x, y, orientation='horizontal')\n",
        "\n",
        "\n",
        "\nplt.polar(labels, height)\n",
        "\nplt.pie(data, labels=l, wedgeprops={'width': 0.4})\n",
        "\n",
        "\nplt.plot(x, y)\nplt.grid(which='minor', axis='both', linestyle='--', color='gray')\nplt.grid(which='major', axis='both', linestyle='--', color='gray')\n",
        "\n",
        "\n",
        "\nplt.plot(x, y, 'o', alpha=0.5, edgecolor='black')\n",
        "\n",
        "\n",
        "\n",
        "\nplt.scatter(x, y, c=y, cmap='Spectral')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\nplt.plot(x, y, label=\"Line\")",
        "\nx = np.arange(10)\ny = np.arange(10)\n# Plot y over x with a legend of \"Line\"\n# Adjust the length of the legend handle to be 0.3\nplt.plot(x, y, label=\"Line\")\nplt.legend(bbox_to_anchor=(0.0, 1.0), loc=1, prop=plt.FontProperties(size=10), handlelength=0.3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\nplt.scatter(x, y, s=10, c='red', edgecolor='black')\n",
        "\n",
        "\n",
        "\n# Plot y over x and show the error according to `error`\nplt.plot(x, y, color='blue')\n# Plot the error as a shaded region rather than error bars\nplt.fill_between(x, y, y + error, color='red', alpha=0.5)\n",
        "\n",
        "\n",
        "\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.plot(x, y)\nplt.title(\"Y\")\nplt.subplot(1, 2, 2)\nplt.plot(z, a)\nplt.title(\"Z\", fontsize=15)\n",
        "\n",
        "\nd = np.random.random((10, 10))\n# Use matshow to plot d and make the figure size (8, 8)\nplt.matshow(d)\nplt.figure(figsize=(8, 8))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\nplt.plot(x, y, label=\"y\")\nplt.legend(fontsize=8)\n",
        "\nx = np.arange(10)\ny = np.arange(10)\n# Plot y over x with figsize (5, 5) and dpi 300\nplt.plot(x, y, figsize=(5, 5), dpi=300)\n",
        "\nplt.plot(x, y, label=\"y\")\nplt.legend()\nplt.legend(loc='upper right')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n# Make a 2x2 subplots with fig and plot x in each subplot as an image\ngs = gridspec.GridSpec(nrow, ncol, hspace=0, wspace=0)\nfor i in range(nrow):\n    for j in range(ncol):\n        ax = fig.add_subplot(gs[i, j])\n        ax.imshow(x)\n# Remove the space between each subplot and make the subplot adjacent to each other\nfor i in range(nrow):\n    for j in range(ncol):\n        if i == 0 and j == 0:\n            continue\n        else:\n            ax = fig.add_subplot(gs[i, j])\n            ax.set_visible(False)\n# Remove the axis ticks from each subplot\nfor i in range(nrow):\n    for j in range(ncol):\n        ax = fig.add_subplot(gs[i, j])\n        ax.set_xticks([])\n        ax.set_yticks([])\n"
    ],
    "Tensorflow": [
        "\nx.assign(1)\n",
        "\nx.assign(114514)\n",
        "\nresult = tf.one_hot(labels, 10)\n",
        "\nresult = tf.one_hot(labels, 10)\n",
        "\nresult = tf.one_hot(labels, 10)\n",
        "\n    result = tf.one_hot(labels, 10)\n    ",
        "\nresult = tf.one_hot(labels, 10)\n",
        "\ndef my_map_func(i):\n  return [i, i+1, i+2]\nds = tf.data.Dataset.from_tensor_slices(input)\nds = ds.map(map_func=lambda input: tf.compat.v1.py_func(\n  func=my_map_func, inp=[input], Tout=[tf.int64]\n))\nelement = tf.compat.v1.data.make_one_shot_iterator(ds).get_next()\nresult = []\nwith tf.compat.v1.Session() as sess:\n  for _ in range(9):\n    result.append(sess.run(element))\nprint(result)\n",
        "\n    # [Missing Code]\n    ",
        "\nresult = tf.zeros(8, dtype=tf.int32)\nfor i, length in enumerate(lengths):\n    result[i:i+length] = 1\n",
        "\nresult = tf.zeros(8, dtype=tf.int32)\nfor i, length in enumerate(lengths):\n    result[i:i+length] = 1\n",
        "\nresult = tf.zeros(8)\nfor i in range(len(lengths)):\n    result[i:i+lengths[i]] = 1\n",
        "\n    # [Missing Code]\n    ",
        "\nresult = tf.zeros(8, dtype=tf.int32)\nfor i in range(len(lengths)):\n    result[i:i+lengths[i]] = 1\n",
        "\nresult = tf.expand_dims(a, axis=0) * tf.expand_dims(b, axis=1)\n",
        "\n    # [Missing Code]\n    ",
        "\nresult = a.reshape(50, 100, 512)\n",
        "\nresult = tf.expand_dims(a, axis=3)\n",
        "\nresult = tf.expand_dims(a, axis=0)\n",
        "\nresult = tf.reduce_sum(A, axis=1)\n",
        "\nresult = tf.reduce(A, axis=1)\n",
        "\nresult = 1/A\n",
        "\nresult = tf.reduce_sum(tf.square(tf.sub(a, b)), axis=1)\n",
        "\nresult = tf.reduce_sum(tf.square(tf.sub(a, b)), axis=1)\n",
        "\n    # [Missing Code]\n    ",
        "\nresult = x[y,z]\n",
        "\nresult = x[row,col]\n",
        "\n    return x[y,z]\n    ",
        "\nresult = tf.matmul(A, B)\n",
        "\nresult = tf.matmul(A, B)\n",
        "\nresult = tf.keras.utils.decode_utf8(x)\n",
        "\n                                          use_id_as_index_v2=False,\n                                          use_id_as_index_v3=False,\n                                          use_id_as_index_v4=False,\n                                          use_id_as_index_v5=False,\n                                          use_id_as_index_v6=False,\n                                          use_id_as_index_v7=False,\n                                          use_id_as_index_v8=False,\n                                          use_id_as_index_v9=False,\n                                          use_id_as_index_v10=False,\n                                          use_id_as_index_v11=False,\n                                          use_id_as_index_v12=False,\n                                          use_id_as_index_v13=False,\n                                          use_id_as_index_v14=False,\n                                          use_id_as_index_v15=False,\n                                          use_id_as_index_v16=False,\n                                          use_id_as_index_v17=False,\n                                          use_id_as_index_v18=False,\n                                          use_id_as_index_v19=False,\n                                          use_id_as_index_v20=False,\n                                          use_id_as_index_v21=False,\n                                          use_id_as_index_v22=False,\n                                          use_id_as_index_v23=False,\n                                          use_id_as_index_v24=False,\n                                          use_id_as_index_v25=False,\n                                          use_id_as_index_v26=False,\n                                          use_id_as_index_v27=False,\n                                          use_id_as_index_v28=False,\n                                          use_id_as_index_v29=False,\n                                          use_id_as_index_v30=False,\n                                          use_id_as_index_v31=False,\n                                          use_id_as_index_v32=False,\n                                          use_id_as_index_v33=False,\n                                          use_id_as_index_v34=False,\n                                          use_id_as_index_v35=False,\n                                          use_id_as_index_v36=False,\n                                          use_id_as_index_v37=False,\n                                          use_id_as_index_v38=False,\n                                          use_id_as_index_v39=False,\n                                          use_id_as_index_v40=False,\n                                          use_id_as_index_v41=False,\n                                          use_id_as_index_v42=False,\n                                          use_id_as_index_v43=False,\n                                          use_id_",
        "\nresult = tf.math.reduce_mean(x, axis=2, keep_dims=True)\n",
        "\nresult = tf.math.reduce_mean(x, axis=2)\n",
        "\n    # [Missing Code]\n    ",
        "\n# [Missing Code]\n",
        "\nresult = tf.argmax(a, axis=1)\n",
        "\nresult = tf.argmax(a, axis=1)\n",
        "\n    # [Missing Code]\n    ",
        "\nimport tensorflow as tf\na = tf.constant(\n    [[0.3232, -0.2321, 0.2332, -0.1231, 0.2435, 0.6728],\n     [0.2323, -0.1231, -0.5321, -0.1452, 0.5435, 0.1722],\n     [0.9823, -0.1321, -0.6433, 0.1231, 0.023, 0.0711]]\n)\nresult = tf.argmin(a, axis=1)\nprint(result)\n",
        "\nmodel.save('export/1')\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n    # [Missing Code]\n    ",
        "\nresult = tf.__version__\n"
    ],
    "Scipy": [
        "\nresult = np.polyfit(x, y, 1)\n",
        "\nresult = np.polyfit(x, y, 1)\n",
        "\nresult = scipy.optimize.curve_fit(lambda x, a, b, c: a*np.exp(b*x) + c, x, y, p0)\n",
        "\nstatistic, p_value = stats.ks_2samp(x, y)\n",
        "\n# [Missing Code]\n",
        "\nresult = optimize.minimize(f, initial_guess, method='Nelder-Mead',\n                           bounds=(-1, 1),\n                           args=(0, 0, 0),\n                           tol=1e-10)\n",
        "\nimport numpy as np\nimport scipy.stats\nz_scores = np.array([-3, -2, 0, 2, 2.5])\np_values = scipy.stats.norm.ppf(z_scores)\nprint(p_values)\n",
        "\np_values = [scipy.stats.norm.cdf(z_score, mu, sigma) for z_score in z_scores]\n",
        "\nz_scores = [scipy.stats.norm.ppf(p) for p in p_values]\n",
        "\n# [Missing Code]\n",
        "\nimport numpy as np\nfrom scipy import stats\nstddev = 2.0785\nmu = 1.744\nexpected_value = stats.lognorm(mu, stddev).mean()\nmedian = stats.lognorm(mu, stddev).median()\nprint(expected_value, median)\n",
        "\nfrom scipy import sparse\nimport numpy as np\nsa = sparse.csr_matrix(np.array([[1,2,3],[4,5,6],[7,8,9]]))\nsb = sparse.csr_matrix(np.array([0,1,2]))\nresult = sa * sb\nprint(result)\n",
        "\n    result = sA * sB\n    ",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nresult = np.diag(M)\n",
        "\nresult = stats.kstest(times, 'uniform')\n",
        "\n    # [Missing Code]\n    ",
        "\n# [Missing Code]\n",
        "\nFeature = sparse.hstack([c1, c2])\n",
        "\nFeature = sparse.hstack([c1, c2])\n",
        "\nFeature = sparse.vstack([c1, c2])\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nb.setdiag(0)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n    # [Missing Code]\n    ",
        "\n# [Missing Code]\n",
        "\nM.fill_diagonal(0)\n",
        "\n    for i in range(len(sA)):\n        for j in range(len(sA)):\n            if sA[i,j] != 0:\n                sA[j,i] = sA[i,j]\n    ",
        "\nimport numpy as np\nimport scipy.ndimage\nsquare = np.zeros((32, 32))\nsquare[10:-10, 10:-10] = 1\nnp.random.seed(12)\nx, y = (32*np.random.random((2, 20))).astype(int)\nsquare[x, y] = 1\nsquare = scipy.ndimage.binary_erosion(square)\nprint(square)\n",
        "\nimport numpy as np\nimport scipy.ndimage\nsquare = np.zeros((32, 32))\nsquare[10:-10, 10:-10] = np.random.randint(1, 255, size = (12, 12))\nnp.random.seed(12)\nx, y = (32*np.random.random((2, 20))).astype(int)\nsquare[x, y] = np.random.randint(1, 255, size = (20,))\nsquare = scipy.ndimage.binary_erosion(square)\nprint(square)\n",
        "\nmean = np.mean(col)\nstandard_deviation = np.std(col)\n",
        "\nMax = np.max(col)\nMin = np.min(col)\n",
        "\n# [Missing Code]\n",
        "\nfrom scipy.optimize import curve_fit\nimport numpy as np\ns = '''1.000000000000000021e-03,2.794682735905079767e+02\n4.000000000000000083e-03,2.757183469104809888e+02\n1.400000000000000029e-02,2.791403179603880176e+02\n2.099999999999999784e-02,1.781413355804160119e+02\n3.300000000000000155e-02,-2.798375517344049968e+02\n4.199999999999999567e-02,-2.770513900380149721e+02\n5.100000000000000366e-02,-2.713769422793179729e+02\n6.900000000000000577e-02,1.280740698304900036e+02\n7.799999999999999989e-02,2.800801708984579932e+02\n8.999999999999999667e-02,2.790400329037249776e+02'''.replace('\\n', ';')\narr = np.matrix(s)\nz = np.array(arr[:, 0]).squeeze()\nUa = np.array(arr[:, 1]).squeeze()\ntau = 0.045\ndegree = 15\t\ndef fourier(x, a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12, a13, a14, a15):\n    return a1 * np.cos(1 * np.pi / tau * x) + \\\n           a2 * np.cos(2 * np.pi / tau * x) + \\\n           a3 * np.cos(3 * np.pi / tau * x) + \\\n           a4 * np.cos(4 * np.pi / tau * x) + \\\n           a5 * np.cos(5 * np.pi / tau * x) + \\\n           a6 * np.cos(6 * np.pi / tau * x) + \\\n           a7 * np.cos(7 * np.pi / tau * x) + \\\n           a8 * np.cos(8 * np.pi / tau * x) + \\\n           a9 * np.cos(9 * np.pi / tau * x) + \\\n           a10 * np.cos(10 * np.pi / tau * x) + \\\n           a11 * np.cos(11 * np.pi / tau * x) + \\\n           a12 * np.cos(12 * np.pi / tau * x) + \\\n           a13 * np.cos(13 * np.pi / tau * x) + \\\n           a14 * np.cos(14 * np.pi / tau * x) + \\\n           a15 * np.cos(15 * np.pi / tau * x)\npopt, pcov = curve_fit(fourier, z, Ua)\nprint(popt, pcov)\n",
        "\nresult = scipy.spatial.distance.cdist(example_array, example_array, 'euclidean')\n",
        "\n# [Missing Code]\n",
        "\n    # [Missing Code]\n    ",
        "\n# [Missing Code]\n",
        "\nstatistic, critical_values, significance_level = ss.anderson_ksamp(x1, x2, x3, x4)\n",
        "\nresult = ss.anderson_ksamp(x1, x2)\n",
        "\ndef tau1(x):\n    y = np.array(df['A']) #  keep one column fix and run it in the other two\n    tau, p_value = stats.stats.kendalltau(x, y)\n    return tau\ndf['AB'] = pd.rolling_apply(df['B'], 3, lambda x: tau1(x))\n",
        "\nresult = sa.nnz == 0\n",
        "\nresult = sa.nnz == 0\n",
        "\nresult = block_diag(*a)\n",
        "\np_value = stats.ranksums(pre_course_scores, during_course_scores)[1]\n",
        "\n    p_value = stats.ranksums(pre_course_scores, during_course_scores)[1]\n    ",
        "\nkurtosis_result = np.mean(np.power(a - np.mean(a), 4)) / np.power(np.std(a), 4)\n",
        "\nkurtosis_result = scipy.stats.kurtosis(a, fisher=True)\n",
        "\nimport numpy as np\nimport scipy.interpolate\ns = np.linspace(-1, 1, 50)\nt = np.linspace(-2, 0, 50)\nx, y = np.ogrid[-1:1:10j,-2:0:10j]\nz = (x + y)*np.exp(-6.0 * (x * x + y * y))\nresult = scipy.interpolate.interp2d(s, t, z)(s, t)\nprint(result)\n",
        "\n    # [Missing Code]\n    ",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nresult = sparse.vstack(vectors)\n",
        "\nb = scipy.ndimage.median_filter(a, 3, mode='constant', origin=1)\n",
        "\nresult = M.getrow(row)[column]\n",
        "\nresult = [M[row[i], column[i]] for i in range(len(row))]\n",
        "\nnew_array = np.zeros((100, 10, 10))\nfor i in range(100):\n    new_array[i] = interp1d(x, array[:, i, i])(x_new)\n",
        "\n# [Missing Code]\n",
        "\n    dev = abs((x-u)/o2)\n    P_inner = scipy.integrate.quad(NDfx,-dev,dev)[0]\n    P_outer = 1 - P_inner\n    P = P_inner + P_outer/2\n    ",
        "\nresult = np.zeros((N,N))\nfor i in range(N):\n    for j in range(N):\n        result[i,j] = sf.dctn(np.array([1,0,0,0,0,0,0,0]))[i]\n",
        "\nresult = sparse.diags(matrix, [-1,0,1], (5, 5)).toarray()\n",
        "\nresult = np.zeros((N+1, N+1))\nfor i in range(N+1):\n    for j in range(i+1):\n        result[i,j] = scipy.stats.binom.pmf(j, N, p)\n",
        "\n# [Missing Code]\n",
        "\ndf['sample1'] = df['sample1'] - df['sample1'].mean()\ndf['sample2'] = df['sample2'] - df['sample2'].mean()\ndf['sample3'] = df['sample3'] - df['sample3'].mean()\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nresult = scipy.optimize.line_search(test_func,test_grad,starting_point,direction)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n    # [Missing Code]\n    ",
        "\nresult = scipy.ndimage.zoom(x, shape[0]/x.shape[0], order=1)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nimport scipy.integrate\nimport numpy as np\nN0 = 10\ntime_span = [-0.1, 0.1]\ndef dN1_dt_simple(t, N1):\n    return -100 * N1\ndef dN1_dt_sin(t, N1):\n    return -100 * N1 + np.sin(t)\nsol = scipy.integrate.solve_ivp(fun=dN1_dt_sin, t_span=time_span, y0=[N0,])\nresult = sol.y\nprint(result)\n",
        "\ndef dN1_dt_simple(t, N1):\n    return -100 * N1\ndef dN1_dt_sin(t, N1):\n    return -100 * N1 + t - np.sin(t)\nsol = scipy.integrate.solve_ivp(fun=dN1_dt_sin, t_span=time_span, y0=[N0,])\nresult = sol.y\nprint(result)\n",
        "\ndef dN1_dt_simple(t, N1):\n    return -100 * N1\ndef dN1_dt_simple_with_input(t, N1):\n    return -100 * N1 - np.cos(t)\nsol = scipy.integrate.solve_ivp(fun=dN1_dt_simple_with_input, t_span=time_span, y0=[N0,])\nresult = sol.y\n",
        "\nimport numpy as np\nfrom scipy.optimize import minimize\ndef function(x):\n    return -1*(18*x[0]+16*x[1]+12*x[2]+11*x[3])\nI=np.array((20,50,50,80))\nx0=I\ncons=[]\nsteadystate={'type':'eq', 'fun': lambda x: x.sum()-I.sum() }\ncons.append(steadystate)\nfor t in range (4):\n    def const(x):\n        y=x[t]\n        return y\n    cons.append({'type':'ineq', 'fun': const})\nout=minimize(function, x0, method=\"SLSQP\", constraints=cons)\nx=out[\"x\"]\n",
        "\nresult = sa.toarray()\nresult = np.vstack((result, sb.toarray()))\n",
        "\nresult = sa.hstack(sb)\n",
        "\nresult = integrate.quad(lambda x: 2*x*c,low,high)\n",
        "\n    # [Missing Code]\n    ",
        "\nV = V + x\n",
        "\nfrom scipy import sparse\nV = sparse.random(10, 10, density = 0.05, format = 'coo', random_state = 42)\nx = 100\nV = V + x\nprint(V)\n",
        "\nV = V + x\n",
        "\nfor Col in xrange(sa.shape[1]):\n    Column = sa[:,Col].data\n    List = [x**2 for x in Column]\n    Len = math.sqrt(sum(List))\n    sa[:,Col] = sa[:,Col] * (1/Len)\n",
        "\nsa.data = sa.data / np.sqrt(sa.data**2).sum()\n",
        "\na = a > 0\n",
        "\na = a > 0\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nresult = np.array([fsolve(lambda x, a, b: x + 2*a - b**2, 0, args=(x, b)) for x, b in zip(xdata, bdata)])\n",
        "\nimport numpy as np\nfrom scipy.optimize import fsolve\ndef eqn(x, a, b):\n    return x + 2*a - b**2\nxdata = np.arange(4)+3\nadata = np.random.randint(0, 10, (4,))\nresult = []\nfor i in range(len(xdata)):\n    for j in range(len(adata[i])):\n        result.append(fsolve(lambda b: eqn(xdata[i], a=adata[i][j], b=b), 0))\nprint(result)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nresult = []\nfor i in range(len(arr)):\n    if i == 0:\n        if arr[i] <= arr[i+1]:\n            result.append(i)\n    elif i == len(arr)-1:\n        if arr[i] <= arr[i-1]:\n            result.append(i)\n    else:\n        if arr[i] <= arr[i-1] and arr[i] <= arr[i+1]:\n            result.append(i)\n",
        "\nresult = []\nfor i in range(arr.shape[0]):\n    for j in range(arr.shape[1]):\n        if i == 0 and j == 0:\n            continue\n        if i == 0 and j == 1:\n            continue\n        if i == 0 and j == 2:\n            continue\n        if i == 0 and j == 3:\n            continue\n        if i == 0 and j == 4:\n            continue\n        if i == 0 and j == 5:\n            continue\n        if i == 1 and j == 0:\n            continue\n        if i == 1 and j == 1:\n            continue\n        if i == 1 and j == 2:\n            continue\n        if i == 1 and j == 3:\n            continue\n        if i == 1 and j == 4:\n            continue\n        if i == 1 and j == 5:\n            continue\n        if i == 2 and j == 0:\n            continue\n        if i == 2 and j == 1:\n            continue\n        if i == 2 and j == 2:\n            continue\n        if i == 2 and j == 3:\n            continue\n        if i == 2 and j == 4:\n            continue\n        if i == 2 and j == 5:\n            continue\n        if i == 3 and j == 0:\n            continue\n        if i == 3 and j == 1:\n            continue\n        if i == 3 and j == 2:\n            continue\n        if i == 3 and j == 3:\n            continue\n        if i == 3 and j == 4:\n            continue\n        if i == 3 and j == 5:\n            continue\n        if i == 4 and j == 0:\n            continue\n        if i == 4 and j == 1:\n            continue\n        if i == 4 and j == 2:\n            continue\n        if i == 4 and j == 3:\n            continue\n        if i == 4 and j == 4:\n            continue\n        if i == 4 and j == 5:\n            continue\n        if i == 5 and j == 0:\n            continue\n        if i == 5 and j == 1:\n            continue\n        if i == 5 and j == 2:\n            continue\n        if i == 5 and j == 3:\n            continue\n        if i == 5 and j == 4:\n            continue\n        if i == 5 and j == 5:\n            continue\n        if i == 0 and j == 0:\n            if arr[i, j] <= arr[i, j + 1] and arr[i, j] <= arr[i, j - 1]:\n                result.append([i, j])\n        if i == 0 and j == 1:\n            if arr[i, j] <= arr[i, j + 1] and arr[i, j] <= arr[i, j - 1]:\n                result.append([i, j])\n        if i == 0 and j == 2:\n            if arr[i, j] <= arr[i, j + 1] and arr[i, j] <= arr[i, j - 1]:\n                result.append([i, j])\n        if i == 0 and j == 3:\n            if arr[i, j] <= arr[i, j + 1] and arr[i, j] <= arr[i, j - 1]:\n                result.append([i, j])\n        if i == 0 and j == 4:\n            if arr[i, j] <= arr[i, j + 1] and arr[i, j] <= arr[i, j - 1]:\n                result.append([i, j])",
        "\ndf = df[(np.abs(stats.zscore(df.select_dtypes(np.float64))) < 3).all(axis=1)]\n"
    ],
    "Sklearn": [
        "\ndata1 = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "\ndata1 = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "\ndata1 = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "\n    data1 = pd.DataFrame(data.data, columns=data.feature_names)\n    ",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\ndf = pd.concat([df_origin, transform_output], axis=1)\n",
        "\ndf = pd.DataFrame(transform_output.toarray(), columns=df_origin.columns)\n",
        "\n    # [Missing Code]\n    ",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nclf.named_steps.pop('pOly')\n",
        "\nclf.named_steps['poly'] = PolynomialFeatures(degree=2)\n",
        "\nclf.steps.insert(1,('dim_svm', PCA()))\n",
        "\nclf.named_steps['t1919810'] = PCA()\n",
        "\ngridsearch.fit(trainX, trainY,\n               cv=TimeSeriesSplit(n_splits=gridsearch.cv),\n               n_jobs=gridsearch.n_jobs,\n               iid=gridsearch.iid,\n               early_stopping_rounds=gridsearch.fit_params['early_stopping_rounds'],\n               eval_metric=gridsearch.fit_params['eval_metric'],\n               eval_set=gridsearch.fit_params['eval_set'])\n",
        "\ngridsearch.fit(trainX, trainY, eval_set=[(testX, testY)],\n               eval_metric='mae',\n               early_stopping_rounds=42,\n               verbose=1,\n               cv=TimeSeriesSplit(n_splits=3).get_n_splits([trainX, trainY]),\n               n_jobs=1,\n               iid=True)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nscaled = scaler.inverse_transform(scaled)\n",
        "\n    # [Missing Code]\n    ",
        "\nmodel_name = model.__class__.__name__\n",
        "\nmodel_name = model.__class__.__name__\n",
        "\nmodel_name = model.__class__.__name__\n",
        "\ntf_idf_out = pipe.named_steps[\"tf_idf\"].fit_transform(data.test)\n",
        "\ntf_idf_out = pipe.named_steps[\"tf_idf\"].fit_transform(data.test)\n",
        "\nselect_out = pipe.named_steps['select'].fit_transform(data, target)\n",
        "\nclf = GridSearchCV(bc, param_grid, cv=5, n_jobs=-1)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\ntfidf = TfidfVectorizer(preprocessor=preprocess)\n",
        "\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ndef prePro(text):\n    return text.lower()\ntfidf = TfidfVectorizer(preprocessor=prePro)\nprint(tfidf.preprocessor)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\ncoef = grid.best_estimator_.named_steps['model'].coef_\n",
        "\ncoef = grid.best_estimator_.named_steps['model'].coef_\n",
        "\ncolumn_names = clf.feature_importances_.argsort()[-10:]\n",
        "\ncolumn_names = clf.feature_importances_\n",
        "\ncolumn_names = clf.feature_importances_\n",
        "\ncolumn_names = [clf.feature_importances_.argsort()[-10:][::-1]]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n    # [Missing Code]\n    ",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nfrom sklearn.svm import SVR\nmodel = SVR(kernel='gaussian')\nmodel.fit(X, y)\npredict = model.predict(X)\n",
        "\nfrom sklearn.svm import SVR\nsvr = SVR(kernel='gaussian')\nsvr.fit(X, y)\npredict = svr.predict(X)\n",
        "\nfrom sklearn.svm import SVR\nsvr = SVR(kernel='poly', degree=2)\nsvr.fit(X, y)\npredict = svr.predict(X)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\ntfidf_query = tfidf.transform(queries)\ncosine_similarities = np.dot(tfidf_query, tfidf.transform(documents).T)\ncosine_similarities = cosine_similarities / np.sqrt(np.dot(tfidf_query, tfidf_query.T))\ncosine_similarities = cosine_similarities / np.sqrt(np.dot(tfidf.transform(documents), tfidf.transform(documents).T))\n",
        "\n    # [Missing Code]\n    ",
        "\nnew_features = pd.DataFrame(features)\n",
        "\nnew_f = pd.DataFrame(f)\n",
        "\nnew_features = pd.DataFrame(features)\n",
        "\n    # [Missing Code]\n    ",
        "\n# [Missing Code]\n",
        "\ncluster_labels = sklearn.cluster.AgglomerativeClustering(n_clusters=2).fit(data_matrix).labels_\n",
        "\ncluster_labels = sklearn.cluster.AgglomerativeClustering(n_clusters=2).fit(data_matrix).labels_\n",
        "\ncluster_labels = sklearn.cluster.AgglomerativeClustering(n_clusters=2).fit(simM).labels_\n",
        "\ncluster_labels = scipy.cluster.hierarchy.cluster_dendrogram(data_matrix)\n",
        "\ncluster_labels = scipy.cluster.hierarchy.cluster_dbscan(data_matrix, 2)\n",
        "\ncluster_labels = scipy.cluster.hierarchy.cut(simM, 2)\n",
        "\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.preprocessing import Normalizer\n",
        "\n# [Missing Code]\n",
        "\nfrom sklearn.preprocessing import BoxCox\nbox_cox_data = BoxCox().fit_transform(data)\n",
        "\nfrom sklearn.preprocessing import BoxCoxTransformer\nbox_cox_data = BoxCoxTransformer().fit_transform(data)\n",
        "\nfrom sklearn.preprocessing import YeoJohnson\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n    # [Missing Code]\n    ",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n    # [Missing Code]\n    ",
        "\nvectorizer = CountVectorizer(stop_words=\"english\",binary=True,lowercase=False,vocabulary={'Jscript','.Net','TypeScript','SQL', 'NodeJS','Angular','Mongo','CSS','Python','PHP','Photoshop','Oracle','Linux','C++',\"Java\",'TeamCity','Frontend','Backend','Full stack', 'UI Design', 'Web','Integration','Database design','UX'})\n",
        "\nvectorizer = CountVectorizer(stop_words=\"english\",binary=True,lowercase=False,vocabulary={'Jscript','.Net','TypeScript','NodeJS','Angular','Mongo','CSS','Python','PHP','Photoshop','Oracle','Linux','C++',\"Java\",'TeamCity','Frontend','Backend','Full stack', 'UI Design', 'Web','Integration','Database design','UX'})\n",
        "\nvectorizer = CountVectorizer(stop_words=\"english\",binary=True,lowercase=False,vocabulary={'Jscript','.Net','TypeScript','SQL', 'NodeJS','Angular','Mongo','CSS','Python','PHP','Photoshop','Oracle','Linux','C++',\"Java\",'TeamCity','Frontend','Backend','Full stack', 'UI Design', 'Web','Integration','Database design','UX'})\nX = vectorizer.fit_transform(corpus)\nprint(vectorizer.get_feature_names())\nprint(X.toarray())\n",
        "\nvectorizer = CountVectorizer(stop_words=\"english\",binary=True,lowercase=False,vocabulary={'Jscript','.Net','TypeScript','NodeJS','Angular','Mongo','CSS','Python','PHP','Photoshop','Oracle','Linux','C++',\"Java\",'TeamCity','Frontend','Backend','Full stack', 'UI Design', 'Web','Integration','Database design','UX'})\nX = vectorizer.fit_transform(corpus)\nprint(vectorizer.get_feature_names())\nprint(X.toarray())\n",
        "\nfor col in df1.columns:\n    if col != 'Time':\n        df2 = df1[~np.isnan(df1[col])]\n        df3 = df2[['Time', col]]\n        npMatrix = np.matrix(df3)\n        X, Y = npMatrix[:,0], npMatrix[:,1]\n        slope = LinearRegression().fit(X,Y)\n        m = slope.coef_[0]\n        print(m)\n",
        "\nfor col in df1.columns:\n    if col != 'Time':\n        df2 = df1[~np.isnan(df1[col])]\n        df3 = df2[['Time', col]]\n        npMatrix = np.matrix(df3)\n        X, Y = npMatrix[:,0], npMatrix[:,1]\n        slope = LinearRegression().fit(X,Y)\n        m = slope.coef_[0]\n        print(m)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n    # [Missing Code]\n    ",
        "\nlasso = linear_model.ElasticNet()\nlasso.fit(X_train, y_train)\nprint(lasso.score(X_train, y_train))\nprint(lasso.score(X_test, y_test))\n",
        "\n# [Missing Code]\n",
        "\ntransformed = np.array(np_array)\ntransformed = MinMaxScaler().fit_transform(transformed)\n",
        "\n    # [Missing Code]\n    ",
        "\n# [Missing Code]\n",
        "\nnew_X = np.array(X)\n",
        "\nnew_X = np.array(X)\n",
        "\nnew_X = np.array(X)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n    # [Missing Code]\n    ",
        "\ncols = df.columns[2:4]\ndf[cols + '_scale'] = df.groupby('Month')[cols].apply(scaler.fit_transform)\n",
        "\nmyData['new_A2'] = myData['A2'].apply(lambda x: scaler.fit_transform(x.reshape(-1,1)))\nmyData['new_A3'] = myData['A3'].apply(lambda x: scaler.fit_transform(x.reshape(-1,1)))\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "import numpy as np\nimport pandas as pd\nimport sklearn\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ndef load_data():\n    df = pd.DataFrame({\n        'items': ['1fgg', '2hhj', '3jkl'],\n        'description': ['abcd ty', 'abc r', 'r df']\n    })\n    return df\ndef get_tfidf_matrix(df):\n    tfidf = TfidfVectorizer()\n    tfidf_matrix = tfidf.fit_transform(df['description'])\n    return tfidf_matrix\ndef get_cosine_similarity_matrix(tfidf_matrix):\n    cosine_similarity_matrix = np.dot(tfidf_matrix, tfidf_matrix.T)\n    return cosine_similarity_matrix\ndef get_cosine_similarity_matrix_with_item_names(df):\n    tfidf_matrix = get_tfidf_matrix(df)\n    cosine_similarity_matrix = get_cosine_similarity_matrix(tfidf_matrix)\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_matrix = cosine_similarity_matrix.T\n    cosine_similarity_"
    ],
    "Pytorch": [
        "\noptim.param_groups[0]['lr'] = 0.001\n",
        "\noptim.lr = 0.001\n",
        "\noptim.param_groups[0]['lr'] = 0.0005\n",
        "\noptim.lr = 0.0005\n",
        "\nembedded_input = torch.nn.Embedding(len(word2vec.vectors), 100)\nembedded_input.weight.data = torch.from_numpy(word2vec.vectors)\n",
        "\n    # [Missing Code]\n    ",
        "\nx = x.detach().numpy()\n",
        "\nx = x.detach().cpu().numpy()\n",
        "\nx = x.numpy()\npx = pd.DataFrame(x)\n",
        "\nC = B[:, A_log]\n",
        "\nC = B[:, A_logical]\n",
        "\nC = B[:, A_log]\n",
        "\nC = B[:, A_log]\n",
        "\n    C = B[:, A_log]\n    ",
        "\nC = B[:, A_log]\n",
        "\nC = B[idx]\n",
        "\nx_tensor = torch.from_numpy(x_array)\n",
        "\nx_tensor = torch.from_numpy(x_array)\n",
        "\n    # [Missing Code]\n    ",
        "\nmask = torch.zeros(len(lens), len(lens[0]))\nfor i in range(len(lens)):\n    mask[i, :lens[i]] = 1\n",
        "\nmask = torch.zeros(len(lens), 10)\nfor i in range(len(lens)):\n    mask[i, 0:lens[i]] = 1\n",
        "\nmask = torch.zeros(len(lens), len(lens[0]))\nfor i in range(len(lens)):\n    mask[i, :lens[i]] = 1\n",
        "\n    mask = torch.zeros(len(lens), len(lens[0]))\n    for i in range(len(lens)):\n        mask[i, 0:lens[i]] = 1\n    ",
        "\nTensor_3D = torch.diag(Tensor_2D)\n",
        "\n    # [Missing Code]\n    ",
        "\nab = torch.stack((a,b),0)\n",
        "\nab = torch.stack((a,b),0)\n",
        "\n    # [Missing Code]\n    ",
        "\na[:, lengths:] = 0\n",
        "\na[ : , lengths : , : ]  = 2333\n",
        "\na[:, :lengths, :] = 0\n",
        "\na[ : , : lengths , : ]  = 2333\n",
        "\n# [Missing Code]\n",
        "\nnew_tensors = torch.stack(list)\n",
        "\n    # [Missing Code]\n    ",
        "\ntensor_of_tensors = torch.stack(list_of_tensors)\n",
        "\nresult = t[idx]\n",
        "\nresult = t[idx]\n",
        "\nresult = t[idx]\n",
        "\nresult = x[ids]\n",
        "\nresult = x[torch.arange(30), ids, :]\n",
        "\nresult = torch.gather(x, 1, ids)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\ny = torch.argmax(softmax_output, dim=1)\n",
        "\n    # [Missing Code]\n    ",
        "\n    # [Missing Code]\n    ",
        "\n# [Missing Code]\n",
        "\ncnt_equal = torch.sum(A == B)\n",
        "\ncnt_equal = np.sum(A == B)\n",
        "\ncnt_not_equal = (A != B).sum()\n",
        "\n    # [Missing Code]\n    ",
        "\ncnt_equal = torch.equal(A[:, -x:], B[:, -x:])\n",
        "\ncnt_not_equal = torch.sum(torch.abs(A-B) > 0)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\noutput = clean_input_spectrogram * mask\n",
        "\noutput = torch.where(mask == 0, clean_input_spectrogram, output)\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n    # [Missing Code]\n    ",
        "\nconfidence_score = torch.nn.functional.softmax(output, dim=1)\n",
        "\nresult = torch.cat([a, b], dim=1)\n",
        "\n    # [Missing Code]\n    ",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nresult = torch.bmm(data, W.unsqueeze(1))\n"
    ]
}