{
    "Pandas": [
        "df = df.iloc[List]\nprint(df)",
        "result = df.iloc[List]\nprint(result)",
        "\ndf['Qu1'] = df['Qu1'].replace(['apple', 'egg'], 'other')\ndf['Qu2'] = df['Qu2']\ndf['Qu3'] = df['Qu3'].replace(['apple', 'egg'], 'other')\nresult = df",
        "\ndf['Qu1'] = df['Qu1'].replace({'apple': 'other', 'potato': 'other', 'banana': 'other', 'cheese': 'cheese', 'egg': 'other'})\ndf['Qu2'] = df['Qu2'].replace({'sausage': 'other', 'banana': 'banana', 'apple': 'apple'})\ndf['Qu3'] = df['Qu3'].replace({'apple': 'other', 'potato': 'other', 'sausage': 'other', 'cheese': 'cheese', 'egg': 'other'})\nresult = df",
        "\nfor col in ['Qu1', 'Qu2', 'Qu3']:\n    if pd.value_counts(df[col]) >= 2:\n        df[col] = df[col].replace(to_replace=df[col].unique(), value='other')\n    else:\n        df[col] = df[col].astype(str)\nreturn result",
        "\ndf['Qu1'] = df['Qu1'].replace({'apple': 'other', 'potato': 'other', 'banana': 'other', 'cheese': 'cheese', 'egg': 'other'})\ndf['Qu2'] = df['Qu2'].replace({'sausage': 'sausage', 'banana': 'banana', 'apple': 'apple'})\ndf['Qu3'] = df['Qu3'].replace({'apple': 'other', 'potato': 'potato', 'sausage': 'other', 'cheese': 'cheese', 'egg': 'other'})\nresult = df",
        "\ndf['Qu1'] = df['Qu1'].replace({'apple': 'other', 'potato': 'other', 'banana': 'other', 'egg': 'other', 'cheese': 'cheese'})\ndf['Qu2'] = df['Qu2']\ndf['Qu3'] = df['Qu3'].replace({'apple': 'other', 'potato': 'other', 'sausage': 'other', 'cheese': 'cheese', 'potato': 'other', 'egg': 'other'})\nresult = df",
        "df['keep_if_dup'] = df['keep_if_dup'].astype('bool')\ndf = df.drop_duplicates(subset='url', keep='first')\ndf['keep_if_dup'] = df['keep_if_dup'].astype('str')\ndf = df.loc[df['keep_if_dup'] == 'Yes']\nprint(df)",
        "df = df.drop_duplicates(subset='url', keep='first')\ndf['drop_if_dup'] = df['drop_if_dup'].map({'Yes': True, 'No': False})\nresult = df[['id', 'url', 'drop_if_dup']]\nprint(result)",
        "df = df.drop_duplicates(subset='url', keep='first')\ndf['keep_if_dup'] = df['keep_if_dup'].map({'Yes': True, 'No': False})\ndf = df[df['keep_if_dup']]\ndf = df.drop_duplicates(subset='keep_if_dup', keep='first')\ndf = df.drop_duplicates(subset='url', keep='first')\nresult = df",
        "result = {}\nfor name, row in df.iterrows():\n    result[name] = {}\n    for col, value in zip(row['v1'], row['v2']):\n        result[name][col] = {row['v3']: value}\nprint(result)",
        "",
        "",
        "df['datetime'] = df['datetime'].dt.tz_localize('UTC').dt.tz_convert('UTC').dt.tz_localize('UTC').dt.strftime('%Y-%m-%d %H:%M:%S')",
        "",
        "\ndf['job'] = df['message'].str.extract('job: (.*?)', expand=False)\ndf['money'] = df['message'].str.extract('money: (.*?)', expand=False)\ndf['wife'] = df['message'].str.extract('wife: (.*?)', expand=False)\ndf['group'] = df['message'].str.extract('group: (.*?)', expand=False)\ndf['kids'] = df['message'].str.extract('kids: (.*?)', expand=False)\nresult = df.set_index('name')\nresult.columns = ['name', 'status', 'number', 'job', 'money', 'wife', 'group', 'kids']\nresult = result.astype({'job': 'str', 'money': 'str', 'wife': 'str', 'group': 'str', 'kids': 'str'})\nprint(result)",
        "df.loc[df['product'].isin(products), 'score'] *= 10\nresult = df\nprint(result)",
        "result['score'] = result['score'].where(result['product'].isin(products), result['score'] * 10)\nprint(result)",
        "result['score'] = result['score'].mask(result['product'].isin(products), result['score'] * 10)\nprint(result)",
        "df.loc[df['product'].isin(products), 'score'] = df.loc[df['product'].isin(products), 'score'].min() - df.loc[df['product'].isin(products), 'score'].max()\ndf.loc[df['product'].isin(products), 'score'] = (df.loc[df['product'].isin(products), 'score'] - df.loc[df['product'].isin(products), 'score'].min()) / (df.loc[df['product'].isin(products), 'score'].max() - df.loc[df['product'].isin(products), 'score'].min())\nresult = df\nprint(result)",
        "# [Missing Code]\n result['category'] = df.apply(lambda row: ''.join(sorted(list(row.values))), axis=1)\nprint(result)",
        "df['category'] = df.apply(lambda row: ''.join(sorted(list(row.values))), axis=1)\nresult['category'] = result['category'].astype('category')\nresult = result.reset_index()\nprint(result)",
        "df['category'] = df.apply(lambda row: [col for col in row if row[col] == 1], axis=1)\nresult['category'] = result['category'].apply(lambda x: list(set(x)))\nresult = result.drop(columns=['A', 'B', 'C', 'D'])\nprint(result)",
        "\ndf['Date'] = df['Date'].dt.to_period(\"M\")\ndf['Date'] = df['Date'].dt.strftime('%B-%Y')\n",
        "\ndf['Date'] = df['Date'].dt.to_period(\"M\")\ndf['Date'] = df['Date'].dt.strftime('%d-%B-%Y')\n",
        "\ndf['Date'] = df['Date'].dt.to_period(\"M\")\nresult = df\nprint(result)",
        "\ndf = df.shift(1, axis=0)\n# [Missing Code]\ndf.iloc[0, 0] = 72.4399\ndf.iloc[0, 1] = 126.0\n",
        "\ndf = df.shift(1, axis=0)\nresult = df\nprint(result)\n",
        "\ndf = df.shift(1, axis=0)\nresult = df\nprint(result)\n",
        "\ndf = df.iloc[[0, 1, 2, 4, 5], :]\ndf.columns = ['#1', '#2']\ndf.index = ['1980-01-01', '1980-01-02', '1980-01-03', '1980-01-04', '1980-01-05']\n# [Missing Code]\n",
        "\ndf.rename(columns={'HeaderA': 'HeaderAX'}, inplace=True)\n",
        "\ndf.columns = ['XHeaderA', 'XHeaderB', 'XHeaderC']\n",
        "\ndf.rename(columns={'HeaderA': 'HeaderAX', 'HeaderB': 'HeaderBX', 'HeaderC': 'HeaderCX', 'HeaderX': 'HeaderX'}, inplace=True)\n",
        "df.groupby('group').agg({\"group_color\": \"first\", \"val1\": \"mean\", \"val2\": \"mean\", \"val3\": \"mean\"})",
        "df.groupby('group').agg({\"group_color\": \"first\", \"val1\": \"sum\", \"val2\": \"sum\", \"val3\": \"sum\"})",
        "df.groupby('group').agg({\"group_color\": \"first\", \"val1\": \"sum\", \"val2\": \"mean\", \"val32\": \"mean\", \"val42\": \"mean\"})",
        "result = df.mean(axis=0, row_list=row_list, column_list=column_list)",
        "result = df.sum(axis=0, columns=column_list, index=row_list)",
        "result = df.sum(axis=0, columns=column_list).loc[row_list].drop_duplicates()",
        "\n# [Missing Code]\n",
        "result = df.isnull().sum().to_frame('null').reset_index()\nprint(result)",
        "\n# [Missing Code]\n",
        "df = df.iloc[[0,1]].reset_index(drop=True)\nprint(df)",
        "df = df.iloc[[0,1]].reset_index(drop=True)\nprint(df)",
        "df.apply(lambda x : (x[x.notnull()].values.tolist()+x[x.isnull()].values.tolist()),1)",
        "df.apply(lambda x : (x[x.isnull()].values.tolist()+x[x.notnull()].values.tolist()),1)",
        "df.apply(lambda x : (x[x.isnull()].values.tolist()+x[x.notnull()].values.tolist()),0)",
        "df_smaller = df.loc[df['value'] < thresh]\nresult = df_smaller.sum(axis=1)\nresult.index = ['X']\ndf = df.join(result)\nprint(df)",
        "result = df.loc[df['value'] < thresh].sum(axis=0) / len(df.loc[df['value'] < thresh].index)\nprint(result)",
        "result = df.loc[df['value'].isin([section_left, section_right]) == False, 'value'].mean()\nprint(result)",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "result = df.loc[df.idxmin():df.idxmin()+1].max()\nprint(result)",
        "result = df.idxmin().astype(int) - df.idxmax().astype(int)\nprint(result)",
        "\ndf['dt'] = df['dt'].dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes",
        "\ndf['dt'] = df['dt'].dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('D').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes",
        "\ndf['dt'] = df['dt'].astype('datetime64[D]')\ndf['dt'] = df['dt'].resample('D').ffill()\ndf['dt'] = df['dt'].resample('D').asfreq()\ndf['dt'] = df['dt'].astype('datetime64[ns]')\ndf['dt'] = df['dt'].dt.date\ndf['val'] = 233\nresult = df.set_index('dt')\nresult.sort_index(inplace=True)\nresult.reset_index(inplace=True)\nprint(result)",
        "\ndf['dt'] = df['dt'].dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes\ndf['dt'] = df['dt'].dt.to_timestamp('s').dt.date\ndf['dt'] = df['dt'].dt.to_period('D').cat.codes",
        "df['dt'] = df['dt'].dt.date\nresult = df.set_index('dt').unstack('user').fillna(method='ffill').stack().reset_index()\nprint(result)",
        "\ndf['unique_id'] = df['name'].astype(str).replace(df['name'], str(df.index+1))\ndf = df.set_index('unique_id')\ndf.reset_index(inplace=True)\nresult = df.to_dict('list')\nprint(result)\n",
        "df['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')\ndf['a'] = df['a'].astype('str')\ndf['a'] = df['a'].astype('int')",
        "    result = example_df.set_index('name').index.to_series().astype(str).str.cat(example_df.index.astype(str), sep='_')\n    example_df.index = result\n    return example_df",
        "\ndf['ID'] = df['name'] + df['a']\ndf = df.drop(['name', 'a'], axis=1)\ndf['ID'] = df['ID'].astype(int)\ndf = df.set_index('ID')\ndf = df.sort_index()\ndf = df.reset_index()\nresult = df[['ID', 'b', 'c']]\n",
        "result = df.pivot_table(index='user', columns='date', values='value', aggfunc=lambda x: (x, x['someBool'].astype(str)))\nprint(result)",
        "result = df.pivot_table(index='user', columns=['01/12/15', '02/12/15'], values=['someBool'])\nprint(result)",
        "result = df.pivot_table(index='user', columns='date', values='value', aggfunc=lambda x: x)\nprint(result)",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "df_filtered = df[df['c'] > 0.5][columns]\nresult = df_filtered.to_numpy()\nreturn result",
        "df_filtered = df[df.c > 0.5][locs]\nresult = df_filtered[columns].sum(axis=1)\nreturn result",
        "df = DataFrame(np.random.rand(4,5), columns = list('abcde'))\nlocs = [df.columns.get_loc(_) for _ in ['a', 'd']]\ndf = DataFrame(np.random.rand(4,5), columns = list('abcde'))\nlocs = [df.columns.get_loc(_) for _ in ['a', 'd']]\ndf = DataFrame(np.random.rand(4,5), columns = list('abcde'))\nlocs = [df.columns.get_loc(_) for _ in ['a', 'd']]\ndf = DataFrame(np.random.rand(4,5), columns = list('abcde'))",
        "\nfilter_dates = []\nfor index, row in df.iterrows():\n     if observation_time == 'D':\n        for i in range(1, observation_period):\n            filter_dates.append((index.date() + timedelta(days=i)))\ndf = df[~df.index.isin(filter_dates)]\n",
        "\nfilter_dates = []\nfor index, row in df.iterrows():\n     if observation_time == 'D':\n        for i in range(1, observation_period):\n            filter_dates.append((index.date() + timedelta(months=i)))\ndf = df[~df.index.isin(filter_dates)]\n",
        "\nfilter_dates = []\nfor index, row in df.iterrows():\n     if observation_time == 'D':\n        for i in range(1, observation_period):\n            filter_dates.append((index.date() + timedelta(months=i)))\ndf = df[~df.index.isin(filter_dates)]\n",
        "df = df.groupby(df.index // 3).mean()\nresult = df.reset_index()\nprint(result)",
        "df = df.groupby(df.index // 3).mean()\nresult = df.reset_index()\nprint(result)",
        "df = df.groupby(df.index // 4).mean()\nresult = df.reset_index()\nprint(result)",
        "result = df.groupby(df.index // 3).mean()\nprint(result)",
        "result = df.groupby(df.index // 3).agg({'col1': ['sum', 'mean']})\nprint(result)",
        "\ndf = df.resample('3S', on='col1').agg({'col1': ['sum', 'mean']})\nresult = df.iloc[:-1].groupby(df.index.astype('int') // 3).agg({'col1': ['sum', 'mean']})\nprint(result)",
        "df.fillna(method='ffill', inplace=True)\n",
        "\ndf.fillna(method='ffill', inplace=True)\n",
        "df['A'] = df['A'].fillna(method='ffill')\nresult = df\nprint(result)",
        "df ['numer'] = df.duration.replace(r'\\d.*' , r'\\d', regex=True, inplace = True)\ndf [ 'time']= df.duration.replace (r'\\.w.+',r'\\w.+', regex=True, inplace = True )\nresult = df\nprint(result)",
        "df ['numer'] = df.duration.replace(r'\\d.*' , r'\\d', regex=True, inplace = True)\ndf [ 'time']= df.duration.replace (r'\\.w.+',r'\\w.+', regex=True, inplace = True )\nresult = df\nprint(result)",
        "df ['numer'] = df.duration.replace(r'\\d.*' , r'\\d', regex=True, inplace = True)\ndf [ 'time']= df.duration.replace (r'\\.w.+',r'\\w.+', regex=True, inplace = True )",
        "df['time_day']= df.duration.replace(r'\\d.*' , r'\\d', regex=True, inplace=True)\ndf['time_day']*=df['number']\nresult = df\nprint(result)",
        "check = np.where([df[column] != df[column] for column in columns_check_list])\nresult = [False, False, False]",
        "check = np.where([df[column] == df[column] for column in columns_check_list])\nresult = [True if len(np.where(check)) == 0 else False for column in columns_check_list]\nprint(result)",
        "df.index.levels[1] = pd.to_datetime(df.index.levels[1])",
        "df.index.levels[1] = pd.to_datetime(df.index.levels[1])",
        "    dates = df['date'].to_numpy()\n    x = df['x'].to_numpy()\n    y = df['y'].to_numpy()\n    return np.array([dates, x, y])",
        "\n    df.index = pd.to_datetime(df.index)\n    df = df.swaplevel(0, 1, axis=1)\n    ",
        "df = pd.melt(df, id_vars='Country', value_name='Var1', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var2', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var3', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var4', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var5', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var6', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var7', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var8', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var9', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var10', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var11', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var12', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var13', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var14', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var15', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var16', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var17', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var18', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var19', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var20', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var21', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var22', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var23', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var24', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var25', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var26', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var27', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var28', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var29', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var30', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var31', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var32', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var33', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var34', var_name='year')",
        "df = pd.melt(df, id_vars='Country', value_name='Var1', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var2', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var3', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var4', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var5', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var6', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var7', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var8', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var9', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var10', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var11', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var12', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var13', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var14', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var15', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var16', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var17', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var18', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var19', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var20', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var21', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var22', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var23', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var24', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var25', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var26', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var27', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var28', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var29', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var30', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var31', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var32', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var33', var_name='year')\ndf = pd.melt(df, id_vars='Country', value_name='Var34', var_name='year')",
        "\nresult = df[df.abs().sum(axis=1) < 1]\nprint(result)",
        "\nresult = df[df.abs().gt(1).any(axis=1)]\nprint(result)",
        "\nresult = df[df.abs().gt(1).any(axis=1)]\nresult.columns = result.columns.map(lambda x: x.replace('Value_', ''))\nprint(result)",
        "\ndf['A'] = df['A'].replace('&AMP;', '&')\ndf['C'] = df['C'].replace('&AMP;', '&')\n# [Missing Code]\n",
        "\ndf['A'] = df['A'].replace('&LT;', '<')\ndf['C'] = df['C'].replace('&LT;', '<')\nresult = df\nprint(result)\n",
        "\n # [Missing Code]\n ",
        "\ndf['A'] = df['A'].replace('&AMP;', '&''<''>')\ndf['A'] = df['A'].replace('&LT;', '&''<''>')\ndf['A'] = df['A'].replace('&GT;', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')\ndf['A'] = df['A'].str.replace('&', '&''<''>')",
        "\ndf['A'] = df['A'].replace('&AMP;', '&')\ndf['C'] = df['C'].replace('&AMP;', '&')\nresult = df\nprint(result)\n",
        "\nname_df['first_name'] = name_df['name'].apply(lambda x: x.split(' ', 1)[0])\nname_df['last_name'] = name_df['name'].apply(lambda x: x.split(' ', 1)[1] if len(x.split(' ', 1)) > 1 else None)\nresult = name_df\nprint(result)",
        "\nname_df['1_name'] = name_df['name'].apply(lambda x: validate_single_space_name(x))\nname_df['2_name'] = name_df['name'].apply(lambda x: x if x is not None else '')\nresult = name_df\nprint(result)",
        "\ndf['name'] = df['name'].apply(lambda x: validate_single_space_name(x))\ndf['first_name'] = df['name'].str.split(' ', n=1, expand=True)[0]\ndf['middle_name'] = df['name'].str.split(' ', n=1, expand=True)[1]\ndf['last_name'] = df['name'].str.split(' ', n=2, expand=True)[1]\nresult = df\nprint(result)",
        "result = df1.set_index('Timestamp').join(df2.set_index('Timestamp'), how='left')",
        "result = df1.merge(df2, on='Timestamp', how='left')\nprint(result)",
        "df['state'] = df.apply(lambda row: row['col1'] if (row['col2'] <= 50 and row['col3'] <= 50) else max(row['col1'], row['col2'], row['col3']), axis=1)\nresult = df\nprint(result)",
        "\ndf['state'] = df.apply(lambda row: 125 if row['col2'] > 50 and row['col3'] > 50 else row['col1'] + row['col2'] + row['col3'], axis=1)\nresult = df\nprint(result)",
        "\nfor index, row in df.iterrows():\n    if not row[\"Field1\"].isnumeric():\n        result.loc[index, \"Field1\"] = row[\"Field1\"]\nprint(result)",
        "\nfor index, row in df.iterrows():\n    if row[\"Field1\"].isnumeric():\n        result.loc[index, \"Field1\"] = int(row[\"Field1\"])\nprint(result)",
        "\nfor index, row in example_df.iterrows():\n    if not row[\"Field1\"].isnumeric():\n        result.append(row[\"Field1\"])\nreturn result",
        "result['val1'] = result['val1'] / result['val1'].sum()\nresult['val2'] = result['val2'] / result['val2'].sum()\nresult['val3'] = result['val3'] / result['val3'].sum()\nresult['val4'] = result['val4'] / result['val4'].sum()\nprint(result)",
        "\n",
        "df.loc[test]",
        "df.loc[test]",
        "df = df.loc[~df.index.isin(test),:]",
        "df.loc[test]",
        "nearest_neighbour = df.groupby('car')['car'].transform('nearest')\ndf['nearest_neighbour'] = nearest_neighbour\ndf['euclidean_distance'] = df.apply(lambda x: dist(x['x'], x['y'], x['nearest_neighbour']['x'], x['nearest_neighbour']['y']), axis=1)\ndf = df.groupby(['time', 'car']).agg({'euclidean_distance': 'mean'})\nprint(df)\n",
        "df['farthest_neighbour'] = df.groupby('car')['car'].transform('max')\ndf['euclidean_distance'] = df.groupby(['time', 'car', 'farthest_neighbour'])['x'].apply(lambda x: np.sqrt(np.sum(np.square(x - x.shift(1))))).fillna(0)\ndf = df.set_index(['time', 'car', 'farthest_neighbour'])\ndf['average_distance'] = df['euclidean_distance'].groupby(level=['time']).mean()\ndf = df.reset_index()\nresult = df\nprint(result)",
        "cols = [df.keywords_0, df.keywords_1, df.keywords_2, df.keywords_3]\ndf[\"keywords_all\"] = df[\"keywords_all\"].apply(lambda cols: \",\".join(cols), axis=1)\nresult = df\nprint(result)",
        "cols = [df.keywords_0, df.keywords_1, df.keywords_2, df.keywords_3]\ndf[\"keywords_all\"] = df[\"keywords_all\"].apply(lambda cols: \"-\".join(cols), axis=1)\nresult = df\nprint(result)",
        "cols = [df.keywords_0, df.keywords_1, df.keywords_2, df.keywords_3]\ndf[\"keywords_all\"] = df[\"keywords_all\"].apply(lambda cols: \"-\".join(cols), axis=1)",
        "cols = [df.keywords_0, df.keywords_1, df.keywords_2, df.keywords_3]\ndf[\"keywords_all\"] = df[\"keywords_all\"].apply(lambda cols: \"-\".join(cols), axis=1)\nresult = df\nprint(result)",
        "result = df.sample(int(len(df) * 0.2), random_state=0)\nresult['Quantity'] = result['Quantity'].fillna(0)\nprint(result)",
        "\nresult = df.sample(int(len(df) * 0.2), random_state=0)\nresult['ProductId'] = result['ProductId'].map(lambda x: 0 if x == 4 else x)\nresult = result.reset_index(drop=True)\nprint(result)\n",
        "\nresult = df.sample(n=0.2, random_state=0)\nresult['Quantity'] = result['Quantity'].mask(result['Quantity'] == 0)\nresult = result.reset_index(drop=True)\nprint(result)\n",
        "\nduplicate_bool = df.duplicated(subset=['col1','col2'], keep='first')\nduplicate = df.loc[duplicate_bool == True]\nduplicate['index_original'] = duplicate['col1'].astype(int)\nresult = duplicate\n",
        "result = df.loc[duplicate_bool == True].assign(index_original=df.index[duplicate_bool == True])\nprint(result)",
        "result['index_original'] = duplicate.index.values[0]\nreturn result",
        "duplicate_bool = df.duplicated(subset=['col1','col2', '3col'], keep='first')\nduplicate = df.loc[duplicate_bool == True]\nduplicate['index_original'] = duplicate['index']\nresult = duplicate",
        "duplicate_bool = df.duplicated(subset=['col1','col2'], keep='last')\nduplicate = df.loc[duplicate_bool == True]\nduplicate['index_original'] = duplicate.index.repeat(duplicate.duplicated(subset=['col1','col2']).sum())\nduplicate\n",
        "result = df.groupby(['Sp', 'Mt'])['count'].max()\nprint(result)",
        "result = df.groupby(['Sp', 'Mt'])['count'].max()\nprint(result)",
        "result = df.groupby(['Sp', 'Mt'])['count'].min()\nprint(result)",
        "result = df.groupby(['Sp', 'Value'])['count'].max()\nprint(result)",
        "df.query(\"Category==filter_list\")",
        "df.query(\"Category!=filter_list\")",
        "value_vars = [('A', 'B', 'E'), ('A', 'B', 'F'), ('A', 'C', 'G'), ('A', 'C', 'H'), ('A', 'D', 'I'), ('A', 'D', 'J')]\nresult = pd.melt(df, value_vars=value_vars)\nprint(result)",
        "\nvalue_vars = [(col1, col2, col3), (col1, col2, col4), (col1, col2, col5), (col1, col2, col6)]\nresult = df.melt(id_vars=['col1'], value_vars=value_vars)\n",
        "df['cumsum'] = df.groupby('id').cumsum(['val'])",
        "result['cumsum'] = result['val'].cumsum()",
        "df['cumsum'] = df.groupby('id').cumsum(['val'])",
        "df['cummax'] = df.groupby('id').cummax(['val'])",
        "df['cumsum'] = df.groupby('id').cumsum(['val'])",
        "result = df.groupby('l')['v'].apply(lambda x: np.nan if np.isnan(x) else x.sum())",
        "result = df.groupby('r')['v'].apply(lambda x: np.nan if np.isnan(x) else x.sum())",
        "result = df.groupby('l')['v'].apply(lambda x: np.nan if np.isnan(x) else x.sum())\nprint(result)",
        "result = ['Column1 Column2 one-to-many',\n 'Column1 Column3 one-to-many',\n 'Column1 Column4 one-to-one',\n 'Column1 Column5 one-to-many',\n 'Column2 Column1 many-to-one',\n 'Column2 Column3 many-to-many',\n 'Column2 Column4 many-to-one',\n 'Column2 Column5 many-to-many',\n 'Column3 Column1 many-to-one',\n 'Column3 Column2 many-to-many',\n 'Column3 Column4 many-to-one',\n 'Column3 Column5 many-to-many',\n 'Column4 Column1 one-to-one',\n 'Column4 Column2 one-to-many',\n 'Column4 Column3 one-to-many',\n 'Column4 Column5 one-to-many',\n 'Column5 Column1 many-to-one',\n 'Column5 Column2 many-to-many',\n 'Column5 Column3 many-to-many',\n 'Column5 Column4 many-to-one']\nprint(result)",
        "result = ['Column1 Column2 many-2-many',\n 'Column1 Column3 many-2-many',\n 'Column1 Column4 one-2-one',\n 'Column1 Column5 many-2-many',\n 'Column2 Column1 many-2-one',\n 'Column2 Column3 many-2-many',\n 'Column2 Column4 many-2-one',\n 'Column2 Column5 many-2-many',\n 'Column3 Column1 many-2-one',\n 'Column3 Column2 many-2-many',\n 'Column3 Column4 many-2-one',\n 'Column3 Column5 many-2-many',\n 'Column4 Column1 one-2-one',\n 'Column4 Column2 many-2-many',\n 'Column4 Column3 many-2-many',\n 'Column4 Column5 many-2-many',\n 'Column5 Column1 many-2-one',\n 'Column5 Column2 many-2-many',\n 'Column5 Column3 many-2-many',\n 'Column5 Column4 many-2-one']\nprint(result)",
        "result = df.apply(lambda x: {'Column1': 'one-to-many', 'Column2': 'many-to-one', 'Column3': 'many-to-one', 'Column4': 'one-to-one', 'Column5': 'many-to-one'}, axis=1)\nprint(result)",
        "result = pd.DataFrame({\n    'Column1': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n    'Column2': [4, 3, 6, 8, 3, 4, 1, 4, 3],\n    'Column3': [7, 3, 3, 1, 2, 2, 3, 2, 7],\n    'Column4': [9, 8, 7, 6, 5, 4, 3, 2, 1],\n    'Column5': [1, 1, 1, 1, 1, 1, 1, 1, 1]},\n    columns=['Column1', 'Column2', 'Column3', 'Column4', 'Column5'],\n    index=['one-2-many', 'many-2-one', 'many-2-many', 'one-2-one', 'many-2-many'])\nprint(result)",
        "df = df[df['bank'].notnull()]\nprint(df)",
        "result = s.astype(str).str.replace(',','').astype(float)",
        "\nresult = df.groupby([\"Survived\", \"Has Family\"])[\"Survived\"].mean()\nprint(result)\n",
        "\nresult = df.groupby([\"Survived\", \"Parch\"])[\"SibSp\"].mean()\nprint(result)",
        "\nresult = df.groupby([\"Survived\", \"SibSp\", \"Parch\"])[\"Survived\"].mean()\nprint(result)",
        "df.groupby('cokey').sort('A')",
        "df.groupby('cokey').sort('A')",
        "df.columns = ['Caps', 'Lower', 'A', 'B']\nresult = df.set_index(['Caps', 'Lower', 'A', 'B'])\nprint(result)",
        "\ndf.columns = [('Caps', 'Middle', 'Lower')]\ndf = df.set_index(['Caps', 'Middle', 'Lower'])\ndf = df.sort_index()\ndf = df.reset_index()\ndf.columns = ['Caps', 'A', 'B']\nresult = df\nprint(result)\n",
        "df.columns = [('Caps', 'Middle', 'Lower')]\nresult = df.set_index(['Caps', 'Middle', 'Lower'])\nprint(result)",
        "result = pd.DataFrame(someTuple, columns=['birdType', 'birdCount'])\nprint(result)",
        "\na                 \n",
        "\nb                 \n",
        "\ndf['softmax'] = df['b'].apply(lambda x: np.exp(x) / np.sum(np.exp(df['b']), axis=1, keepdims=True))\ndf['min-max'] = df['b'].apply(lambda x: (x.min(), x.max()))\nresult = df\nprint(result)",
        "df = df.loc[:, df.sum(axis=1) != 0]\nresult = df.reset_index(drop=True)\nprint(result)",
        "\nresult = df.loc[:, df.sum(axis=1) == 0]\nresult = result.drop(columns=['A','B'])\nresult = result.reset_index(drop=True)\n",
        "\ndf = df.loc[:, df.max(axis=1) != 2]\nresult = df.reset_index()\nprint(result)\n",
        "\ndf.loc[df.max() == 2, :] = 0\n",
        "s.sort_values(by=['index', 'value'], inplace=True)",
        "s.sort_values(by=['index', 'value'], inplace=True)",
        "\ndf = df[df['A'].astype(int) | df['A'].astype(float)]\n",
        "\nresult = df[df['A'].astype(str)]\n",
        "result = df.groupby(['Sp', 'Mt'])['count'].max()\nprint(result)",
        "result = df.groupby(['Sp', 'Mt'])['count'].max()\nprint(result)",
        "result = df.groupby(['Sp', 'Mt'])['count'].min()\nprint(result)",
        "result = df.groupby(['Sp', 'Value'])['count'].max()\nprint(result)",
        "df['Date'] = df['Member'].map(dict)\nprint(df)",
        "df['Date'] = df['Member'].map(dict)\nprint(df)",
        "\n for key, value in dict.items():\n     if key in df['Member']:\n         df.loc[df['Member'] == key, 'Date'] = value\n ",
        "df['Date'] = df['Member'].map(dict)\nprint(df)",
        "df1 = df.groupby([df['Date'].dt.year.rename('year'), df['Date'].dt.month.rename('month')]).agg({'count': 'sum'})\nprint(df1)",
        "df['Date'] = pd.to_datetime(df['Date'], format= '%d/%m/%y')\ndf['Count_d'] = df.Date.map(df.groupby('Date').size())\ndf['Count_m'] = df.groupby([df['Date'].dt.year, df['Date'].dt.month]).size()\ndf['Count_y'] = df.groupby([df['Date'].dt.year]).size()\ndf['Count_Val'] = df.groupby(['Date', 'Val']).size()\nresult = df\nprint(result)",
        "df['Date'] = pd.to_datetime(df['Date'], format= '%d/%m/%y')\ndf['Count_d'] = df.Date.map(df.groupby('Date').size())\ndf['Count_m'] = df.groupby(['Date'].dt.month).size()\ndf['Count_y'] = df.groupby(['Date'].dt.year).size()\ndf['Count_w'] = df.groupby(['Date'].dt.weekday).size()\ndf['Count_Val'] = df.groupby(['Date', 'Val']).size()\nresult = df\nprint(result)",
        "\nresult1 = df.loc[:, 'B'].eq(0).sum()\nresult2 = df.loc[:, 'B'].eq(0).sum()\n",
        "\nresult1 = df.groupby('Date')['B'].apply(lambda x: x.sum() if x.sum() % 2 == 0 else 0)\nresult2 = df.groupby('Date')['C'].apply(lambda x: x.sum() if x.sum() % 2 == 0 else 0)\n",
        "pd.pivot_table(df, values=['D','E'], rows=['B'], aggfunc=np.sum)\n",
        "result = pd.pivot_table(df, values=['D'], rows=['B'], aggfunc=np.sum)\nresult2 = pd.pivot_table(df, values=['E'], rows=['B'], aggfunc=np.mean)\nprint(result)\nprint(result2)",
        "result = pd.pivot_table(df, values=['D', 'E'], rows=['B'], aggfunc=lambda x: np.sum(x) if 'D' in x else np.mean(x))\nprint(result)",
        "pd.pivot_table(df, values=['D','E'], rows=['B'], aggfunc=lambda x: (np.max(x['D']), np.min(x['E'])))",
        "",
        "",
        "df = df.explode('var2')\nresult = df.to_dict('records')\nprint(result)",
        "def count_special_char(string):\n    special_char = 0\n    for i in range(len(string)):\n        if(string[i].isalpha()):\n            continue\n        else:\n            special_char = special_char + 1\n    return special_char\ndf[\"new\"] = df[\"str\"].apply(count_special_char)\nresult = df\nprint(result)",
        "def count_special_char(string):\n    special_char = 0\n    for i in range(len(string)):\n        if(string[i].isalpha()):\n            continue\n        else:\n            special_char = special_char + 1\n    return special_char\ndf[\"new\"] = df[\"str\"].apply(count_special_char)\nresult = df\nprint(result)",
        "df['fips'] = df['row'].str.split(' ', expand=True)[0]\ndf['row'] = df['row'].str.split(' ', expand=True)[1]\nresult = df",
        "df['fips'] = df['row'].str[:2]\ndf['row'] = df['row'].str[2:]\nresult = df",
        "df['fips'] = df['row'].str.split(' ', n=1, expand=True)[0]\ndf['medi'] = df['row'].str.split(' ', n=2, expand=True)[1]\ndf['row'] = df['row'].str.split(' ', n=3, expand=True)[2]\nresult = df",
        "result['2001'] = result['2001'].where(result['2001'] != 0, result['2001']).cumsum()\nresult['2002'] = result['2002'].where(result['2002'] != 0, result['2002']).cumsum()\nresult['2003'] = result['2003'].where(result['2003'] != 0, result['2003']).cumsum()\nresult['2004'] = result['2004'].where(result['2004'] != 0, result['2004']).cumsum()\nresult['2005'] = result['2005'].where(result['2005'] != 0, result['2005']).cumsum()\nresult['2006'] = result['2006'].where(result['2006'] != 0, result['2006']).cumsum()\nresult = result.set_index('Name')\nresult = result.T\nresult.columns = ['2001', '2002', '2003', '2004', '2005', '2006']\nprint(result)",
        "\ndf['2001'] = df['2001'].astype(float).fillna(0)\ndf['2002'] = df['2002'].astype(float).fillna(0)\ndf['2003'] = df['2003'].astype(float).fillna(0)\ndf['2004'] = df['2004'].astype(float).fillna(0)\ndf['2005'] = df['2005'].astype(float).fillna(0)\ndf['2006'] = df['2006'].astype(float).fillna(0)\ndf['2001'] = df['2001'].astype(float).fillna(0)\ndf['2002'] = df['2002'].astype(float).fillna(0)\ndf['2003'] = df['2003'].astype(float).fillna(0)\ndf['2004'] = df['2004'].astype(float).fillna(0)\ndf['2005'] = df['2005'].astype(float).fillna(0)\ndf['2006'] = df['2006'].astype(float).fillna(0)\ndf['2001'] = df['2001'].astype(float).fillna(0)\ndf['2002'] = df['2002'].astype(float).fillna(0)\ndf['2003'] = df['2003'].astype(float).fillna(0)\ndf['2004'] = df['2004'].astype(float).fillna(0)\ndf['2005'] = df['2005'].astype(float).fillna(0)\ndf['2006'] = df['2006'].astype(float).fillna(0)\ndf['2001'] = df['2001'].astype(float).fillna(0)\ndf['2002'] = df['2002'].astype(float).fillna(0)\ndf['2003'] = df['2003'].astype(float).fillna(0)\ndf['2004'] = df['2004'].astype(float).fillna(0)\ndf['2005'] = df['2005'].astype(float).fillna(0)\ndf['2006'] = df['2006'].astype(float).fillna(0)\ndf['2001'] = df['2001'].astype(float).fillna(0)\ndf['2002'] = df['2002'].astype(float).fillna(0)\ndf['2003'] = df['2003'].astype(float).fillna(0)\ndf['2004'] = df['2004'].astype(float).fillna(0)\ndf['2005'] = df['2005'].astype(float).fillna(0)\ndf['2006'] = df['2006'].astype(float).fillna(0)\ndf['2001'] = df['2001'].astype(float).fillna(0)\ndf['2002'] = df['2002'].astype(float).fillna(0)\ndf['2003'] = df['2003'].astype(float).fillna(0)\ndf['2004'] = df['2004'].astype(float).fillna(0)\ndf['2005'] = df['2005'].astype(float).fillna(0)\ndf['2006'] = df['2006'].astype(float).fillna(0)\ndf['2001'] = df['2001'].astype(float).fillna(0)\ndf['2002'] = df['2002'].astype(float).fillna(0)\ndf['2003'] = df['2003'].astype(float).fillna",
        "\ndf['2001'] = df['2001'].where(df['2001'] != 0, df['2001'])\ndf['2002'] = df['2002'].where(df['2002'] != 0, df['2002'])\ndf['2003'] = df['2003'].where(df['2003'] != 0, df['2003'])\ndf['2004'] = df['2004'].where(df['2004'] != 0, df['2004'])\ndf['2005'] = df['2005'].where(df['2005'] != 0, df['2005'])\ndf['2006'] = df['2006'].where(df['2006'] != 0, df['2006'])\ndf['2001'] = df['2001'].astype(float).cumsum()\ndf['2002'] = df['2002'].astype(float).cumsum()\ndf['2003'] = df['2003'].astype(float).cumsum()\ndf['2004'] = df['2004'].astype(float).cumsum()\ndf['2005'] = df['2005'].astype(float).cumsum()\ndf['2006'] = df['2006'].astype(float).cumsum()\nresult = df.set_index('Name')\nresult.to_csv('output.csv')",
        "\ndf['cum_avg'] = df.iloc[::-1].agg({'2001': 'mean', '2002': 'mean', '2003': 'mean', '2004': 'mean', '2005': 'mean', '2006': 'mean'}).iloc[::-1]\ndf['cum_avg'] = df['cum_avg'].mask(df['cum_avg'] == 0, df['cum_avg'].fillna(df['cum_avg'].mean()))\ndf = df.set_index('Name')\ndf = df.sort_index()\nresult = df\nprint(result)",
        "df['Label'] = (df['Close'] - df['Close'].shift(1) > 1)\ndf['Label'] = df['Label'].astype(int)\ndf['Label'][0] = 1\ndf['Label'] = df['Label'].astype(int)\nresult = df\nprint(result)",
        "\nimport pandas as pd\ndf = pd.DataFrame({'DateTime': ['2000-01-04', '2000-01-05', '2000-01-06', '2000-01-07', '2000-01-08'],\n                   'Close': [1460, 1470, 1480, 1480, 1450]})\ndf['label'] = df['Close'].diff().astype(int).replace(0, 1).replace(-1, -1)\nresult['label'] = df['label']\nprint(result)\n",
        "\n#     DateTime  Close  label\n",
        "df['Duration'] = df.departure_time.iloc[i+1] - df.arrival_time.iloc[i]",
        "df['Duration'] = df.departure_time.iloc[i+1] - df.arrival_time.iloc[i]",
        "df['Duration'] = df.departure_time.iloc[i+1] - df.arrival_time.iloc[i]",
        "df.groupby(['key1']).apply(lambda x: x['key2'].eq('one').sum())",
        "df.groupby(['key1']).apply(lambda x: x['key2'].eq('two').sum())",
        "df.groupby(['key1']).apply(lambda x: x[x['key2'].str.endswith(\"e\")].size())",
        "max_result = df.index.max()\nmin_result = df.index.min()\nprint(max_result,min_result)",
        "mode_result = df.value.mode()[0]\nmedian_result = df.value.median()\nprint(mode_result,median_result)",
        "df = df[(99 <= df['closing_price'] <= 101)]",
        "df = df[~(99 <= df['closing_price'] <= 101)]",
        "df1 = df.groupby([\"item\", \"otherstuff\"], as_index=False)[\"diff\"].min()",
        "",
        "df['SOURCE_NAME'] = df['SOURCE_NAME'].str.split('_', expand=True)[-1]\nresult = df\nprint(result)",
        "\n for i in range(len(strs)):\n    if strs[i].find('_') != -1:\n        strs[i] = strs[i][:strs[i].find('_')]\n    else:\n        strs[i] = strs[i]\n ",
        "df['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)",
        "df['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\ndf['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)",
        "df['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)",
        "print(result)",
        "print(result)",
        "print(result)",
        "groups = df.groupby(pd.cut(df.views, bins))\nresult = groups.username.value_counts()\nprint(result)",
        "groups = df.groupby(pd.cut(df.views, bins))\nresult = groups.username.value_counts()\nprint(result)",
        "groups = df.groupby(pd.cut(df.views, bins))\nresult = groups.username.value_counts()\nprint(result)",
        "\n",
        "\n",
        "",
        "result = df.text.str.cat(sep=', ')\nprint(result)",
        "\nimport pandas as pd\ndf = pd.DataFrame({'text': ['abc', 'def', 'ghi', 'jkl']})\ndf['text'].str.cat(sep='-')\n",
        "result = pd.concat([df1, df2], axis=0)\nprint(result)",
        "result = pd.concat([df1, df2], axis=0)\nresult['date'] = result['date'].map(lambda x: x.strftime('%d-%b-%Y'))\nresult = result.sort_values(['id', 'date'])\nprint(result)",
        "result = pd.concat([df1, df2], axis=0)\nresult = result.sort_values(by=['id', 'date'])\nresult = result.reset_index(drop=True)\nprint(result)",
        "result = pd.merge(C, D, how='outer', on='A')\nprint(result)",
        "result = pd.merge(C, D, how='outer', on='A')\nresult.loc[result['B_x'].isna(), 'B'] = result['B_y']\nprint(result)",
        "result = C.merge(D, how='outer', on='A')\nresult['dulplicated'] = result['A_x'] == result['A_y']\nresult = result.drop('A_x', axis=1).drop('A_y', axis=1)\nprint(result)",
        "df.groupby('user').agg(lambda x: x.tolist()).sort_values(by=['time', 'amount']).reset_index(drop=True)",
        "result = df.groupby('user')['time', 'amount'].apply(list).sort_values(by=['time', 'amount']).reset_index(drop=True)\nprint(result)",
        "df.groupby('user').agg(lambda x: x.tolist()).sort_values(['time', 'amount']).reset_index(drop=True)",
        "result = pd.DataFrame(series.values, index=series.index, columns=list('0123'))\nprint(result)",
        "result = pd.DataFrame({'name': ['file1', 'file2', 'file3'],\n                       '0': [1, 5, 9],\n                       '1': [2, 6, 10],\n                       '2': [3, 7, 11],\n                       '3': [4, 8, 12]})\nprint(result)",
        "# [Missing Code]\nresult = [col for col in df.columns if s in col and col.find(s) != -1]\nprint(result)",
        "# [Missing Code]\nresult = df[df.columns.str.contains(s, na=False, case=False)]\nprint(result)",
        "\n# [Missing Code]\n",
        "# [Missing Code]\ndf['code_0'] = df['codes'].apply(lambda x: x[0] if len(x) > 0 else np.nan)\ndf['code_1'] = df['codes'].apply(lambda x: x[1] if len(x) > 1 else np.nan)\ndf['code_2'] = df['codes'].apply(lambda x: x[2] if len(x) > 2 else np.nan)\nprint(result)",
        "# [Missing Code]\ndf['code_1'] = df['codes'].apply(lambda x: x[0] if len(x) > 0 else np.nan)\ndf['code_2'] = df['codes'].apply(lambda x: x[1] if len(x) > 1 else np.nan)\ndf['code_3'] = df['codes'].apply(lambda x: x[2] if len(x) > 2 else np.nan)\nprint(result)",
        "# [Missing Code]\ndf['codes'] = df['codes'].apply(pd.Series)\ndf = df.explode('codes')\ndf.columns = ['code_' + str(i+1) for i in range(len(df.columns))]\ndf = df.reset_index(drop=True)\nresult = df.to_dict('list')\nprint(result)",
        "ids = df.loc[0:index, 'User IDs'].values.tolist()\nresult = [item for sublist in ids for item in sublist]\nprint(result)",
        "\nresult = ''.join(str(x) for x in df.col1)\n",
        "ids = str(df.loc[0:index, 'User IDs'].values.tolist())\nresult = ''.join(ids)\nprint(result)",
        "result = df.groupby(df.Time.dt.floor('2 minutes')).mean()",
        "result = df.groupby(df.Time.dt.floor('3min')).mean()",
        "df['RANK'] = df.groupby('ID')['TIME'].rank(ascending=True)",
        "df['RANK'] = df.groupby('ID')['TIME'].rank(ascending=False)",
        "df['RANK'] = df.groupby('ID')['TIME'].rank(ascending=False)",
        "df[filt]",
        "df[filt]",
        "result = df.loc[0].equals(df.loc[8])\nprint(result)",
        "df.loc[0, \"c2\"] = np.nan\ndf.loc[0, \"c5\"] = np.nan\ndf.loc[8, \"c2\"] = np.nan\ndf.loc[8, \"c5\"] = np.nan\nresult = df.loc[0, \"c2\"] == df.loc[8, \"c2\"] and df.loc[0, \"c5\"] == df.loc[8, \"c5\"]\nprint(result)",
        "result = df.loc[0].dropna().diff(df.loc[8].dropna()).tolist()\nprint(result)",
        "result = [(nan, 18.0), (nan, 18.0), (17.0, 16.0), (16.0, nan), (0.0, nan)]",
        "ts = pd.Series(df['Value'], index=df['Date'])",
        "# [Missing Code]\n result = df.stack().reset_index(level=1, drop=True)\nprint(result)",
        "result = df.stack().reset_index(level=1, drop=True)\nprint(result)",
        "df['dogs'] = df['dogs'].round(2)",
        "df['dogs'] = df['dogs'].round(2)\ndf['cats'] = df['cats'].round(2)\nresult = df\nprint(result)",
        "df['Sum'] = df[list_of_my_columns].sum(axis=1)",
        "df['Avg'] = df[list_of_my_columns].mean(axis=1)",
        "df['Avg'] = df[list_of_my_columns].mean(axis=1)",
        "df = df.sort_index(axis=1, level=1, ascending=True)",
        "df.sort_index(axis=1, level=1, inplace=True)",
        "df = df[(df.index != '2020-02-17') & (df.index != '2020-02-18')]",
        "df['Day_of_week'] = df['Date'].dt.day_name()\ndf['Date'] = df['Date'].dt.strftime('%d-%b-%Y')\ndf = df.set_index('Date')\nresult = df.T.reset_index()",
        "result = df.filter(lambda x: x > 0.3)\nprint(result)",
        "result = df.filter(lambda x: x > 0.3).values\nprint(result)",
        "df.columns[-1] = 'Test'",
        "df.columns[0] = 'Test'",
        "\nfrequent = df.apply(lambda x: x.value_counts().index[0], axis=1)\nfreq_count = df.apply(lambda x: x.value_counts().index[1], axis=1)\nresult['frequent'] = frequent\nresult['freq_count'] = freq_count\nprint(result)",
        "\ndf['frequent'] = df.apply(lambda row: row.max(), axis=1)\ndf['freq_count'] = df['frequent'].value_counts().index.to_series()\nresult = df\nprint(result)",
        "\ndf['frequent'] = df.apply(lambda row: list(set(row.values)), axis=1)\ndf['freq_count'] = df.groupby(['frequent']).size().reset_index(name='freq_count')\nresult = df\nprint(result)",
        "res = df.groupby([\"id1\",\"id2\"])[\"foo\",\"bar\"].mean()",
        "res = df.groupby([\"id1\",\"id2\"])[\"foo\",\"bar\"].mean()",
        "df_c = pd.merge(df_a, df_b, on='EntityNumber', how='left')\nresult = df_c[['EntityNum', 'foo', 'a_col']]\nprint(result)",
        "df_c = pd.merge(df_a, df_b, on='EntityNumber', how='left')\nresult = df_c[['EntityNum', 'foo', 'b_col']]\nprint(result)"
    ],
    "Numpy": [
        "result = a.shape\nprint(result)",
        "x = x.astype(float)\nx = x.dropna()\nprint(x)",
        "x[np.isnan(x)] = np.inf\nprint(x)",
        "\nresult = [item for item in x if item != np.nan]\n",
        "b = np.zeros((len(a), 4))\nb[np.arange(len(a)), a] = 1\nprint(b)",
        "b = np.zeros((len(a)+1,), dtype=np.uint8)\nb[np.arange(len(a)), a] = 1\nprint(b)",
        "b = np.zeros((len(a)+1, 5))\nb[np.arange(len(a)), a] = 1\nprint(b)",
        "",
        "\nb = np.zeros((len(a), len(a[0])), dtype=np.uint8)\nfor i in range(len(a)):\n    for j in range(len(a[0])):\n        if a[i][j] == 1:\n            b[i][j] = 1\n",
        "result = np.percentile(a, p)\nprint(result)",
        "B = A.reshape((-1, ncol))",
        "B = np.reshape(A, (nrow, nrow))",
        "B = A.reshape((-1, ncol))",
        "B = np.reshape(A, (ncol, -1))",
        "\nresult = np.roll(a, shift, axis=0)\n",
        "result = np.roll(a, shift, axis=1)",
        "result = np.roll(a, shift, axis=0)\nprint(result)",
        "\nr_old = np.random.randint(3, size=(100, 2000)) - 1\nr_new = r_old\n",
        "\nresult = np.argmax(a, axis=1)\n",
        "\nresult = a.argmin(axis=1)\n",
        "\nresult = np.argmax(a, axis=1)\n",
        "\nresult = np.argmax(a, axis=1)\n",
        "\nresult = a.argmax(axis=1)\n",
        "\nresult = np.argmax(a, axis=1)\n",
        "\nimport numpy as np\na = np.array([[np.nan, 2., 3., np.nan],\n\t\t[1., 2., 3., 9]])\nz = np.isnan(a)\na = a[~z]\nprint(a)\n",
        "\na = a[~np.isnan(a).any(axis=1)]\n",
        "result = np.array(a)",
        "",
        "result = np.moveaxis(a, permutation, 0)\nprint(result)",
        "result = np.unravel_index(np.argmin(a), a.shape)\nprint(result)",
        "result = np.unravel_index(np.argmax(a), a.shape)\nprint(result)",
        "result = np.unravel_index(np.argmin(a, axis=None), a.shape)\nprint(result)",
        "result = np.sin(degree) * np.cos(degree)",
        "result = np.cos(degree)",
        "if np.sin(number) > 0:\n    result = 0\nelse:\n    result = 1\n",
        "result = np.rad2deg(np.arcsin(value))\nprint(result)",
        "result = np.pad(A, (length - len(A)), 'constant', constant_values=0)\nprint(result)",
        "result = np.pad(A, (length - len(A)), 'constant', constant_values=0)\nprint(result)",
        "",
        "result = np.power(a, power)\nreturn result",
        "result = (numerator // denominator, denominator)\nprint(result)",
        "result = (numerator // denominator, denominator)\nreturn result",
        "result = (numerator // denominator, denominator)\nprint(result)",
        "result = np.array([np.mean(a), np.mean(b), np.mean(c)])\nprint(result)",
        "result = np.maximum(a, b)\nresult = np.maximum(result, c)\nprint(result)",
        "result = a[np.diag_indices(a.shape[0])]",
        "diagonal = np.diag_indices(a.shape[0]-1, a.shape[1]-1)\nresult = a[diagonal]\nprint(result)",
        "result = np.diag(a.T)\nprint(result)",
        "result = np.diag(a.T)\nprint(result)",
        "\nresult = []\nfor i in range(len(X)):\n    for j in range(len(X[i])):\n        result.append(X[i][j])\n",
        "\nresult = []\nfor i in range(r):\n    for j in range(c):\n        result.append(X[i, j])\n",
        "\nresult = []\nfor i in range(r):\n    for j in range(c):\n        result.append(X[i][j])\n",
        "\nresult = []\nfor i in range(r):\n    for j in range(c):\n        result.append(X[i, j])\n",
        "",
        "\nresult = a[:, col] * multiply_number\nresult = np.cumsum(result)\n",
        "\nresult = a[row] * multiply_number\ncumulative_sum = np.cumsum(result)\n",
        "\nresult = a[row] / divide_number\nresult *= a[row]\n",
        "result = np.linalg.matrix_rank(a)\nprint(result)",
        "\nfor i in range(a.shape[0]):\n    result = a.shape[0]\n",
        "p_value = scipy.stats.ttest_2tailed(a, b, equal_var=False)",
        "\n# Calculate the mean and standard deviation for each sample\nmean_a, std_a = np.mean(a), np.std(a)\nmean_b, std_b = np.mean(b), np.std(b)\n# Calculate the weighted sum of squares\nwss = (mean_a - mean_b)**2 / (std_a**2 + std_b**2)\n# Calculate the t-statistic\nt_stat = (mean_a - mean_b) / np.sqrt(wss)\n# Calculate the p-value using scipy.stats\np_value = scipy.stats.t.sf(abs(t_stat), n_a - 1, n_b - 1)\nprint(p_value)\n",
        "\nt_stat, p_value = scipy.stats.ttest_2tailed(amean, avar, anobs, bmean, bvar, bnobs)\n",
        "output = A[np.in1d(A, B)]",
        "output = np.setdiff1d(A, B) + np.setdiff1d(B, A)\nprint(output)",
        "sort_indices = np.argsort(a, axis=0)\nc = b[sort_indices]\nprint(c)",
        "sort_indices = np.argsort(a, axis=0)\nc = b[sort_indices]\nprint(c)",
        "sort_indices = np.argsort(a, axis=0)\nc = b[sort_indices]\nprint(c)",
        "result = np.sort(b, axis=0, order=np.argsort(a))",
        "\na[:, 2] = 0\n",
        "\na = np.delete(a, 1, axis=0)\n",
        "\na = np.delete(a, 0, 1)\na = np.delete(a, 1, 2)\n",
        "\n result = a[:, ~np.isin(np.arange(a.shape[1]), del_col)]\n ",
        "a[pos] = element",
        "a[pos] = element",
        "a[pos] = element\nreturn a",
        "a[pos[0]] = element[0]\na[pos[1]] = element[1]\nprint(a)",
        "c = np.array(array_of_arrays, copy=True) # Does not work",
        "result = np.all(a == a[np.newaxis, :])\n",
        "result = np.all(a[:, np.newaxis] == a)\n",
        "\n    result = np.all(a == a[0])\n    ",
        "result = np.sum(np.array([simpson_rule(x, y, (cosx)^4 + (siny)^2) for x in x for y in y]))\nprint(result)",
        "",
        "result = np.cumsum(x)\n",
        "result = np.interp(eval, grades, ecdf(grades))",
        "\nlow = np.argmin(ecdf(grades) < threshold)\nhigh = np.argmax(ecdf(grades) < threshold)\n",
        "nums = np.random.choice([0, 1], size=size, p=[one_ratio, 1-one_ratio])\n",
        "a_np = a.numpy()\n",
        "\na_pt = torch.from_numpy(a)\n",
        "a_np = a.numpy()\n",
        "\na_tf = tf.convert_to_tensor(a)\n",
        "",
        "\nresult = np.argsort(a)\n",
        "\nresult = a.argsort()[-N:]\n",
        "A**n",
        "\nresult = np.array([[a[i:i+2, j:j+2] for i in range(0, len(a), 2) for j in range(0, len(a[0]), 2)] for i in range(0, len(a), 2) for j in range(0, len(a[0]), 2)])\n",
        "result = np.array([[a[i:i+2, j:j+2] for i in range(len(a)) for j in range(len(a[0]))] for i in range(len(a)) for j in range(len(a[0]))])\nprint(result)",
        "\nresult = np.array([[a[i:i+2, j:j+2] for i in range(0, len(a), 2) for j in range(0, len(a[0]), 2)] for i in range(0, len(a), 2) for j in range(0, len(a[0]), 2)])\n",
        "\nresult = np.array([[a[i:i+patch_size, j:j+patch_size] for i in range(0, len(a), patch_size) for j in range(0, len(a[0]), patch_size)]])\n",
        "\n result = np.reshape(a, (h, w))\n ",
        "\nresult = np.array([[a[i:i+patch_size, j:j+patch_size] for i in range(0, len(a), patch_size) for j in range(0, len(a[0]), patch_size)]])\n",
        "result = a[:, low:high]\nprint(result)",
        "\nresult = a[low:high]\n",
        "result = a[:, low-1:high]\nprint(result)",
        "\n",
        "result = np.random.uniform(min, max, n)\n",
        "result = np.random.uniform(np.log(min), np.log(max), n)\nprint(result)",
        "    result = np.random.uniform(np.log(min), np.log(max), n)\n    return result",
        "B = A.copy()\nB[0] = a * A[0]\nfor t in range(1, len(A)):\n    B[t] = a * A[t] + b * B[t-1]\nprint(B)",
        "B[0] = a * A[0]\nB[1] = a * A[1] + b * B[0]\nB[t] = a * A[t] + b * B[t-1] + c * B[t-2]\n",
        "\nresult = np.empty((0,))\n",
        "\nresult = np.zeros((3, 0))\n",
        "result = np.sub2ind(dims, index[0], index[1], index[2])",
        "result = np.sub2ind(a, index)\nprint(result)",
        "df = pd.DataFrame(data=values, index=index, columns=columns)\nprint(df)",
        "result = np.cumsum(a[accmap])",
        "result = a[index].max()\nprint(result)",
        "result = np.cumsum(a[accmap])",
        "result = a[index]\nprint(result)",
        "\nfor i in range(len(x)):\n    for j in range(len(x[i])):\n        z[i][j] = elementwise_function(x[i][j], y[i][j])\n",
        "np.random.choice(lista_elegir, samples, probabilit)",
        "result = a[low_index:high_index, low_index:high_index]",
        "",
        "result = x[x.real == True]\nprint(result)",
        "\nbin_data = np.split(data, np.arange(0, len(data), bin_size))\nbin_data_mean = []\nfor i in range(0, len(bin_data), 1):\n    bin_data_mean.append(np.mean(bin_data[i]))\nprint(bin_data_mean)\n",
        "\nbin_data = np.split(data, np.arange(0, len(data), bin_size))\nbin_data_max = np.max(bin_data, axis=0)\nprint(bin_data_max)\n",
        "\nbin_data = np.array([[4, 2, 5, 6, 7],\n[5, 4, 3, 5, 7]])\nbin_data_mean = []\nfor i in range(0, len(bin_data), bin_size):\n    bin_data_mean.append(np.mean(bin_data[i:i+bin_size]))\nprint(bin_data_mean)\n",
        "\nbin_data = np.split(data, np.cumsum(np.ones(len(data)) // bin_size))\nbin_data_mean = [np.mean(bin) for bin in bin_data]\n",
        "\nbin_data = np.split(data, np.cumsum(np.ones(len(data))), axis=1)\nbin_data_mean = []\nfor i in range(len(bin_data)):\n    bin_data_mean.append(np.mean(bin_data[i], axis=0))\nprint(bin_data_mean)\n",
        "\nbin_data = np.array([[5, 6, 7],\n                    [3, 5, 7]])\nbin_data_mean = np.array([[6],\n                         [5]])\n",
        "result = np.interp(x, (x_min, x_max), (x_min, x_max))\n",
        "result = np.interp(x, np.linspace(x_min, x_max, N), np.linspace(0, 1, N))\n",
        "result = np.correlate(a, b, mode='full')\nprint(result)",
        "result = np.array(df.values)",
        "result = df.to_numpy()",
        "result = np.zeros((len(a), m), dtype=np.uint8)\nfor i in range(len(a)):\n    result[i, :m] = np.unpackbits(np.uint8(a[i]))\nprint(result)",
        "result = np.unpackbits(np.uint8(a), m)\nprint(result)",
        "\nresult = np.zeros((m, m))\nfor i in range(len(a)):\n    result[i] = np.unpackbits(np.uint8(a[i]))\n    result = np.exclusive_or(result, result.T)\n",
        "\nresult = (np.mean(a) - 3 * np.std(a), np.mean(a) + 3 * np.std(a))\n",
        "\n# Calculate the mean and standard deviation of the array\nmean = np.mean(a)\nstd = np.std(a)\n# Calculate the 2nd standard deviation\ntwo_sigma = std * 2\n# Calculate the start and end of the 2nd standard deviation interval\nresult = (mean - two_sigma, mean + two_sigma)\nprint(result)\n",
        "\ndef f(a = example_a):\n    mu = np.mean(a)\n    sigma = np.std(a)\n    three_sigma = mu - 3 * sigma\n    return (mu - three_sigma, mu + three_sigma)\n",
        "\nresult = np.abs(a - np.mean(a)) > np.sqrt(np.var(a)) * 2\n",
        "\nprob = np.percentile(masked_data, percentile)\n",
        "\na[zero_rows][zero_cols] = 0\na[zero_rows+1:][zero_cols] = 0\na[:, zero_cols+1:] = 0\n",
        "\na[zero_rows, zero_cols] = 0\n",
        "a[1] = 0\na[0] = 0",
        "",
        "mask = np.where(a == a.min(axis=1), True, False)\nprint(mask)",
        "\nresult = np.corrcoef(post, distance)\n",
        "",
        "\n X = np.reshape(Y, (M, N))\n ",
        "is_contained = number in a",
        "C = A[~np.isin(A, B)]",
        "C = np.array([1,1,2,8,8])",
        "C = A[np.where(A.isin(B))[0]]",
        "result = np.array(rankdata(a).astype(int))[::-1]\nprint(result)",
        "\nresult = np.argsort(a)[::-1].astype(int)\n",
        "result = np.array(rankdata(a).astype(int))[::-1]\nreturn result",
        "",
        "",
        "A[:][second][third]",
        "arr = np.zeros((20,)*4)",
        "X = np.array([[1, -2, 3, 6],\n              [4, 5, -6, 5],\n              [-1, 2, 5, 5],\n              [4, 5,10,-25],\n              [5, -2,10,25]])\nresult = np.array([LA.norm(v,ord=1) for v in X])\nprint(result)\n",
        "result = np.array([LA.norm(v, ord=2) for v in X])\nprint(result)",
        "result = np.array([LA.norm(v, ord=np.inf) for v in X])\nprint(result)",
        "conditions = [df['a'].str.contains(target)]\nchoices = ['XX']\ndf['page_type'] = np.select(conditions, choices, default=np.nan)\nprint(df)",
        "result = np.zeros((len(a), len(a)))\nfor i in range(len(a)):\n    for j in range(len(a)):\n        result[i][j] = np.linalg.norm(a[i] - a[j])\nprint(result)",
        "\nresult = np.zeros((len(a), len(a)))\nfor i in range(len(a)):\n    for j in range(len(a)):\n        result[i][j] = np.linalg.norm(a[i] - a[j])\n",
        "\nresult = np.zeros((len(a), len(a)))\nfor i in range(len(a)):\n    for j in range(i+1, len(a)):\n        result[i, j] = np.linalg.norm(a[i] - a[j])\n",
        "AVG = np.mean(NA)",
        "AVG = np.mean(NA, axis=0)",
        "AVG = np.mean(NA, axis=0)",
        "\nresult = np.unique(a[~np.isclose(a, 0)])\n",
        "\nresult = a.copy()\nresult[~np.isnan(result)] = np.unique(result[~np.isnan(result)])\nprint(result)\n",
        "df = pd.DataFrame({'lat': lat, 'lon': lon, 'val': val})\nprint(df)",
        "df = pd.DataFrame({'lat': lat, 'lon': lon, 'val': val})\nreturn df",
        "df = pd.DataFrame({'lat': lat, 'lon': lon, 'val': val})\ndf['maximum'] = df.apply(lambda row: max(row['lat'], row['lon'], row['val']), axis=1)\nprint(df)",
        "\nresult = np.lib.stride_tricks.as_strided(a, shape=(size[0], size[1], a.shape[1]), strides=((size[0] - 1) * size[1], size[1] * a.shape[1]))\n",
        "\nresult = np.lib.stride_tricks.as_strided(a, shape=(size[0], size[1], a.shape[1]), strides=((size[0] - 1) * size[1], size[1] * a.shape[1]))\n",
        "\nresult = np.mean(a)\n",
        "result = np.mean(a)\nreturn result",
        "\n# [Missing Code]\n",
        "\nresult = a[-1:, :]\n",
        "",
        "\nresult = any(np.all(c == a, axis=1) for a in CNTS)\n",
        "\nresult = intp.interp2d(x_new, y_new, a, kind='linear')\n",
        "df['Q_cum'] = np.cumsum(df.Q)",
        "i = np.diag(i)",
        "\na[np.triu_indices(a, k=1)] = 0\n",
        "result = pd.date_range(start, end, periods=n)\nprint(result)",
        "\nresult = np.where(x == a)[0]\nif result == -1:\n    result = np.where(y == b)[0]\n",
        "\nresult = []\nfor i in range(len(x)):\n    if x[i] == a and y[i] == b:\n        result.append(i)\n        if i < len(x) - 1 and x[i+1] == a:\n            result.append(i+1)\n        if i > 0 and x[i-1] == a:\n            result.append(i-1)\n",
        "result = np.polyfit(x, y, deg=2)\nprint(result)",
        "\nresult = np.polyfit(x, y, degree)\n",
        "temp_arr = [0,1,2,3]\nfor i in range(len(temp_arr)):\n    df.iloc[:, i] = df.iloc[:, i] - temp_arr[i]\nprint(df)",
        "result = np.einsum('ijk,jl->ilk', A, B)",
        "result = MinMaxScaler().fit_transform(a)\nprint(result)",
        "result = MinMaxScaler()\nresult.fit(arr)\nresult.transform(arr)",
        "\nresult = MinMaxScaler().fit_transform(a)\n",
        "\nmask = arr < -10\nmask2 = arr >= 15\nmask3 = mask ^ mask2\narr[mask] = 0\narr[mask3] = arr[mask3] + 5\narr[~mask2] = 30\n",
        "\nmask = arr_temp < n1\nmask2 = arr_temp < n2\nmask3 = mask ^ mask3\narr[mask] = 0\narr[mask3] = arr[mask3] + 5\narr[~mask2] = 30\n",
        "result = np.nonzero(s1 != s2)[0].shape[0]\nprint(result)",
        "result = np.isnan(np.diff(np.append(s1, np.nan), axis=0)).any()\nprint(result)",
        "result = np.array_equal(a, a)",
        "result = all(np.isnan(arr) for arr in a)\n",
        "result = np.pad(a, ((0, 93-41), (0, 13-13)), 'constant', constant_values=(0, 0))\nprint(result)",
        "result = np.pad(a, ((0, 93-41), (0, 13-12)), 'constant', constant_values=(0, 0))\nprint(result)",
        "\nresult = np.pad(a, (0, shape[0] - a.shape[0]), (0, shape[1] - a.shape[1]), 'constant', constant_values=(element, element))\n",
        "\nresult = np.zeros(shape)\nresult[:arr.shape[0], :arr.shape[1]] = arr\nreturn result\n",
        "\nresult = np.pad(a, (0, (shape[0] - a.shape[0]) // 2, (shape[1] - a.shape[1]) // 2), 'constant', constant_values=(0, 0))\n",
        "a.shape[0] / 3\n",
        "\n result = np.zeros((a.shape[0], a.shape[1]))\n for i in range(a.shape[0]):\n     for j in range(a.shape[1]):\n         result[i, j] = a[i, j, b[i, j]]\n ",
        "\n result = np.zeros((a.shape[0], a.shape[1]))\n for i in range(a.shape[0]):\n     for j in range(a.shape[1]):\n         result[i, j] = a[i, j, b[i, j]]\n ",
        "\n    [[ 0,  3,  6],\n     [ 8,  9, 13],\n     [13, 14, 19]]\n",
        "result = np.sum(a[b[:, 0], b[:, 1], b[:, 2]], axis=2)\nprint(result)",
        "result = np.sum(a[b[:, 0], b[:, 1], b[:, 2]])\nprint(result)",
        "x = df[:, 0]\ny = np.where(1 < x <= 4, df[:, 1], np.nan)\nresult = y.tolist()\nprint(result)",
        "\nresult = np.array([[0,1,1,1], [1,1,0,1], [0,0,1,1]])\n",
        "\nresult = A[A != 0]\n",
        "\nresult = np.array([[0, 0, 1, 2, 0],\n                   [1, 0, 0, 1, 0],\n                   [0, 0, 7, 1, 0],\n                   [0, 0, 0, 0, 0]])\n",
        "\nresult = []\nfor i in range(len(im)):\n    for j in range(len(im[i])):\n        if im[i][j] != 0:\n            result.append([im[i][j]])\n"
    ],
    "Matplotlib": [
        "\nfig, ax = plt.subplots()\nax.plot(x, y, 'o')\nax.set_title('x vs y')\nax.set_xlabel('x')\nax.set_ylabel('y')\nax.legend(['x-y'], loc='best')\n",
        "\nax = plt.gca()\nax.yaxis.set_minor_formatter(ticker.FormatStrFormatter('%.0f'))\nax.yaxis.set_minor_locator(ticker.MultipleLocator(1))\n",
        "plt.minorticks_on()",
        "plt.xaxis.set_minor_tick_params(which='both', numticks=10)",
        "\n",
        "\n",
        "\nplt.plot(x, y, 'o-', linewidth=0.5, markerfacecolor='none', markeredgecolor='black', markersize=10)\n",
        "\n",
        "ax.set_ylim(0, 40)",
        "\nplt.plot(x)\nplt.axvline(x=2, color='red', linestyle='--')\nplt.axvline(x=4, color='red', linestyle='--')\n",
        "\nplt.plot([0, 1], [0, 2])\n",
        "\nplt.plot([0, 1], [0, 2])\n",
        "\nsns.set_style(\"ticks\")\nsns.set_palette(\"muted\")\nfig, ax = plt.subplots(figsize=(10, 5))\ndf.plot(x=\"Height (cm)\", y=\"Weight (kg)\", kind=\"scatter\", ax=ax, s=100, c=\"Gender\")\nplt.show()\n",
        "\nsns.set_style(\"whitegrid\")\nsns.set_context(\"talk\", font_scale=1.2)\nfig, ax = plt.subplots(figsize=(10, 5))\nax.plot(x, y, \"o\", label=\"Random Data\")\nax.set_xlabel(\"x-axis\")\nax.set_ylabel(\"y-axis\")\nax.legend()\nplt.show()\n",
        "\n",
        "plt.plot(x, y, '+', markerfacecolor='red', markeredgewidth=7)",
        "plt.legend(fontsize=20)",
        "\n",
        "\nl.set_facecolor(\"white\")\n",
        "\nl.set_markeredgecolor(\"black\")\n",
        "(l,) = plt.plot(range(10), \"o-\", lw=5, markersize=30, color=\"red\")",
        "\n",
        "\n",
        "\nx_ticks = np.arange(0, 2 * np.pi, 2 * np.pi / 10)\nplt.xticks(x_ticks, x_ticks)\n",
        "\nplt.legend(handles=[sns.distplot(x, label=\"a\", color=\"0.25\"), sns.distplot(y, label=\"b\", color=\"0.25\")],\n           labels=[\"a\", \"b\"], loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
        "\n",
        "\nplt.imshow(H, cmap=plt.cm.gray)\nplt.show()\n",
        "plt.xlabel('X')\nplt.xlim(0, 2 * np.pi)",
        "\n",
        "\nmyTitle = \"Some really really long long long title I really really need - and just can't - just can't - make it any - simply any - shorter - at all.\"\n",
        "\ny = y[::-1]\n",
        "\nplt.xlim([0, 1.5])\n",
        "\n",
        "\nfig, ax = plt.subplots(1, 1, figsize=(10, 5))\nax.plot(x, 'b-', label='x')\nax.plot(y, 'r-', label='y')\nax.plot(z, 'g-', label='z')\nax.legend()\n",
        "\n",
        "\nx = np.arange(10)\ny = 2 * np.random.rand(10)\n",
        "\n",
        "\nax.plot(x, y, linestyle='dashed')\n",
        "\nfig, ax1 = plt.subplots(1, 2, sharex=True)\nax1[0].plot(x, y1)\nax1[1].plot(x, y2)\n",
        "\nfig, ax1 = plt.subplots(1, 2, figsize=(10, 5))\nax1[0].plot(x, y1, 'b', label='y1')\nax1[0].set_title('y1 vs x')\nax1[0].set_xlabel('x')\nax1[0].set_ylabel('y1')\nax1[0].legend()\nax1[1].plot(x, y2, 'r', label='y2')\nax1[1].set_title('y2 vs x')\nax1[1].set_xlabel('x')\nax1[1].set_ylabel('y2')\nax1[1].legend()\n# remove the frames from the subplots\nfor ax in ax1:\n    ax.spines['right'].set_visible(False)\n    ax.spines['top'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n",
        "\nplt.gca().axes.get_xaxis().set_label('')\n",
        "\nax = plt.gca()\nax.xaxis.set_tick_labels([])\n",
        "plt.xticks(np.arange(3, 5, 1))\nplt.grid(which='major', axis='y', linestyle='--')",
        "\nplt.yticks([3, 4])\nplt.yticks(np.arange(3, 5, 1), ['3', '4'])\nplt.grid(which='major', axis='y', linestyle='--', linewidth=0.5, color='gray')\n",
        "\nplt.yticks([3, 4])\nplt.yticks(np.arange(3, 5, 1), ['3', '4'])\nplt.xgrid(True, which='major', linestyle='-', linewidth=0.5, color='k')\nplt.xgrid(True, which='minor', linestyle='-', linewidth=0.5, color='k')\nplt.xlim(0, 10)\nplt.xlabel('x-axis')\nplt.ylabel('y-axis')\nplt.xticks([1, 2])\nplt.xticks(np.arange(1, 3, 1), ['1', '2'])\nplt.ylabel('y-axis')\nplt.show()\n",
        "\n",
        "\nplt.legend(loc=\"lower right\")\n",
        "\nfig, axes = plt.subplots(ncols=2, nrows=2, figsize=(8, 6), subplot_kw=dict(wspace=0.2, hspace=0.2))\naxes = axes.flatten()\nfor ax in axes:\n    ax.set_ylabel(r\"$\\ln\\left(\\frac{x_a-x_b}{x_a-x_c}\\right)$\")\n    ax.set_xlabel(r\"$\\ln\\left(\\frac{x_a-x_d}{x_a-x_e}\\right)$\")\nplt.show()\nplt.clf()\n",
        "plt.legend(['Y', 'Z'])",
        "\nax.invert_yaxis()\n",
        "\nfig, ax = plt.subplots()\nax.plot(x, y)\nax.set_xlabel('X')\nax.set_xticks(x)\nax.set_xticklabels(x)\nax.set_xlim(0, 10)\nax.set_ylim(0, 10)\nax.grid(True)\n",
        "\nplt.plot(x, y)\nplt.show()\n",
        "\n",
        "\nplt.plot(x, y)\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.xticks(x, x)\nplt.yticks(y, y)\nplt.show()\n",
        "\nsns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"reg\", color=\"green\")\n",
        "\nsns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"reg\", color=\"green\")\n",
        "\n",
        "\nfig, ax = plt.subplots(figsize=(10, 5))\nax.bar(df[\"celltype\"], df[\"s1\"], width=0.8, label=\"s1\")\nax.bar(df[\"celltype\"], df[\"s2\"], width=0.8, label=\"s2\")\nax.set_xticklabels(df[\"celltype\"], horizontal=True)\nax.set_ylabel(\"Value\")\nax.set_title(\"Bar Plot\")\nax.legend()\nplt.show()\n",
        "\nfig, ax = plt.subplots(figsize=(10, 5))\nax.bar(df[\"celltype\"], df[\"s1\"], width=0.8, align=\"center\", alpha=0.7)\nax.set_xticklabels(df[\"celltype\"], rotation=45)\nax.set_ylabel(\"s1\")\nax.set_xlabel(\"celltype\")\nplt.show()\n",
        "\nplt.plot(x, y)\nplt.xlabel('X', color='red')\nplt.xticks(x, x, color='red')\n",
        "\nplt.plot(x, y)\nplt.xlabel(\"X\")\nplt.plot(x, y, 'r')\n",
        "\nplt.plot(x, y)\nplt.gca().tick_params(axis='both', which='major', labelsize=10)\nplt.gca().xaxis.set_tick_direction('vertical')\n",
        "\nplt.plot([0.22058956, 0.33088437, 2.20589566])\nplt.axvline(x=0.22058956, color='r', linestyle='--')\nplt.axvline(x=0.33088437, color='r', linestyle='--')\nplt.axvline(x=2.20589566, color='r', linestyle='--')\n",
        "\n",
        "\n",
        "\nfig, ax = plt.subplots(2, 1, sharex=True, figsize=(10, 5))\nfor i in range(2):\n    ax[i].set_title(\"Y\")\n    ax[i].plot(x, y)\nplt.show()\n",
        "\nsns.set(style=\"whitegrid\", context=\"talk\", font_scale=1.2)\nsns.set_palette(\"muted\")\nfig, ax = plt.subplots(figsize=(10, 6))\nax.scatter(df[\"bill_length_mm\"], df[\"bill_depth_mm\"], marker=\".\", s=30, c=\"k\", alpha=0.7)\nax.set_xlabel(\"Bill Length (mm)\")\nax.set_ylabel(\"Bill Depth (mm)\")\nax.set_title(\"Bill Length vs. Bill Depth\")\nplt.show()\n",
        "\nfig, ax = plt.subplots()\nfor i in range(len(a)):\n    ax.scatter(a[i], b[i], c=c[i], marker='o', s=100)\nplt.xlabel('a')\nplt.ylabel('b')\nplt.title('Scatter plot of a over b')\nplt.show()\n",
        "\nfig, ax = plt.subplots()\nax.plot(x, y, label=\"y over x\")\nax.legend()\nax.set_title(\"y over x\")\n",
        "\nfig, ax = plt.subplots()\nax.plot(x, y, label=\"y over x\")\nax.legend(loc=\"best\", title=\"Legend\", title_fontweight=\"bold\")\n",
        "\n",
        "\nfig, ax1 = plt.subplots(1, 2, figsize=(10, 5))\nax1.set_title('First Subplot')\nax2 = ax1.twinx()\nax2.set_title('Second Subplot')\n",
        "\nfig, ax = plt.subplots(1, 1, sharex=True)\nax.hist(x, bins=bins, alpha=0.5, label='x')\nax.hist(y, bins=bins, alpha=0.5, label='y')\nplt.legend()\nplt.show()\n",
        "\nfig, ax = plt.subplots(1, 1, sharex=True)\n# Create a grid with 10 bins for each variable\nx_bins = np.linspace(min(x), max(x), 10)\ny_bins = np.linspace(min(y), max(y), 10)\n# Create the histograms\nhist_x, bins_x = np.histogram(x, bins=x_bins)\nhist_y, bins_y = np.histogram(y, bins=y_bins)\n# Plot the histograms\nax.bar(bins_x, hist_x, align='center', alpha=0.5, color='r')\nax.bar(bins_y, hist_y, align='center', alpha=0.5, color='b')\n# Add the x-axis labels\nax.set_xticks(bins_x)\nax.set_xticklabels(np.arange(len(x_bins)))\n# Add the y-axis labels\nax.set_yticks(bins_y)\nax.set_yticklabels(np.arange(len(y_bins)))\n# Set the plot title\nax.set_title('Grouped Histograms of x and y')\n",
        "\nplt.plot([a, c], [b, d])\nplt.xlim(0, 5)\nplt.ylim(0, 5)\n",
        "\n",
        "\nfig, ax = plt.subplots(1, 1, figsize=(10, 5))\nfor i in range(x.shape[1]):\n    ax.plot(x[:, i], label=f\"{i}\")\nax.legend()\nax.set_title(\"Individual Columns of x\")\nplt.show()\n",
        "\nfig, ax = plt.subplots(1, 2, figsize=(10, 5))\nax[0].plot(x, y)\nax[0].set_title('Y over X')\nax[1].plot(a, z)\nax[1].set_title('Z over A')\nplt.suptitle('Y and Z')\n",
        "\npoints = [(3, 5), (5, 10), (10, 150)]\nfig, ax = plt.subplots()\nax.plot(points, 'b-')\nax.set_xscale('linear')\nax.set_yscale('log')\nplt.show()\n",
        "\nfig, ax = plt.subplots()\nax.plot(x, y)\nax.set_title('Plot of y over x', fontsize=20)\nax.set_xlabel('x', fontsize=18)\nax.set_ylabel('y', fontsize=16)\n",
        "\nax.plot(x, y)\nax.set_xticks(x)\nax.set_xticklabels(np.arange(1, 11))\n",
        "\n",
        "\nfig, ax = plt.subplots()\nax.plot(x, y)\nax.set_xscale('log')\nax.set_yscale('log')\nax.set_xlim(1, 1000)\nax.set_ylim(1, 1000)\nax.set_xticks([1, 10, 100, 1000])\nax.set_yticks([1, 10, 100, 1000])\nax.set_xticklabels(['1', '10', '100', '1000'])\nax.set_yticklabels(['1', '10', '100', '1000'])\nplt.show()\n",
        "\nfig, ax = plt.subplots(1, 4, figsize=(10, 4))\nfor i in range(4):\n    ax[i].plot(df.index, df[\"A\"])\n    ax[i].plot(df.index, df[\"B\"])\n    ax[i].plot(df.index, df[\"C\"])\n    ax[i].plot(df.index, df[\"D\"])\n    ax[i].set_title(f\"Line Plot {i+1}\")\n    ax[i].grid(True)\n    ax[i].set_xlabel(\"Date\")\n    ax[i].set_ylabel(\"Value\")\n    ax[i].scatter(df.index, df[\"A\"], color=\"red\")\n    ax[i].scatter(df.index, df[\"B\"], color=\"blue\")\n    ax[i].scatter(df.index, df[\"C\"], color=\"green\")\n    ax[i].scatter(df.index, df[\"D\"], color=\"yellow\")\nplt.show()\n",
        "\n",
        "\nplt.plot(x, y, 'o', alpha=0.5, linewidth=2)\n",
        "\nfig, ax1 = plt.subplots(1, 2, figsize=(10, 5))\nax1[0].plot(x, y)\nax1[1].plot(z, a)\nax1[0].set_title('y')\nax1[1].set_title('a')\nax1[0].legend(loc='upper left', prop={'size': 12})\nax1[1].legend(loc='upper left', prop={'size': 12})\nplt.show()\n",
        "\n",
        "\nax.set_xticklabels(range(1, 10), minor=False)\nax.set_xticklabels(range(1, 10), minor=True, fontsize=8)\nax.set_xticklabels(range(1, 10), minor=True, fontsize=8, ha='right')\nax.set_xticklabels(range(1, 10), minor=True, fontsize=8, ha='right', rotation='vertical')\nax.set_xticklabels(range(1, 10), minor=True, fontsize=8, ha='right', rotation='vertical', label='second')\n",
        "\nplt.plot(x, y)\nplt.legend([\"y over x\"], loc=\"best\", fontsize=12)\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.title(\"y over x\")\nplt.show()\n",
        "\nxticks = [2.1, 3, 7.6]\nplt.xticks(range(0, 10, 2), xticks)\n",
        "\nplt.xticks(x, y, rotation=60, horizontalalignment='left')\n",
        "\nplt.gca().set_yticklabels(np.rot90(y, k=0, p=1), ha='right', va='top')\n",
        "\nplt.xticks(x, y, fontsize=10, rotation=45, ha='right', alpha=0.5)\n",
        "\nplt.xmargin(0)\nplt.ymargin(0.1)\n",
        "plt.ylim(0, 9)",
        "\nfig, ax = plt.subplots(1, 2, figsize=(10, 5))\nfor i in range(2):\n    ax[i].plot(x, y)\nplt.title(\"Figure\")\n",
        "\nfig, ax = plt.subplots()\ndf.plot(x='Type A', y='Type B', ax=ax)\nax.set_xlabel('X')\nax.set_ylabel('Y')\n",
        "\nplt.scatter(x, y, marker='v', hatch='/', s=100)\n",
        "\nplt.scatter(x, y, marker='o', hatch='/')\n",
        "\nplt.scatter(x, y, marker='*')\n",
        "\n",
        "\nxlim = 1\nylim = 4\nplt.imshow(data, cmap='Reds', extent=[xlim, 5, ylim, 1])\n",
        "plt.stem(x, y, orientation='horizontal')",
        "\nfig, ax = plt.subplots(figsize=(10, 5))\nbar_width = 0.2\nfor key, value in d.items():\n    x_pos = bar_width * key\n    rect = plt.Rectangle((x_pos, 0), bar_width, value, facecolor=c[key])\n    ax.add_patch(rect)\nplt.show()\n",
        "\nplt.axvline(x=3, color='k', linestyle='--')\nplt.text(3, 1.05, 'cutoff', fontsize=12, horizontalalignment='center')\nplt.legend()\n",
        "\nfig, ax = plt.subplots(1, 1, polar=True)\nax.bar(labels, height, bottom=0, align='center')\nplt.show()\n",
        "\n",
        "\n",
        "\nplt.plot(x, y)\nplt.minorticks_on()\nplt.grid(which='minor', linestyle='dashed', color='gray')\nplt.grid(which='major', linestyle='none', color='none')\n",
        "\nplt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90, labeldistance=1.1)\nplt.title(\"Pie Chart\")\nplt.legend(handles=range(len(labels)), labels=labels, loc=\"upper left\", prop={\"size\": 12})\n",
        "\nplt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90, labeldistance=1.1)\nplt.title(\"Pie Chart\")\nplt.legend(handles=range(len(labels)), labels=labels, loc=\"upper left\", prop={\"size\": 12})\n",
        "\nplt.plot(x, y, 'o-', alpha=0.5, edgecolor='k')\n",
        "\nplt.axvline(x=55, color=\"green\")\n",
        "\nfig, ax = plt.subplots()\n# Create a bar plot with the specified blue and orange bars\nax.bar(range(len(blue_bar)), blue_bar, color='blue', label='Blue')\nax.bar(range(len(orange_bar)), orange_bar, color='orange', label='Orange')\n# Set the plot title and x-axis label\nax.set_title('Bar Plot')\nax.set_xlabel('Bar Label')\n# Add a legend to the plot\nax.legend()\n",
        "\nfig, ax = plt.subplots(1, 2, sharex=True, sharey=True)\nax[0].plot(x, y, label='y')\nax[1].plot(a, z, label='z')\nax[0].legend(loc='best')\n",
        "\n",
        "\nplt.plot(x, y)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.grid(True)\nplt.tick_params(axis='x', which='both', bottom='on', top='on', labelbottom='on', labeltop='on')\nplt.show()\n",
        "sns.factorplot(df, x=\"bill_length_mm\", y=\"sex\", hue=\"species\", aspect=1, sharey=False, palette=\"muted\", multiple=True)",
        "\nplt.plot([0.5, 0.5], [0.5, 0.5], 'k')\nplt.fill(\n    [0.5, 0.5],\n    [0.5, 0.5],\n    'k',\n    alpha=0.2,\n    edgecolor='k',\n)\n",
        "plt.plot(x, y)\nplt.title('$\\phi$', fontweight='bold')",
        "\nplt.plot(x, y, label=\"Line\")\nplt.legend(handles=plt.gca().get_legend_handles(), loc=\"best\", bbox_to_anchor=(1, 1), borderaxespad=0.1)\n",
        "\nplt.plot(x, y, label=\"Line\")\nplt.legend(handles=[], loc=\"best\", prop={\"size\": 0.3})\n",
        "\nplt.legend(handles=[plt.gca().get_line_collection()[0], plt.gca().get_line_collection()[1]], labels=[\"Line\", \"Flipped\"], loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
        "\nplt.legend(loc=\"best\", fontsize=12)\nplt.plot(x, y, marker=\"o\", label=\"Line\")\n",
        "\nfig, ax = plt.subplots(figsize=(10, 10))\nim = ax.imshow(data, cmap=plt.cm.RdBu_r, interpolation='nearest')\nplt.colorbar(im)\nplt.show()\n",
        "plt.plot(x, y)\nplt.title(\"Figure 1\")\nplt.text(0.5, 1.1, \"Figure\", fontweight='bold')",
        "\nsns.pairplot(df, hue=\"id\", x_vars=[\"x\"], y_vars=[\"y\"], diag_kind=\"kde\", aspect=1, diag_kwds={\"c\": \"k\", \"lw\": 2})\nplt.legend(handles=(), labels=(), loc=\"upper left\", bbox_to_anchor=(1, 1), borderaxespad=0)\n",
        "\nplt.plot(x, y)\nplt.gca().invert_xaxis()\n",
        "\nplt.axis('off')\n",
        "\nplt.scatter(x, y, c='red', s=50, edgecolor='black')\n",
        "\nfig, ax = plt.subplots(2, 2, figsize=(15, 15))\nfor i in range(2):\n    for j in range(2):\n        ax[i, j].plot(x, y)\n        ax[i, j].set_title(f\"Subplot {i+1} {j+1}\")\n",
        "\n",
        "\nplt.plot(x, y, 'o')\nplt.fill_between(x, y-error, y+error, alpha=0.2)\nplt.show()\n",
        "\n",
        "\nax.errorbar(box_position, box_height, yerr=box_errors, color=c)\n",
        "\nfig, ax = plt.subplots(1, 2, sharex=True, sharey=True)\nax[0].plot(x, y, 'b-')\nax[0].set_title('Y')\nax[1].plot(a, z, 'r-')\nax[1].set_title('Z', fontsize=12)\nax[1].set_ylim(ax[0].get_ylim())\nplt.tight_layout()\n",
        "\nfig, ax = plt.subplots(4, 4, figsize=(5, 5))\nfor i in range(4):\n    for j in range(4):\n        ax[i, j].plot(x, y)\n        ax[i, j].set_xlabel('x')\n        ax[i, j].set_ylabel('y')\n        ax[i, j].grid(True)\n        ax[i, j].set_xticks(x)\n        ax[i, j].set_yticks(y)\n        ax[i, j].set_xticklabels(x)\n        ax[i, j].set_yticklabels(y)\n        ax[i, j].set_title('Subplot ' + str(i+1) + 'x' + str(j+1))\n        ax[i, j].spines['top'].set_visible(False)\n        ax[i, j].spines['right'].set_visible(False)\n        ax[i, j].spines['bottom'].set_visible(False)\n        ax[i, j].spines['left'].set_visible(False)\n        ax[i, j].set_facecolor('white')\n        ax[i, j].set_edgecolor('black')\n        ax[i, j].tick_params(axis='both', which='major', labelsize=10)\n        ax[i, j].tick_params(axis='both', which='minor', labelsize=10)\n        ax[i, j].set_axisbelow(True)\n        ax[i, j].set_aspect('equal')\n        ax[i, j].set_frame_on(False)\n        ax[i, j].set_title('Subplot ' + str(i+1) + 'x' + str(j+1))\n        ax[i, j].set_facecolor('white')\n        ax[i, j].set_edgecolor('black')\n        ax[i, j].tick_params(axis='both', which='major', labelsize=10)\n        ax[i, j].tick_params(axis='both', which='minor', labelsize=10)\n        ax[i, j].set_axisbelow(True)\n        ax[i, j].set_aspect('equal')\n        ax[i, j].set_frame_on(False)\n        ax[i, j].set_title('Subplot ' + str(i+1) + 'x' + str(j+1))\n        ax[i, j].spines['top'].set_visible(False)\n        ax[i, j].spines['right'].set_visible(False)\n        ax[i, j].spines['bottom'].set_visible(False)\n        ax[i, j].spines['left'].set_visible(False)\n        ax[i, j].set_facecolor('white')\n        ax[i, j].set_edgecolor('black')\n        ax[i, j].tick_params(axis='both', which='major', labelsize=10)\n        ax[i, j].tick_params(axis='both', which='minor', labelsize=10)\n        ax[i, j].set_axisbelow(True)\n        ax[i, j].set_aspect('equal')\n        ax[i, j].set_frame_on(False)\n        ax[i, j].set_title('Subplot ' + str(i+1) + 'x' + str(j+1))\n        ax[i, j].spines['top'].set_visible(False)\n        ax[i, j].spines['right'].set_visible(False)\n        ax[i, j].spines['bottom'].set_visible(False)\n        ax[i, j].spines['left'].set_visible(False)\n        ax[i, j].set_facecolor('white')\n        ax[i, j].set_edgecolor('black')\n        ax[i, j].tick_params(axis='both', which='major', labelsize=10)\n        ax[i, j].tick_params(axis='both', which='minor', labelsize=10)\n        ax[i, j].set_axisbelow(True)",
        "plt.matshow(d)\nplt.figure(figsize=(8, 8))",
        "\nfig, ax = plt.subplots(figsize=(10, 10))\ndf.plot(kind=\"table\", ax=ax, bbox=[0, 0, 1, 1])\n",
        "\nplt.plot(x, y)\nplt.xticks(x, x, rotation=90)\nplt.show()\n",
        "\nplt.plot(x, y)\nplt.xticks(x, x)\nplt.show()\n",
        "\nplt.plot(x, y)\nplt.xlabel('x axis')\nplt.ylabel('y axis')\nplt.xticks(np.arange(10))\nplt.yticks([])\nplt.show()\n",
        "\n",
        "\n",
        "\n",
        "\nplt.plot(x, y, label=\"y\")\nplt.legend(fontsize=8)\n",
        "plt.figure(figsize=(5, 5), dpi=300)\nplt.plot(x, y)\nplt.show()",
        "\nplt.plot(x, y, label=\"y\")\nplt.legend(loc=\"best\", frameon=False)\n",
        "\nfig, ax = plt.subplots()\nax.plot(t, a, 'r', label='a')\nax.plot(t, b, 'b', label='b')\nax.plot(t, c, 'g', label='c')\nax.legend()\nax.grid()\n",
        "\n",
        "\ng = sns.FacetGrid(df, col=\"b\", hue_order=[\"A\", \"B\", \"C\"])\ng.map(sns.pointplot, \"c\", \"a\", hue_order=[\"A\", \"B\", \"C\"], xtick_rotation=90)\ng.add_legend()\nplt.show()\n",
        "\nfig = plt.figure()\nax = Axes3D(fig)\nax.scatter(x, y, z)\nax.view_init(100, 50)\nplt.show()\n",
        "\nplt.plot(x, y)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.xticks([], [])\nplt.yticks([], [])\nplt.grid(True)\n",
        "\n"
    ],
    "Tensorflow": [
        "\nx.assign(1)\n",
        "\nx.assign(114514)\n",
        "\nresult = tf.constant(labels, dtype=tf.int32)\n",
        "\nresult = tf.constant(labels, dtype=tf.int32)\n",
        "\nresult = tf.constant(labels, dtype=tf.int32)\n",
        "result = tf.constant(labels, dtype=tf.int32)\nreturn result",
        "\nresult = tf.constant(labels, dtype=tf.int32)\n",
        "\nds = ds.flat_map(lambda input: tf.data.Dataset.from_tensor_slices(input).map(lambda i: [[i, i+1, i+2]]))\n",
        "result = [input[0], input[0] + 1, input[0] + 2]\nreturn result",
        "\nresult = tf.ones((8,), dtype=tf.int8)\nresult[:len(lengths)] = lengths\nresult = result.reshape([1, 8])\nresult = result.numpy()\n",
        "\nresult = tf.ones((8,), dtype=tf.int32)\nresult[:len(lengths)] = lengths\nresult = result.reshape([4, 2, 2])\nresult = result.astype(int)\n",
        "\nresult = tf.ones(shape=(8,), dtype=tf.int32)\nresult[:len(lengths)] = lengths\nresult = result.reshape([8, 1])\n",
        "\nresult = tf.ones(shape=[8, 1], dtype=tf.int32)\nresult[:len(lengths)] = tf.constant(lengths, dtype=tf.int32)\nreturn result",
        "\nresult = tf.ones((8,), dtype=tf.int32)\nresult[:len(lengths)] = lengths\nresult = result.reshape([8, 1])\nresult = result.astype(int)\n",
        "\n",
        "result = tf.concat([a, b], axis=0)\nreturn result",
        "\nresult = a.reshape(50, 100, 512)\n",
        "# [Missing Code]\nresult = tf.reshape(a, (50, 100, 1, 512))\nprint(result)",
        "# [Missing Code]\nresult = tf.reshape(a, (1, 50, 100, 1, 512))\nprint(result)",
        "\nresult = tf.reduce_sum(A, axis=1)\n",
        "\nresult = tf.reduce_prod(A, axis=1)\n",
        "result = tf.reciprocal(A)",
        "\nresult = tf.reduce_sum(tf.square(tf.subtract(a, b)), axis=1)\n",
        "\nresult = tf.reduce_sum(tf.square(tf.subtract(a, b)), axis=1)\n",
        "result = tf.reduce_sum(tf.square(tf.subtract(A, B)), axis=1)\nreturn result",
        "m = x[y,z]",
        "m = x[row, col]",
        "result = x[y,z]\nreturn result",
        "\nC = tf.einsum('ijk,ijk->ij', A, B)\n",
        "\nC = tf.einsum('ijk,ijk->ijk', A, B)\n",
        "result = [x.decode() for x in x]\nprint(result)",
        "result = [bytes.decode(x) for x in example_x]\nreturn result",
        "result = tf.reduce_sum(x, axis=-2, keepdims=True) / tf.reduce_sum(x, axis=-2, keepdims=True, keepdims=True)",
        "\n y = x.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])\n y = y.mean(axis=1)\n y = y.reshape([-1, 1, 1, 1])",
        "\nresult = tf.reduce_sum(x, axis=-2)\nresult = result / tf.reduce_sum(tf.cast(x != 0, tf.float32), axis=-2)\n",
        "\n# [Missing Code]\n",
        "\nresult = tf.argmax(a, axis=1)\n",
        "\nresult = tf.argmax(a, axis=1)\n",
        "\nresult = tf.argmax(a, axis=1)\n",
        "result = tf.stack([tf.argmin(a[:, i]) for i in range(a.shape[1])], axis=1)\nprint(result)",
        "model.save('my_model')",
        "\nresult = tf.random.uniform([10], minval=1, maxval=4, dtype=tf.int32)\n",
        "\nresult = tf.random.uniform([114], minval=2, maxval=5, dtype=tf.int32, seed=seed_x)\n",
        "result = tf.random.uniform([1, 10], minval=1, maxval=4, dtype=tf.int32, seed=seed_x)",
        "\nresult = tf.__version__\n"
    ],
    "Scipy": [
        "result = scipy.polyfit(x, y, 1)\nprint(result)",
        "result = scipy.polyfit(x, y, 1)\nprint(result)",
        "result = scipy.optimize.curve_fit(lambda x, A, B, C: A*np.exp(B*x) + C, x, y, p0)\nprint(result)",
        "test_stat = stats.ks_2samp(x, y)\nprint(test_stat)",
        "test_stat = stats.ks_2samp(x, y)\nresult = test_stat[0] > alpha\nprint(result)",
        "\nresult = optimize.minimize(f, initial_guess, method='L-BFGS-B', options={'maxiter': 1000})\n",
        "p_values = scipy.stats.norm.cdf(-z_scores)\n",
        "\np_values = scipy.stats.norm.cdf(-z_scores, loc=mu, scale=sigma)\n",
        "z_scores = scipy.stats.norm.ppf(p_values)\nprint(z_scores)",
        "dist = stats.lognorm(mu, loc=stddev)\nresult = dist.cdf(x)\nprint(result)",
        "\nexpected_value = stats.norm.ppf(0.5, loc=mu, scale=np.sqrt(stddev**2))\nmedian = stats.norm.ppf(0.5, loc=mu, scale=np.sqrt(stddev**2))\n",
        "result = sa * sb",
        "result = sparse.csr_matrix(np.dot(sA.toarray(), sB.toarray()))\nreturn result",
        "\nresult = scipy.interpolate.LinearNDInterpolator(points, V)(request)\n",
        "\nV_interp = scipy.interpolate.LinearNDInterpolator(points, V)\nresult = V_interp(request)\nprint(result)\n",
        "data_rot = rotate(data_orig, angle) # data array\nxrot, yrot = data_rot[x0-x0%data_orig.shape[1], y0-y0%data_orig.shape[0]] # (xrot, yrot) should point there",
        "",
        "result = stats.kstest(times, \"uniform\")",
        "from scipy import stats\nimport random\nimport numpy as np\ndef poisson_simul(rate, T):\n    time = random.expovariate(rate)\n    times = [0]\n    while (times[-1] < T):\n        times.append(time+times[-1])\n        time = random.expovariate(rate)\n    return times[1:]\nexample_rate = 1.0\nexample_T = 100.0\nexample_times = poisson_simul(example_rate, example_T)\ndef f(times = example_times, rate = example_rate, T = example_T):\n    result = stats.kstest(times, \"uniform\")\n    return result\nprint(f())",
        "result = stats.kstest(times, \"uniform\", nsup=1000, ninf=1000, nan_policy='omit')\nprint(result)",
        "Feature = sparse.csr_matrix(c1.toarray()[:,None] + c2.toarray())",
        "Feature = sparse.csr_matrix([[0, 0, 1, 0], [2, 0, 0, 0], [0, 0, 0, 0], [0, 3, 4, 0], [0, 0, 0, 5], [6, 7, 0, 8]])",
        "\n cFeature = sparse.hstack([c1, c2])\n ",
        "result = scipy.spatial.KDTree(points1).nearest_neighbors(points2, N)\nprint(result)",
        "\n # [Missing Code]\n ",
        "b.setdiag(0)",
        "\nresult = ndimage.label(img > threshold)\n",
        "\nresult = np.count_nonzero(img > threshold)\n",
        "result = np.count_nonzero(img > threshold)\nreturn result",
        "\nresult = []\n# Find the regions of cells which value exceeds a given threshold, say 0.75\nregions = ndimage.label(img > threshold)\n# Determine the distance between the center of mass of such regions and the top left corner, which has coordinates (0,0)\nfor region in regions:\n    center_x, center_y = region.sum(axis=0) / 2, region.sum(axis=1) / 2\n    result.append(np.sqrt((center_x - 0) ** 2 + (center_y - 0) ** 2))\nprint(result)\n",
        "M= sparse.random(10, 10, density=0.1, format='lil')\nM.make_symmetric()\nprint(M)",
        "\n    sA.make_symmetric()\n    ",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nmean = np.mean(col.data)\nstandard_deviation = np.std(col.data)\n",
        "\nMax = np.max(col)\nMin = np.min(col)\n",
        "Median = np.median(col)\nMode = np.mode(col)",
        "\ndef fourier(x, a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12, a13, a14, a15):\n    return a1 * np.cos(1 * np.pi / tau * x) + \\\n           a2 * np.cos(2 * np.pi / tau * x) + \\\n           a3 * np.cos(3 * np.pi / tau * x) + \\\n           a4 * np.cos(4 * np.pi / tau * x) + \\\n           a5 * np.cos(5 * np.pi / tau * x) + \\\n           a6 * np.cos(6 * np.pi / tau * x) + \\\n           a7 * np.cos(7 * np.pi / tau * x) + \\\n           a8 * np.cos(8 * np.pi / tau * x) + \\\n           a9 * np.cos(9 * np.pi / tau * x) + \\\n           a10 * np.cos(10 * np.pi / tau * x) + \\\n           a11 * np.cos(11 * np.pi / tau * x) + \\\n           a12 * np.cos(12 * np.pi / tau * x) + \\\n           a13 * np.cos(13 * np.pi / tau * x) + \\\n           a14 * np.cos(14 * np.pi / tau * x) + \\\n           a15 * np.cos(15 * np.pi / tau * x)\n",
        "\nresult = scipy.spatial.distance.cdist(example_array, example_array, 'euclidean')\n",
        "\nresult = scipy.spatial.distance.cdist(example_array, example_array, 'cityblock')\n",
        "\nresult = scipy.spatial.distance.cdist(example_array, example_array, 'euclidean')\n",
        "result = interpolate.splev(x_val, tck, der = 0)\nprint(result)",
        "\nstatistic, critical_values, significance_level = ss.anderson_ksamp(np.array([x1, x2, x3, x4]))\n",
        "\nresult = ss.anderson_ksamp(x1, x2, n_samples=1000, alternative='two-sided')\n",
        "A['AB'] = pd.rolling_apply(A['B'], 3, lambda x: stats.kendalltau(x, A['A']))",
        "result = sa.nnz == 0\nprint(result)",
        "result = sa.nnz == 0\nprint(result)",
        "result = block_diag(*a)",
        "p_value = stats.ranksums(pre_course_scores, during_course_scores).pvalue\nprint(p_value)",
        "p_value = stats.ranksums(pre_course_scores, during_course_scores).pvalue\nreturn p_value",
        "kurtosis_result = scipy.stats.kurtosis(a)\n",
        "\nkurtosis_result = scipy.stats.kurtosis(a)\n",
        "# [Missing Code]\n result = scipy.interpolate.interp2d(x, y, z, kind='cubic')([s1, s2], [t1, t2])\nprint(result)",
        "# [Missing Code]\n    z = scipy.interpolate.interp2d(x, y, z, kind='cubic')(s, t)\n    return z",
        "result = np.array([vor.regions[vor.vertices[i][0]].index for i in range(len(extraPoints))], dtype=int)",
        "result = np.array([vor.regions[vor.vertices[i][0]].index for i in range(len(extraPoints))], dtype=int)",
        "result = sparse.csr_matrix(vectors)\nprint(result)",
        "\norigin = 1\n",
        "result = M[row, column]",
        "result = [M[row[i], column[i]] for i in range(len(row))]",
        "f = scipy.interpolate.interp1d(x, array)\nnew_array[:, :, :] = f(x_new)",
        "\nP_inner = scipy.integrate.quad(NDfx, -dev, dev)\n",
        "def NormalDistro(u,o2,x):\n    dev = abs((x-u)/o2)\n    P_inner = scipy.integrate(NDfx,-dev,dev)\n    P_outer = 1 - P_inner\n    P = P_inner + P_outer/2\n    return(P)\ndef f(x = 2.5, u = 1, o2 = 3):\n    P_inner = scipy.integrate(NDfx,-dev,dev)\n    P_outer = 1 - P_inner\n    P = P_inner + P_outer/2\n    return prob",
        "result = sf.dctn(np.eye(N), norm='ortho')\n",
        "diags(matrix, [-1,0,1], (5, 5)).toarray()",
        "M = scipy.stats.binom.pmf(i, p, size=N)",
        "result = df.apply(lambda x: stats.zscore(x.values), axis=1)\nprint(result)",
        "\nresult = df.apply(lambda x: stats.zscore(x.sample1), axis=1)\nresult = df.apply(lambda x: stats.zscore(x.sample2), axis=1)\nresult = df.apply(lambda x: stats.zscore(x.sample3), axis=1)\n",
        "\n# [Missing Code]\n",
        "\ndf['data'] = df.sample1 + df.sample2 + df.sample3\ndf['zscore'] = stats.zscore(df['data'])\ndf['zscore'] = df['zscore'].round(3)\nresult = df.set_index('probegenes')\nprint(result)",
        "result = scipy.optimize.line_search(test_func, test_grad, starting_point, direction)",
        "mid = np.array([[0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0]])\nresult = distance.cdist(scipy.dstack((y, x)), mid)\nprint(result)",
        "mid = np.array([[0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5]])\nreturn scipy.spatial.distance.cdist(scipy.dstack((y, x)), mid)\n",
        "mid = np.zeros((shape[0], shape[1], 2))\nreturn scipy.spatial.distance.cdist(scipy.dstack((y, x)), mid)",
        "result = scipy.ndimage.zoom(x, 1.5, order=1)\n",
        "from scipy.optimize import minimize\ndef func(x,a):\n    return np.dot(a, x**2)\ndef residual(pars, a, y):\n    vals = pars.valuesdict()\n    x = vals['x']\n    model = func(x,a)\n    return (y - model) **2\ndef main():\n    # simple one: a(M,N) = a(3,5)\n    a = np.array([ [ 0, 0, 1, 1, 1 ],\n                   [ 1, 0, 1, 0, 1 ],\n                   [ 0, 1, 0, 1, 0 ] ])\n    # true values of x\n    x_true = np.array([10, 13, 5, 8, 40])\n    # data without noise\n    y = func(x_true,a)\n    #************************************\n    # Apriori x0\n    x0 = np.array([2, 3, 1, 4, 20])\n    fit_params = Parameters()\n    fit_params.add('x', value=x0)\n    out = minimize(residual, fit_params, args=(a, y))\nif __name__ == '__main__':\n    main()\n",
        "\n# [Missing Code]\n",
        "dy_dt = -100 * y + np.sin(t)\nsol = solve_ivp(fun=dy_dt, t_span=time_span, y0=[N0,])\nresult = sol.y\nprint(result)",
        "",
        "y0 = np.array([N0, -np.cos(t)])\nresult = sol.y\nprint(result)",
        "for t in range (4):\n    def const(x):    \n        y=x[t]\n        return y\n    cons.append({'type':'ineq', 'fun': const})",
        "\nresult = sa.copy()\nresult.data += sb.data\nresult.indices += sb.indices\nresult.indptr += sb.indptr\n",
        "\nresult = sa.copy()\nresult.data += sb.data\nresult.indices += sb.indices\nresult.indptr += sb.indptr\n",
        "\nresult, error = scipy.integrate.quad(lambda x: 2*x*c, low, high)\n",
        "result, error = scipy.integrate.quad(lambda x: 2*x*c, low, high)\nreturn result",
        "\nV = V + x\n",
        "\n# [Missing Code]\n",
        "\n V = V + x\n B = V + y\n ",
        "\n # [Missing Code]\n ",
        "\n # [Missing Code]\n ",
        "b = scipy.sparse.csr_matrix(a)\nprint(b)",
        "a = scipy.sparse.csr_matrix(a)\nprint(a)",
        "result = scipy.spatial.KDTree(data).query(centroids, k=1)[:, 0]\nprint(result)",
        "result = scipy.spatial.KDTree(centroids).query(data, k=1, p=2)[:, 0]",
        "result = scipy.spatial.KDTree(data).query(centroids, k=k, return_distance=False)[:, 1]\nprint(result)",
        "result = np.array([fsolve(eqn, x0=x, args=(a, b)) for x in xdata for b in bdata])\nprint(result)",
        "result = fsolve(eqn, xdata, args = (adata,))\nprint(result)",
        "result = stats.kstest(sample_data, bekkers, 'exponential', args=(estimated_a, estimated_m, estimated_d))\nprint(result)",
        "kstest_result = stats.kstest(sample_data, bekkers, args=(range_start, range_end, estimated_a, estimated_m, estimated_d))\nresult = kstest_result[1]\nprint(result)",
        "integral_df = df.groupby(pd.Grouper(freq='25S')).apply(integrate.trapz)\nprint(integral_df)",
        "import scipy.interpolate\nx = [(2,2), (1,2), (2,3), (3,2), (2,1)]\ny = [5,7,8,10,3]\neval = [(2.7, 2.3)]\nresult = scipy.interpolate.griddata(x, y, eval, method='linear')\nprint(result)",
        "\n# [Missing Code]\n",
        "popt = sciopt.fminbound(e, pmin, pmax, args=(x,y))",
        "\nresult = np.where(np.diff(arr) <= 0, np.arange(len(arr)), [])\n",
        "\nresult = []\nfor i in range(len(arr)):\n    for j in range(len(arr[i])):\n        if arr[i][j] <= arr[i-n:i+n+1][j].mean():\n            result.append([i, j])\n",
        "df = df[(np.abs(stats.zscore(df.loc[:, df.select_dtypes('number')])) < 3).all(axis=1)]"
    ],
    "Sklearn": [
        "data1 = pd.DataFrame(data)",
        "data1 = pd.DataFrame(data)\nprint(data1)",
        "data1 = pd.DataFrame(data)",
        "data1 = pd.DataFrame(data)",
        "df_out = df.melt(id_vars=['Col1', 'Col2'], value_vars=['Col3'])\ndf_out = df_out.drop('variable', axis=1)\ndf_out = df_out.rename(columns={'Col3': 'Col3'})\ndf_out = df_out.set_index('Col1')\ndf_out = df_out.unstack(level=1)\ndf_out = df_out.reset_index()\ndf_out = df_out.rename(columns={'Col3': 'Apple', 'Col3': 'Orange', 'Col3': 'Banana', 'Col3': 'Grape'})\nprint(df_out)",
        "df_out = pd.get_dummies(df, columns=['Col3'])\nprint(df_out)",
        "df_out = df.iloc[:, :-1].join(df.iloc[:, -1].apply(pd.Series).stack().reset_index(level=1, drop=True))\nprint(df_out)",
        "df_out = df.iloc[:, :-1].join(df.iloc[:, -1].apply(pd.Series).stack().reset_index(level=1, drop=True))\nprint(df_out)",
        "df_out = df.iloc[:, :3].join(pd.get_dummies(df.iloc[:, -1], prefix=None))\nprint(df_out)",
        "proba = np.exp(x_test) / (np.exp(x_test) + np.exp(-x_test))",
        "proba = np.array([1 / (1 + np.exp(-x)) for x in predicted_test_scores])\nprint(proba)",
        "df_new = pd.concat([df_origin, transform_output], axis=1)\nprint(df_new)",
        "df = pd.concat([df_origin, pd.DataFrame(transform_output)], axis=1)\nprint(df)",
        "df_new = pd.concat([df_origin, transform_output], axis=1)\nreturn df_new",
        "\n steps = clf.named_steps()\n steps.pop(1)\n clf.set_steps(steps)\n ",
        "steps = clf.named_steps()\nsteps.pop(0)\nclf.set_steps(steps)\nprint(len(clf.steps))",
        "steps = clf.named_steps()\nsteps.pop(1)\nclf = Pipeline(estimators)\nprint(clf.named_steps)",
        "\n clf.steps.insert(1, ('poly', PolynomialFeatures()))\n ",
        "\nprint(len(clf.steps))",
        "\n# [Missing Code]\n",
        "\nfit_params = {\n    \"early_stopping_rounds\": 42,\n    \"eval_metric\": \"mae\",\n    \"eval_set\": [[testX, testY]]\n}\n",
        "fit_params={\"early_stopping_rounds\":42,\n            \"eval_metric\" : \"mae\",\n            \"eval_set\" : [[testX, testY]]}\n",
        "proba = logreg.predict_proba(X)",
        "proba = logreg.predict_proba(X)",
        "inversed = scaler.inverse_transform(scaled)\nprint(inversed)",
        "\n    # [Missing Code]\n    ",
        "model_name = model.name",
        "model_name = model.__class__.__name__\nprint(model_name)",
        "model_name = model.name",
        "pipe.named_steps[\"tf_idf\"].fit_transform(data.test)",
        "pipe.named_steps[\"tf_idf\"].fit_transform(data.test)",
        "select_out = select.fit_transform(data, target)",
        "\ngrid_search = GridSearchCV(estimator=bc, param_grid=param_grid, cv=3, n_jobs=-1)\ngrid_search.fit(X_train, y_train)\n",
        "\n# [Missing Code]\n",
        "X_test = np.array(X_test)\ny_test = np.array(y_test)\n",
        "processor=preprocess",
        "preprocessor = lambda x: x.lower()\n",
        "df_out = preprocessing.scale(data)\n",
        "df_out = preprocessing.scale(data)\nprint(df_out)",
        "\n coef = grid.best_estimator_.coef_\n ",
        "\n coef = grid.best_estimator_.coef_\n ",
        "column_names = np.array(X.columns)",
        "column_names = model.get_support()[1]",
        "column_names = model.get_support()",
        "column_names = np.array(clf.feature_importances_.argsort()[-10:][::-1])",
        "\nclosest_50_samples = km.predict(X)\n",
        "closest_50_samples = km.fit(X).predict(p)",
        "closest_100_samples = km.fit(X).predict(X)[:100]",
        "\nclosest_50_samples = km.predict(X)\nreturn closest_50_samples[:50]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "\nfrom sklearn.svm import SVC\nsvc = SVC(kernel='rbf', gamma=0.1)\nsvc.fit(X, y)\npredict = svc.predict(X)\n",
        "\nmodel = sklearn.svm.SVC(kernel='rbf', gamma='auto')\nmodel.fit(X, y)\npredict = model.predict(X)\n",
        "\nfrom sklearn.svm import SVC\nsvc = SVC(kernel='poly', degree=2)\nsvc.fit(X, y)\npredict = svc.predict(X)\n",
        "\nmodel = sklearn.svm.SVC(kernel='poly', degree=2)\nmodel.fit(X, y)\npredict = model.predict(X)\n",
        "# [Missing Code]\n cosine_similarities_of_queries = np.dot(tfidf.transform(queries), tfidf.transform(documents)) / (np.linalg.norm(tfidf.transform(queries), axis=1) * np.linalg.norm(tfidf.transform(documents), axis=1))\nprint(cosine_similarities_of_queries)",
        "# [Missing Code]\n cosine_similarities_of_queries = np.dot(tfidf, queries.T)\n cosine_similarities_of_queries = cosine_similarities_of_queries / np.linalg.norm(cosine_similarities_of_queries, axis=1)\n print(cosine_similarities_of_queries)",
        "    query_tfidf = tfidf.transform(queries)\n    query_cosine_similarities = np.dot(query_tfidf, documents.T) / (np.linalg.norm(query_tfidf) * np.linalg.norm(documents.T))\n    return query_cosine_similarities",
        "new_features = np.array(features)\nnew_features = new_features.astype(np.float64)\nnew_features = sklearn.preprocessing.normalize(new_features, axis=1)\nnew_features = new_features.reshape(len(features), -1)\nprint(new_features)",
        "new_f = pd.DataFrame(f)\nnew_f = new_f.astype(np.int8)\nnew_f = new_f.values\nnew_f = sklearn.preprocessing.get_dummies(new_f, drop_first=True)\nprint(new_f)",
        "new_features = np.array(features)\nnew_features = new_features.astype(np.float64)\nnew_features = sklearn.preprocessing.normalize(new_features, axis=1)\nnew_features = new_features.reshape(len(features), -1)\nprint(new_features)",
        "\nnew_features = np.array(features)\nnew_features = new_features.astype(np.int8)\nnew_features = new_features.reshape(len(features), -1)\nreturn new_features",
        "new_features = np.array(features)\nnew_features = new_features.astype(np.int8)\nnew_features = new_features.reshape(len(features), -1)\nprint(new_features)",
        "\ncluster_labels = sklearn.cluster.AgglomerativeClustering(n_clusters=2).fit_predict(data_matrix)\n",
        "\ncluster_labels = sklearn.cluster.AgglomerativeClustering(n_clusters=2).fit_predict(data_matrix)\n",
        "\nsimM = simM.astype(float)\ncluster_labels = sklearn.cluster.AgglomerativeClustering(n_clusters=2, linkage='complete', affinity='precomputed').fit(simM).labels_\n",
        "\n# [Missing Code]\n",
        "\ncluster_labels = scipy.cluster.hierarchy.linkage(data_matrix, method='ward')\n",
        "\n# [Missing Code]\n",
        "\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, FunctionTransformer, RobustScaler, Normalizer, Standardizer\nscaler = StandardScaler()\ncentered_scaled_data = scaler.fit_transform(data)\nprint(centered_scaled_data)",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, FunctionTransformer\nscaler = StandardScaler()\ncentered_scaled_data = scaler.fit_transform(data)\nprint(centered_scaled_data)",
        "from sklearn.preprocessing import BoxCoxTransformer\nbox_cox_data = data.apply(BoxCoxTransformer().fit_transform)",
        "box_cox_data = sklearn.preprocessing.BoxCox(lambda x: np.log(x))\nbox_cox_data.fit(data)\nbox_cox_data.transform(data)\n",
        "from sklearn.preprocessing import YeoJohnson\nyeo_johnson_data = YeoJohnson().fit_transform(data)\nprint(yeo_johnson_data)",
        "from sklearn.preprocessing import MinMaxScaler\nyeo_johnson_data = MinMaxScaler().fit_transform(data)\nprint(yeo_johnson_data)",
        "transformed_text = CountVectorizer(tokenizer=lambda x: x.replace('!', '!').replace('?', '?').replace('\"', '\\\"').replace(\"'\", \"\\\"'\")).fit_transform(text)\n",
        "\nx_train, y_train, x_test, y_test = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\nx_train, y_train, x_test, y_test = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\nx_train, y_train, x_test, y_test = train_test_split(dataset, test_size=0.3, random_state=42)\n",
        "\nx_train, y_train, x_test, y_test = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "X = df['mse'].values\nkmeans = KMeans(n_clusters=2).fit(X)\nlabels = kmeans.predict(X)\nprint(labels)",
        "X = np.array(list(zip(f1, f2)))",
        "selected_feature_names = np.asarray(vectorizer.get_feature_names())[LinearSVC(C=1.0, penalty='l1').fit(X).support_]",
        "selected_feature_names = np.asarray(vectorizer.get_feature_names())[LinearSVC().fit(X, y).support_]",
        "selected_feature_names = np.asarray(vectorizer.get_feature_names())[LinearSVC(C=1.0, penalty='l1').fit(X).support_]",
        "vectorizer = CountVectorizer(stop_words=\"english\",binary=True,lowercase=False,vocabulary=vocabulary)\n",
        "vectorizer = CountVectorizer(stop_words=\"english\",binary=True,lowercase=False,vocabulary=vocabulary)\n",
        "feature_names = vectorizer.get_feature_names()\nX = vectorizer.fit_transform(corpus)\nX = np.array(X)\nX = X.astype(int)\nprint(feature_names)\nprint(X)",
        "\nvectorizer = CountVectorizer(stop_words=\"english\",binary=True,lowercase=False,vocabulary={'Jscript','.Net','TypeScript','NodeJS','Angular','Mongo','CSS','Python','PHP','Photoshop','Oracle','Linux','C++',\"Java\",'TeamCity','Frontend','Backend','Full stack', 'UI Design', 'Web','Integration','Database design','UX'})\nX = vectorizer.fit_transform(corpus)\nprint(vectorizer.get_feature_names())\nprint(X.toarray())\n",
        "\nfor col in df1.columns:\n    df2 = df1[~np.isnan(df1[col])]\n    df3 = df2[['Time', col]]\n    npMatrix = np.matrix(df3)\n    X, Y = npMatrix[:,0], npMatrix[:,1]\n    slope = LinearRegression().fit(X,Y)\n    m = slope.coef_[0]\n    series = np.concatenate((series, m), axis = 0)\nprint(series)",
        "for col in df1.columns:\n    df2 = df1[~np.isnan(df1[col])]\n    df3 = df2[['Time', col]]\n    npMatrix = np.matrix(df3)\n    X, Y = npMatrix[:,0], npMatrix[:,1]\n    slope = LinearRegression().fit(X,Y)\n    m = slope.coef_[0]\n    series = np.concatenate((SGR_trips, m), axis = 0)\n    slopes.append(m)\nprint(slopes)",
        "df['Sex'] = LabelEncoder().fit_transform(df['Sex'])\n",
        "df['Sex'] = LabelEncoder().fit_transform(df['Sex'])\n",
        "df['Sex'] = LabelEncoder().fit_transform(df['Sex'])\n",
        "\n ElasticNet = linear_model.ElasticNet() # create a lasso instance\n ElasticNet.fit(X_train, y_train) # fit data\n print (\"R^2 for training set:\"),\n print (ElasticNet.score(X_train, y_train))\n print ('-'*50)\n print (\"R^2 for test set:\"),\n print (ElasticNet.score(X_test, y_test))\n ",
        "transformed = MinMaxScaler().fit_transform(np_array)\n",
        "transformed = MinMaxScaler().fit_transform(np_array.reshape(-1, np_array.shape[1]))\n",
        "    new_a = np.array([[np_array[:, 0].min(), np_array[:, 0].max()],\n                      [np_array[:, 1].min(), np_array[:, 1].max()]])\n    return new_a\n",
        "close_buy1 = close[:-1]\nm5 = ma_50[:-1]\nm10 = ma_100[:-1]\nma20 = ma_200[:-1]\nb = np.concatenate([close_buy1, m5, m10, ma20], axis=1)\nclf.predict(b)",
        "new_X = np.array(X)\nclf.fit(new_X, ['2', '3'])",
        "new_X = np.array(X)\nclf.fit(new_X, ['2', '3'])",
        "new_X = np.array(X)\nclf.fit(new_X, ['4', '5'])",
        "predict = logReg.predict(X)\nprint(predict)",
        "X = dataframe.iloc[-1:].astype(float)\ny = dataframe.iloc[:,-1]\nlogReg = LogisticRegression()\nlogReg.fit(X,y)\npredict = logReg.predict(X)\nprint(predict)",
        "train_size = 0.2\ntrain_dataframe, test_dataframe = train_test_split(features_dataframe, train_size=train_size)\ntrain_dataframe = train_dataframe.sort([\"date\"])\ntest_dataframe = test_dataframe.sort([\"date\"])\nprint(train_dataframe)\nprint(test_dataframe)",
        "train_size = 0.8\ntrain_dataframe, test_dataframe = train_test_split(features_dataframe, train_size=train_size)\ntrain_dataframe = train_dataframe.sort([\"date\"])\ntest_dataframe = test_dataframe.sort([\"date\"])\nprint(train_dataframe)\nprint(test_dataframe)",
        "train_size = 0.2\ntrain_dataframe, test_dataframe = train_test_split(features_dataframe, train_size=train_size)\ntrain_dataframe = train_dataframe.sort([\"date\"])\ntest_dataframe = test_dataframe.sort([\"date\"])\nreturn train_dataframe, test_dataframe",
        "cols = df.columns[2:4]\ndf[cols + '_scale'] = scaler.fit_transform(df[cols])",
        "myData['new_' + cols] = myData.groupby('Month')[cols].transform(scaler.fit_transform)",
        "\ncount = CountVectorizer(lowercase = False)\nvocabulary = count.fit_transform(words)\nfeature_names = count.get_feature_names()\n",
        "feature_names = count.get_feature_names_out()\nprint(feature_names)",
        "\nfull_results = pd.DataFrame(GridSearch_fitted.cv_results_)\nfull_results['params'] = GridSearch_fitted.cv_params_\nfull_results['mean_test_score'] = GridSearch_fitted.cv_mean_test_score_\nfull_results['std_test_score'] = GridSearch_fitted.cv_std_test_score_\nfull_results['score'] = GridSearch_fitted.best_score_\nfull_results['time'] = GridSearch_fitted.best_time_\nfull_results['n_jobs'] = GridSearch_fitted.best_n_jobs_\nfull_results['fit_time'] = GridSearch_fitted.best_fit_time_\nfull_results['n_jobs'] = GridSearch_fitted.best_n_jobs_\nfull_results['fit_time'] = GridSearch_fitted.best_fit_time_\nfull_results['score'] = GridSearch_fitted.best_score_\nfull_results['time'] = GridSearch_fitted.best_time_\nfull_results['n_jobs'] = GridSearch_fitted.best_n_jobs_\nfull_results['fit_time'] = GridSearch_fitted.best_fit_time_\nfull_results['score'] = GridSearch_fitted.best_score_\nfull_results['time'] = GridSearch_fitted.best_time_\nfull_results['n_jobs'] = GridSearch_fitted.best_n_jobs_\nfull_results['fit_time'] = GridSearch_fitted.best_fit_time_\nfull_results['score'] = GridSearch_fitted.best_score_\nfull_results['time'] = GridSearch_fitted.best_time_\nfull_results['n_jobs'] = GridSearch_fitted.best_n_jobs_\nfull_results['fit_time'] = GridSearch_fitted.best_fit_time_\nfull_results['score'] = GridSearch_fitted.best_score_\nfull_results['time'] = GridSearch_fitted.best_time_\nfull_results['n_jobs'] = GridSearch_fitted.best_n_jobs_\nfull_results['fit_time'] = GridSearch_fitted.best_fit_time_\nfull_results['score'] = GridSearch_fitted.best_score_\nfull_results['time'] = GridSearch_fitted.best_time_\nfull_results['n_jobs'] = GridSearch_fitted.best_n_jobs_\nfull_results['fit_time'] = GridSearch_fitted.best_fit_time_\nfull_results['score'] = GridSearch_fitted.best_score_\nfull_results['time'] = GridSearch_fitted.best_time_\nfull_results['n_jobs'] = GridSearch_fitted.best_n_jobs_\nfull_results['fit_time'] = GridSearch_fitted.best_fit_time_\nfull_results['score'] = GridSearch_fitted.best_score_\nfull_results['time'] = GridSearch_fitted.best_time_\nfull_results['n_jobs'] = GridSearch_fitted.best_n_jobs_\nfull_results['fit_time'] = GridSearch_fitted.best_fit_time_\nfull_results['score'] = GridSearch_fitted.best_score_\nfull_results['time'] = GridSearch_fitted.best_time_\nfull_results['n_jobs'] = GridSearch_fitted.best_n_jobs_\nfull_results['fit_time'] = GridSearch_fitted.best_fit_time_\nfull_results['score'] = GridSearch_fitted.best_score_\nfull_results['time'] = GridSearch_fitted.best_time_\nfull_results['n_jobs'] = GridSearch_fitted.best_n_jobs_\nfull_results['fit_time'] = GridSearch_fitted.best_fit_time_\nfull_results['score'] = GridSearch_fitted.best_score_\nfull_results['time'] = GridSearch_fitted.best_time_\nfull_results['n_jobs'] = GridSearch_fitted.best_n_jobs_",
        "\nfull_results = GridSearch_fitted.cv_results_\nfull_results = full_results.sort_values(by=['mean_fit_time'], ascending=False)\nfull_results = full_results.reset_index()\nfull_results.columns = ['parameter', 'mean_fit_time', 'score']\nprint(full_results)\n",
        "# [Missing Code]\n with open(\"sklearn_model\", \"wb\") as f:\n     pickle.dump(fitted_model, f)",
        "\n"
    ],
    "Pytorch": [
        "optim.set_lr(0.001)",
        "optim.set_lr(0.001)",
        "optim.param_groups[0]['lr'] = 0.0005",
        "optim.set_lr(0.005)",
        "embedded_input = torch.Tensor(np.array(word2vec.wv.vectors))",
        "embedded_input = torch.Tensor(np.array(word2vec.wv.vectors))\nreturn embedded_input",
        "\npx = pd.DataFrame(x.numpy())\n",
        "px = pd.DataFrame(x.numpy())\n",
        "\npx = pd.DataFrame(x.numpy())\n",
        "C = B[:, A_log]",
        "C = B[:, A_logical]",
        "C = B[:, A_log]",
        "C = B[:, A_log]",
        "C = B[:, A_log]",
        "C = B[:, A_log]",
        "C = torch.LongTensor([[1, 3], [4, 6]])",
        "\nx_tensor = torch.from_numpy(x_array)\n",
        "x_tensor = torch.from_numpy(x)",
        "\nx_array = x_array.astype(np.float16)\nx_tensor = torch.from_numpy(x_array)\n",
        "\nmask = torch.zeros(len(lens), lens[0]).to(torch.long)\nfor i in range(len(lens)):\n    mask[i, :lens[i]] = torch.arange(lens[i]).to(torch.long)\n",
        "\nmask = torch.zeros(len(lens), 10)\nfor i in range(len(lens)):\n    mask[i, lens[i]:lens[i]+1] = 1\n",
        "\nmask = torch.zeros(len(lens), 5)\nfor i in range(len(lens)):\n    mask[i, lens[i]] = 1\n",
        "\nmask = torch.zeros(len(lens), 5)\nfor i in range(len(lens)):\n    mask[i, lens[i]:lens[i]+1] = 1\nreturn mask",
        "Tensor_3D = torch.diag(Tensor_2D.reshape(-1, 1)).reshape(index_in_batch, -1)\nprint(Tensor_3D)",
        "\nresult = torch.diag(torch.tensor(drag_ele))\n",
        "ab = torch.cat((a, b), dim=0)\nprint(ab)",
        "\n ab = torch.cat((a, b), dim=0)\n ",
        "ab = torch.cat((a, b), dim=0)\nreturn ab",
        "a[ : , lengths : , : ] = 0",
        "a[ : , lengths : , : ] = 2333",
        "a[ : , : lengths , : ] = 0",
        "a[ : , : lengths , : ] = 2333",
        "",
        "new_tensors = torch.stack(list, dim=0)\n",
        "tt = torch.tensor(lt)\nreturn tt",
        "",
        "",
        "",
        "result = t[idx]\nprint(result)",
        "result = x.gather(1,ids)",
        "result = x.gather(1,ids)",
        "result = x[ids == 1]",
        "y = np.argmax(softmax_output, axis=1)\nprint(y)",
        "y = np.argmax(softmax_output, axis=1)\nprint(y)",
        "\ny = np.argmin(softmax_output, axis=1)\nprint(y)",
        "\ny = np.argmax(softmax_output, axis=1)\nreturn y",
        "\ny = torch.argmin(softmax_output, dim=1)\nreturn y.numpy().astype(np.long)",
        "\nloss = F.nll_loss(log_p, target.view(-1), weight=weight, size_average=False)\nif size_average:\n    loss /= mask.data.sum()\nreturn loss",
        "cnt_equal = np.sum(np.equal(A, B))\n",
        "cnt_equal = np.sum(np.equal(A, B))\n",
        "cnt_not_equal = np.sum(np.abs(A - B))\n",
        "\ncnt_equal = np.sum(np.equal(A, B))\n",
        "cnt_equal = np.equal(A[-x:], B[-x:], axis=0).sum()\n",
        "cnt_not_equal = np.count_nonzero(np.diff(A[-x:]))\n",
        "\nfor i in range(0, 40, chunk_dim):\n    tensor = a[:, :, i:i+chunk_dim, :, :]\n    tensors_31.append(tensor)\n",
        "\nfor i in range(0, 40, chunk_dim):\n    start_index = i * chunk_dim\n    end_index = (i + 1) * chunk_dim\n    tensor = a[:, :, start_index:end_index, :, :]\n    tensors_31.append(tensor)\n",
        "\noutput[mask] = clean_input_spectrogram[mask]\n",
        "\noutput[mask] = clean_input_spectrogram[mask]\n",
        "\n# [Missing Code]\n",
        "\n# [Missing Code]\n",
        "    sign_x = torch.sign(x)\n    sign_y = torch.sign(y)\n    min = torch.min(torch.abs(x), torch.abs(y))\n    sign_min = torch.where(torch.eq(min, torch.abs(x)), sign_x, sign_y)\n    return sign_min",
        "\nconfidence_score = torch.nn.functional.softmax(output, dim=1)\n",
        "result = torch.cat([a[:, :-1], torch.mean(a[:, -1:], 1).unsqueeze(-1), b[:, 1:], torch.mean(b[:, :-1], 1).unsqueeze(1)], dim=1)\nprint(result)",
        "\nresult = torch.cat([a[:, :-1], b[:, 1:], a[:, -1:]], dim=1)\n",
        "\nr = torch.stack([t,new])\nprint(r)\n",
        "\nr = torch.stack([t,new])\nprint(r)\n",
        "r = torch.stack([t,new])",
        "result = torch.bmm(data, W).squeeze() # error, want (N, 6)\nresult = result.view(10, 2, 3)"
    ]
}