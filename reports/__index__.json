[
    {
        "model_type": "fastchat",
        "model_name": "lmsys/vicuna-33b-v1.3",
        "benchmarks": [
            "lm-evaluation-harness"
        ],
        "url": "https://huggingface.co/lmsys/vicuna-33b-v1.3",
        "short_name": "Vicuna 33B V1.3"
    },
    {
        "model_type": "fastchat",
        "model_name": "lmsys/vicuna-7b-v1.3",
        "benchmarks": [
            "lm-evaluation-harness"
        ],
        "url": "https://huggingface.co/lmsys/vicuna-7b-v1.3",
        "short_name": "Vicuna 7B V1.3"
    },
    {
        "model_type": "chatml",
        "model_name": "mosaicml/mpt-7b-chat",
        "benchmarks": [
            "lm-evaluation-harness"
        ],
        "url": "https://huggingface.co/mosaicml/mpt-7b-chat",
        "short_name": "MPT-7B-Chat"
    },
    {
        "model_type": "base",
        "model_name": "mosaicml/mpt-30b",
        "benchmarks": [
            "lm-evaluation-harness"
        ],
        "url": "https://huggingface.co/mosaicml/mpt-30b",
        "short_name": "MPT-30B"
    },
    {
        "model_type": "chatml",
        "model_name": "mosaicml/mpt-30b-chat",
        "benchmarks": [
            "lm-evaluation-harness"
        ],
        "url": "https://huggingface.co/mosaicml/mpt-30b-chat",
        "short_name": "MPT-30B-Chat"
    },
    {
        "model_type": "openai",
        "model_name": "gpt-3.5-turbo-0613",
        "benchmarks": [],
        "short_name": "GPT-3.5-Turbo-0613"
    },
    {
        "model_type": "falcon-instruct",
        "model_name": "tiiuae/falcon-7b-instruct",
        "benchmarks": [
            "lm-evaluation-harness"
        ],
        "url": "https://huggingface.co/tiiuae/falcon-7b-instruct",
        "short_name": "Falcon-7B-Instruct"
    },
    {
        "model_type": "falcon-instruct",
        "model_name": "tiiuae/falcon-7b",
        "benchmarks": [
            "lm-evaluation-harness"
        ],
        "url": "https://huggingface.co/tiiuae/falcon-7b",
        "short_name": "Falcon-7B"
    },
    {
        "model_type": "open-assistant",
        "model_name": "OpenAssistant/oasst-sft-1-pythia-12b",
        "benchmarks": [
            "lm-evaluation-harness"
        ],
        "url": "https://huggingface.co/OpenAssistant/oasst-sft-1-pythia-12b",
        "short_name": "Open-Assistant Pythia-12B SFT-1"
    },
    {
        "model_type": "open-assistant",
        "model_name": "OpenAssistant/pythia-12b-sft-v8-7k-steps",
        "benchmarks": [
            "lm-evaluation-harness"
        ],
        "url": "https://huggingface.co/OpenAssistant/pythia-12b-sft-v8-7k-steps",
        "short_name": "Open-Assistant Pythia-12B SFT-8"
    },
    {
        "model_type": "alpaca-without-prefix",
        "model_name": "NousResearch/Nous-Hermes-13b",
        "benchmarks": [
            "lm-evaluation-harness"
        ],
        "url": "https://huggingface.co/NousResearch/Nous-Hermes-13b",
        "short_name": "Nous-Hermes-13B"
    },
    {
        "model_type": "alpaca-with-prefix",
        "model_name": "WizardLM/WizardCoder-15B-V1.0",
        "benchmarks": [
            "lm-evaluation-harness"
        ],
        "url": "https://huggingface.co/WizardLM/WizardCoder-15B-V1.0",
        "short_name": "WizardCoder-15B"
    },
    {
        "model_type": "open-assistant",
        "model_name": "OpenAssistant/oasst-sft-7-llama-30b",
        "benchmarks": [
            "lm-evaluation-harness"
        ],
        "url": "https://huggingface.co/OpenAssistant/oasst-sft-7-llama-30b-xor",
        "short_name": "Open-Assistant Llama-33B SFT-7",
        "num_params": "33B"
    },
    {
        "model_type": "open-assistant",
        "model_name": "OpenAssistant/oasst-sft-7e3-llama-30b",
        "benchmarks": [
            "lm-evaluation-harness"
        ],
        "short_name": "Open-Assistant Llama-33B SFT-7e3",
        "num_params": "33B"
    },
    {
        "model_type": "open-assistant",
        "model_name": "OpenAssistant/llama-30b-sft-v8-2.5k-steps",
        "benchmarks": [
            "lm-evaluation-harness"
        ],
        "short_name": "Open-Assistant Llama-33B SFT-8",
        "num_params": "33B"
    },
    {
        "model_type": "open-assistant",
        "model_name": "OpenAssistant/oasst-rlhf-3-llama-30b-5k-steps",
        "benchmarks": [
            "lm-evaluation-harness"
        ],
        "short_name": "Open-Assistant Llama-33B RLHF-3",
        "num_params": "33B"
    },
    {
        "model_type": "falcon-instruct",
        "model_name": "tiiuae/falcon-40b",
        "benchmarks": [
            "lm-evaluation-harness"
        ],
        "url": "https://huggingface.co/tiiuae/falcon-40b",
        "short_name": "Falcon-40B"
    },
    {
        "model_type": "falcon-instruct",
        "model_name": "tiiuae/falcon-40b-instruct",
        "benchmarks": [
            "lm-evaluation-harness"
        ],
        "url": "https://huggingface.co/tiiuae/falcon-40b-instruct",
        "short_name": "Falcon-40B-Instruct"
    },
    {
        "model_type": "open-assistant",
        "model_name": "OpenAssistant/falcon-40b-sft-top1-560",
        "benchmarks": [
            "lm-evaluation-harness"
        ],
        "url": "https://huggingface.co/OpenAssistant/falcon-40b-sft-top1-560",
        "short_name": "Open-Assistant Falcon-40B SFT-Top1"
    },
    {
        "model_type": "open-assistant",
        "model_name": "OpenAssistant/falcon-40b-sft-mix-1226",
        "benchmarks": [
            "lm-evaluation-harness"
        ],
        "url": "https://huggingface.co/OpenAssistant/falcon-40b-sft-mix-1226",
        "short_name": "Open-Assistant Falcon-40B SFT-Mix"
    },
    {
        "model_type": "guanaco",
        "model_name": "timdettmers/guanaco-65b-merged",
        "benchmarks": [
            "lm-evaluation-harness"
        ],
        "url": "https://huggingface.co/timdettmers/guanaco-65b-merged",
        "short_name": "Guanaco-65B"
    },
    {
        "model_type": "openai",
        "model_name": "gpt-3.5-turbo-0301",
        "benchmarks": [],
        "short_name": "GPT-3.5-Turbo-0301"
    }
]
