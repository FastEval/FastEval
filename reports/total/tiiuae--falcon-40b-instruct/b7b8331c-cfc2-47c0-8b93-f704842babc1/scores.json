{
    "cot": 0.11851145510835914,
    "human-eval-plus": 0.11585365853658534,
    "lm-evaluation-harness": 72.67046958408486,
    "mt-bench": 5.2125,
    "ds1000": 0.07372348099719166,
    "code": 0.0912777216386057,
    "total": 27.307077703227467
}