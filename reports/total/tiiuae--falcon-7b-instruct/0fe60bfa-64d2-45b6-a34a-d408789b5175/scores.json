{
    "cot": 0.07220227038183695,
    "human-eval-plus": 0.004065040650406503,
    "lm-evaluation-harness": 62.499676950878346,
    "mt-bench": 3.875,
    "ds1000": 0.011485957742804974,
    "code": 0.05036345372583366,
    "total": 18.300735548649467
}