{
    "cot": 0.28311826625387,
    "human-eval-plus": 0.1951219512195122,
    "lm-evaluation-harness": 71.30944751863265,
    "mt-bench": 6.19375,
    "ds1000": 0.1141170955615981,
    "code": 0.14786911875239564,
    "total": 38.516116435196814
}