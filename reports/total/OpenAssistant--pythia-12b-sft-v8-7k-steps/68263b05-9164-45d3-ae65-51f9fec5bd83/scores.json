{
    "cot": 0.09388854489164088,
    "human-eval-plus": 0.09756097560975609,
    "lm-evaluation-harness": 60.300566158762216,
    "mt-bench": 5.115625,
    "ds1000": 0.0506891487576144,
    "code": 0.06826608382716753,
    "total": 27.10298364927582
}