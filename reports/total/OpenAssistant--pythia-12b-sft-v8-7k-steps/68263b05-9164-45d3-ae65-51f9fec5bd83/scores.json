{
    "cot": 0.09388854489164088,
    "human-eval-plus": 0.09756097560975609,
    "lm-evaluation-harness": 60.300566158762216,
    "mt-bench": 5.115625,
    "ds1000": 0.0506891487576144,
    "code": 0.42131445967604064,
    "total": 25.527745454803235
}