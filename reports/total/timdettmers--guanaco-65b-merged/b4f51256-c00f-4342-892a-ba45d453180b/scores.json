{
    "cot": 0.2814105263157895,
    "human-eval-plus": 0.2113821138211382,
    "lm-evaluation-harness": 73.92421116065573,
    "mt-bench": 6.634375,
    "ds1000": 0.12064755505263096,
    "code": 0.9507217272370538,
    "total": 40.47116585631664
}