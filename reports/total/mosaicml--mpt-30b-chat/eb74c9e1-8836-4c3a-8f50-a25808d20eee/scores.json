{
    "cot": 0.2490142414860681,
    "human-eval-plus": 0.2865853658536585,
    "lm-evaluation-harness": 69.44732636040673,
    "mt-bench": 6.453125,
    "ds1000": 0.08910972854497977,
    "code": 0.1713912440902626,
    "total": 38.89040255166475
}