{
    "cot": 0.2893135190918473,
    "human-eval-plus": 0.20528455284552843,
    "lm-evaluation-harness": 72.42375634168857,
    "mt-bench": 6.384375,
    "ds1000": 0.10970958105687616,
    "code": 0.1495324859688146,
    "total": 39.54156635055806
}