{
    "cot": 0.18350918472652222,
    "human-eval-plus": 0.18292682926829265,
    "lm-evaluation-harness": 68.47612759800032,
    "mt-bench": 6.6625,
    "ds1000": 0.06543577463578648,
    "code": 0.6863422843959843,
    "total": 36.00169978773874
}