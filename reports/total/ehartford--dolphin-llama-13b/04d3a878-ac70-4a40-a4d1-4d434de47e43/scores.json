{
    "cot": 0.30397069143446853,
    "human-eval-plus": 0.12804878048780485,
    "lm-evaluation-harness": 67.124991538381,
    "mt-bench": 6.0375,
    "ds1000": 0.036000150229840704,
    "code": 0.07051838657657726,
    "total": 39.37091204007185
}