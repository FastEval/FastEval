{
    "cot": 0.13232156862745098,
    "human-eval-plus": 0.17682926829268292,
    "lm-evaluation-harness": 64.76078622321252,
    "mt-bench": 5.340625,
    "ds1000": 0.05626172481508391,
    "code": 0.10147455361918355,
    "total": 30.162684052712148
}