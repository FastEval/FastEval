{
    "cot": 0.1580140350877193,
    "human-eval-plus": 0.09349593495934959,
    "lm-evaluation-harness": 65.83317088393866,
    "mt-bench": 6.109375,
    "ds1000": 0.037135458684589465,
    "code": 0.05827063728762451,
    "total": 33.759060282347704
}