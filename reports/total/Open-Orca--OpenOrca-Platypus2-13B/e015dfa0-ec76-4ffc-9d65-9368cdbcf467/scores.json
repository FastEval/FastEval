{
    "cot": 0.26356284829721366,
    "human-eval-plus": 0.13008130081300812,
    "lm-evaluation-harness": 72.2162197347262,
    "mt-bench": 6.49375,
    "ds1000": 0.062432160550323634,
    "code": 0.09061930232644218,
    "total": 37.638125794534304
}