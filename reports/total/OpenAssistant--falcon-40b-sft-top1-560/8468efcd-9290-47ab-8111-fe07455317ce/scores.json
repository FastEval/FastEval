{
    "cot": 0.19117110423116615,
    "human-eval-plus": 0.1382113821138211,
    "lm-evaluation-harness": 73.94864990263017,
    "mt-bench": 6.303125,
    "ds1000": 0.11188044305285212,
    "code": 0.12285166766158921,
    "total": 35.04309977620012
}