{
    "cot": 0.2707240454076367,
    "human-eval-plus": 0.1260162601626016,
    "lm-evaluation-harness": 70.35287686850494,
    "mt-bench": 6.965625,
    "ds1000": 0.0953057332836834,
    "code": 0.1081017861498993,
    "total": 40.2030085022725
}