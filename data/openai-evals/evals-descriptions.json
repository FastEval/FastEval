{
    "aba_mrpc_true_false.dev.v0": null,
    "aime_evaluation.dev.v0": "Test the model's ability to solve math problems from the AIME competition.",
    "actors-sequence.dev.match-v1": "Evaluate multiple actor output, sequence following, tokenization, logic ability",
    "algebra-word-problems.s1.simple-v0": "Test the model's ability to perform basic algebra word problems",
    "anagrams.test.v1": null,
    "balance-chemical-equation.dev.v0": null,
    "match_banking77.test.v1": null,
    "belarusian-lexicon.dev.v0": "Test the model's ability to distinguish between existing and hallucinated Belarusian words.",
    "bigrams.dev.v0": null,
    "bitwise.dev.v0": "Test the model's ability to simulate a simple bitwise operating machine",
    "born-first.dev.v0": "Test the model's ability to determine who was born first.",
    "brazilian-lexicon.dev.v0": "Test the model's ability to distinguish between existing Brazilian words.",
    "bulgarian-lexicon.dev.v0": "Test the model's ability to distinguish between existing and hallucinated Bulgarian words.",
    "categorize-with-distractors.dev.v0": "Test the model's ability to select from a list of nouns (or proper nouns), only those belonging to a specific classification, where one of the nouns of said classification is preceded by one or more distractors from a different classification",
    "chess-piece-count.s1.simple-v0": "Test the model's ability to understand chess moves, rules and theory",
    "chess.match.dev.v0": "Test the model's ability to play chess",
    "compare-countries-area.dev.v0": "Test the model's ability to determine which country has the largest area.",
    "complex-replace-characters.dev.v0": null,
    "connect4.s1.v1": null,
    "convert-hex-hsl-lightness.dev.v0": "Eval that checks ability to convert a color represented as a hex code to HSL accurately.",
    "coqa-match.dev.v0": null,
    "coqa-fact.dev.v0": null,
    "coqa-fact-expl.dev.v0": null,
    "coqa-closedqa-correct.dev.v0": null,
    "coqa-closedqa-relevance.dev.v0": null,
    "coqa-closedqa-conciseness.dev.v0": null,
    "crepe.dev.v2": null,
    "cube-pack.dev.v0": null,
    "decrypt-caesar-cipher.dev.v0": null,
    "determinant.test.v1": null,
    "diagrammatic_logic.dev.v2": null,
    "dice-rotation-sequence.dev.v0": "Test the model's ability to follow simple rotations of a 6-sided die, and determine the number on the front face after a series of rotations.",
    "dutch-lexicon.dev.v0": "Test the model's ability to distinguish between existing and often misspelled and hallucinated Dutch words.",
    "emoji-riddle.s1.simple-v0": "Test the model's ability to solve emoji riddles.",
    "emotional-intelligence.dev.v0": "Test the AI's ability to understand and manage emotional situations, using modified items from the well-validated STEU and STEM (MacCann & Roberts, 2008).",
    "escher-sentences.dev.v0": null,
    "fcc_amateur_extra.dev.v0": "Multiple choice questions (with answers) about from the US FCC Amateur Radio License question pool.",
    "finance.dev.v0": "Test the model's ability to understand financial concepts and do math.",
    "first-letters.dev.v0": null,
    "formal-logic.dev.v0": "Test the model's ability to evaluate expressions in formal logic.",
    "forth-stack-sim.dev.v0": "Test the model's ability to simulate a simple forth stack machine",
    "forth-stack-sim-basic.dev.v0": "Test the model's ability to simulate a simple forth stack machine with a basic explanation",
    "forth-stack-sim-detailed.dev.v0": "Test the model's ability to simulate a simple forth stack machine with a detailed explanation",
    "greek-vocabulary.dev.v0": null,
    "heart-disease.v0": "Test model's capability of predicting the presence of heart disease.",
    "hebrew-rhyme.v0": "Composite task that involves translation and rhyming.",
    "hindi_upsc.dev.v0": null,
    "illinois-law.v0": "Test model's capability of predicting the verdict on several Illinois law cases.",
    "imperial_date_to_string.dev.v0": null,
    "infiniteloop-match.s1.simple-v0": "Test the model's ability to recognized if a piece of code can get into a state where it would run forever.",
    "invoices.dev.v0": "Test the model's ability to parse real-world data, with an emphasis on numerical data",
    "japanese-national-medical-exam01.dev.v0": null,
    "japanese_driving_license.s1.simple-v0": "Test the model's ability to correctly answer Japanese Driving licence exam.",
    "job_listing_title_for_a_caregiver_in_japan.test.v1": "Test to identify the job listing title for a caregiver in Japan.",
    "knot-theory-unknotting-problem.dev.v0": null,
    "knot-theory-code-conversion.dev.v0": null,
    "knot-theory-unknotting-number.dev.v0": null,
    "hellaswag.val.ab-v1": null,
    "lambada.oaitest.v1": null,
    "last-word-nth.s1.simple-v0": "Test the model's ability to tell what the last word of a sentence is, but by asking it indirectly based on its index.",
    "lat_long_identify.dev.v0": null,
    "logic-liar-paradox.dev.v0": "An array of Liar Paradox-based evals, examining the model's proficiency in navigating linguistic nuances and logical reasoning within self-referential statements.",
    "logic-statements.dev.v0": null,
    "logic-fact.dev.v0": null,
    "logiqa.dev.v0": null,
    "loss-logic-fact.dev.v0": null,
    "manga-translation-page.dev.v0": null,
    "manga-translation-panel.dev.v0": null,
    "manga-translation-bubble.dev.v0": null,
    "map-electronic-component-part-to-fact.dev.v0": null,
    "medmcqa.dev.v0": null,
    "mendelian_inheritance.dev.v0": null,
    "mmlu-abstract-algebra.val.ab-v1": null,
    "mmlu-anatomy.val.ab-v1": null,
    "mmlu-astronomy.val.ab-v1": null,
    "mmlu-business-ethics.val.ab-v1": null,
    "mmlu-clinical-knowledge.val.ab-v1": null,
    "mmlu-college-biology.val.ab-v1": null,
    "mmlu-college-chemistry.val.ab-v1": null,
    "mmlu-college-computer-science.val.ab-v1": null,
    "mmlu-college-mathematics.val.ab-v1": null,
    "mmlu-college-medicine.val.ab-v1": null,
    "mmlu-college-physics.val.ab-v1": null,
    "mmlu-computer-security.val.ab-v1": null,
    "mmlu-conceptual-physics.val.ab-v1": null,
    "mmlu-econometrics.val.ab-v1": null,
    "mmlu-electrical-engineering.val.ab-v1": null,
    "mmlu-elementary-mathematics.val.ab-v1": null,
    "mmlu-formal-logic.val.ab-v1": null,
    "mmlu-global-facts.val.ab-v1": null,
    "mmlu-high-school-biology.val.ab-v1": null,
    "mmlu-high-school-chemistry.val.ab-v1": null,
    "mmlu-high-school-computer-science.val.ab-v1": null,
    "mmlu-high-school-european-history.val.ab-v1": null,
    "mmlu-high-school-geography.val.ab-v1": null,
    "mmlu-high-school-government-and-politics.val.ab-v1": null,
    "mmlu-high-school-macroeconomics.val.ab-v1": null,
    "mmlu-high-school-mathematics.val.ab-v1": null,
    "mmlu-high-school-microeconomics.val.ab-v1": null,
    "mmlu-high-school-physics.val.ab-v1": null,
    "mmlu-high-school-psychology.val.ab-v1": null,
    "mmlu-high-school-statistics.val.ab-v1": null,
    "mmlu-high-school-us-history.val.ab-v1": null,
    "mmlu-high-school-world-history.val.ab-v1": null,
    "mmlu-human-aging.val.ab-v1": null,
    "mmlu-human-sexuality.val.ab-v1": null,
    "mmlu-international-law.val.ab-v1": null,
    "mmlu-jurisprudence.val.ab-v1": null,
    "mmlu-logical-fallacies.val.ab-v1": null,
    "mmlu-machine-learning.val.ab-v1": null,
    "mmlu-management.val.ab-v1": null,
    "mmlu-marketing.val.ab-v1": null,
    "mmlu-medical-genetics.val.ab-v1": null,
    "mmlu-miscellaneous.val.ab-v1": null,
    "mmlu-moral-disputes.val.ab-v1": null,
    "mmlu-moral-scenarios.val.ab-v1": null,
    "mmlu-nutrition.val.ab-v1": null,
    "mmlu-philosophy.val.ab-v1": null,
    "mmlu-prehistory.val.ab-v1": null,
    "mmlu-professional-accounting.val.ab-v1": null,
    "mmlu-professional-law.val.ab-v1": null,
    "mmlu-professional-medicine.val.ab-v1": null,
    "mmlu-professional-psychology.val.ab-v1": null,
    "mmlu-public-relations.val.ab-v1": null,
    "mmlu-security-studies.val.ab-v1": null,
    "mmlu-sociology.val.ab-v1": null,
    "mmlu-us-foreign-policy.val.ab-v1": null,
    "mmlu-virology.val.ab-v1": null,
    "mmlu-world-religions.val.ab-v1": null,
    "moral_exceptQA.test.v1": "This eval tests the models ability to align with human intuition on when is it acceptable to break an established moral norm.",
    "multi-step-equations.dev.v0": null,
    "naughty_strings.test.v1": null,
    "naughty_strings_fuzzy.test.v1": null,
    "naughty_strings_graded.test.v1": null,
    "naughty_strings_graded_meta.test.v1": null,
    "number-pattern.dev.v0": null,
    "number-reading.dev.v0": "Test the model's ability to translate chinese written number into arabic numerals.",
    "partially_solved_crossword_clues.dev.v0": null,
    "pattern_identification.dev.v0": null,
    "ph-calculation.dev.v0": "Test the model's ability to apply basic mathematics to chemistry problems.",
    "hand_ranks.test.v1": null,
    "positive-binary-operations.test.v1": null,
    "qa.dev.v0": "Tests the model's ability to correctly answer a question when the answer of the question is relocated in a great deal of context.",
    "regex.match.dev.v0": null,
    "reverse-string.s1.simple-v0": "Test the model's ability to reverse complex and simple strings.",
    "rot13.s1.simple-v0": "Test the model's ability to perform the simple ROT13 character level operation.",
    "rucola.test.v0": ".",
    "russe.test.v0": "Russian Word-in-Context dataset. Russian Word-in-Context dataset. Detect whether a word has the same meaning in both sentences or not.",
    "russian-nlp-tasks.dev.v0": null,
    "russian-rhyme.v0": "Composite task that involves translation and rhyming.",
    "russian_medical.dev.v0": null,
    "sarcasm.test.v1": "An evaluation on sarcasm detection.",
    "simple-knowledge-mongolian.dev.v0": "Test the model's ability to understand simple world knowledge in mongolian language cyrillic and latin variants",
    "sort-numbers.s1.simple-v0": "Tests performance sorting different comma-separated values under different circumstances (integers/decimals, positives/negatives, as well as currency-formatted values).",
    "spider-sql.dev.v0": "Eval that scores SQL code from 194 examples in the Spider Text-to-SQL test dataset. The problems are selected by taking the first 10 problems for each database that appears in the test set. Yu, Tao, et al. \\\"Spider; A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task.\\\" Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, 2018, https://doi.org/10.18653/v1/d18-1425.",
    "stock-options-bear-call-spread.dev.v0": "Test the model's ability to interpret stock option trading positions.",
    "stock-options-bull-call-spread.dev.v0": "Test the model's ability to interpret stock option trading positions.",
    "stock-options-iron-butteryfly-spread.dev.v0": "Test the model's ability to interpret stock option trading positions.",
    "stock-options-inverse-iron-butterfly-spread.dev.v0": "Test the model's ability to interpret stock option trading positions.",
    "stock-options-iron-condor-spread.dev.v0": "Test the model's ability to interpret stock option trading positions.",
    "stock-options-inverse-iron-condor-spread.dev.v0": "Test the model's ability to interpret stock option trading positions.",
    "stock-option-terms-bear-call-spread.dev.v0": "Test the model's ability to interpret stock option trading positions.",
    "stock-option-terms-bull-call-spread.dev.v0": "Test the model's ability to interpret stock option trading positions.",
    "stock-option-terms-iron-butterfly-spread.dev.v0": "Test the model's ability to interpret stock option trading positions.",
    "stock-option-terms-inverse-iron-butteryfly-spread.dev.v0": "Test the model's ability to interpret stock option trading positions.",
    "stock-option-terms-iron-condor-spread.dev.v0": "Test the model's ability to interpret stock option trading positions.",
    "stock-option-terms-inverse-iron-condor-spread.dev.v0": "Test the model's ability to interpret stock option trading positions.",
    "svg_understanding.v0": "Test visual understanding of SVG files.",
    "swedish-spelling.dev.v0": "Test the model's ability to identify misspelled Swedish words.",
    "taxes.dev.v0": null,
    "tempo_to_measure_count.dev.v0": "Test the model's ability to calculate the number of measures in a song, based on the tempo of each note and the corresponding time signature of the piece.",
    "test-match.s1.simple-v0": "Example eval that checks sampled text matches the expected output.",
    "test-fuzzy-match.s1.simple-v0": "Example eval that uses fuzzy matching to score completions.",
    "test-includes.s1.simple-v0": "Example eval that uses fuzzy matching to score completions.",
    "test-includes-ignore-case.s1.simple-v0": "Example eval that uses fuzzy matching to score completions.",
    "computer-science-problems.s1.simple-v0": "Testing the models ability to answer multiple choice computer science questions correctly.",
    "joke-animals-vs-fruits.dev.v0": null,
    "rap-people-vs-people.dev.v0": null,
    "rap-animals-vs-fruits.dev.v0": null,
    "rap-people-vs-fruits.dev.v0": null,
    "mg-humor-people_jp.dev.v0": null,
    "joke-fruits.dev.v0": null,
    "joke-fruits-v2.dev.v0": null,
    "joke-fruits-likert.dev.v0": null,
    "joke-fruits-meta.dev.v0": null,
    "joke-fruits-expl-meta.dev.v0": null,
    "joke-fruits-ans-meta.dev.v0": null,
    "diversity.dev.v0": null,
    "best.dev.v0": null,
    "three-pt-mapping.dev.v0": "Test the model's ability to calculate gene positions given a three-point cross using the laws of genetics",
    "ukraine-eit.val.v0": null,
    "unified-patch.dev.v0": null,
    "us-tort-law.dev.v0": "Multiple choice questions (with answers) about United States tort law.",
    "utility_price_parsing.dev.v0": null,
    "which-is-heavier.dev.v0": "Test the model's ability to determine which of two quantities is heavier when the heavier quantity is made up of lighter objects (and vice versa).",
    "2d_movement.dev.v0": "Test the model's ability to keep track of position and orientation in a 2D environment.",
    "3d_globe_movement.dev.v0": "Test the model's ability to keep track of position and orientation in a 3D environment, using the globe of planet earth as the test environment.",
    "3d_object_manipulation.dev.v0": "This evaluation attempts to calculate the location of a generic 3D object in space given an initial location, a rotation angle, and a translation.",
    "Chinese_character_riddles.dev.v0": "Test the model's capability to deeply understand Chinese characters, Chinese language and Chinese culture.",
    "GPT-model-text-detection.dev.v0": "Evaluation of AI's ability to distinguish between human-written and AI-generated text.",
    "Unfamiliar-Chinese-Character.dev.v0": null,
    "abstract-causal-reasoning-text.dev.v0": "Evaluate the abstract causal reasoning abilities of the model on a text version of the ACRE (Abstract Causal REasoning beyond covariation) dataset.",
    "abstract-causal-reasoning-symbolic.dev.v0": "Evaluate the abstract causal reasoning abilities of the model on a symbolic version of the ACRE (Abstract Causal REasoning beyond covariation) dataset.",
    "abstract2title.test.v1": "Test the model's ability to generate proper title using the abstract section of the literature.",
    "accounting_audit.dev.v0": null,
    "adultery_state_laws.dev.v0": "This evaluation checks the model's ability to accurately answer true or false questions about adultery laws in various states.",
    "arc.dev.v0": null,
    "afrikaans-lexicon.dev.v0": "Test the model's ability to distinguish between existing Afrikaans words.",
    "allergen-information.dev.v0": "Test the model's ability to identify the allergen information of different food products in the israeli market.",
    "alternate_numeral_systems.dev.v0": "Test the model's ability to convert base 10 numbers into alternate numeral systems.",
    "ambiguous-sentences.dev.v0": "test pair of sentences that differ in only one or two words and that contain an ambiguity that is resolved in opposite ways in the two sentences and requires the use of world knowledge and reasoning for its resolution.",
    "arithmetic-expression.dev.v0": "Tests the model's ability to generate arithmetic expressions that evaluate to a given number.",
    "arithmetic-expression-meta.dev.v0": "Tests the model's ability to evaluate submissions against the correct answer",
    "arithmetical_puzzles.dev.v0": "Test the model's ability to solve complex arithmetical puzzles stated in natural language.",
    "ascii-digit-recognition.dev.v0": "Evaluate ASCII digit recognition ability",
    "ascii-wordart.dev.v0": "Check the model's ability to identify ASCII art that represents words.",
    "asl-classifiers.dev.v0": "Test the model's ability to understand the usage of ASL classifiers.",
    "astro_eval.dev.v0": "This evaluation tries to predict planetary routes according to their repetitive trajectories in a specific time and location",
    "atpl_exams.dev.v0": null,
    "automata-and-complexity.dev.v0": "Test the model's ability to answer true/false questions relating to theoretical computer science concepts.",
    "backgammon-can-hit.dev.v0": "Evaluate if a checker can be hit given the a board state and a dice roll.",
    "backgammon-illegal-move.dev.v0": "Evaluate if the the given move is illegal given a board state, a dice roll and a suggested play.",
    "base64-decode-simple.dev.v0": "Test the model's ability to decode Base64 encoded text.",
    "beam.analysis.dev.v0": "Test the model's ability to solve beam analysis questions",
    "belarusian-grammar.dev.v0": "Test the model's ability to distinguish between grammatically well-formed and ungrammatical Belarusian sentences.",
    "belarusian-numerals.dev.v0": "Test the model's ability to convert Belarusian numerals to numbers.",
    "belarusian-orthography.dev.v0": "Test the model's ability to switch between classical and modern orthographies of Belarusian.",
    "belarusian-proverbs.dev.v0": "Test the model's ability to complete proverbs in belarusian language",
    "belarusian-rhyme.dev.v0": "Test the model's ability to find rhyming words in Belarusian.",
    "belarusian-russian-translation.dev.v0": "Test the model's ability to recover Belarusian sentences by translating into Russian and back.",
    "belarusian-syllable-count.dev.v0": "Test the model's ability to count syllables in Belarusian words.",
    "belarusian-synonyms.dev.v0": "Test the model's ability to classify if the Belarusian words are synonyms or not.",
    "belarusian-word-analogy-inflection.dev.v0": "Test the model's ability to solve word analogy problems in the domain of Belarusian inflectional morphology.",
    "benjaminmoore_to_hex.dev.v0": null,
    "bias_detection.dev.v0": "Test the model's ability to classify sentences in news as \"fact\", \"opinion\", \"claim\", \"argument\", \"data\", \"quote\", \"narrative\", \"sensationalism\", or \"speculation\".",
    "blackfoot-numerals-modern.dev.v0": "Test the model's ability to convert Blackfoot numerals from the modern roman-based orthography to numbers.",
    "body-movement.dev.zero_shot_v0": "Test the model's ability to understand human body movement",
    "brazilian_laws.test.v1": null,
    "building_floorplan.test.v1": null,
    "canto_wu_pronunciation.dev.v0": "Test the model's knowledge of Cantonenese and Wu Chinese pronounciation in a zero-shot setting",
    "canto_wu_pronunciation_fewshot.dev.v0": "Test the model's knowledge of Cantonenese and Wu Chinese pronounciation in a few-shot setting",
    "cardinal-directions.dev.v0": null,
    "chinese-lantern-riddles.dev.v0": "Test the model's ability to solve Chinese lantern riddles.",
    "chinese-remainder-theorem.dev.v0": "Test the model's ability to solve systems of congruences with the Chinese remainder theorem.",
    "chinese_ancient_masterpieces_dynasty.dev.v0": "Identify the dynasty of Chinese ancient masterpieces",
    "chinese_ancient_poetry.dev.v0": "Evaluate the model's capability to answer the title and author of the given poems.",
    "chinese_chu_ci.dev.v0": "Given a Chinese Chu Ci content, return the name of it.",
    "chinese_famous_novel.dev.v0": "Given a Chinese famous novel, return the author of it.",
    "chinese_hard_translations.dev.v0": "Evaluate the model's ability of understanding hard-to-understand Chinese sentences.",
    "chinese_homonym.dev.v0": "Check the model's ability to recognize Chinese homonyms, which are words that have the same pronunciation (H\u00e0ny\u01d4 P\u012bny\u012bn) but different meanings.",
    "chinese-homophonic.dev.v0": "Example eval that checks sampled text matches the expected output.",
    "chinese_idioms.dev.v0": "Check the model's ability to recognize Chinese idioms, which are words have different meanings with its original meaning.",
    "chinese_modern_poem_identification.test.v1": null,
    "chinese_poem.dev.v0": null,
    "chinese_shi_jing.test.v1": null,
    "chinese_song_ci.dev.v0": null,
    "chinese_tang_poetries.dev.match-v1": "Evaluate the mobel's ability of identifying the accurate author of Chinese Tang Poetries.",
    "chinese_zodiac.dev.v0": null,
    "cissp-study-questions.test.v1": null,
    "co-sql.dev.v0": "Evaluates performance on a 100 samples of the CoSQL dataset, a conversational version of Text-to-SQL tasks. Each conversation simulates a real-world DB scenario where a user asks NLP questions and a SQL expert retrieves answers in response. Yu, Tao, et al. \\\"CoSQL A Conversational Text-to-SQL Challenge Towards Cross-Domain Natural Language Interfaces to Databases\\\" https://arxiv.org/abs/1909.05378",
    "code_combination.dev.v0": "Test the model's ability to ingest code snippets (python/Javascript/C#) over multiple prompts and return the ingested code as one complete and unchanged snippet.",
    "code_progress.dev.v0": "Test the model's ability to assess whether a code block is an in-progress solution to a problem, or a completed solution. If in progress, assess whether it's on the right track.",
    "color_theory_complementary.dev.v0": "Test the model's ability to accurately recognize complementary colors in the color theory.",
    "complex-analogies-en-ru.dev.v0": null,
    "comprehensive-graph-reasoning.dev.v0": "Test the model's ability to identify the number of rings and clusters, and the shortest path between two random nodes in undirected, weighted graphs.",
    "confusing_korean.dev.v0": "Evaluates the model's ability to correctly use confusing Korean.",
    "consensus_summary.dev.v0": "Utilize the model's ability to produce a Consensus in response to a scientific inquiry.",
    "context-free-grammar.dev.v0": "Checking whether a string can be produced by a CFG",
    "convert_chinese_lower_case_num_to_num.dev.v0": "Check the model's ability to convert Chinese lower case number to numeric number.",
    "convert_num_to_chinese_lower_case_num.dev.v0": "Check the model's ability to convert numeric number to Chinese lower case number.",
    "convert_chinese_upper_case_num_to_num.dev.v0": "Check the model's ability to convert Chinese upper case number to numeric number.",
    "convert_num_to_chinese_upper_case_num.dev.v0": "Check the model's ability to convert numeric number to Chinese upper case number.",
    "coq-editing.dev.v0": "Test the model's ability to correctly diagnose Coq error messages, and interpret and edit Coq code.",
    "coq-editing-meta.dev.v0": null,
    "coq-proof-step-match.dev.v0": "Tests the model's ability to correctly predict the next proof step in Coq, given the current proof state. The proof states are generated by running Coqtop on a simple Coq tutorial (https://mathsanew.com/misc/coq_natural_numbers.html).",
    "corr2cause.dev.v0": "Test the model's ability to infer causation from correlation. Based on arXiv:2306.05836 and https://github.com/causalNLP/corr2cause.",
    "count_intersections_polynomial.dev.v0": "Test the models ability to count the intersections between the x-axis and a polynomial of third degree, with simple inputs that humans would be able to do in their head.",
    "count_token_freq_dna.dev.v0": "Test the model's ability to count the occurrence of a specific nucleotide (A, T, G, or C) within provided DNA sequences.",
    "counterfactual-reasoning-fuzzy-match.dev.simple-v0": "Example eval that uses fuzzy matching to score completions.",
    "countries.dev.v0": null,
    "cricket_situations.dev.v0": "Tests the models ability to apply rules of the sport cricket to different situations",
    "crontab.dev.v0": null,
    "csharp-linq.dev.v0": "Evaluate models knowledge of LINQ operators and deferred execution in C#",
    "css-selectors-verbal.dev.v0": "Test the model's ability to translate verbal description to css selectors",
    "css-selectors-explain.dev.v0": "Test the models ability to describe css selectors verbaly",
    "cybersecurity-filepaths.dev.v0": "Assess cybersecurity skills by identifying the malicious Windows filepath from a given collection. Experienced threat analysts over time learn to recognize the patterns of malicious filepaths, and this eval tests that ability with a set of tricky clean applications and malicious attacks that an expert human can identify.",
    "date-booking.dev.v0": null,
    "date-calculator.test.v1": null,
    "day-of-week-from-date.dev.v0": null,
    "detect-hshd.dev.v0": null,
    "dhammapada-reference.dev.v0": "Given a snippet of a Dhammapada verse in Pali, identify who the Buddha was referencing when speaking that verse.",
    "diabetes.dev.v0": null,
    "direct-speech-tag.dev.v0": null,
    "directions.dev.v0": "Eval that tests the models ability to keep state of direction after a series of turns",
    "dna-melting-calculation.dev.v0": "Test the model's ability to solve DNA melting temperature problems.",
    "dutch-rhymes.dev.v0": "Checking if two words in the Dutch rhyme",
    "euler_problems.dev.v0": "Test the model's ability to tackle Euler problems and find a result. Named after Leonhard Euler, a Swiss mathematician in the 1700's, Euler problems are complex challenging mathematical and/or logical problems to solve. Some may require complex thought process to reach a solution while others may need computational resource for which an elegant and efficient approach must be used.",
    "european-date-format-challenge.dev.v0": "This performance evaluation examines the model's ability to reasonably assume that a date in a text follows the DD/MM/YYYY format when a subsequent date in the text is invalid for the MM/DD/YYYY format (e.g., 27/2/2024).",
    "event-categories.dev.v0": "Categorize Windows Event Logs as Information, Warning, or Error",
    "finance_calc.dev.v0": "Testing the models ability to calculate and understand interest and inflation.",
    "financial-derivatives.dev.v0": "Testing the models ability to answer derivative questions correctly.",
    "find-letter.dev.v0": null,
    "find-thirukkural.dev.v0": "Accurately finds the correct Thirukkural in Tamil which the user asks for in English.",
    "find_country_from_svg.dev.v0": "Test the model's ability to distinguish a country based on its svg shape (from wikimedia svg file).",
    "finger-tracking.dev.v0": "Eval that checks ability to track a ring moving across fingers.",
    "finnish-rhyme.dev.v0": "Composite task that involves translation and rhyming.",
    "food.test.v1": null,
    "formal-grammar-to-regex.dev.v0": null,
    "french-lexicon.dev.v0": "Test the model's ability to distinguish between existing French words.",
    "french-part-of-speech.dev.v0": "Test the model's knowledge what part of speech a given word can have in French, using data from fr.wiktionary.org (as of 2023-05-20)",
    "french_homonym_and_homograph.dev.v0": "We evaluated the ability of GPT to distinguish, in the French language, between homonyms (homophones) - words that are spelled differently but have the same pronunciation - and homographs (heterophones) - words that are spelled the same but have different pronunciations.",
    "game-theory.dev.v0": "Practical reasoning about normal-form games such as Paper-Rock-Scissors",
    "gears_rotation.dev.v0": "Test the model's ability to determine the rotation of a gear given a disposition of multiple gears and the rotation of one of them.",
    "geometry_puzzle.dev.v0": "Assesses the model's performance in solving spatial and geometrical puzzles that require imagination, logic, and pattern recognition.",
    "german-part-of-speech.dev.v0": "Test the model's knowledge what part of speech a given word can have in German, using data from de.wiktionary.org (as of 2023-05-20)",
    "gol.dev.v1": "Robust test. Evaluate model's ability to determine the next state in a simple game of life board",
    "gpt-protocol-buffers.dev.v0": null,
    "greek-nt-manuscripts.v0": "Test model's capability of providing Gregory-Aland coding, symbolic sigla, and common designated century for the most important Greek Uncial manuscripts of the New Testament",
    "gregorian-to-hebrew-date.dev.v0": "The simple task of converting Gregorian dates to Hebrew dates (written in English).",
    "hebrew-bible.dev.v0": "Simple questions on the bible, similar to preliminary questions in the international yearly bible contest in Israel.",
    "guess-the-singer.dev.v0": "Test the model's ability to predict singer by the first 10 words of the song",
    "hebrew-homophones.dev.v0": "Evaluating the number of Hebrew homophone errors in a sentence.",
    "hebrew-same-noun-gender.v0": "Do these hebrew nouns have the same grammatical gender?",
    "hebrew-plurals.dev.v0": "Return the plural form for all the singular words in the sentences.",
    "hebrew_talmud_suka.dev.v0": "Simple questions on the \"suka\" part of the jewish \"talmud babli\", similar simple tests in jewish schools at 5 grade.",
    "hindi_shuddha.dev.v0": null,
    "hindi_words.dev.v0": null,
    "historical-kana-orthography-reading.dev.v0": "Test the model's ability to reading historical kana orthography.",
    "human-safety.test.v0": "An evaluation of logical reasoning about (almost) real-life situation where humans might be in danger.",
    "iambic-pentameter.dev.v0": null,
    "indonesian_numbers.dev.v0": null,
    "integer-sequence-predictions.dev.v0": null,
    "integer-sequence-predictions-notable.dev.v0": null,
    "integer-sequence-predictions-obscure.dev.v0": null,
    "integer-sequence-predictions-misc.dev.v0": null,
    "interlingual-homograph.dev.v0": "Evaluation of a model's ability to determine whether the given word is an interlingual homograph or not.",
    "internal_representations.dev.v0": null,
    "invert_word_wise.dev.v0": "Logically, inverting strings twice just results in the original string again. The LLMs find it very difficult to deduce it, and somehow (at least up to GPT-3.5) mix things up.",
    "invoice_due_date_leap_day_adjustment.dev.v0": null,
    "iqbal-poetry-translation.dev.v0": "Test the model's ability to correctly translate Iqbal's poetry into English. Translating poetry is a tricky task, and almost every translation tool fails at this.",
    "translation-meta.dev.v0": null,
    "irish-lexicon.dev.v0": "Test the model's ability to distinguish between existing and hallucinated Irish words.",
    "irish-plural-nouns.dev.v0": "Test the model's ability on Irish plural nouns in both the genitive and nominative case.",
    "irony.dev.v0": "Tests the ability to identify one of three types of irony, situational, verbal, or dramatic.",
    "japanese-remote-island-to-prefecture.dev.v0": "Testing the models ability to answer prefecture of given Japanese remote island.",
    "isosceles-right-triangle.dev.v0": null,
    "italian-new-words.dev.v0": "Test the model's ability to distinguish Italian words that have recently entered the language.",
    "italian-rhyme.v0": "Composite task that involves translation and rhyming.",
    "italian_big_math_expression.dev.v0": "This test aims to assess the model's ability to solve written mathematical expressions in Italian involving large numbers and provide the answers in written form.",
    "japanese-decimal-units.dev.v0": "Japan has its own decimal unit. Test it.",
    "japanese-itpassport-exam01.dev.v0": "source from IT\u30d1\u30b9\u30dd\u30fc\u30c8\u8a66\u9a13 \u4ee4\u548c5\u5e74\u5ea6\u5206(IT Passport Examination for FY2023) in https://www3.jitec.ipa.go.jp/JitesCbt/html/openinfo/questions.html",
    "japanese-national-medical-exam02.dev.v0": null,
    "japanese-station.dev.v0": null,
    "japanese_approval.dev.v0": "Tests for proper translation of Japanese \"\u306f\u3044\" and \"\u3044\u3044\u3048\" depending on the context.",
    "japanese_city_name_pronunciation.dev.v0": "Test the model's ability to answer the correct pronunciation of Japanese cities in hiragana(phonetic characters of Japanese).",
    "japanese_mahjong_discard_tile.dev.v0": "Test the model's ability to correctly understand the common rule of discarding tile strategy in Japanese Mahjong.",
    "japanese-number-reading.dev.v0": "Test the model's ability to translate japanese written number into arabic numerals.",
    "japanese_onomatopoeia.dev.v0": null,
    "japanese_populer_video_game_title_and_the_publisher.val.v0": "Test the model's ability to identify game publisher published popular japanese video games.",
    "jee-math.dev.v0": null,
    "json_patch_object.dev.v0": "Test the model's ability to create minimal, correct JSON Patches for nested objects.",
    "kanji-idioms.test.v0": "Test the model's ability to recognize kanji idioms.",
    "korean-consonant-vowel-combination.dev.v0": "Evaluating the model's ability to accurately combine Korean consonants and vowels to form Hangul character.",
    "korean-honorific.dev.v0": "Evaluates LLMs on classifying Korean honorific/non-honorific sentences.",
    "korean-phonetics.dev.v0": "Evaluates GPT can identify Korean words and their phonetic transcriptions.",
    "korean-postposition.dev.v0": "Evaluates GPT can identify correct postposition in a Korean sentence.",
    "korean_date_counting.dev.v0": "Test the model's understanding of Korean date counting.",
    "korean_dialects.dev.v0": "Test the model's ability to determine which South Korean dialect a sentence belongs to.",
    "korean_foreign_words.dev.v0": "Choose correctly spelled foreign words in Korean.",
    "korean_romanization.dev.v0": "Test the model's understanding of Korean Romanization Rules. Capitalization is not tested because it depends on the context. Only test whether romanization follows the standard pronunciation method of the Korean language.",
    "korean_spelling.dev.v0": null,
    "korean_yaminjeongeum.dev.v0": "Yamin-Jeongeum is a leetspeak for Korean. Test your ability to translate it to proper Korean.",
    "largest_country.dev.v0": "Determining the largest country by the area from the list",
    "latin-grammar.dev.v0": "Test the model's ability to distinguish between grammatically well-formed and ungrammatical Latin sentences.",
    "linear-equations.dev.v0": null,
    "linear-regression.dev.v0": "Tests the model's ability to run linear regressions on small datasets",
    "linear-regression-meta.dev.v0": "Tests the model's ability evaluate submissions against the correct answer",
    "list_comparison_missing_name.dev.v0": "Test the model's ability to determine which name is present in list 1 but not in list 2. List 1 is formatted 'First Last' while list two is formatted 'Last First'. Lists are between 20-35 names long.",
    "logic-container.dev.v0": "Eval that checks ability to do logical problems involving jars with water and balances.",
    "logic-grid.dev.v0": "Test the model's ability to solve grid-based logic puzzles.\nThis eval contains 90 puzzles in combinations of 3 to 4 categories and 4 to 7 unique values per category.\nThe exact cardinality combinations of categories to unique values is as follows;\n15 puzzles each for sizes 3x4, 3x5, 4x4, 4x5, 4x6, and 4x7.\n",
    "logic-riddles.dev.v0": null,
    "logic_and_probability.dev.v0": "Eval that checks ability to do logical physics and statistics questions.",
    "logical-black-scholes.test.v1": "Test the model's ability to determine an individual variables' effect on the output of the black-scholes model.",
    "logical_counting.dev.v0": null,
    "logical_reasoning_letter_series_test.dev.v0": "I have tested the model ability by giving it Logical Reasoning Questions about letter series. Where gpt-3.5-turbo accuray is 0.4.",
    "logiqa-logical-reasoning-plus.dev.v0": "logical reasoning instruction or the logiqa plus dataset",
    "logiqav2-logical-reasoning-plus.dev.v0": "logical reasoning instruction for the logiqav2 plus dataset",
    "reclor-logical-reasoning-plus.dev.v0": "logical reasoning instruction for the reclor plus dataset",
    "iso-to-lunar-calendar.dev.v0": "Test the model's ability to convert dates from ISO 8601 format into the Chinese lunar calendar.\n\nAll dates are in the future as of 2023-05-04.",
    "lunar-calendar-to-iso.dev.v0": "Test the model's ability to convert dates from the Chinese lunar calendar into ISO 8601 format, with a target Gregorian-calendar year given as a hint (the lunar calendar operates on a 60-year cycle, so this eliminates any ambiguity).\n\nAll dates are in the future as of 2023-05-04.",
    "mandaliof-table.dev.v0": "Test the model's ability to determine which atom has the largest atomic number.",
    "mapping_to_matricies.dev.v0": null,
    "marxist_philosophy_exam_simple.dev.v0": "Test the model's ability to solve Chinese Marxist Philosophy Exam.",
    "mate-in-one.dev.v0": "Find the checkmating move for various board positions",
    "math-derivatives.dev.v0": "Test the model's ability to calculate math functions derivatives.",
    "math_equations.dev.v0": "Test model's ability to explain and solve math equations described in words.",
    "math_for_5th-grader.dev.v0": "Evaluates the model's ability to solve 5th grade level math problems with slightly complicated sentences.",
    "math_logic_operations.dev.v0-1": "Evaluates the model's ability to perform mathematical operations given a redefinition of standard operation rules.",
    "math_polish.dev.v0": "Test the model's ability to solve simple math problems written in Polish language using words and respond in the same way.",
    "matrix_mult_rows.dev.v0": "Test the model's mathematical ability to infer what is needed to multiply two matrices.",
    "mazes-singlemove-3x3.test.v2": "Evaluate a model's ability to make the correct first move in a 2-dimensional 3x3 maze.",
    "mazes-singlemove-4x4.test.v2": "Evaluate a model's ability to make the correct first move in a 2-dimensional 4x4 maze.",
    "mazes-singlemove-10x10.test.v2": "Evaluate a model's ability to make the correct first move in a 2-dimensional 10x10 maze.",
    "mazes-3x3.test.v2": "Evaluate a model's ability to solve a 2-dimensional 3x3 maze to completion.",
    "mazes-4x4.test.v2": "Evaluate a model's ability to solve a 2-dimensional 4x4 maze to completion.",
    "mazes-10x10.test.v2": "Evaluate a model's ability to solve a 2-dimensional 10x10 maze to completion.",
    "medication_dose.dev.v0": "Test to model's ability to accurately identify medication doses that are outside the standard dose range.",
    "missing-operators.s1.simple-v0": "Example eval that checks sampled text matches the expected output.",
    "monthly_metric_comparison.dev.v0": "This eval tests the models ability to compare monthly metric.",
    "multistep-word-problems.dev.v0": "Test the model's ability to solve complex, multistep math word problems",
    "music-theory-chord-names.dev.v0": "Test the model's ability to identify chords from the given four notes",
    "music-theory-chord-notes.dev.v0": "Test the model's ability to spell out the notes in a given chord name",
    "music-theory-triads-identification.dev.v0": "Test the model's ability to identify triadic structures using the jazz shorthand notation",
    "music-theory-tetrads-identification.dev.v0": "Test the model's ability to identify tetradic structures using the jazz shorthand notation",
    "music_theory_scale_modes.dev.v0": "Test the model's ability to identify which western music scale a series of 8 notes belongs to",
    "nepali-numerals.dev.v0": "Test the model's ability to convert Nepali numerals to numbers.",
    "nepali-song-singer.dev": "Test the model's ability to understand English transliteration of Nepali phrase and provide us the singer of that particular title.",
    "ner_finance.dev.v0": "Named entity recognition over financial documents.",
    "newsology.dev.v0": "Ask the model to pick a fruit, when telling the model that we have provided a list of vegetables. And then vice versa (pick vegetable, from basket of fruit).",
    "next-val-series.dev.simple-v0": "Test the model's ability to predict the next value in a series.",
    "nfl-point-combinations.dev.v0": "Test the model's ability to calculate all the possible ways to for an NFL team to achieve a final score.",
    "non-compound-names.dev.v0": null,
    "non-compound-names-meta.dev.v0": null,
    "norwegian-lexicon.dev.v0": "Test the model's ability to distinguish old Norwegian words.",
    "norwegian-rhymes.dev.v0": "Test the knowledge of Norwegian Bokm\u00e5l phonetics with dictionary words that appear to rhyme but do not, or words that appear to not rhyme, but do.",
    "number_series_test.dev.v0": null,
    "numbers_game.dev.v0": "Test the model's ability to solve permutation questions",
    "numeral-type-comparisons.dev.v0": "Evaluate the LLM's ability to compare similar or identical numerals across formats in arithmetic and linguistic contexts",
    "numerical-cabbala-casanova.dev.v0": null,
    "nutrition.dev.v0": "Test the model's nutritional accuracy, providing parsable and accurate responses using metric notation when asked about specific values.",
    "ordered-history-events.dev.v0": null,
    "ordering_randomised_versionlist.dev.v0": "This evaluation aims to test prompt engineered failure cases to order a randomised version history list, but causes chronological ordering failures such as 7.5.2 -> 7.4.2 -> 7.5.1 -> 7.4.1 (incorrectly inserted 7.4.2 in between 7.5.2 and 7.5.1 in the Explainable AI chain of thoughts) and 7.5.2 -> 7.5.1 -> 7.5.0 -> 7.4.1 (incorrectly skipped over 7.4.2 in the Explainable AI chain of thoughts).",
    "override-system-instruction.dev.v0": null,
    "pantone_to_hex.dev.v0": null,
    "parable-to-moral-match-en.dev.v0": null,
    "parable-to-moral-match-zh.dev.v0": null,
    "passing-balls.dev.v0": "Tests the model's ability to correctly determine the last player holding a ball after a sequence of passes.",
    "quartz.test.v1": null,
    "pararule-plus-multi-step-deductive-reasoning.dev.v0": "multi-step deductive reasoning instruction for the PARARULE-Plus dataset",
    "path_enclosed_area.dev.v0": "Geometric calculation of the total area enclosed by a given path on a flat plane",
    "persian-kinship-riddles.dev.v0": "An evaluation set to assess the logical reasoning abilities for solving kinship riddles in Persian language",
    "phonetics-identify-words-needing-missing-gpcs.s1.simple-v0": "Identify if an input string matches the list of allowed Grapheme-Phoneme Correspondences",
    "physics.interaction.dev.v0": "Test the model's ability to predict the direction in which an object is likely to fall towards.",
    "pointer-value-retrieval-easy-few-examples.dev.v0": "Easy pointer-value retrieval task from few examples, pointer is seperated from values.",
    "pointer-value-retrieval-easy-many-examples.dev.v0": "Easy pointer-value retrieval task from many examples, pointer is separated from values.",
    "pointer-value-retrieval-medium-few-examples.dev.v0": "Medium difficulty pointer-value retrieval task from few examples, pointer targets multiple values.",
    "pointer-value-retrieval-medium-many-examples.dev.v0": "Medium difficulty pointer-value retrieval task from many examples, pointer targets multiple values.",
    "pointer-value-retrieval-hard-few-examples.dev.v0": "Hard pointer-value retrieval task from few examples, pointer hidden among values.",
    "pointer-value-retrieval-hard-many-examples.dev.v0": "Hard pointer-value retrieval task from many examples, pointer hidden among values.",
    "points-on-line.dev.v0": "Tests the model's ability to calculate three points (start, center, end) on a line.",
    "poker_analysis.test.v1": "Examine the model's capacity to strategize & make probabilistic reasoning within the framework of poker.",
    "polish-lexicon.dev.v0": "Test the model's ability to distinguish between existing and hallucinated Polish words.",
    "polish-proverbs.dev.v0": "Test the model's ability to complete proverbs in Polish language",
    "polish-syllable-count.val.v0": null,
    "polish_rhymes_generation.v0": "Generating polish rhymes.",
    "population_span_extraction.dev.v0": "The model is shown abstracts of clinical drug trials and tasked with extracting the text spans that specify the population demographic of the shown abstract. The population demographic can be but is not necessarily specified in multiple seperate spans.",
    "portuguese-kinship-riddles.dev.v0": "An evaluation of the ability to solve logical reasoning problems involving kinship relationships.",
    "portuguese-sarcasm.dev.v0": "An evaluation on sarcasm detection in Portuguese sentences",
    "portuguese-syllable-count.dev.v0": "Evaluates how many syllabels a given word has.",
    "premature-conclusions.dev.v0": "This test evaluates the model's ability to identify insufficient data and prevent premature or unsupported deductions.",
    "probabilities-word-problems.test.v1": "Test the model's ability to calculate probabilities given word problems.",
    "probability-questions.dev.v0": "A collection of probability questions that ChatGPT fails.  Let's see if GPT-4 can do better.",
    "match_product-matching_fewshot.dev.v1": "Evaluate LLM performance on the task of Product Matching (pair-wise binary classification). Examples are a subsample of the WDC Products 80cc20rnd000un validation set. This is the few-shot version with 10 negative and 10 positive demonstrations from the paper 'Using ChatGPT for Entity Matching' by Ralph Peeters and Christian Bizer.",
    "match_product-matching_rules.dev.v1": "Evaluate LLM performance on the task of Product Matching (pair-wise binary classification). Examples are a subsample of the WDC Products 80cc20rnd000un validation set. This is the zeroshot with rules version from the paper 'Using ChatGPT for Entity Matching' by Ralph Peeters and Christian Bizer.",
    "match_product-matching_zeroshot.dev.v1": "Evaluate LLM performance on the task of Product Matching (pair-wise binary classification). Examples are a subsample of the WDC Products 80cc20rnd000un validation set. This is the zeroshot version from the paper 'Using ChatGPT for Entity Matching' by Ralph Peeters and Christian Bizer.",
    "prompt-injection.dev.v0": "Test the model's ability to distinguish between instructions and data.",
    "proofreader.dev.v0": "Test the model ability to check text correctness without fact checking.",
    "pure_korean.dev.v0": "Evaluates GPT can identify pure Korean words.",
    "python_list_comprehension.dev.v0": "Test model's ability to understand a basic usage of python's list comprehension syntax.",
    "ral_to_hex.dev.v0": null,
    "rare-and-loanwords-dutch-lexicon.dev.v0": "Test the model's ability to distinguish between existing Dutch words, including rare words and loanwords.",
    "raven-matrices-symbolic-center-single.dev.v0": "Evaluate the abstract reasoning abilities of the model on a symbolic version of the Raven test. Matrices composed of a single centered object.",
    "raven-matrices-symbolic-distribute-four.dev.v0": "Evaluate the abstract reasoning abilities of the model on a symbolic version of the Raven test. Matrices composed of four object.",
    "raven-matrices-symbolic-distribute-nine.dev.v0": "Evaluate the abstract reasoning abilities of the model on a symbolic version of the Raven test. Matrices composed of nine object.",
    "raven-matrices-symbolic-in-center-single-out-center-single.dev.v0": "Evaluate the abstract reasoning abilities of the model on a symbolic version of the Raven test. Matrices composed of a small object inside a big object.",
    "raven-matrices-symbolic-in-distribute-four-out-center-single.dev.v0": "Evaluate the abstract reasoning abilities of the model on a symbolic version of the Raven test. Matrices composed of four small objects inside a big object.",
    "raven-matrices-symbolic-left-center-single-right-center-single.dev.v0": "Evaluate the abstract reasoning abilities of the model on a symbolic version of the Raven test. Matrices composed of two objects aligned horizontally.",
    "raven-matrices-symbolic-up-center-single-down-center-single.dev.v0": "Evaluate the abstract reasoning abilities of the model on a symbolic version of the Raven test. Matrices composed of two objects aligned vertically.",
    "raven-matrices-symbolic-open-center-single.dev.v0": "Evaluate the abstract reasoning abilities of the model on a symbolic version of the Raven test with no multiple choices provided. Matrices composed of a single centered object.",
    "raven-matrices-symbolic-open-distribute-four.dev.v0": "Evaluate the abstract reasoning abilities of the model on a symbolic version of the Raven test with no multiple choices provided. Matrices composed of four object.",
    "raven-matrices-symbolic-open-distribute-nine.dev.v0": "Evaluate the abstract reasoning abilities of the model on a symbolic version of the Raven test with no multiple choices provided. Matrices composed of nine object.",
    "raven-matrices-symbolic-open-in-center-single-out-center-single.dev.v0": "Evaluate the abstract reasoning abilities of the model on a symbolic version of the Raven test with no multiple choices provided. Matrices composed of a small object inside a big object.",
    "raven-matrices-symbolic-open-in-distribute-four-out-center-single.dev.v0": "Evaluate the abstract reasoning abilities of the model on a symbolic version of the Raven test with no multiple choices provided. Matrices composed of four small objects inside a big object.",
    "raven-matrices-symbolic-open-left-center-single-right-center-single.dev.v0": "Evaluate the abstract reasoning abilities of the model on a symbolic version of the Raven test with no multiple choices provided. Matrices composed of two objects aligned horizontally.",
    "raven-matrices-symbolic-open-up-center-single-down-center-single.dev.v0": "Evaluate the abstract reasoning abilities of the model on a symbolic version of the Raven test with no multiple choices provided. Matrices composed of two objects aligned vertically.",
    "raven-matrices-text-center-single.dev.v0": "Evaluate the abstract reasoning abilities of the model on a text version of the Raven test. Matrices composed of a single centered object.",
    "raven-matrices-text-distribute-four.dev.v0": "Evaluate the abstract reasoning abilities of the model on a text version of the Raven test. Matrices composed of four object.",
    "raven-matrices-text-distribute-nine.dev.v0": "Evaluate the abstract reasoning abilities of the model on a text version of the Raven test. Matrices composed of nine object.",
    "raven-matrices-text-in-center-single-out-center-single.dev.v0": "Evaluate the abstract reasoning abilities of the model on a text version of the Raven test. Matrices composed of a small object inside a big object.",
    "raven-matrices-text-in-distribute-four-out-center-single.dev.v0": "Evaluate the abstract reasoning abilities of the model on a text version of the Raven test. Matrices composed of four small objects inside a big object.",
    "raven-matrices-text-left-center-single-right-center-single.dev.v0": "Evaluate the abstract reasoning abilities of the model on a text version of the Raven test. Matrices composed of two objects aligned horizontally.",
    "raven-matrices-text-up-center-single-down-center-single.dev.v0": "Evaluate the abstract reasoning abilities of the model on a text version of the Raven test. Matrices composed of two objects aligned vertically.",
    "raven-matrices-text-open-center-single.dev.v0": "Evaluate the abstract reasoning abilities of the model on a text version of the Raven test with no multiple choices provided. Matrices composed of a single centered object.",
    "raven-matrices-text-open-distribute-four.dev.v0": "Evaluate the abstract reasoning abilities of the model on a text version of the Raven test with no multiple choices provided. Matrices composed of four object.",
    "raven-matrices-text-open-distribute-nine.dev.v0": "Evaluate the abstract reasoning abilities of the model on a text version of the Raven test with no multiple choices provided. Matrices composed of nine object.",
    "raven-matrices-text-open-in-center-single-out-center-single.dev.v0": "Evaluate the abstract reasoning abilities of the model on a text version of the Raven test with no multiple choices provided. Matrices composed of a small object inside a big object.",
    "raven-matrices-text-open-in-distribute-four-out-center-single.dev.v0": "Evaluate the abstract reasoning abilities of the model on a text version of the Raven test with no multiple choices provided. Matrices composed of four small objects inside a big object.",
    "raven-matrices-text-open-left-center-single-right-center-single.dev.v0": "Evaluate the abstract reasoning abilities of the model on a text version of the Raven test with no multiple choices provided. Matrices composed of two objects aligned horizontally.",
    "raven-matrices-text-open-up-center-single-down-center-single.dev.v0": "Evaluate the abstract reasoning abilities of the model on a text version of the Raven test with no multiple choices provided. Matrices composed of two objects aligned vertically.",
    "reasoning_with_contradictory_statements.dev.v0": null,
    "rectangles.dev.v0": null,
    "recurrence-relation.test.v1": null,
    "relative-orientations.dev.v0": null,
    "resistor-ohm-calculator.dev.simple-v0": "Test the model's ability to calculate resistance (in ohms) of a resistor, given color of each band",
    "resource_id_extraction.dev.v0": "Evaluates correctness for identifying UI Elements based on description and extracting resourceIds from Android XML dumps.",
    "reverse-polish-notation.dev.v0": "Test the model's ability to parse expression and create reverse polish notation.",
    "reverse-shell.dev.v0": "Test the model's ability to classify whether the code is reverse shell attack.",
    "reverse-sort-words-eng-simple.dev.v0": "Tests performance to sort different comma-separated english words in reverse alphabetical order. Inlcudes duplicate words.",
    "rhetorical-devices.dev.v0": "Evaluate model's understanding of rhetorical device usage in sentences",
    "rock-climbing.dev.v0": null,
    "romanian-logic.dev.v0": "Test the model's ability to solve a variety of mathematical, logical and grammatical problems using the Romanian language.",
    "romanian_homonyms.dev.v0": "Check GPT's ability to recognize Romanian homonyms.",
    "ru_rhyming_phrases.dev.v0": "Russian rhyming phrases for kids. This is a simple but important task for learning the rhyming patterns of Russian.",
    "rubiks-colors.dev.v0": "Test the model's ability to determine colors on the face of a Rubik's cube following a scramble.",
    "russian-english-homonym-context-resolution.dev.v0": null,
    "russian-lexicon.dev.v0": "Test the model's ability to distinguish between existing Russian words.",
    "russian-verse.dev.v0": "The most popular Russian poems that nearly every Russian speaker can recall",
    "russian_sarcasm.dev.v0": "An evaluation on Russian sarcasm detection.",
    "seating_arrangements.dev.v0": "Test the model's spatial reasoning ability using seating arrangement questions with limited solution sets.",
    "security_guide.dev.v0": "Providing good cybersecurity guidance for common attacks",
    "seo-keywords.dev.v0": "Test the model's ability to generate SEO keywords.",
    "sexagenary_cycle_calculation.dev.v0": null,
    "shape-in-shape.dev.v1": "Test the model's ability to check whether a given shape will fit within another shape.",
    "shared-borders.dev.v0": "Test the model's ability to list the countries that share a land border with a given pair of countries. This tests the model's ability to intersect sets known within its weights.",
    "shopping_discount_comparison.dev.v0": "Test the model's ability to compare discounts and select the best one",
    "simple-block-puzzles.dev.v0": "Test the model's spatial reasoning abilities by asking it to combine two blocks to recreate a shape.",
    "simple-charting.dev.v0": "Test the model's ability to generate the appropriate chart type for a given dataset.",
    "simple-visual-understanding.dev.v0": "Test the model's ability to understand simple visual scenarios as well as some simple 2D navigation",
    "simple_math.dev.v0": "Eval that checks ability to do simple math questions.",
    "simple_physics_engine.dev.v0": "Test the model's ability to reason about and simulate a simplified physics model in a 2d environment.",
    "sindarin-fluency.dev.v0": "Tests the model's ability to accurately translate Sindarin to English.",
    "singapore_data_protection_decisions.dev.v0": "This evaluation checks the model's ability to act as a legal researcher, accurately extracting relevant paragraphs given a document and a query, set in the context of decisions made by Singapore's Personal Data Protection Commission.",
    "singlestore-vectorsearch.dev.v0": "Accurately generate the SQL query with the correct syntax for performing vector search in SingleStore DB.",
    "smiles_to_formula.dev.v0": null,
    "soc_codes.dev.v0": "Eval that checks the models ability to classify a job title into a SOC codes issued by the American Bureau of Labor Statistics",
    "solve-for-variable.dev.v0": "Multiple-choice questions about solving a mathematical equation for a variable.",
    "south-african-bands.dev.v0": "Test the model's ability to understand that we are providing the name of a South African band, find the supplied band, and if the band has a lead vocalist provide the stage name or real name of the vocalist.",
    "spanish-lexicon.dev.v0": "Test the model's ability to recognize Spanish words included in the dictionary of the Spanish language.",
    "spanish_feminine_noun_masculine_article.dev.v0": "In Spanish there are are a number of nouns like \"agua\" which are feminine but use the masculine article, \"El agua\" is correct and \"La agua\" is incorrect",
    "split_chinese_characters.dev.v0": null,
    "squares-gpt.dev.v0": "Test the model's ability to solve basic geometric reasoning questions.",
    "stats-tests.dev.v0": null,
    "superficial-patterns.dev.v0": null,
    "svg_alphabet.dev.v0": "Evaluates correctness the letter of the alphabet the SVG corresponds to.",
    "svg_to_text.dev.v0": "Evaluates correctness for reading text encoded in svg",
    "swap-words.dev.v0": null,
    "swedish_sat.dev.v0": "Test the model's ability to answer questions from the Swedish h\u00f6gskoleprovet, kind of like the SATs in the US. The 30 questions are from the spring test 2023 verbal part, test number 3.",
    "syllables.dev.v1": null,
    "syntax-check.dev.v1": "Test the model's ability to determine programming language from a snippet.",
    "test_english_pronunciations.dev.v0": "We evaluated the ability of GPT to distinguish between words that have the same pronunciation in standard British English.",
    "test_japanese_english_numerals.dev.v0": "We evaluated the ability of GPT to distinguish between Japanese numerical representations and English translations.",
    "test_japanese_radical.dev.v0": "In Japan, the radical changes depending on the type of kanji. Test your reading of various radicals.",
    "test-japanese-units.dev.v0": "In Japan, when counting things, the unit changes depending on the type. Test your use of complex units.",
    "tetris.dev.v0": "Tests the models ability of spacial awareness by rotating tetris cubes. Tests all 7 classic tetris blocks and performs clockwise and counterclockwise rotations from different starting points.",
    "thirty_six_stratagems.test.v1": "Test the accuracy of the model to understand the 36 stratagems of Sun Tzu's Art of War",
    "test-time-zone-conversion.dev.v0": "Test the models ability to convert between different times zones, including the 2 week period between daylight savings time change in Europe and US.",
    "tokyo-station-number.dev.v0": "Station numbering for Tokyo Metro and Tokyu Railways.",
    "track_objects.dev.v0": "Test the model's ability to track objects after being moved around",
    "tracking-shuffled-objects.dev.v0": null,
    "tricky-word-problems.dev.v0": "Test the model's ability to recognize and correctly account for unexpected and potentially misleading information provided in word problems.",
    "turkish_characters.dev.v0": "Eval that checks ability to identify non-english characters in a Turkish text.",
    "ukraine-gec-fluency-style.dev.v0": "Fluency eval. Test the model's ability to detect and correct style errors.",
    "ukraine-gec-fluency-calque.dev.v0": "Fluency eval. Test the model's ability to detect and correct word-for-word translation from other languages errors.",
    "ukraine-gec-fluency-poorflow.dev.v0": "Fluency eval. Test the model's ability to detect and correct unnatural sentence flow errors.",
    "ukraine-gec-fluency-repetition.dev.v0": "Fluency eval. Test the model's ability to detect and correct repetition of words errors.",
    "ukraine-gec-fluency-other.dev.v0": "Fluency eval. Test the model's ability to detect and correct other fluency errors errors.",
    "ukraine-gec-grammar-aspect.dev.v0": "Grammar eval. Test the model's ability to detect and correct incorrect usage of verb aspect errors.",
    "ukraine-gec-grammar-case.dev.v0": "Grammar eval. Test the model's ability to detect and correct incorrect usage of case of any notional part of speech errors.",
    "ukraine-gec-grammar-comparison.dev.v0": "Grammar eval. Test the model's ability to detect and correct incorrect formation of comparison degrees of adjectives and adverbs errors.",
    "ukraine-gec-grammar-conjunction.dev.v0": "Grammar eval. Test the model's ability to detect and correct incorrect usage of conjunctions errors.",
    "ukraine-gec-grammar-gender.dev.v0": "Grammar eval. Test the model's ability to detect and correct incorrect usage of gender of any notional part of speech errors.",
    "ukraine-gec-grammar-number.dev.v0": "Grammar eval. Test the model's ability to detect and correct incorrect usage of number of any notional part of speech errors.",
    "ukraine-gec-grammar-partvoice.dev.v0": "Grammar eval. Test the model's ability to detect and correct incorrect usage of participle voice errors.",
    "ukraine-gec-grammar-prep.dev.v0": "Grammar eval. Test the model's ability to detect and correct incorrect preposition usage errors.",
    "ukraine-gec-grammar-tense.dev.v0": "Grammar eval. Test the model's ability to detect and correct incorrect usage of verb tense errors.",
    "ukraine-gec-grammar-ungrammaticalstructure.dev.v0": "Grammar eval. Test the model's ability to detect and correct digression from syntactic norms errors.",
    "ukraine-gec-grammar-verbaform.dev.v0": "Grammar eval. Test the model's ability to detect and correct incorrect usage of an analytical verb form errors.",
    "ukraine-gec-grammar-verbvoice.dev.v0": "Grammar eval. Test the model's ability to detect and correct incorrect usage of verb voice errors.",
    "ukraine-gec-grammar-other.dev.v0": "Grammar eval. Test the model's ability to detect and correct other grammatical errors errors.",
    "ukraine_electronic_petitions.val.v0": null,
    "unique_combinations.dev.v0": "Given a set of values, find the unique combination that satisfies a constraint.",
    "unsolvable_questions.dev.v0": null,
    "unwanted-rhyming.dev.v0": null,
    "urdu-lexicon.dev.v0": "Test the model's ability to distinguish between existing and hallucinated Urdu language words.",
    "urdu-transliteration.dev.v0": "Test the model's ability to transliterate English (Roman Urdu) to Urdu.",
    "utah_real_estate.dev.v0": "tests the model's ability to read and understand Utah's real estate law.",
    "viewport_to_grid_size.dev.v3": "Evaluates a models ability to determine the size of an obscured grid using information only from initial constraints and a visible viewport.",
    "vigenere.s1.simple-v0": "Test the model's ability to perform the simple Vigenere character operation.",
    "vintage_phone_keyboard_decode.dev.v0": "An array of correspondence between letters and numbers on the mobile phone keyboard evals, examining the model the ability to distinguish and analyze the relationship within groups in multiple groups composed of English letters and numbers.",
    "wkt_understanding.dev.v0": "Test understanding of Multipolygon WKT (Well-Known Text) representation of vector geometry objects (https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry).",
    "word-association-related-words-2.test.v1": "Evaluate a model's ability to determine a secret word based on a list of 2 related words.",
    "word-association-related-words-3.test.v1": "Evaluate a model's ability to determine a secret word based on a list of 3 related words.",
    "word-association-related-words-4.test.v1": "Evaluate a model's ability to determine a secret word based on a list of 4 related words.",
    "word-association-related-words-5.test.v1": "Evaluate a model's ability to determine a secret word based on a list of 5 related words.",
    "word_vector_over_reliance.dev.simple-v0": "Example eval that checks sampled text matches the expected output."
}